#############################
# query = えーっとえー焦げじゃんネットワークを作った使った音声検索でえー未知語の検索結果が知りたいです
# rank = 1
# slide = 12-11_fix.match_word.jout.txt
# value = -4.83950571325781
#############################
ええーそれでは音声中の検索を検出における
先生あんまり抑制パラメーターの検討について
山梨大学工学部コンピューターメディア工学科の
クリアが発表します
って本研究では音声中の検索を検出
ですＴＤにおける探索パラメーターを
検索語の音訴訟によりえー調整することで
検索性の約二十パーセント向上させることができました
えー
．あうえー初めに研究の背景です
え近年記憶媒体の進歩やネットワークに空の充実にあり
大量の音声や映像が
保存利用可能となってきています
えー
えーそれに伴い
えーこれらのデーターからえー二の検索を含む発話や子音の検索を効率良く行ないたいという要求が高まってきました
えー音声中の検索をケースの一般的な指標は
音声認識結果を利用するものとなりますが
えー検索語が日
可能な語未知語である場合や認識性能が低い場合には経験し性能が低下してしまいます
ってこのような背景から
音声中の検索を検出する
ＳＴ性能の向上が必要となります
えー性能の向上の為にえー我々は
音素たら音素遷移ネットワークＰＴＡの用いたデンシティー事象を提案してきました
えーこれは複数の音声認識システムをするから
ネットワーク分かんないんで
靴をえー構築し
えＧＰを用いて音素単位での検査語の検出を行なうものです
えまたえーピッチの構築する際に得られる情報を
利用し
えー利用したえー五ページ抑制する検索し検索手法をえ提案してきました
えこれによりえー五検査を抑制しえ高い検索精度を実現することができました
一えーしかしえー本手法に
え音素長の短い検索を与えた場合
え合計数が増加してしまい
検索精度が低下してしまうこと分かりました
一えそこでえけえ本研究ではえー検索語の音調に応じた
探索パラメーターを調整することで英語検査を抑制し
で検索精度を改善させることを目的とします
え今回の発表における報告要点です
え初めにえー複数の音声認識システムの
視力を利用したネットワーク型インデキシングやえＢＢを用いた八八検索を先生
えー合計属性パラメーターの導入など
えー我々が提案してきたＩＰ遅延を用いた
こう減衰抑制したい付い事象について述べます
で続いてえー検索語の音素町の違いによる
検索性能のその調査を行ない
ってそこから検索語の音早朝に応じた探索パラメーターのえー調整方法
の検討を行なったＳＤについて述べていきます
で最後にえーＣＳＪのテストコレクション用例検索性能の評価を行ない
えー検索精度が改善したことを示します
ってこの図はえー本研究におけるえーシティーのタスクとなります
えー
え初めにえー音
音声データーをえー複数の音声認識システムに入力し
えーその音です出力をえー使用インデックス
えＰＴＭに変換します
え次にいー検査語の検出を行なう為にえー検索語を
音素単位の検査語に分割し
で先程構築したＰＴＭから
え検索語の検出を行ないえその結果解析結果として得られます
ってこの検索を点数を行なう際に
のえーっとパラ探索パラメーターを調整することで英語検査を抑制し検索性能改善させます
えー
えー一え次に複数の音声認識システムの利用方法について述べます
て本研究では
えー五種類の言語モデルとえー二種類の音響モデルの組み合わせにより
第一種類の音声認識性能を構築しています
え五種類の言語モデルについてえー簡単に説明しますと
えー食べるＡＢＣは
単語単位のトライグラムでありえこのように
すえー仮名漢字交じりで構成されています
一えＷ利益はえーＷ３Ｃ４全て平仮名で構成された構築したものとなっています
えー
えー
えーＣＢはえー文字単位のトライグラムでありえこのように
平仮名で構成されています
ステップＡＢ円は絵文字系列別のトライグラムであり
音系列は全て二文字の平仮名で構成されています
えー
一えーま他の音はえーっと
えモーラ数現実を全てそして四割えーこれによりえー疑似的に
連続音素音節認識が可能となっています
えまた音響モデルはえー音節百二十四四からなるシラブルモデルと
え音素四十三四からなるえトライホンモデルを使用しています
えこれらのモデルはえーＣＳＪの子は講演文二階から学習したものとなっています
でまたあのデコーダーにはえーＪｕｌｉｕｓの
二月のえー理由上位四．一．三を使用しています
えー
えー
えー予備実験としてえー複数の音声認識してるの
音声認識率を調べました
えー認識対象の音声はえーＣＳＪの子は講演音声となっています
え実験の結果
で単一の音声認識システムのえー前提とする子を組み合わせた結果よりもえー複数あっ二種類の音声認識性能のえー番目とする国があった結果の効果
音節正解率が向上してること分かりました
えつまりえー単一の音声認識してるの圧力を実力の活力よりえ複数の音声認識の出力を組み合わせた方が
えー二のキーワードを見つけられる可能性が高くなると言えますでしかし音声正解精度を見ると分かる通りえー大量のえ挿入誤りが発生していたんで
えー多くの湧き出し誤りが発生する可能性が高くなっています
えー
え続いて寝た方インデックスの構築例を図を用いて述べます
えー
えまずえー入力音声としてえーコサインと発話した
音声データーをえーこれら二種類の音声認識してみに
えー入力しえその認識結果おります
え次に
その認識結果をえー音素列に変換して
アラインメントを取ったものは
えーこのようになっています
ってこのアラインメントが取れた最後にこのアラインメントも取られた者の
で一つの列を
アークとして登録することで
ネットワーク型インデックスが構築されます
えーネットワーク型インデックスの特徴として
えーヌル遷移を意味すると頭が存在します
えーヌル遷移はえー変動をどうぞノードを飛ばしの検索ができる為え柔軟に幅広い検索が可能となります
えー
ってついにいー日を利用したよう検索例について述べます
え本研究ではえーＧＰの距離尺度に
えー編集距離を用いています
えー編集距離はえー一の場合は
全員コースを〇誤りの場合はえー時間脱落挿入にかかわらず
えー全て一としたので
えこの図はえインデックスＰＴＭからえー検索をコサインの
検出する〇となっています
でこの例では
低コストサインのえー慶応Ｓは
でこちらの枠に含まれて炒め
一致したと
てえー整理していきます
えしかしえ水のえーの増加には
体が含まれていない為
えここでえヌル遷移を使用してえー喉飛ばして計算えー検索を続けます
え次のあっの増加にはえーが含まれている為一つとし一そして千し
で次の二つのノードには
えーＩが含まれていない為
また再びえーヌル遷移を利用して
能動飛ばし
で最後の
えー二つのノード間に場合というのが含まれて炒め
一致しそして一度説明しえーこれにより
え検索は終了となります
えー
えーこの検出結果の中にはえーヌル遷移が三つ含まれていおり
えー本研究ではえー寝る前のコストに全て一応設定して一日目えー最終的にインデックスをえー検索語の距離は
〇．三となります
ってこの距離はえー検索語の早朝によりえー正規化した閾値以下であればえ検索語が検出されたと判断します
えー
えー
え次に語源強くてパラメーターについて説明します
言って合計属性パラメーターはえーＰＴＭを構築する際に
えーられる情報を利用したものであり
で今回は二十五のパラメーターを用意しました
えー
えー一つ目はコーディングです
でボーリングは同じ音素認識結果を音声認識システムの数を表わしており
多くの音声認識システムでえー認識されていること
その音素の信頼度が高くなる可能性があります
えー
え二つ目は食です
がクイズはえー日本語化に存在するアークの数を表わしており
拍の数が少なくなる程そのノード間の
認識結果の信頼度が高くなる可能性があります
えー
って合計属性パラメーターはえー編集距離ベースの距離計算に
えー合計属性パラメーターを管理することで適用されます
えーボーリングとはクイズはえー共に
ピッチのマイナスにコストにえー管理されます
でこれにより位置し
んーピッチした音素がえーどの程度信頼できるかということがあって管理された用語を検索エンジンとなります
一え例えば
平成五チームの課題はこのようになっていたとすると
えこちらのノード間ではあの音像ではえー信頼度が低い為え一の場合の水コストにえー高いコストが設定されます
え一方こちらのノード間では
その後音像はえーっと
信頼度が高い為えこちらの喉があの一致し一の場合のす
遷移コストはえー低い値が設定されます
えー
定額出雲同様にえーこちらのノード間では
えー喉の数が多い為
すえー高いコストは設定されてこちらのノード間ではえ制約の数が少ない為
で低いコストが設定されます
えー後
ということでんー
えーと以上の条件で五ページ抑制パラメーターをえ導入した場合の検索精度の比較実験を行ないました
でまずあー実験条件ですで検索対象の音声データーには
えＣＳＪの方は講演音声を
え検索語にはえーＣＤの為のテストコレクションのうち猫は声を未知語テストセット
え評価尺度にはえーリコールと一緒んかあうえええ有名じゃ
マップを用いましたえー
えー
またえー実験結果です
えまずはリコールプリシジョン下部を示します
一編集距離のみを用いた場合えーこのようなカーブとなっていますが
え合計属性パラメーターを導入することで
検索性能が改善してること分かります
え特にえー母音人類やコーディング確率を組み合わせたものでは
え同じリコールを維持したまま
二十パーセント以上をえープリシジョンが改善していることがあります
で次にえー彼らがまーこの値について示します
えこちらも
えー一距離の五の場合と比べ
えー五．五．五抑制パラメーターを導入することで
検索性能が改善していること分かります
えー特に
えーボーリングとあクイズを組み合わせることで
最も高いえーじゃ終えることはできました
え以上のことから後継続性パラメーターを導入することで
検索性能が向上してる分かりました
えまたえーコーディング確率を組み合わせることで
高い検索性能となることは分かりました
えー
えー
えしかしえー編集距離のみを用いた
用語を検索エンジンにおいてえー検索語の音素町が一以上と
一今の検査語に分類した時の
検索性能を調査すると
えー検索閾値を緩くすると
本当長の短い検索語の五．一が
こう幅に増加してしまうこと分かりました
いっえー例えばえー音素町が一以上の場合の検索性能では
で閾値を入力すると
えー正解数が一億フレームに対しえー合計三つがえー一四十五増えてしまっていますが
え音素場が一今の場合の検索性能では
発声回数は一三個しか取れないのに対しえー合計数はえー三百四十三ことを大幅に増加してしまっていること分かります
でまたそれに伴いえープリシジョンやりメジャーが
こう幅に低下してしまっていること分かります
えーこの原因としてネットワーク型インデックスの表現能力の高さの悪影響が考えられます
え具体的には経験音素長の短い点最後に
後えーわずかに異なる
音素列パターンが
猫ネットワーク上に存在している可能性があることや
抵抗そういう流線れる遷移の存在があ定常であることが考えられます
一えこの対策として
え最後の音素上に応じた探索パラメーターの調整を行ない
検索性能改善させることを考えました
えー具体的にはえー一距離な遷移コストを増加させることや
入れる際の遷移こそえー多数です信頼度
ポーズ犬により決定することを考えました
えー
んー
って探索パラメーターの調整はえー検索語の素性に応じて行ないます
えーまずえー一距離の遷移コストは
え検索語の音素町が一以上の場合にはえー変わりませんが
えー音素場が一今の場合には
一の場合は〇誤りの場合はえー全て一．五に変更しています
えー
えーこれはエコーは声を未知語テストセットを用いた予備実験において
えー
本当町が一万の検索におけるえー遷移コストを
一．五に設定することでえー最も検索性能が良くなった為です
えまたえー音素場が一以上の場合には
えー先行音を１．〇とすることで最も検索性能が
良いことが分かりました
でまたね水を遷移コストは
え検索語の町が
えー一以上の場合には定数を〇．四五とした方て意味において停止
体中今の場合にはえー係数を〇．六七五とした後二三より
徹底しています
えーこれらの定数は英語で女性パラメーターの
某Ｄの定数の設定方法に倣ったものとなっています
いっえー探索パラメーターの組み合わせはえーこのようになっています
ってえーＥＧＧはえー編集距離を表わし
表わしておりＬ１れる遷移を表わしています
えー二は
えー
えーっと全ての検査語において
えーとあっ同じ探索は
パラメーターの値を設定しいうことを表わしておりえー理由は
えーと検索語の主張に応じてえー探索パラメーターを変更していることを表わしています
一え実験結果ですえまずはリコールプリシジョン皮を示します
えこちらは先程と同様の結果となりますが
えー編集距離の五の場合に比べ
えー某Ｄの一八五金額い当時のか確率一
えーつまり合計属性パラメーターを
う導入することで
で検索性能が改善していることが分かります
えー
え次にこの合計属性パラメーターを導入したものとえーそれに更に
え一距離の遷移構造を変更したもものの検索性能の比較です
えー赤い丸で囲まれた領域においてえーすこれに更に全員編集距離の遷移コストを変更した
えー五チームにはえーコーチングバスはクイズ
二において
えー検索性能が改善していることから
えー編集距離の遷移コースを変更することで
え検索性能が改善しようと分かりますえー
えー
って最後にえー合計属性パラメーターを導入しえー一九の構造を変更した者と
で三人れる定位の遷移コスト
で五チームにより決定した場合の検索性能の比較です
一えこちらも赤い丸に囲まれた領域においてえーする前のコストを
変更した
えーコーディング単位やえボディーのクラスタークイズ三の検索性能が高くなっていることから
えーヌル遷移のコストをえーコーディングにより決定することで
検索性能が改善しようと分かります
一え次にえー明治後まーこの値を示します
えこちらもえー注意距離のみの場合に比べ
えーコーディング一や
法人のクラスター一一一の方が検索性能が掛かっていることから
えー合計属性パラメーターを導入することで
検索性能が向上していること分かります
えー
また合計属性パラメーターを導入した
のみのものに比べえー編集距離のコストを
こう変更することでえーＦメジャーが高くなっており
で更に入れる前のコスト法チームにより決定することで
で不明者はマップと共に改善しようと分かります
え以上のことからえー検査語の早朝に応じて
探索パラメーターを調整することでえー検索性能が向上すること分かりました
言ってまたあ音素町が一今の検査語における
ＳＴ性能では
えーと編集距離のの三の場合と比べえーっと検索性パラメーターを導入することで
で検索性能が大幅に改善していること分かります
ってつまりこ検索性パラメーターの導入は非常に効果的であると言えます
えまた
で検査語の音素上に応じてえー探索パラメーターを調整したことにより
更に検索性能が改善していることが分かります
えー
で一方音素町が一以上の検査語における
でＣＤ性能では
えー
一編集距離の三の場合の方で
えー
誤検索性パラメーターを導入しても
えー音素町が重要官能検査語と比べると
改善の側が小さいことが分かります
えー
でまた
探索パネル水の遷移コストをえ五チームに決定することで
えー持っ検索性能が最もよくある閾値では
で逆に検索性能が低下してしまっていること分かりました
えー
全体としては検索性能が改善していもののえー音素町が一以上の検索においては
検索性能が低下していることから
えー音声が一以上の検索に関してはえー探索パラメーターを固定した方が
で全体としても検索性能が
改善訳作成の若くなる可能性があると言えます
あえー終わりにえーまとめとしてえーＰ型の用いたえーと演奏抑制したいしー小をについてのでえー合計属性パラメーターを導入することでえー検索性能が向上することを示しました
また探索パラメーターを調整したえー一について述べ
えー検査語の素性に応じて
え探索パラメーターを調整することにより
え検索性能が向上することが示されました
で今後の課題として
で今回のたんパラメーター調整はえークローズドな実験となっている為
提示されないんのえーフォーマルなのテストセットを用いた評価を行ない考察することや
えーより細かな音素情報との探索パラメーター調整を行なうことでえー更なる改善性能を改善を目指したいと思います
って以上で発表終わります
#############################


#############################
# query = えーっとえー焦げじゃんネットワークを作った使った音声検索でえー未知語の検索結果が知りたいです
# rank = 2
# slide = 13-02_fix.match_word.jout.txt
# value = -4.87770083935048
#############################
一えーそれでは音声中の検索を検出の為の音素遷移ネットワークのエントロピー先頭のＰ分析についてえ山梨大学大学院のプレーヤーが発表します
すえー本研究ではえー七八為のインデックスであるえー音素データーの値でえ九つのえー複雑さに着目しえそのエントロピーの分析を行ないましたでその結果とえーその日による検索どう改善の試みについてえー本日は述べます
えー
えまず初めに研究の背景です
えー近年えー記録媒体の進歩やえーネットワークにからの実より
で大量の音声や映像が保存利用可能となってきています
えーそれに伴いえーこれらのデーターからえー二のキーワードを含む発話ヤシの検索を
えー効率良く行ないたいという要求が高まってきました
えー音声認識結果をえ音声中の計算をベースのえー一般的な手法はえー音声チケットを利用した本がありますが
えー検索語がえー認識時間は後
えー未知語である場合や
えー認識性能が百五場合にはえー検出精度が低下してしまいます
えーすこの背景からえー音声中の検索を形成している性能の向上が必要となります
えー精度向上の為にえー我々は
えー音素遷移ネットワークＰＴＡの用いたえー七昭和提案してきました
えーこれはえー複数の音声認識するの実力を利用してえーネットワーク型のえーベースを構築し
えーＧＰを用いたえー音素単位での検索表一行なうものです
えーまたえーＴ２を構築する際に得られる情報を利用した
えー個別抑制したりする手法も提案してきました
えー更に
えーえー
音素数の三身近少ない検索語のえ国立を抑制する為に
えー検査語の音素それに基づいたえー探索パラメーターの調整を行ないました
えーこれによりえー高い検索精度を実現することができました
すえー今回はえー我々が提案したインデックスのえーＰＴＭのえーください着目し
えーそのエントロピーを分析しました
えーその分析結果をえー検索エンジンにえー適切に導入することで
えー合計数を抑制しえ更なる検索精度の向上目立つことは
で本研究の目的となります
えー今回の発表における報告予定です
えーまずえー前回のワークショップのおさらいとなりますが
えー一例を用いたえー国立抑制したりスキー手法について述べます
えー次に
えーＰＴＡのエントロピーを分析し
えーその分析結果を用いたえー合計得点手法について述べます
で最後にえー本手法はえーテストコレクションにより
で評価を行なっ
だことを述べます
えーこの図はえー本研究に四ページのタスクとなります
えーまずえーインデックスを構築する為にえー音声データーを
えー複数の音声認識システムに入力し
えーその出力をえー
えーです適用インデックスがＰＴＭで変換します
え次にえー計算表一を行なう為に
えー検索語をえー音素単位を検索語に変換し
で先程構築したＰＴＡからえー検索表一行なうことで
決していい結果が得られます
え今回はえーこのＰＴＡの
えーください着目してエントロピーを分析しました
え次にえー複数の音声認識システムの利用方法について
え本研究ではえー形態の異なるえーこの五種類の言語モデルと
えー二種類の音響モデルの組み合わせにより
えー二種類の音声認識実験を構築して今
えー言語モデルの内訳ですが
えーＷ３Ｃは
えー
形態素単位のトライグラムであり
えー仮名漢字交じりで構成されています
えＷにうちはえーＷ３Ｃ４えー全て平仮名で構成したものとなっています
でＣＢはえー文字単位のえー
父トライグラムでありえー全て平仮名で構成されています
えービールはえー五十境界のえートライグラムであり
音系列は全てにもそちらで構成されています
えー父はえー全てのモーラの出現確率が等しくなっており
えー疑似的にえー連続音素音節認識を実現しています
え音響モデルはえー音節百二十四力があるシラブルモデルと
えー音素四十三四からなるえートライホンモデルを使用しています
えー各モデルはえＣＳＪの強語彙外からえー学習を行なっています
えまたデコーダーにはえー事例暑い日上位四て言って三を使用しています
えーここ予備実験としてえー複数の音声認識システムの
えー音声認識率を調べました
えー実験対象の音声はえー四つ中の子は講演音声です
えー実験結果より
えー単一の
えー音声認識システムのえテンベスト出力をえー
組み合わせた結果よりも
えー複数あ二種類の音声認識システムのえーワンベスト出力を行なった結果の方が
えー音節正解率が高いとなることが分かりました
えーつまり
え単一の音声認識システムの出力より
ベクトルの音声認識システムの出力を組み合わせた方が
えー二のキーワード見つけられる可能性が高くなると言えます
んーんえーしかし
えー正解精度を見ると分かる通り
で大量の挿入誤りが発生していい為
えー多くの湧き出し誤りが発生する可能性が高くなっています
えー次にデーターが対立のえー構築方法についてです
えーまずえー例えば例ですがえーっと音声データーコサインという発話したデーターを
え複数の音声認識システムに入力すると
でその認識結果が得られます
でその次にこの認識結果をえー音素
音素列に変換し
えアラインメントを取ります
で最後にこのアラインメントが取られた
えーとこの列のえー悪として登録することで
ネットワークあ対立が構築されます
えーと若いＸの特徴として
並列い有意する後膜が存在します
平成五はえー能動とバスの検索ができる為
七十何幅広い検索が可能となります
で次にえーより洋裁を検索エンジンについてです
え本研究ではえー二三マッチにおける距離尺度に
えー編集距離を用いています
って編集距離はえー一の場合はえー遷移コストを〇
誤りの場合はえー置換脱落挿入にかかわらずえー全て一としたものです
えーこの図はえーＰＴＡからえ検索をコサインをえー定位し
数〇となっています
えーこの例ではえーコサインの形容え数はえー
ＰＴＡの枠中に含まれている為え一として採用していきますが
で次の枠にはえーっと〇が含まれていない為
えーここはルール遷移を使用してえー喉音はして検索を続けます
えー
えー最終的にえー
と薬がえーこのえー正解が含まれている為
で本研究ではえー水のコストを
えー一設定しているので
えーいインデックスとえー検索語の距離はえー〇．三となります
で最終的にこの距離は
んえー設定した閾値我々は検索語が提示されたと判断します
え次に貢献強くてえーパラメーターについてです
えー合計属性パラメーターはえーＰＣＡを構築する際に得られる情報をえー利用したものであり
て今回は二種類を用意しました
えー一つ目は五チームですえーボーリングはえ同じ音を認識していた音声認識システムの数を表わしており
えー多くの二二システムでえー認識されていることでそのその信頼度が高くなる可能性があります
えー二つ目はえー三つです
えー約一はえー二音化に存在する拍の数を表わしており
えー拍の数が少なくなる程えーそのノード間の認識結果の
え信頼度が高くなる可能性があります
えー合計属性パラメーターはえー二種類別の
で距離計算に
えー合計えパラメーターを加味することで適用されます
えー傍線部とえー後一共にえー一の場合の先行するにえー関することで
ま一致した音素がどの程度信頼できるかということはえー管理された用語を検索エンジンとなります
えー例えばえーコーチングのえー値がえーこのような通じなかったとすると
えー
左のノードあーこれ英語とかではえー
信頼度が低い為
えーコースとは違う設計され
ゼミのモデルの音ではえー信頼度が高い為えコストが低く設定されます
約一に関しても同様で
えー左のノードではえー八数が多い為えコストが高く設定され
えー三四では悪は少ない為えーコストが低く設定されます
でここでえー現状で二重性のえー評価する為の実験を行ないました
えー実験条件です
えー検索対象の音声データーには
えＣＳＪの子は講演音声を
えー検索語にはえーこの声を未知語テストセットとえーされないのです多くの情報も卵テストセットを用いました
えーこちらのテストセットはえー場合に応じてえー未知語と既知語に分割しています
って評価尺度にはえーリコールプリシジョン被ってるしまこう用いました
えー実験結果です
でまずはリコールプリシジョンカーブです
えー小学校四未知語テスト千
投資をした場合えー
編集処理のみの場合ではえーこのような顔となっていますが
えー合計属性でまーデーターを導入することでえー大幅に検索性能が向上してることが分かります
えー特にえーコーディングをえーアコーディング曰くいと組み合わせることによって
えー同じ有効類似した者はえープリシジョンが二十パーセント以上
改善してることが分かります
え次にえーされない方も何テストセットです
でこちらのえー二種類のみの場合はえーこのような結果となっていますが
えー合計属性パラメーターを導入することでえー改善し
えー検索性能が改善していること分かります
えしかし
でえー
でこれが七十パーセント前後ではえー編集距離が三の場合の方が
えー検索精度が高くなってしまっています
で次にえー舌をまーこの値についてです
えー後は講演音声テストセットはえーうちまー二共に
えー国え属性パラメーターを導入することでえー検索精度が大幅に改善しています
提示法をえー歳の方もま等のテストセットでは
テーマは改善していいもののえーピッチはえーボーリング単体以外の三ではえー検索精度は低下している
という結果となってしまいました
えーこれはえー一部の検査語において
えー
合計属性パラメーターの効果が薄く
えー
こくえー湧き出し誤りを四つ嫌だった為だと考えています
え以上のことから
英語専攻継続性パラメーターを導入することでえー検索精度が向上することは分かりました
えーまたえー以前より閾値を細かくすることにより
えーボディー部単体の方が検索精度が高くなっていることは分かりました
えー次にえーＰＴＡのエントロピー分析についてです
でまたエントロピーを算出方法です
え本研究ではえーピッチの二のノードからエントロピーをえーコーディングエントロピーとして
えー
その日本語が存在する音素の数とえー事後確率により算出しています
えー事後確率はえーその音素認識させるでしたえ音声認識システムの方に基づいて三つ行なっています
で算出方法はえーこのような式で
行なっています
えーついにえーピッチえーっと五．〇と料理をしてえＰＴＭ全体のエントロピーＰＴＡとのＰを求めます
えこちらはえこのような式でえー単一行なっています
えーなおえーとそのＰＴＡではえー音声と発話文の音声認識結果より構築を行なっています
えーこの図はえーＰＴＡのもしたものであり
えーこれらの政治はえーその音素認識していた音声認識システムの数を表わしています
でこの例では
えー五十メートルＰはえー各このような値となっており
で最終的に利用ＡとＢはこのように算出できます
えー最後に
えーあるって錯誤が生まれる日の日のエントロピーをえー
求める意識がこれつこちらとなります
えー先程の三次元のえーこの四角で囲まれた区間をえー検出空間とすると
えー本一メートル二はえーこの間の三の
値を使用しえーＰＴＡのえーと四三する為
で先程とは異なる値となっています
えーそれが分析の結果です
えまずはえー各テストセットに含まれるえ検索語は存在するかのＡとＢを集計した結果です
でその結果こちらの表となります
えー赤い四角で囲まれたえー未知語の検索音を
えー緑の四角で囲まれたえー既知語の検査語では
えー必要な検索語が生まれる官の方はえーとゆいうことが分かります
えーこれはえー未知語はこうれる可能ではえー単語認識が可能である為
え音声認識システム考えが大きく
で八月の多い
ＢＧＭが構築され易いあっためだと考えています
えーそれに対してえー既知語は囲まれる区間では
えー単語認識が可能である為
えー音声認識システムがあまりいい例が小さく
ペア数の少ないＰＴＭが構築され易いと言えます
えー以上のことからえーまー情報量の観点から相手を的手法はテニスが容易であると言えます
えーそこでえー今回はえー未知語の計算量は囲まれる区間のエントロピーはえー高くなるという事実を踏まえ
えーエントロピーの閾値を設定しました
んえーこれはえー七二五三はえー閾値と連動する形であり
えーとローリーの閾値よりも
えー提示する単語エントロピーが付い使った場合には
でその結果を国立と見なしえー格するようにしました
えーこれによりえー考慮ホールでの吐き出し誤りを抑制し
しえー検索精度が改善できないかえ調査を行ないました
えーこの図は
えー
横軸にエントロピーええ縦軸にえ水変数コストをを取った場合の
えー検出結果
正解率と英語系列の一えー一部の
分布を示したものです
えーこの一直線がえー今回設定しタイトルの閾値で
えーこちらは
えー本研究で検索エンジンのえー最大の点数
構想である〇．九の時に
えー一最もえーＡとＢの高い正解率の最大値である値になるように設定しています
えー
えこの図のＡＢ
古い音声より上のえー部分のえー
部分出会ったえー結果はえー四百行ないます
で図を見ると分かる通りえー正解率を
で幾つかえー棄却してしまう為
えリコールが低下することが予想されますが
でそれに見合ううー訳五えー五．五はえー抑制できれば
えー検索精度が改善できます
えーそれがえーと閾値の導入結果です
えー
えこちらがえービザが生徒のＢはえー先程示したえ従来の結果であり
えー水エントロピーはえー今回のエントロピー四つの導入結果となっています
えー声を未知語テストセットではえー最大値となる
提示音は
えー正解率を記録してしまっている為
え若干精度は低下してしまっていますが
えーリコールが六十五パーセントから八十パーセントにかけてはえーエントロピーによる国立の抑制により
え検索性能が改善していました
えー続いてえー伝える困らテストセットでは
えー今回はえーっと未知語の検索母音の三えーとＰの
閾値を設定しましたが
えー全体的にえーリコールが低下してしまう結果となりました
えー次にえーその二あー一度えー僕海外スピーチの合計数についてです
えーこちらもえー
えー正解率を手付けてしまった為
えー父が若干低下していますが
て最大五記事の合計数を見てみると
えーエントロピーの閾値を導入することでえー従来の
ものよりもえー十分近くに貢献し
数を減らすことができました
で以上のことからえー正解率が記憶される為えー最大名詞が若干低下してしまうことは分かりました
えーまたえーこうイコール一の国立をえ大幅に抑制することができましたが
えー最大の歴史のある閾値成人ではえー効果が薄いことがありました
で更にえー未知語であっても
でその日の低いものが存在することがありました
えー単純なえーとＢによるえー二十一ではえー効果をすること分かったので
えー
これ更に分析を食べる為えー最良な一次性の二の
えーとＰを示したえー調べました
でその結果がこちらとなります
でえー頭のあ表のえー正解がリストはえーその
最大の一なる閾値でえー
された
で正解を含む発話のことであり
えー合計実はえーその閾値で
提示された者の
えー正解であったものの発話では発話であり
え二．一つは
えーその閾値では提言されなかった
発話のあ正解発話のことです
えー表を見て分かる通りえー正解で一つ
えー五．五
提出の一にエントロピーが違う流れていることが分かります
えーまたはえー正解率のエントロピーが低いことから
えー
検索を含む発話では
えー音声認識システムあの家が小さい場合には
えー検査語の検出が容易であると言えます
えー一方えーす検出のえーっとＰが高いことから
えー音声認識システムを考え揺れが大きい場合には
えー検出閾値をえー固定すると
えー検査語の検出が困難であることも言えます
えー
んーこの場合えー閾値を言えることでえーケースが可能となりますか
え同時に合計数が増加してしまいます
えー以上のことからえー未知語企業に限らずえー国立を抑制しようとすると
エントロピーが低い発話者が駅一できないことになってしまいます
えーそこでえーと
検索精度を改善する為のえーアプローチの一つとして
まエントロピーが高い発話に対する音声認識上の対策は必要であると考えています
えーまたえー五．五よりも
でえーと四つの発話の方がエントロピーが高いことから
えー合計された発話ではえー検索語と類似している音素列が
えー音声に複数の音声認識して認識されている可能性があります
えーこちらは
えー
感じな音素系列マッチングであるＧＰでは
えーこうペースかどうかの判断が難しい為
えー何らかの対策が必要であると言います
え終わりにえーまとめとしてえーピッチを用いた
えー合計強い訳です抑制した一時についてので
えー合計属性パラメーターを導入することでえー検索精度が向上することが示されました
テーマ化ＨＭＭエントロピーを分析し
でそのエントロピーのえー閾値を用いた後えー属性手法について述べました
えーこちらはえー氷これでは合計相対両方ハワイ抑制することができましたが
え歳でしたらＳＤ法そして一では
で効果が薄いことが分かりました
えー今後の課題として
えー今回のようなえー単純なエントロピーによる足切りではえー効果をすること分かった為
えーより厳密な音響マッチングの導入をこうするなど
を検討しています
えーまたえ音響尤度をパラメーターとえーと六Ｐの関係の調査を行ない
えー更なる検索精度の改善を目指したいと思います
え以上で発表終わります
#############################


#############################
# query = えーっとーがあのええー子音分割あの文話でえーっとーってう統計的手法についてえー詳しく知りたい
# rank = 1
# slide = 09-08_fix.match_word.jout.txt
# value = -3.3520152462884
#############################
えっとー資格をするのカメラと申します
えーとですねいたします
えーっと本日は
えーっと講義音声を利用した後
一九．三等分割と検索について御報告させていただきます
えーっと
えーま皆さん部分というようにえーネットワーク上に最近特に色んなビデオ教材があのー
たくさん増えてきました
えしかしながらなかなか学生さんがあのー使いたいという目的なもんなんなかなか少ない
いうことで
でえーまー実際に作らないとなかなかうまく教育とかに使い
でいざ作るとなるとね
え時間とか手間が掛かって大変
いう訳で
えー私共は
えー
登録が遊び行数は幾らまー普通の大学等の方で四録画したものを
えーとかをえー話題元に自動的に分割数いたしまして
えー
ビデオ教材作成のテーマを
減らしたい
それから更にえー分割した
んえー子音の音に
えーっと
実際にえー見る時にそれをまー検索したいってのはえー目的で二
あここで子音と申し上げてるのは
えー
トピックをモデル化を全く知らサブトピックの区間をえここでは四と呼ばしていただいて
で実際にはこういう風に
えー自動的に
えー
子音境界が求まったとしますと
でこの中から練習とか不要な部分を削除しますと
えー
最低限のビデオ教材化できる
いうことですがこの
新聞月一を決めるのは非常に
えー大変何回も
でえー同じところを見直してあここだっていう風に決める際の画面ということな
でえー以前にあのー御報告さしていただきましたえーこういう支援するシステムの内容なんですが
でまず最初ビデオ素材から音声の情報を取り出しまして
え音声認識をしてて
と情報を言って
でこれを元にして
えー子音の分割位置推定を行なって
えその中から
えふような身を削除すれば四状態ができ
まこのシステムにつきましては
えーここのＵＲＬの方で
で公開させていただいており
でこのシステムは
え続いていやい対応の
音声認識ソフトであればえーそれでも使えるようになっておりまして
えー
語彙音声認識を使った
やり方とえ単純にポーズだけを使った素早く
買うことができればちゃんとお二種類用意をしており
で実際の画面はこのような
えー関係して
えーっと
ビデオを指定してえ分割っていう風にしますと
えーこういうシーンが出てきます
当該の信用をクリックしますとおー再生されますので不要であれば削除ボタンをですだけで
最低限のものができ
いうのはえー理想でござい
でえー本報告では
あーのーこれまで進めてましたあの素材として使ってました石川高専のえー二料理を言いますか本にビデオ
に加えまして
えーと
はい提案しテニスがあって大学三のえーデーターベースをえー利用させていただきまして
えこの二つを素材として
でえートピックのえサブトピックの分割と検索について調査した結果を報告させていただき
えまずサブトピックを分割につきましては
で二つのサブトピック分割手法を比較した結果
それから音声認識性能と方に携帯の
影響について御報告いたし
それからえーサブトピックの検索に関しましては
えーキーは父を実際にえー学生さんとかが
日は父して
えー指定する
ものと
え実際の発話内容との関係
それから音声認識性能の影響について御報告さ
まず最初にソースｉに関してですが
え石川高専の傾向にビデオにつきましては五名の教員による九十分のおー
えービデオでござい
でこれをえー接話型のヘッドセットを使用してますのでえー雑音との駅は殆どは
え音声認識には二つの音響モデルを使ってまして一つは
新聞記事
による
えー二千状態一録音を捉え方を持って
それからもう一つは
えー
ＣＳＪ
の
でえーっとー
音響モデルを
使わしていただい
それから
え言語モデルにつきましてもＣＳＪの言語モデルを使わしていた
でえーこのビデオはえーっとそれぞれ平均しまして各五百文ぐらい
で
えー
変わり
なってきた練習どうも含まれてまして
えー少しゆっくりしたケースです
それからえー
共通性が良い評価五って書いてますがえこれは最終的に子音としてえー
好奇
切った正解の数が二十
それから平均して
でパープレキシティーは四百ってことでちょっと音声認識としても難しい
え未知語率は平均で三．四ません
で実際音声認識をしてみますとえ新聞記事
で学習した音響モデルですという非常に低くてえー単語正解率で四十三パーセントぐらい
それからえーＣＳＪでえー学習された音響モデルでも
で五十三パーセント
ということで
えーっとー
なかなか厳しい
えー認識結果
で一方
えー
クラス二が第三のえー日本語をこう利用性やコンテンツコーパスとしているし
後英語話者六講義を使わしていたら
で学校にはあの前半後半に分かれてらっしゃるようで
えーそれぞれ七十五分
な旅行に文を使う
言わしていただき
で
でえー大学院の体の大き
でえーこのようなもので次子音の
えー分割位置を推定する訳ですが
えー
と二つの方法試しました一つは
えーここですと類似法と呼ばしていただいてますが
えー隣接してる新刊が
えー似ていれば
もう一つ付きの非
似ていなければ新聞月一月
存在するっていうようなえー単純な方法
でえー身を比較する為にそれぞれの子音ごとに
獣をインデックスが必要になりますがま通常使われるなら一ＦＹ
先程ちょっと話がありましたけど
えーっと
これはあー五四へあのー独立成分分析を用いた指標をおー使いまして市場のサイズを役さんとしており
性能的にはまーほぼ同等以上
ぐらいの間
で簡単に申し上げますと
えーっと冒頭文の
英語の頻度行列を
えー
話題と文
またえっとー後
二分割するようなえー方法に最終的になった
これによりましこの話題数字に設定できますので
でえー好きな自分
でやることができ
先程一番こうだと一万次元になってますがえここで百円ぐらいすると百二年でお様
いうことで計算時間がない
それでえーと
その進化を比較する度には八名を使い
んー身が似てるという個体表現が大きくなるんですがえー二なければえー小さくなるということなので
えーこの
四年の総和が最小になるように影響って計画法でこの切れ目を決めてやるというのは二十です
次にあの統計的手法について
えーっとこれは打ち合わせの方から御提案アーティスト分野で使われている
提案されてる方法ですがこれをえーのんびり音声に適用した結果です
でえーまず
えー単語の並びの与えられ
でこの単語の並びからシーンの切れ目を決めるという問題で単語の並びが与えられた時にえーっとそのシーンの切れ目
が最大になるような確率
そう最大なるように身を決めてやっ
いうことで
でこの中のえー分子の部分が最大なるような
セグメント一を決めてあっ
んで
テーマ細々したところは省略させていただきますけれども幾つかの形で
例えば
えーっとー
確信
のえー
単語まー他の
Ｃには依存しないとかっていう独立性の
えー
買ってきます本来は成り立たないと思うんですが簡略化の為に幾つかの
えー過程をえー仮定しますと
最終的にはこのような式で
えーこの
確率が計算でき
でこれはえ一般になっプラスぼうっと
えー
形で知られている
で方法で
えーっとーが五人の
えー単語数暮らすこと大語彙数分の
えその
子音内での
同じ単語数プラス一
これで
えー
この確率を
えーっと
金水一は
で今の
ちょっと細々とした日はえこちらの方ですけどもう一つの
えーっとＰＲえすの方は
単純に聴覚
で
与えて
でこれも同様に
えー対数化してから動的計画法で
えーっと
この確率が最大になるような
えーえ数を決めてやればいい
でこのような二つのえー方法についてえー四分割実験を行ないましたま水しか合成のビデオについてですけれども
えー音響モデル一
で横軸がえ分割五で分割数を文の数で
正規化したもの
例えば
凸のえー講師が百文感嘆文百文だとしますと
でそのうちえー二分割したら
分割に連れて一っていうような形で
でえー当然文化率あ分割分割三つ挙げますとえーこれがあのー
再現率なんですが際に繋がって
でえこちら適合率です
でえーこのおー
我々のこの研究ではえーっと適合率
よりも
でえーこの再現率の方重視いたします
これは実際ビデオ編集する時にシーンの切れ目がないと非常に
その切れ目を入れなくちゃいけない計算量は非常につらいので
でえっと再現率はなるべく高い方ができれば百パーセントになるとい
これが五十パーセントしかないと
半分は自分でシーンの切れ目を決めないといけないということになり
一方適合率が
えある程度までなら低くても無視すれば良いのであんまり多過ぎるとなかなかにづらくなってしまいますが
ある程度までであればもしすればいいのでそれ程気になりませんが適合率は
再現率の方はなるべく若い方がいいということで
ですがちょっと
あの再現率の方を中心に見てまいりたいと
でこの赤色のグラフが
えーと統計的手法による菜園
それから青色が
えー類似法による
え再現率です
でえー比較していただくと分かるように統計的手法の方が
えー少し良い結果
で音響モデルについてもえーこれは
えーっとＣＳＪで学会講演で学習したもですが同じ傾向が出て
更にえー書き起こしテキストについても同様に統計的手法の方が
えー良い結果が得ない
ま以上
のことより
えーっと統計的手法の方がＢ地方よりも
えー良さそうだということが分かり
次に
え音声認識性能の影響について
えー
調べました
え同じ結果なんですけれども見方を
グラフを買いまして
横軸が
えーっと先程の分割率ですが
えーっとー赤色が音響モデル一
えーそれから
えーっと
次熱が青色のものな音響モデルに
それから
で紫
のものな
えー書き起こしテキストで
えーっとかなり音声認識性能かなり違うにもかかわらず書き起こしテキストとほぼ同じようなカーブを描いており
でこの原因といたしましてはえー今回適用した方法というのはあのー母音の情報を使っていない
んで
同じようにややもあれば
でまー問題ない
いうようなことが気にしているの方法もある
んでえー
それを確認する意味で幾つかのシミュレーションの実験を行ない
これは書き起こしテキストをおーまざっと
が誤りを持たせたものです
でえー当然置換誤りな
であっても
えー原理的には
えー性能が一緒ということを
え実際に試してみて確認
しました横軸が
えー置換誤り
縦軸が
で先程の分割一〇．五から〇．四までの平均の
え再現率
それからこちらの方は横軸が
えーっと挿入誤り
これは書き起こしテキストにわざと挿入誤りを
えー入れたもので
って挿入誤りについても類似の方ではほぼ同じ
えー統計的手法でも二十パーセントぐらいまではほぼ同じ
でまー
それ程大きく影響しない
それから
でえー脱落誤り
についても
えー二十パーセント程度まで暮らしていましたが
それ程変わらない
で更に
えー
とー
脱落誤りが二パーセントでえ挿入誤りが五パーセント五十パーセント
それから
えー置換誤りを付加した場合ですに混合した場合
ちょっと音声認識を
え真似たような感じですが
えーについてもまーどの
条件についても大体
それ程
で大きな変動はない
まこういうなことから
えー二つの音響モデル書き起こしテキストシミュレーションをいずれの実験を通しても音声認識性能の影響は
宮内っていうことが分かっ
次にあのこう二境界の影響をなんですけれども
えーっと
まず
これはえー四じえー子音による新聞かつ結果です
でえーこの赤色の部分な書き起こしテキスト
それから青色が
えー
と音響モデル一致による結果です
んんでえーどちらも
ほぼ同じ分かって泣いてまして先程の音声認識性能に相手をしないというのと
で同じ結果がえー提案し率が大学のデーターベースでも同じ傾向が得られてい
それから
えーこの図は
えーっと高い評価四十四．四日間で大学のえーこう来それから青色の方が石川高専のおー工程なんですが
音韻形態がかなり違うんですけども
えほぼ同じようなか方以外体を
ま以上のことよりいーこうにこう携帯の影響もえ少なく取ったいうことがあり水
んで
え次に
図はえー検索について
えー
まーこれまでの結果あるのでえー簡単に
いただき
えまず利用する情報としては
え音声情報以内にスライド情報などさまざまな情報を用い方法がまあのー提案されていますが本報告では音声情報のみを
えー使います
これはスライドを用いない方にもまー対話したいってこともありまして
え音声情報のみを利用します
それから未知語対策につきましても
でこれまでの御発表が色々あったように音素えー音素インデックスファイルを
えー生成ＣＤを抑える方法であるとか
えサブワードを用いられる方法であるとか
ま先程もございましたが
傾向に音声から上って一
体を検索して
検索キーワードから六ページを比較して両方を比較するような方法ですとか
っていうさまざまな未知語対策がえ提案されて
それからあのー最初の御発表にありましたようにえ検索テストコレクションが
えーっとそろそろこう愛されそうってことで非常に楽しみにした
まこれができれば
でこう色んな
えー
方法を比較検討し易くなるってことで期待させていただい
でえ今回は
行ないました子音検索の予備実験Ａでは
えー各子音についてえそれぞれえー指標を求めて
えーそれがキーワードについても指標を求めて両者を比較するという単純なもの
指標には一般的な二杯で二を用いて
材料こちらと申し上げました場合冷えてもちょっとやったんですが
あまりまたうまく行ってないって言って
ここでは出てき
それから
えーっとこれは子音検索実験の結果ですでえーと縦軸はユーモアがあるということで
平均逆数順位んをえー
がありました
でこれはえー一ですとえ全て第一二三
〇．五ですと
でえーっとー
逆す七で二ということで二平均的には二ぐらいに
その検索したものが出てくるというな指標でござい
でキーワードとしては
で一つだけ指定した場合とか二月から一つまで
え横軸が言わですが変化
でえーこの最初のピンク色のものな
えーっとえ足ですか大学の四てるＣの書き起こしテキストによるもので
んで
でえーこのえーブルーの
ハウスい水色のものは
え石川高専の書き起こしテキストまほぼ同じカーブを描いておりまして
っていうまーあるＲがほぼ一致にしたいってことで
えほぼ一致入れてというなことで
えー非常に
高い結果で
えーところがえーこれについ
誰の音声認識
えテキストを使いますと極端に
触りまして
えーどちらも
でえーこのぐらい顔をしてしまー
まーちょっと
見た目がかなり川するんですけどもＭＲＩをなのでえ健康で主にいー何やってるようぐらいの八十
それからえーっと次にですねあのー実際にはあの学生さんがキーワードをしていするんですけど学生さんは色んないわゆる
否定のし方をするので
で実際に被験者そして学生さんに対し過去数年の五年生ぐらいの
学生さんに
キーワードを
でえーそれぞれの子音ごとに出してもえー
でえー出してもらってそのキーワードを使って実際検索してみたのが
えーとまずこのグラフですこれは書き起こしテキストなんて光っとしてはこの一番上のものとおー
このぐらいで
このぐらい触っ
いうことですね
で音声認識についてはこのタームから
この確認をしてしまう
でえーどうして落ちるのかなっていうことで
えーちょっと
調査したのがこの表です
でえー最初は当然未知語があるとそう分は確実に落ちてしまういうことでこれが
わりあいとしては平均的二十三．八パーセント五歳
一ワードの総数は
ここに書いてあると
これ百パーセントとしまして
えー一三．八パーセント程度の未知語で音です
それからえーと二視覚音声の場合にちょっと特徴的だったのは抽象化
でここであったさしていただいてるんですが
これは何かと申しますと
えー直接発話していないんだけれども
で発話内容を総括したり
ほイベントを表現したい
するような言葉例えば練習とか実習とか説明とか
例えばそれからこれこれを説明しますっていう場合もあれば言わずに説明する
んとま
それ説明っていう言葉は
でえー頭の中に出てこないんだけどまーちょっとした何とかの説明になっ
何とか飲酒
練習これからします理由が珍しくて
えーこれやってみましょうとかっていう場合が多いそういうことですそれをちょっとここでは
抽象化という表現で表わさしていただい
でえー交通の場合はそいつが多いもんですからって求まって
えー一一パーセントぐらい抽象化あるいはえー
まー内容をある程度理解
えーできると
えーより
あのー
感覚的には
体の概念的な表現をするのかなというのも
えーちょっと
そういう気もいたし
それが表現の揺らぎってのは
で表わしますという表現ていう言い方
あのーそういう表現の違い
んで
でこちらがあってただしえーい一日で大学の方の
えー
実際にどういう割合であったか
でえー未知語をは一一パーセントぐらいで
って抽象化は非常に少なくて
って言って八パーセントです
でこれはどうしてかって言うとま練習とかするのは少ないということと
えーそれから
えー多分
あのー
学生が五年生なんで大学院の推量いきなりＴでも
マイナスというよく分からなかったこういう
要するにそのまま
えー出てきたことをそのままいーワードとして書いた割合が多かったのかなというしない
後でしょうからですから
種抽象化っていう表現が出てくるのはこう三によってかなりこうばらつきがあるのかな
できない
そのデーターとしては
まだ少ないので何とも言えませんけれどもそういう傾向が
で以上まとめますと
えー
とー
えー
統計データー丸四の分割に関しましては統計的手法の方が類似法より良い結果でした
でえー音声認識性能を八五に携帯の影響は少ないということがあー確認できます
それからえー検索に関しましては
で三四五ばかりではなくて抽象化表現への対処っていうのも場合によっが必要になるかもしてます
それからえーこれは前から言われてることですが音声認識性能の影響はやはり大きい
えー
っていうことが確認されも
はい以上でござい
#############################


#############################
# query = えーっとーがあのええー子音分割あの文話でえーっとーってう統計的手法についてえー詳しく知りたい
# rank = 2
# slide = 08-20_fix.match_word.jout.txt
# value = -3.39202691303167
#############################
じゃお願いします
えー
とそれではえーと統計的手法に基づくえ講義音声書き起こし文章文境界推定ということで相手端からの歌を発表いたしも
まず初めにえーと既存自然言語処理の送ってもらっ文が認定されている文章ってものを対象としてから多いですと
またえーっと音声が書き起こされた文書部分の境界が明確ではない声場合がまーもう一つと
まー即ちまこの既存の研究でま提案された手法ってものを音声から希望された文章に直接適用することはこの歌を飼っています
んーそこで本研究の目的なんですけども本研究では話し言葉できるされた文章の文境界アーティストの目的とします
知ってそこで今回対象する文章はま大学の講義音声を否定人手で書き起こした文章を対象としています
また程度ちゃうようになります
えーっとこの際まこの文書にはとても苦労されてもらうん
んん同定が付与されていませんまたま他のポストテストではその一は
父は実は思っ音韻情報ってのリサイクルできません
あ書き起こした結果だけです
また本研究提案するというのを対象文書の母音や話者に依存しない手法最も提案します
既存のまーこれどういうことと言いますとその既存の形態素解析や係り受け解析などを用いてみますとこの状態が推定できるかって言ってもこうこう
などはえ文境界が判別できるかと後独立したと
えーとここでその話し言葉を対象とした文境界
おー検出
のま従来木について簡単ですです
まず英語を対象と人間と英語を対象とした研究するのかどうかありますがま
端的に英語っていうものは日本語で二つうまくえー特徴のある言語ではありませんので
ん係り受け解析などを必要となる
資料となります
またそもそも
事情がなかった人でもそのー文境界推定ってものは．二ということだという本が好きですねだの研究では立っている
これに対して日本語
であの文末にあるという特徴がありますので
んー
まー英語よりは制約
文境界推定ってのは．九二文境界の推定を行なうことができます
まー日本語第二に日本語を対象とした研究としましたまーこのような三の方が挙げられ
学ぶ
今回三分程度舌のテンプレートを持つテーブルとマッチングを用い方
んまた機械学習を持ち方
で最後はまとめ
まここで発表させておりましたもう一ではないか総数の接続詞を用いた方法
着いた我々も
まーこの日本語を対象と選挙もう少し詳しく見ていて
んテンプレートマッチングによるほ
んんですが実は非常に高い適合度最近です点を仮定して今
私当然ながらこうま人手によってテンプレートを作成する
コストってが非常に高く
またえーと今回
ものと他の研究ではＣ一二を対象にしてるんですが経験をこうＣＳＪの
のような公園や
講演なら文しか使えないするとされますそこでペット
で次に機械学習の手法ですと
的分析がえーと使ってますのでテーブルとマッチングと比較手法によっては比較的高いと考えますと
父がまたおないとテンプレートと同じように適応度ことの学習を行なった文章の母音やり方をすると考えられて
二異なってその手法なんですがこちらえーと係り受け解析を使っていますのでいう強い解析ん
正解ばかり大声で付与されたあ学習データー一なんですけども
この学習データーを船を単純ですが非常に
ん実はあります
まこれに対して
ま普通あえーっとメンバーで忘れていましたまー
人手によって与えたそうする特徴を用いてえーとこのこと外的に文末を推定する方なんですけども
あー製鉄方がありますと
生かしながらこれにしても適応度の方対象文書実現するその文頭に一二三分の後に出現する表現
卵と言いますと二残ってもう一で高いす終わります
で自分のこのこの対象文書の二呼ばれますので
まこれも少しコースを買ってしまいます
えー
で本研究の提案手法じゃどういうもどういうまー本研究ではまー同様の手法を提案します
今回その対象とする文書の三つを用いて
後形態素分割を行なった後に
モダリティー
まこのモダリティーっていうものは一文の命題に対する話し手の販売
えっと話し手の被験対する心的態度たもの男の人
二個のモダリティーがモダリティーを表わす表現というものが止まって集中するという日本語の特徴から
文境界を推定する手法となりますと
まこのそうなんですけども
何ではそれはこの学習データー人手によって与えるデーターってものを一切必要としな手法となっています
ここでちょっと日本語の問題について簡単に説明してきます日本語のモダリティーん
というま基本的多分末尾に集中する格要素文とそれに対応する
文頭に現われす原稿用紙に表わされます
基本的に各要素が衰退ではこう予測発言しません
で格要素ってのどういうものが出ます達がどういうものがあるかと言いますとこの
種類が挙げられますと
歯でやりますとこのだろうねと言ってもですね
この場合だろうっていうものは
でえーとこの場合は楽しみ半分持ってですね
ですねというま伝達態度についてのもえーっと
持った
こう点数をあの二世ですね実験などが
素晴らしいこちらが時間
んあのモーダルで最後ですでこう丁寧さをもっと一．五できます
行ない日本語では
千分の後ろの方にモダリティーロバスト限定のたいえーとー集中しますので
これを検出してあれば分まー文の
多分の境界とのか推定できるのであのたまたま．八個
で提案しその概要ですま簡単に言いますえまー大きく分けて後でま二つのえまー
歯の初めのステップでは形態素分割の行ないます
と今回
まそう学習で対戦用いませんのでその学習用データーが必要な傾向程度で形態素解析が可能なマージが提案しているマッチングエントロピーっていうものをベースにした手法になって
ってって多分が伴った後に
先程のモダリティーが集中するといっ
えー集中する場所を見つけま文境界推定を行なって違ってそこまでは
まず初めの形態素分割について簡単に説明します
三と言いますブランチのエントロピーというものですがこれ名付けていたり
これはどういうものをどうするかと言いますと的心ある用いある文字列Ｘに後続するその文字の多様性
を表わす指標となっています
ここの値大きければまさまざまな文字や後続する
この値は小さいと特定の文字しか今年は
ということを表わします
即ちプラスＮとＰが高い文字列というも負けてしまう可能性が高い
タイトル
で形態素分のほ手法っていうのを
あーする形態素音楽もえっとー
青のが弱くなってます
と分かりにくいので図を用いて説明します
んーと
あこうねすえーとここで示したのはそれぞれ
この辺がそれぞれ一の主といった問題集の二つ目とこれら手法の価値の時っていうのは一
と
提案ちょうど都内に分割成果と言いますと
えーとある文字の月五メートル一とそれに後続する一文字を加えたものの
もの
あー後続する一文字を加えた文字列行ってねと
をそれぞれ求めますと
でこのサイクルが低下したらまた
場合と後まー
後続する申し上げん出たということでま形態素続いてると判断します
そして次に
一系統の周波と周波数
手を比較した時に
ま周波数で
えっとー周波数の後によっても
えーと例えばこちら経験とか
えーっと
格助詞
あー嫌だっていったものや
まー
そしてパス解析まメンバーと道が続いといったさまざまな表現が
続くますできますので
これから二メートル級の上昇します
この三点目と三が上昇した点でそれ時は
でここまで気をニンジンだの手法と一緒なんですけども
えー
えー
で何そこではこの後
えー
神の持ち方ではずっとこのままえっと
次にえこの次の形態素
の認識に移るのですがで後です起こしとても焦って
えーっと更に
形態素境界決まった時点ではこの三月まで
次のえーと漢字音という計算し
まこの値がスキー場高かった更にここできるといったそれして今
まなぜこのような処理を加えたと言いますと
えーっと
感じの手法ではその一本の形態素
というものに手で決めてたもんだ形で
それに加えてえーっと日本語日本語ではえーっと今年と意見としてま基本的一文字で構成されますので
まそれはそれが問題だとえー今回
えー
でこうやっても超えています
でまた同様に
三ませんけど一．二述べていましてえー低下してるので切らないって
筆の本計算していって最終的にサンプルとサンプリングた時に
サンプリング音でえーとそうしますのでこう子供達え音治療法
何度も繰り返してくのが適当となります
でこのように分割した形態素
思っあー単位として
次にモダリティーが集中設けそしてそのまそう文境界としますと
文という文境界と
するのはえーっとー
番目のステップになり
で
先程言いましたけどもまーアイデアとしましては日本語では特に文末にモダリティーの格要素一九九四取っていたのは格要素を推定します
でこのまま行けるという方って後の地域の声機能語であのー昨日です
ま即ち一のお躊躇することは例えばでき文法側文末やろうを
好きな予測できますと
まここで簡単な仮定を置きましたそういう過程だと言えますとま内容より機能語のま水の高いだろうといった発表しますと
音声が付いてまして
えっともの
ペットの二つ言われていますまず最初に先程求めた形態素のモダリティーの格要素数といったものを計算しも
二十二つのモダリティーの発表酒を使って
あーの文末を推定しておといったことな
えーっとモダリティーの発表と言いますという及ぶしたものも別求めた箱のようになっています
とこちらまた音にくいので
んー図を用いて説明します
んー今ある形態素あー形態素列まー一応は雨が降らないだろうねっていったものとします
その場合
出掛けてたす元確率最もまこのようになりますと四つに
えーっと
格助詞あー音としや後の後ですね女性っての五つのコストの出現確率が高くなります
ここで問題になるのはこれあの一つの部分一二二者で選択したと高いので
そのこの何とおー最後メンバー
この本を最後に古典洋裁今後できればこのようにモダリティーの部分だけをたかったあーの各部分を
が格
なん
んーなるような指標を作ることができます
ここで提案手法では簡単にまこういうその
このとえー出現数の系列とも二系列データーを出して移動平均で平滑化を行ないます
まするとこのようになり
まこのようにすることで
んで一応ところモダリティーの部分ていうのは
高く
あー高い値が得られ
といった
えー
がえー高い値が挙げられます
このようにして求めたそのーん
とモダリティーの発表とラストというのを用いて
積分ところ
あーモデルをプラスを用いて文境界推定します
ま何やってるかと言いますとまあるもどこまでどうもパソコンて言ってそれが閾値以上だったか
んー
多分
それが閾値以上たそれを採用すると
で閾値以下だったら
ま閾値が二つを採用しないとおーなります
で更に
建物い
一番
で最後にその
文末の差っての局所最大端点ていうもの文境界と認定し
まこのようにしないと思うと二人なんで下でのバイトえーと最初のモダリティー語とするとＭＡＰ推定されてしまうのでこの水が入っています
んまこのような提案手法に対して今回ちょっと簡単な実験を行ないました
ままた実験は多くて二つの食べてます
で一つ目の実験てあの形態素音楽に関する実験です
とこちらはまー提案手法においてもてるけれど分割を行ないとかってのが一つと
本実験データーが大勢の再現率といったものがま六つの文章書いている達成できる再現する条件まー
んと分かります
えー
でこれを確認した後三
えっと文境界推定に関する実験を行ないます
あっ
今回対象文書について簡単一今回対象としたのは
えーっと情報工学部にあのこういう音声をするには人手によって書き起こした不足
ま講義内容とした音声言語処理で収録時間を六十七．八分
でまもう一つとした四万四千三百三とさも
ここで形態素分割実験のまー評価法について二つ評価法今回にするやり方
ま突然形態素境界と評価対象としたもので
んこととどういうものかと言いますとそのそれ対処の文書の四分の一に対して人手によって形態素境界を値が出たと
まー
提案手法によって得られた結果状態を比較すると単純比較する実験です
九歳人手で分割ってのＩＤＦ値体験しまして
二つ目っての文境界のみを対象と先程法とかですと
ま今回のしえーと最低こん本研究での目的っての一九文境界
推定ですのでこの文境界の的二万文境界が対訳
テニスできていれば
次のステップになっていてあー
次の徹底的にすできる訳ですので
ん
このような評価法であるとなっています
ま正解データーっていうのは最初の
対象文書四分の一に対して
ま三名により文強化された後その状態後二名以上
二分以上たった安定したものを正解です
でそれ
他元モデルとの比較です
えっと
上の方ではえーと性別第一両方出すのですがその方では際にですのみを達も
テーマ形態素分割
日本一種類の実験てまずまずパラメーターの変動を取って
何もまパラメーターが変動する実験と更にえー提案手法っていうの
適応の文書サイズ完全に依存しますので提案手法に勿論著作っていうもの
迷っても疲れ様の文字まで変化させてまその際の
というのを調べを調べようといった実験
その為と変動と素材のまー結果をうちのグラフのこのなっています
今青色図に示したのがま別の質のも手法ですで赤色できまして示したのがまー
今回提案いたし程
まわずかではありますが
納豆を今回提案さしこの悪くなっています
次いで二タイプの影響ですで
とこのようにまー
えーっと前形態素境界を対象評価対象とした場合ですだとまー
非常に低い再現率になってしまってるのですが
短文章は何を対するこうした場合ですと
んでえーと二十パーセント二十で文字以上使い方
もう七十五パーセント以上正答とするではあー対立を達成できるので
えまたえ手法ではないかと考えるです
ま今回の形態素分割実験に関してはま的二次のまそういう性能を
えそれ程したことに多少向上した方が確認できます
またませ文字以上を使用すれば
ま物をですね一応でないあー五つのステップでま十分使える
の
えーっと系列二．一ているのではないかと考え
続いてまー本研究の
ファミリーであるその形態素語が
文境界のケースに関する実験です
対象文書を実験した後ま先程の情報を強く分野の方に音声を人によって化しようとした文章を用いました
で実験としてはまー
んえーと携帯えーっと
パラメーターを変動またその店で仕事×です
その調べました
で評価の方法なんですが
ま先程のえーと結局形態素分割の時の
えっと文境界の三の情報と同じように三名の被験者に二．三名の被験者のうち
ま二三乗の文境界だと推定した者正解だとして
結果をねなりました
二を八の前期の回答面こちら提案した
えーと人手によって少数のデーターを与えるこの方法の結果で
高いものてんのかと
んー第一部を負けているものですがまーホームね
でつまり勝ってると言えますと
また更にはあのほえーとこのベースラインとしている表示する方法となって一部のどこ人手でデーターを与える必要がありますので
まそうよりも思ってので
まー醸造の結果が得られ得られたとじゃないかと．
とまた
んー
えーと被験者音の正答結果本が生まれました
えー
えー被験者ＡＢＣが三文を共に
えー
後安定被験者ＡＢＣ全員がえと文境界と推定した
部分を正解とした場合ですとまー第一発話で越えております
昔
またえー
定義しあー一被験者に二名の被験者に出てから
文境界推定した者
こう選択した場合ですと
んーまー
精度を行なった後六十五パーセントを達成することができました
まその結果の方はえーと一ですがえ特定ですのでまだまだ
あー行なわれてるものなんですが
絶対にその子を調べた結果今回
これらの要因がえー
問題は多分が分かりました
まどこストレスも多くて後五分のところをえーと主題を取り上げ際に母の代わりに動詞と上昇用いてる場所です
例えばこの周波数ですがえー
こういった部分でお水水というのがえー二つが起こっています
また
とこれあそれといったえっと第三えー七十代名詞が原因で精度が低下してることもありました
えっとこれは誰した出来事を出現頻度が高いとかいったね先程その形態素のモダリティーの各要素が差を求める際に
ん
二万語彙となってしまっていると
一度
下の二の一となってしまってることが挙げです
体を言ってた全て今回人手によって真面目しなければならないデーターベースへ用いずにまー前回の手法ま文頭に自然性を表現音であっという方法ってのはま精度を達成したと言えます
またあーですがまー
幾つか問題点があります
まず第一の問題点としてました的な買い物が必要であると
もうちょっと問題としてしてまそもそもま一応搭載率のものが改良には違うといった問題があります
最後に今後の課題です
まずえーと適合搭載率の向上を目指しますと
んー
ま今回
バッテリーえーと対象といつも認められ統計情報です
踏んだところなんですがまそれは多分恐らくうー
非常になりますので
ま既存の形態ん何か既存の解析を組み合わせ
ま提案手法
の対象文書とられる統計情報目にしつつも
んまー持っ使えるものも使ってえ方法を考えています
また今回
えーと対象文書
がかえー結構長い
文書必要となっていますと
えーと最低でも二十文字以上必要なんだせいもしてもえーっと時間で言うと
えー
一か月五十分程度の
四十分程度そのまー音声
から書き起こした文書が必要なんですけどもそれはまー後はと思いますので
それ少ない文書で文境界推定できるようにしようと考えています
また
まＣＳＪの適用しえー適応しそれのあの手法との比較実験をあのー考えています
以上で終わります
#############################


#############################
# query = まちょっとツールについてちょっと知りたいんだけどもえーまあるする出ますスピーカーとましていＢ型っていう使わして言えばとっていうするかまあるらしいんだけどもうそのツールっていうのがまそういうことを行なうのかまそういうようなことするするのかっていうのをと成長してんだけども
# rank = 1
# slide = 10-21_fix.match_word.jout.txt
# value = -4.95317590915806
#############################
まーあの七．短大の川の水もします
で本日は対象密着型マイクを用いた態度文と発話の収録のこの三そういう
タイトルで
発表さしていただきますとま第二六という文脈で
ＲＡかいない音とか発話を収録するということを試みて
いきたいと思います
まほ
分かってた原稿を書いたと日本の色々死を積分形の見方でしてす五分で若干資料の方に起こるをえーできるだけはしております
えっとまーあのーま勝手の分類ですけどまだ一六基本的にまーそこの
外的なロボットま内的な六つの川もどうもあるようですで解析やるというのも本人があ
で体験した
ものの
記録ま外の風景濃いところに
二絵を見たよとかこういう音を聞いてるとかこういうところに
いったよとかまそういったの方にま色んな方法にへの入力の
記録という意味でのま第二六と
後まー
本人が
えどういう状態であったとか表二に移動したかとか戻ることを喋ったかとかまそういった意味での
ま本人から出力する
で父意味でのまー
それを記録すると意味でのまーん第二六とま両方共あるようで
でえーっとと家の中で生活するとのえー生活の軌跡とか
を記録する
ものとか
まー
えーマニュアルが
ん内的六
で
二えーまー応用としては
えー家族の
記録とかまお年寄り
四
の方の二次のことを見守る
ような
え使われ方子供するようで
で
まー
えー
ま凄く簡単なす頭型とどうしても思い付いたことそのすぐ録音できるような環境を整備するとか
そういったものも含まれるんではないかと思います
で解析老後は
まー
えーそこに
先生があるのなくて動くとこう人が
えーグラフなかったかなとかま幾つかを
えー装着して
で
移動する先々で
えー
その後に
えー夫や
って言うとおーまその位置情報など含めて
補強するというのが
あのースタンダードな
いう方針なのです
んでまそん中に
ま応答というのが
ま色々
組まれていて
パソコンの音とか
もう外で記録としての入力としてのことも外部の音を
店内で記録としてはその日は何の差別とか
えーそれと
えー体の動き
ま空の状態の中でも
体の中のことと言え両方とも含まれているので
えこういった
ことに注目して
えー
第二六の
広く
父ができないかと
えー検討
しております
テーマ
まその中で問題と的な音を
え今回母音とえー
態度をん
えー体内の弟
ここで喋ってる音
も収録
にえー着目することになるんですがそうすると
でも動機としては
えーっと発話の収録とか
外部のとこはもう既に
結構やられているようですので
体内の情報情報体内の状態を
えー約六十
積極的に活用できないことに
あえー考えてきた
んで
その体内ノードだけではなくて
境界の環境を
自発的行動を
トマトともペア自分が喋ってる夫とを関連されさせて
ま両方それらもバスで記録したいと
ことによって
えー外の刺激とかが
本人の中の
体内の
下にどう影響したかとか
あるいは高二の体内をどういう
えー
二状態だったから
えーこういう行動に出たかとかそういったことがまーあの関連付けて
でえー記録し分析できるんじゃないかとえー考えました
でえーまーその繰り返しないまそう音に注目することで
えーカイ二回環境音や
違ってき発売は
態度
という形で一二三一元的にまー使うことができるんじゃないかと
えー考えた島
でまその実現するって機械として
後音的にはまーあのー九八六のもので
ま家とか
えーセンサーが
用意された三守り可能な場所以外でも
ま収録できるような
早朝ます
準備したい
んでえー
ま早朝ちか町期間の
えー創作にも負担がない
では一度
とーまずえー準備する必要がある訳ですけど
まそれ
そして
えーまその県もう七千万台で
えー二千四年ぐらいに
お金開発が
のマイク
というものが使えるんではないかと
って考えており
これについてはえ何ちょうどもう一度
御紹介します
て
えーっと収録さ
あえーライフ六のま一つの意味で名詞として
体に
えー
三万文の場合はまーあのーい量的波形とか
ま色々あの応用が考えられますので
これ局所本人が要するでイメージとしては
ま例えばえーっと
洗車歩いてる時に階段が多くてキーでしたんだけどあの場所は
もう以下のようにショートんだけど個だけとかまー思った時に
その人は
のライフログに
いう選手のデーターなから高級数や
えー
え呼吸の
パワーが有意に高かった場所検索して
とその時間情報とか
えそこでえー収録は
とー
まー同時に
んえーピッチ情報があればその一表一ますとまこういった使われ方が四つあったりえー
えーっとえ
まそのプレゼンテーションをリラックスしていたとしてだろうかとそこに初めて説明する部分では緊張してなかっただろうかとかそういったものをえ後でチェックするというのを
ま発音収録されているので
ピークスをキーワードに音声検索してそのガイド本女子にもとても心拍数とかＦ０を提示して
えー
緊張具合とこう知ることが
後で確認することができるとまー一例としたこういったえー五四ができるんではないかと思います
えねでえそのーマイク
えーっと五のあのこの
えー二つ程後のスライドで改めてこう紹介しますがのマイク
というのは
あーのー対象に密着してえー
適当に小さなさ第四声を
収録するデバイスなんですねそれを
使ってえー既に
一え二回目の色んな信号を面白く証拠というま試みはやっぱりどうも
後五分でちょっと今年三落としてしまっていたんですがえー
体のマイクロホンを用いたのかとか食情報の
テープかと収集
もやっぱり
死んでずんんその電極とかまー魅力は戦争とか色々ある訳ですけどそういうのを使って
後ろから非常にあの負担が大きいので
この名前こう同様に
えー新日本の
えー収録と
でもえま同時に勿論その何も発話の収録
ここでえーっと使えないかというま調査はされて今
やはりまーあのー死んでんずに特化しても見比べ×らも
の性能をする訳ですけども
んのか使えるかもしれないとまそういったあのーぐらいの
他のところは得られている
て
そのー
まこのマイクを使うことによって
ま利点としては
以以上道端であるので体温態度が終了感
って予備的にま色々えー取ってみたんですがましょうが機能ぐるぐるお腹なろうとか
言って大きな
というのとか
方針音と後やはりえーっと
んー
えーっとはい
えー
そこもあのー重きを問わ収録できること水も確認してありますので
えーっと
で
つまり点もう一つとしては
ま音声帯域も
勿論収録はできるただ
えー
高域成分が
あのー名前この構成であの構造上どうしても
用いるという欠点終わるんですけども音声帯域の習得できる
で
まこれは本来あの望ましくないことだったんですがま外部ももう
赴任して
来るものだから外部面白くできる
いう訳です
で
一番最初はまどこに
何を取ることを気にし始めのことをしたんですがまやっぱり一番あのー主要な
分かり易い音であるということで心臓の音は
常に取れるポジションで始めようということで
んえー胸の上の
一番下が捕れる場所に変なマイク
後接することから始めまし
で
ま最初あのー研究しない使っ実環境とかで
あのーじ実際にえーデーターを収録して
取れる音の周波数特性とか
って体内のえー
どういう音が取れるかというの間違ってるというところをしてまして
で
その後に
えーま色んな生の情報も遊びをする予定であります
ま発話六については実環境発話
もう発話区間検出とか
えーま音声認識性能とか
はいどうについてはま心拍数
えーこう係数なども
あーあえー自動抽出とか
あるいは
歯に伝統を
ま赤色響きとかそういったもの
貢献する
まそれぞれ
もあの主規制を使ったり
また音響特徴でのＧＭＭ
作ってとかでも何となく
町方針があるのでこれを進めていきたいと
んで今
でそんなになるものであのーこの辺りは今日おーえーと発表できると人ですがまだあのー
データーを取ったでこういうことになりましたとかまそういうえー段階ですのでまー
そういった音を
実際にそれをと取れたかというのをまー皆さん聞いていただくというのも今日の
えー発表の
名詞ま抽出をしさせていただきたいと思います
えー
で
えとまこの資料一の話と
えー
えー幾つかの収録していて
うえー
研究する実験しないで
父が
音の比較と
あの試験的に
もう外に出て
本を収録した結果について
ま幾つか来てもらって
えー
まとめたいと思い
えー
でえーっとまずま本当毎年音構造とえーその他のマイクの
えー御紹介
えー
えー
ものマイクですま二千四年にえーと開発されたんですが
ま基本的な構造は
でこれは下半分が
その体
心上野のマイクですね
あのー
ま資本のえーま特にここのものでもないもので十分な
コンデンサーマイク
を
えーってえー振動目のところを
まシリコンで
方形で
えそのシリコンを
えー媒体として肌に
一密着させると
でそのシリコンというのは
あーのー音響インピーダンスが側と近い
ということで
えー
方から苦しん道を
ま比較的あのー
ロスなしに
振動伝えることができるそういった構造ですね
んで
ま最小はまこういうマイクまで付いたかと水と
あまりに聞こえないぐらいの小さな島帯域声を
え振動
そしてえー
気温自体が
いう
のがえー目的でしたので
学ぶを取る食べる前ということでまこういった構造の前ともこれはランダムマイクと
あのー総称しておりまー
てまその後そのシリコンでなくてウレタンの方が
ツリーとか
鳥を元の構造とこのようにあのー改良を加え歳とか
えー計量化されたりとか色々をしてる訳ですがま基本的な
の考え方はこの構造です
で
えーとまこれはつまー実際のデーターではあるんですが枚名詞のようなものとしてみて
いただければいいんですが
まー
なも発生
もう
えーこれで収録するとですね
結果的に
まー一時間にも仙台でこう二キロヘルツ
より下の部分しか
あのー
成分がない
ことしか取れないんですね
てこれまでのまー我々もずっとあの理由どこが
分からなくて多分放射特性がないからだろうとか
と声帯振動のその一言
こう位置が低い影響が強いんだろうとか
何何とかないけど
んーやっぱり
体内の伝達で
をそこなれるんだとか色々考えていたんですが
って思って勝手にその
えー
ま記念日だから先生が
よく
測定したところのマイク自体がオクターブ当たり一の何デシベル下がるという特性がもう道もあってこれはまー
このマイクでもあるみたいだという
あのことを報告されてありますので
多分どういう
ものであっても
結果的にこういった上級これまでしか取れない
そういう
まー
構造の丸四です
一出てえー二．四六に使った
えーバイクの転換ですが
まず×別のマイクこれも後にあのー名前怖いですか
して
あのー
集大成とかそう調整をこう
え向上させたものです
一でしたが
そうしんので
えー上が
重心の
で送信のあのえ真ん中国これが
学ぶマイクで中央にコンデンサーマイクがもう待ってると
で
まー
すあのー
作り易いような
あのしゅしゅの収集を
付けて
基本的なもの耳の全ての面白二のことを想定して作られたもの
でま一回
あのー
こっから
デジタルう
録音機のこと気に書いままアナログにしてしまうって言うとこういうスタンスを持たないところもあるのでそれをまーあの
えー新しく
父システムでは
まデジタル
でえーその他の古いような
えー期待も作ってます
今回の収録ではまー六十に生かしたものもう一度録音機でデジタルにします
で体内思い付くのが
ま同じえー
えー口頭で作るんですが
えー
目的そして大人を待ってみましょうというちょっとあの研究がありまして
それでえー
まー二つの中
に上がっていてえー使うことを想定して
ま比較的別に言う必要もないので
安定して
あのー寝ている人の中に乗せるような
んで
あのー収音反意語を広げるという子供とそしてこう体も
で広げたまに来るのを作りました
で
おこれもえっとー
で先程のマイク旅行知能がまー本来のこれあの今回の目的に近いのでまこれを
えっとそのーある気が気にしていたんですがまこれを
えーやっぱり
方法として
んんえー収録しました
ってこちらも一つ前のこちらもそうですが
あのー
え飼ってる人の目につ付ける形になるので
が残って方法が難しくてですねもうあのま規則を使ったりとか
色々試してみたんですがもう
なかなかまだ決定的な音が見つからなかったのでま声の収録では
あのー凄くですがあのー雑多な訳ですが
えー幾ら太って車が持ってるみたいなね固定するという形でえー止めてま
でこれも比較用の
え店長新規何ですか
えー
わりと文の
まこういううーものがあってあのー
やっぱりその体内身をおー
えー
あー聞くのも目的ですので
ま幾つかま二つ子供があってその中で
もえーと
痛いなと思うという
このということが
強調して聞こえる
本をあーもうどうで
でえーま比較用に漱石だとこの二はそれぞれのえー測定
収録してみました
えーとやっぱり本当しんき
足の形で聞くものなので
んあのー
と本き一九六月に
えーまだ三ちょっと
あのまここでのマイクを入ってしまうんですが実平行に
年に一を掴むということでえーまー何度か宿泊しました
んー
えー
で収録した音とのえー
訳ですがまこれも室内で習得した音を
ですねえーっと
ＰＣの三の雑音勝手三十七ＤＤＩのもあしますから親で
えー収録した男
子供は比較の為に
できるとか実際の雑音をスピーカーで六十ＢＢえぐらいの人になるように再生した音
中で
えー
発声した
ま無音の部分と発声したこと
のえーデーター
え発声内容あのー
んー
情報システムへのユーザー発話ですが特にま今回意味はえーございません
であ×です名前
で使った作った
父も
えー彼は資料二音の
えー
一発話近くに銀行あるいは二というものが
上はえー
〇
ヘルツから二十二．一キロヘルツ
までのスペクトログラムでえー
真下は
ま千ヘルツまでを拡大したもの
まー
やはり
あのー四十キロヘルツ以上はもうないので
の
下の部分だけ注目して
えー表示しており
ってことですと
えー
えーっとそうですね
まーし日本がやっぱり聞こえて
であのー所々こういう二スペクトル
の中でスペクトログラムでもとんとこう言って出て
でえ空間
絶対ない思い
あのー丸くて大きいやつです
まーちょっと三十二日の音量の問題でもあるんですがま同じように
あのー唇音が
最初の方で
独特と聞こえてえ
えスペクトルでもその父
んで言うまでもないですが外部マイク
あこれも走ってあのー当時これと同時にするとえー現在マイクで収録した
ことをですねこれが共
そのこれ
多い
まこれまでそま身と当然取れる
ものではない
で店長新規のおー
ですね
で八ページ目とやっぱり
あのー適切なフィルター九月にかけてあるのでま唇音が凄く波形レベルでも大きく出たえー
もう
んで
その結果あのー
も
減少し下の文特性というのはよく分からない人もこれも結果的にあのー四十ヘルツぐらいでもうそして
ある
不要ですね
雑音耐性とかで
体内思い付く
を使った時の
えー後ろ二音と
でえー外部のマイクで取ったこと
ですね
一つのタイプの前で父とおもあのーもうよく
本
んー
うー持ってえー
えー
うー二えーはあー
もう普通のことな訳ですけどでかいない思い出でどのくらい音が入ること言うと
こういう
あのーんー
んー
んー
んで
えー
もう本当にあのー
えー単純に上の方が計画という
んんの鴨はスペクトル二四六的な層ですけどもあのー絶えない神は
勿論当然の方
すえーっていうようなことが
えーとこれます
判定ですねこれをその密着するか月特性が届かないじゃないかということで多くの考えまして
えー
法律のまここでの機能のあの講演音声をまーちょっと置いて若干
あーの普通の外うまいそしてその前こう
二番
て収録した方法で
もう
えーっとですね
まあのー
えー形に付けて様が外になる前二つ顔が結局まー
同じような回帰情報としかも取れないまそういうマイクなんですね
で
これをまそこの環境でえーと
ま実際付けて
ん見たという
本を紹介したいと思います
ソフトの千葉で調べたのでま型紙と全く分からない
訳です
んでえー
えついてここにあのー参照用の
最近マイクも付けてですがまそれも
まこれたまたまあのー隠れて見えない
船が側から見るともう殆ど分からない
んで手法ができる
でま色々屋外で取ったり
えー敵の中で
でしかない訳通さない
えー屋内
ま食堂とか
父も
それをまーあのー利用者な訳ですけど
睡眠中の候補とかいう試みを下のそのまー×です名前です取って
一応こう書いていた
えー
精度車の中の音
怒ら外部マイクですんー
問題マイクの音も普通文と文ですが
んで
えー
えーっと足りない思い
の
他難いですねま車の振動計を提供凄く広くて
振幅は大きく
つまりま
で
歩いてるところを
そういうマイクだとえー
えー
後のまー母音結論です
まー仕事がま聞こえる時代なんですが
体内をマイクだとま決めずま実用的な建築ある時ま九月のずれ出してしょうがとても大変です
というのはします
あって
えーっと
あまりにも
えーっとそうですね
ま就寝中もあのー振幅の進歩の音がちょっと
ほいで
やっぱり
えっとー
とても
あのー
二人目が当然それナイフがいない音の
えーんというものどんだ
うちの父から
えっと今こう
もっと汚いですけどこういうことでは聞こえないんですけど
あのー昔風のあのーまー
それも
でまーとところもあのーま
ん奇麗じゃないんで弟妹も出さない予定ですがま聴覚の
ぐるぐるなろうとかもこういった
あーのー
スペクトル頃の手にいるようにあの結構遺伝子型
えー
ですね
最初にえーっと
二五度文と発話環境当日でるってキロをドライブログを提案しても今なら
この四系列の仕事れないんですがあのー日本のことです
で
ま課題としてま先程述べたような
あのードキュメント処理もやりたい
というのもありますのでこのまー進めていきたいと思います
で
最も保守的にうち一つのマイクで取る必要ないんじゃないかというねちょっとも
で最後のトイレを持っていきまして
勿論マイクと腕のマイクでえー良好で
え進めていてそれはかと
え考えれます以上です
#############################


#############################
# query = まちょっとツールについてちょっと知りたいんだけどもえーまあるする出ますスピーカーとましていＢ型っていう使わして言えばとっていうするかまあるらしいんだけどもうそのツールっていうのがまそういうことを行なうのかまそういうようなことするするのかっていうのをと成長してんだけども
# rank = 2
# slide = 08-21_fix.match_word.jout.txt
# value = -5.01912659009559
#############################
えーそれでは講義音声の自動評価の為の
各種特徴量の調査
ということでえー山梨大学私小×が発表させたりします
えまずえー
もう二二なんですけれどもえー初めに研究の背景目的概要をえー形の上させていただいて
次に実際にえー研究内容の音響分析
えーコースの特徴分析音声認識率との関係
方をえーま述べさせまして最後にまとめえー今後の課題というな形になっております
でまず初めに研究の背景と目的なんですけれども
えー教育の数を向上さ歳
と書いてあるんですけども
場合にはえっとー子供達はえー少なくなってきてえー後大学前に時代とか
えー言われたりしてると思うんですけれども
テーマ
どこの大学もそうだと思うんですけどもそれでそこで些細っていうのは
まみんな思ってることだと思います
でその教育の基本的なまこういっ形式大学で言えばこう
があーま主にいー教育のまー手段
として用いられてるかと思うんですけれども
その方には四つにえー関連する要素として
えーここに寝ました
まー
講義のえー実際の内容とか
えー形態えーまー
どういうような
えー
形でえその抗議を行なうと
針は話型の語
回路の要素は考えられると思うんですけども
テーマ私達はこのお話から
で頭の話し方に注目
んでいたしました
でその話し方を改善しまして
えーより良いより聞き易い音声にしたいと
って思っております
でこの学生が聞き易いの抗議を行なうことでえーより理解し易くまいう印象を持ってもらえるような
えそんなものを考えております
ま最終的な目的といたしましてこの大学の講義音声
えー対象として話かもこう改善したい
おこな目的を持っております
で研究の概要なんですけれども
えーまず
この
えーあ後期においてまその
先生の方針の
え講義音声こちら実際にえー録音させていただきまして
え同時にその工業重宝していたえー実際に消耗していった
学生さん達にアンケートに解答してもらいます
でこの講義音声につきましては
音響分析を行ないましてえま音響特徴量を
パワーホルマント体があると思うんですけども
このような音響えー特徴量が抽出できるかと思います
こちらのアンケートの集計いたしまして
えー本に
場合要求を制御果たすことも書いてあるんですけどもま音響に関するえーアンケートの結果
えーと何計算結果と英語基本的な特徴を
あ百分の一
接近していきまして
えーどのようなえー音響パラメーターが評価に影響を与えるかっていうのを
調査している
します
まーその後にちょうど講師の特徴分析という言葉行なっております
でえその講義音声から分析した音響特徴量としてのアンケートの結果をま統合的に分析する
でこうしてま聞き易い話し方に必要なえー音響
中央は
で何であるのか分析するえーという概要になっております
テーマ
あえーと前回も
発表したんですけどもま今回の着目点といたしまして
えー講師の特徴分析
今にアンケート評価結果でま
観点特徴分析を行なったんですけどもえーその実際の父音響特徴量
でこれ特徴を把握できるかっていうことを調査しいたしました
また
えー音声認識率といたしまして
あの音声認識率
とこれのえー評価と何か関係があるか
方をえー調査していますで関係がもしあるとするならば
えーこの音響尤度とか信頼度などまー音声認識に関係するそのパラメーターが
協会なんか影響を与えてるのではないかってことをまー
考えていきたいと思っております
てまずは大学行為を収録まそのー実際どんな音声かって言うかまこちらに書いてある通り
えー山梨大学工学系でコンピューターメディア工学科
のえー攻撃
えーこ実は一一名でま全て男性
で条件はこのようになっております
提案型とは勉強的評価にいー関係するアンケートの中心に五段階評価
手配家まではまるかどうか
というなえーアンケートになっております
で次にえー音響分析
んーするたいと思うんですけども
ま音響情報のえー分析といたしまして以下の二項目こちらのテーマ促音木について
えアンケート結果と音響特徴量の比較分析を行なっていきます
えー
えーその後本当は発話速度
治療
抑揚を利用性やショートポーズ
このえー五項目を主に音響情報
として捉えていきますアンケートの例で説明いたしましては
た適切な行為で果たしているかとか
テーマ
この速さがいい
ちょうどいいかとかまそういうようなアンケート
えーやっております
でまずその発話速度っていうのをちょっと見てみたいと思うんですけれども
この家は
がえー横軸が発話速度えこれ一秒間のモーラ数
で縦軸はそのアンケートの評価結果
まーえーと一から五の
五段階評価でえーまー
舌が大きい方が良い評価
ち異なっております
てえーま評価学会講演の×となってんのかなっていつも名前を書いてあるんですけども
×四の評価用音声は大体いーそして八モーラ言語ま七．四から八．一
開催の値なんですけどもまこのぐらいは評価高い
で評価低い引く三学級の通りかって言いますと例えばまー
八．五から九の非常に早い
話速だったり
んちょっとそれだと全体的に評価は低く
えーなっていたような
傾向があります
二つの平均と分散はこう二歳の影響が大きい
と書いてるんですけども
まーそのー行為っていうな行くのも非常にまーちょっとえースライド
っていうのをまー二つのこういっ渋滞があると思うんですね
でその場所工事
砂糖
二人黒板に書きながらを考えたりして
果たしていいので全体的に
えーマスクは遅い
誇りを見てもらう
と分かると思うんですけどされるだけ全体的に
体をすることが分かるかと思います
あー多分三えーその母マスクの分散ていうの見ますと
やっぱり
んー判定していないばらつきが大きい
まその講義はま金が言えるのでばらつきが大きい
というな感じになっております
で逆にスライドをまー本当などを用いた
二歳度を使った抗議ですと
まそこは全体的に早め
なおかつえー
パソコンの分散ていうのがわりと安定している
というなことになっております
でこれをもう一
方でえーちょっと
覚えておいてもらいたいことなんですけどもまこの
非常に遅くこの辺の講義を一文
えーする大体八．〇モーラ毎秒の講義が
まー
実際多かった
また話速が速いっていうのはまー
八．五から四モーラ毎秒
はが大きかったとはちょっと覚えてってもらいたいんですけれども
てこの発話速度っていうのはえー
その認識結果を用いてえー求めているんですね
あー自動評価する上で認識結果を用いしかないと書いてあるんですけども
通常評価もまーこんなことを
えーもう目標にしておりまして
で
まそうなると結局認識結果も思っ使わないとちょっともう止まらないんじゃないか
ということで
えーっともの後は二十一度登った
その認識結果本当にのかっていうことをちょっと
えー最近見たんですけどもま正確なコース
で言えば速度は誤差がある
えー
書き起こし文と比較したところ五パーセント
でも差があるということでま二つ
歳の
えー
話速っていうことをま書き起こしたまー策っていうのとえー認識結果のま作って何も五パーセント約二十パーセント未満ですね殆ど
が
ま誤差がある
えーまた
二十五回五二十パーセントをちょっとあえー
結構差があるんですけど
もうま
ある一一先生だけなんですけどもちょっと
えー誤差が発生するんですけどもま前提のデーターの傾向っていうのは殆ど変わらない
で行なっているのでその認識結果まー信頼できる
えーそのもうこの値を用いても大丈夫だと考えております
えー発話速度以外の音響分析についてはちょっと簡単にえーさせていただきたいと思うんですけども
平成四分の二っていうのは
ま全体的にどの後者の評価が高いということで
えー土曜コースも大体
えー評価五段階治療
以上
えーまー昼間で
ま声の国際時代っていうのがこの問題はないかと考えております
ただ一つの表現できないこととして
一定の方向を向いている場合五月九日五と六って
行きながら話で今あー衣装だと
こまの方勤めている
とかまー
あると思うんですねでそういう場合に
えーっと
ま全ての学生まで近いところが届いてるとは言えない
でこれはあの
ほいにくい高校が
存在
二ですんじゃないかと
ある一部のえー二十世紀にまー
その
どこの席に座ってるかってのまー知られまして
その分析
あれ
こちらの方はその評価低いとかまそれに音楽家強者が見れる先生もいたんですねまそういう先生は
えー実際どういう風にこうやってるかっていうの見るとやっぱちょっと同じ方向しかできない
いうのがまーあったんで
結構
あのー
もっと学生の方とかま全体にまして
社会の重要文なのではないかと考えております
二記憶量をこれに関しては
ピッチ大きく変化すること抑揚があるということで
で声の高さっていうのはえ日本語声の高さで
で距離を付けると言われてますけども
実際試合とこうやっぱりこの種
方向機械で先生程
で強弱のあるんじゃないかという風に学生はこれ
学生は感じているようですが
んで
次にえ要請なんですけども
えー低い声の方は御利用が困難さも関係するということで
入っま日本低い方は
見えるように
じゃないかと言われているんです
けれども
実際にそのや結婚は
あるいは三年に買ったんですけども
あっそれ以外はそもそも関係して
んじゃないか
えーと今考えておりましてこれについてあの調査中であります
で
まこの音色的な発話との相互評価に与える影響一番大きいということなんですけどもこの九九中でもやっぱり
この音色性っていうのは
えー非常に
えー学生さん達二十四
んじゃないかと思います
最後ショートポーズなんですけども
二層構造を次に強いということでま発話は
それとえー二過ぎると
えーとー
父が増えてしまうんで
まなるべくまとめてショートコースってのは
がないまをする後続だった為に
でやる方がいいかとあります
例えばフィラーを効果的にもできること
形態をしているってことでまフィラーを自由な要素がそのポーズに関係してて
とおも考えておりますがこれついてちょっと他の研究で
へ行ってはまず
でこれあのー
えー音これはもう今では音響分析の話です
いや講師の特徴分析ということで
テーマ
紅茶の特徴を一目で分かるようにできないかということです
でま二通りの手法って書いてあるんですけど性分析は
やんけと評価項目先程のデーター五項目
ん加えて
えー音響特徴量をえピッチ
のえー平均分散
話速ですとこう頭からえー求めました
で
まその四つが一はおえー二十
二十九二次元に圧縮いたしまして
えー
その結果えーえ第二成分は後に声の質に関する
え予想第二成分を話の展望
風にえー関する要素がえー
えーえ大きくいけするんじゃないか
父はえー
を考えました
て実際アンケートの方も
冬で行なった結果なんですけども
えーとまず短い
大体のおー
えーと表をですね
走りますとえーまー第一成分が大体
声の大きさとかよく読み行政
えーもう頭があると
もう決まってるんですけども持つ大きくえーこの
この一つ
起きた
強弱
えーですから三四歳
でもやっぱり
えー小です
えー
ん決してだと考えております第二軸があの話の
×と書いてるんですけどもえー話速とか大阪とかっていうその係数が大きいということでまこれに
このよう日本ですと店舗という風になっていました
まこう散らばっていただくとこのように
二には九人しかいないんですけども
後そのー
えアンケートの結果で入っさ
えー四つですね
まー例えば
いい先生っていうのは
えーこう二つの検討も非常になっていくんで
テーマはなされていますこうすいいい先生
結婚先生に付いてましたが
この人はいいんですけども
えー話のテンポ
あの悪い
ま話す
非常に速さが
で払ったりす先生だってするんですけれども
あそういう風に
えー特徴が先生ってのも保育第一に
仕事で
本による違いっていうのますがやっぱりこう
こう自然性による
え違いがまー文です
んです
んでできる
ということをだと思います
て実際の音響特徴量を
でこれに関しては
きっちりと
えー
テーマ二十四日のモーラ数ん
とー小と方ず
でえーまー
話ように
えー視点分析を行なった結果です
もえー先生はよく
はいい先生も同じように
すワインに浸けてると思われっていうような結果になっております
まこれを見ますとアンケートではなく
えー音響特徴量っていうのでも
まるで文節の特徴っていうまーあのー分かってくるんじゃないかな
と思っております
三番目といたしましてえー音声認識率の関係
そういうことで
音声認識率を関係
後何かあるんじゃないかというな予測を立てました
えー明瞭な音声程認識率は高くなるんじゃないか
確かにそんなような
感じがま実際するかと思うんですね
後はピッチを変化させる
先程付けたと
進んでいると
低認識率が低くなるんじゃないか
確かに声の教授が強かったたんですねこっちがま二十一低いのかな
体の予測
あるいは
発音発声と認識しにくいのではないか
早過ぎて先生あ次において認識
二つにくいんじゃないかどうも
仮定いたしました
でえ次にすえーこの二つえーについても
えー
条件と言いますか
えー一発見として
え言語情報は考慮しない
ということで
こん言語的情報の
提供で認識率が変化することを
あのせる
えー実際にそのーす
えーで
音声にする時に言語モデルっていうのは八十二例ってを使っているんですけども
そのＣＳＪというのま音響学会の音声とか
で入っていましてそのー
根拠に関するうーとか後トマトとかっていう氷が
あー実際の
交流もありましてその
そういうこういい感じ
えー
まー
でもえ使ってやると実際認識率がまー上がってしまう
ほんでこれで以上があるんですけどもま今回の研究といたしますが
音響情報のみで家って聞くとでま言語情報は
母国
て音響特徴のみで比較を行ないたいと思っております
え音声認識の条件いたしましたこちらにある通りえ言語モデルに依存しない連続音節認識
二十リアスで
ま言語モデルはえー音節単位
結合確率は全て等確率
え言語重み〇それでなってい〇二言語モデルの影響はも指摘ように
考えております
で音響モデルはＣＳＪの男性話者から作成したトライホンモデル
で評価さくさくとは
ま一般的によく使われております正解率
で正解精度音節たいんですけれども
括弧二つをを用いていたいと思います
てまずえー認識率そういう影響が一番大きかったっていうのは発話速度だったんですね
テーマ
んーチケットのえー相関があると出てしまったんですけどもじゃその関係数がまー
〇．七例研究者と非常に
という大きな声が
挙げています
えー横軸はえー話速
その割合がこのグラフなんですけども
まず使用我々正解すとこ見ますと
ん右上がり正解精度だと更に
ではっきりとした特徴が
あります
んで
本当予測ですとえー話速が
速いこと
と認識率落ちるんじゃないかと考えていたんですけども
実際はおすぐ側各認識率が高いなんていう
いい結果出てしまったし
しまいました
ここら同士なのかと考えた時に
音響モデルの話速っていうのはもしかしたりってしてるんではないかと考えました
二十五四つの音響モデルっていうのをちょっと見てみたんですけども
適応モデルの
えーまそういう方がまー調査した程度ですね
でこの抗議と公園二ＣＳＪになりますけども御飯まそこの違い
ということでまー横軸が話速一秒間のモーラ数
で縦軸がまそれ
それがどのぐらいあるかっていうの割合
いーが
ております
でＣＳＪの講義を比較しまいたしますと
二十ＣＳでは全体的にえー右の方に
あるつまりまそこの二速い
っていうのは血管だっていうのはよく分かると思います
まず
で先程挙げますとこれ駄目だと思うんですけれどもえー講義音声
んー
ま
講義音声が最も多く含まれる
えーまー
ま凄く体っていうの大体八
ま八モーラ
んーま医療前後
後は八．〇から八．五でこちら七．五から八
でモーラ毎秒なんですけども講義音声をが非常に多い
グラフにしやつで
予測は
えー八．五から九．〇二
二ピークがあるってことでこの
えーこのまず対話
結構四千中でも非常に早い
えー講義が
んーこの一二一致しているということで
まその入る
えー講師の平均
後は凄く
えーとー
えＣＳＪにおけるま負のピークがまー一致しているということで
えー
まこれは限定
えー講義音声中でもまーその速いんー
攻撃が認識さたかったんじゃないかと
と思われます
それ以外にえー認識率を見る音声の評価これ評価っていうのはまー学生が行なったアンケートのえー評価結果なんですけれども
この関係ないのには
テーマ
相関は大体〇．六〇．六人ぐらいの
んえー結果になっております
ま正の相関はある程度見られたということで認識率は
先程
二三四聞こえるんじゃないか
考えております
で
そその人してる
とーその他の項目で
もうその上そこもあるかっていうのもこの音声を見てみたんですけども
これ減りますと
えー後はそこが一番
あ大きく影響するでこの国ってのアンケートで評価結果なんで
でこれはすぐもう早い方が早く
速い方が
て以上が高いっていう訳でもなかったんでまこのように
そこで何伝わりませんでした
んでえー明瞭度値が〇．六でまー
これもう一
というな結果なっとります
えーそれ以外に関係する
情報といたしまして
本人で
えーということで
負の相関がある
んでまー
やっぱりこう温泉があるんですそれと後やっぱり聞こえにくくなるもんなのかなっていうのは
結果になっております
二これがもしかすると
そのーＣＳＪの音響モデルがまー
そしての音響モデルの
てまー年齢とかってのも
形に見てみたんですけども
三十代四十代の人が多いかなっていうのを感じた点でもしかするとその音響モデルもまー
んでとかっていうのも一としてのかもしれないっですね
でそれ以外二として出しまして
えー抑揚っていう
こう先程強弱うまく認識さはじゃないかと
たんですけども
ま実際はそういうそのーそうか思わなかった
ただ一二九二回生相関が出たんですけれども
まー準備している方が
二日してる方が八
えー推定されので認識戦い何か
まー解釈もできるかと思うんですけども
それが激しかったとかまー
積極的っていうのはちょっとこれは学生が積極的に
増え取り組んでいるかっていう評価項目なんですけどもまこれの相関は
二番大きくなってしまったんですけどもこれちょっとあまり説明は
えーできない
感じなんですまこの終わっておりまして明瞭性
実は測定のもっと
えー影響が大きいんじゃないかというな結果んなっております
でまとめといたしましてえこうした特徴分析
えーこの二つ
とえー話におけるえ店舗二つで大体えー節の特徴っていうのは他じゃないかと考えております
本選に捨てずにえ
たちましてはその速いけど
えー認識高くなったっていうな結果なんですけれどもまー一つの音響モデルのま机の異常ないじゃないかと考えております
最後今後の課題なんですけども
えー音声認識率にか
関しましては
二十二名女性以外の評価以外の
えーパラメーターとの関係で四四では
調音結合と書いてあるんですけどまこれらのパラメーターとか
他にきえー
あるいはその認識ん実際えー出てくる本当の理由と
えー信頼度
これらの評価を実際にえー未決定と考えております
えー二番目は統計的な説明手法の方はもうってことでもう二決定木についてあってデーターも
えー信頼できるもんにしたいと思っています
最後データーの追加なんですけれども
え個につい四十困るんですけれども
星の数一一がえとちょっと捨てんーないと感じておりましてま他の
えー講師の方四千もちょっとえー録音してみようかな
考えております
よいしょ
えー
おーいう
#############################


#############################
# query = いるとねえー尤度とかまーあのーとかまそのフィラーって言っ入れますのでひあーの一つの感じとかまーわりあいとかまそういうものが後期とか公園の掛かり易い取ることま影響がいるのかとかま取る程関連なぜかのというのをちょっとま教えてほしいんだけどもまどうですかね
# rank = 1
# slide = 08-21_fix.match_word.jout.txt
# value = -2.80496012225896
#############################
えーそれでは講義音声の自動評価の為の
各種特徴量の調査
ということでえー山梨大学私小×が発表させたりします
えまずえー
もう二二なんですけれどもえー初めに研究の背景目的概要をえー形の上させていただいて
次に実際にえー研究内容の音響分析
えーコースの特徴分析音声認識率との関係
方をえーま述べさせまして最後にまとめえー今後の課題というな形になっております
でまず初めに研究の背景と目的なんですけれども
えー教育の数を向上さ歳
と書いてあるんですけども
場合にはえっとー子供達はえー少なくなってきてえー後大学前に時代とか
えー言われたりしてると思うんですけれども
テーマ
どこの大学もそうだと思うんですけどもそれでそこで些細っていうのは
まみんな思ってることだと思います
でその教育の基本的なまこういっ形式大学で言えばこう
があーま主にいー教育のまー手段
として用いられてるかと思うんですけれども
その方には四つにえー関連する要素として
えーここに寝ました
まー
講義のえー実際の内容とか
えー形態えーまー
どういうような
えー
形でえその抗議を行なうと
針は話型の語
回路の要素は考えられると思うんですけども
テーマ私達はこのお話から
で頭の話し方に注目
んでいたしました
でその話し方を改善しまして
えーより良いより聞き易い音声にしたいと
って思っております
でこの学生が聞き易いの抗議を行なうことでえーより理解し易くまいう印象を持ってもらえるような
えそんなものを考えております
ま最終的な目的といたしましてこの大学の講義音声
えー対象として話かもこう改善したい
おこな目的を持っております
で研究の概要なんですけれども
えーまず
この
えーあ後期においてまその
先生の方針の
え講義音声こちら実際にえー録音させていただきまして
え同時にその工業重宝していたえー実際に消耗していった
学生さん達にアンケートに解答してもらいます
でこの講義音声につきましては
音響分析を行ないましてえま音響特徴量を
パワーホルマント体があると思うんですけども
このような音響えー特徴量が抽出できるかと思います
こちらのアンケートの集計いたしまして
えー本に
場合要求を制御果たすことも書いてあるんですけどもま音響に関するえーアンケートの結果
えーと何計算結果と英語基本的な特徴を
あ百分の一
接近していきまして
えーどのようなえー音響パラメーターが評価に影響を与えるかっていうのを
調査している
します
まーその後にちょうど講師の特徴分析という言葉行なっております
でえその講義音声から分析した音響特徴量としてのアンケートの結果をま統合的に分析する
でこうしてま聞き易い話し方に必要なえー音響
中央は
で何であるのか分析するえーという概要になっております
テーマ
あえーと前回も
発表したんですけどもま今回の着目点といたしまして
えー講師の特徴分析
今にアンケート評価結果でま
観点特徴分析を行なったんですけどもえーその実際の父音響特徴量
でこれ特徴を把握できるかっていうことを調査しいたしました
また
えー音声認識率といたしまして
あの音声認識率
とこれのえー評価と何か関係があるか
方をえー調査していますで関係がもしあるとするならば
えーこの音響尤度とか信頼度などまー音声認識に関係するそのパラメーターが
協会なんか影響を与えてるのではないかってことをまー
考えていきたいと思っております
てまずは大学行為を収録まそのー実際どんな音声かって言うかまこちらに書いてある通り
えー山梨大学工学系でコンピューターメディア工学科
のえー攻撃
えーこ実は一一名でま全て男性
で条件はこのようになっております
提案型とは勉強的評価にいー関係するアンケートの中心に五段階評価
手配家まではまるかどうか
というなえーアンケートになっております
で次にえー音響分析
んーするたいと思うんですけども
ま音響情報のえー分析といたしまして以下の二項目こちらのテーマ促音木について
えアンケート結果と音響特徴量の比較分析を行なっていきます
えー
えーその後本当は発話速度
治療
抑揚を利用性やショートポーズ
このえー五項目を主に音響情報
として捉えていきますアンケートの例で説明いたしましては
た適切な行為で果たしているかとか
テーマ
この速さがいい
ちょうどいいかとかまそういうようなアンケート
えーやっております
でまずその発話速度っていうのをちょっと見てみたいと思うんですけれども
この家は
がえー横軸が発話速度えこれ一秒間のモーラ数
で縦軸はそのアンケートの評価結果
まーえーと一から五の
五段階評価でえーまー
舌が大きい方が良い評価
ち異なっております
てえーま評価学会講演の×となってんのかなっていつも名前を書いてあるんですけども
×四の評価用音声は大体いーそして八モーラ言語ま七．四から八．一
開催の値なんですけどもまこのぐらいは評価高い
で評価低い引く三学級の通りかって言いますと例えばまー
八．五から九の非常に早い
話速だったり
んちょっとそれだと全体的に評価は低く
えーなっていたような
傾向があります
二つの平均と分散はこう二歳の影響が大きい
と書いてるんですけども
まーそのー行為っていうな行くのも非常にまーちょっとえースライド
っていうのをまー二つのこういっ渋滞があると思うんですね
でその場所工事
砂糖
二人黒板に書きながらを考えたりして
果たしていいので全体的に
えーマスクは遅い
誇りを見てもらう
と分かると思うんですけどされるだけ全体的に
体をすることが分かるかと思います
あー多分三えーその母マスクの分散ていうの見ますと
やっぱり
んー判定していないばらつきが大きい
まその講義はま金が言えるのでばらつきが大きい
というな感じになっております
で逆にスライドをまー本当などを用いた
二歳度を使った抗議ですと
まそこは全体的に早め
なおかつえー
パソコンの分散ていうのがわりと安定している
というなことになっております
でこれをもう一
方でえーちょっと
覚えておいてもらいたいことなんですけどもまこの
非常に遅くこの辺の講義を一文
えーする大体八．〇モーラ毎秒の講義が
まー
実際多かった
また話速が速いっていうのはまー
八．五から四モーラ毎秒
はが大きかったとはちょっと覚えてってもらいたいんですけれども
てこの発話速度っていうのはえー
その認識結果を用いてえー求めているんですね
あー自動評価する上で認識結果を用いしかないと書いてあるんですけども
通常評価もまーこんなことを
えーもう目標にしておりまして
で
まそうなると結局認識結果も思っ使わないとちょっともう止まらないんじゃないか
ということで
えーっともの後は二十一度登った
その認識結果本当にのかっていうことをちょっと
えー最近見たんですけどもま正確なコース
で言えば速度は誤差がある
えー
書き起こし文と比較したところ五パーセント
でも差があるということでま二つ
歳の
えー
話速っていうことをま書き起こしたまー策っていうのとえー認識結果のま作って何も五パーセント約二十パーセント未満ですね殆ど
が
ま誤差がある
えーまた
二十五回五二十パーセントをちょっとあえー
結構差があるんですけど
もうま
ある一一先生だけなんですけどもちょっと
えー誤差が発生するんですけどもま前提のデーターの傾向っていうのは殆ど変わらない
で行なっているのでその認識結果まー信頼できる
えーそのもうこの値を用いても大丈夫だと考えております
えー発話速度以外の音響分析についてはちょっと簡単にえーさせていただきたいと思うんですけども
平成四分の二っていうのは
ま全体的にどの後者の評価が高いということで
えー土曜コースも大体
えー評価五段階治療
以上
えーまー昼間で
ま声の国際時代っていうのがこの問題はないかと考えております
ただ一つの表現できないこととして
一定の方向を向いている場合五月九日五と六って
行きながら話で今あー衣装だと
こまの方勤めている
とかまー
あると思うんですねでそういう場合に
えーっと
ま全ての学生まで近いところが届いてるとは言えない
でこれはあの
ほいにくい高校が
存在
二ですんじゃないかと
ある一部のえー二十世紀にまー
その
どこの席に座ってるかってのまー知られまして
その分析
あれ
こちらの方はその評価低いとかまそれに音楽家強者が見れる先生もいたんですねまそういう先生は
えー実際どういう風にこうやってるかっていうの見るとやっぱちょっと同じ方向しかできない
いうのがまーあったんで
結構
あのー
もっと学生の方とかま全体にまして
社会の重要文なのではないかと考えております
二記憶量をこれに関しては
ピッチ大きく変化すること抑揚があるということで
で声の高さっていうのはえ日本語声の高さで
で距離を付けると言われてますけども
実際試合とこうやっぱりこの種
方向機械で先生程
で強弱のあるんじゃないかという風に学生はこれ
学生は感じているようですが
んで
次にえ要請なんですけども
えー低い声の方は御利用が困難さも関係するということで
入っま日本低い方は
見えるように
じゃないかと言われているんです
けれども
実際にそのや結婚は
あるいは三年に買ったんですけども
あっそれ以外はそもそも関係して
んじゃないか
えーと今考えておりましてこれについてあの調査中であります
で
まこの音色的な発話との相互評価に与える影響一番大きいということなんですけどもこの九九中でもやっぱり
この音色性っていうのは
えー非常に
えー学生さん達二十四
んじゃないかと思います
最後ショートポーズなんですけども
二層構造を次に強いということでま発話は
それとえー二過ぎると
えーとー
父が増えてしまうんで
まなるべくまとめてショートコースってのは
がないまをする後続だった為に
でやる方がいいかとあります
例えばフィラーを効果的にもできること
形態をしているってことでまフィラーを自由な要素がそのポーズに関係してて
とおも考えておりますがこれついてちょっと他の研究で
へ行ってはまず
でこれあのー
えー音これはもう今では音響分析の話です
いや講師の特徴分析ということで
テーマ
紅茶の特徴を一目で分かるようにできないかということです
でま二通りの手法って書いてあるんですけど性分析は
やんけと評価項目先程のデーター五項目
ん加えて
えー音響特徴量をえピッチ
のえー平均分散
話速ですとこう頭からえー求めました
で
まその四つが一はおえー二十
二十九二次元に圧縮いたしまして
えー
その結果えーえ第二成分は後に声の質に関する
え予想第二成分を話の展望
風にえー関する要素がえー
えーえ大きくいけするんじゃないか
父はえー
を考えました
て実際アンケートの方も
冬で行なった結果なんですけども
えーとまず短い
大体のおー
えーと表をですね
走りますとえーまー第一成分が大体
声の大きさとかよく読み行政
えーもう頭があると
もう決まってるんですけども持つ大きくえーこの
この一つ
起きた
強弱
えーですから三四歳
でもやっぱり
えー小です
えー
ん決してだと考えております第二軸があの話の
×と書いてるんですけどもえー話速とか大阪とかっていうその係数が大きいということでまこれに
このよう日本ですと店舗という風になっていました
まこう散らばっていただくとこのように
二には九人しかいないんですけども
後そのー
えアンケートの結果で入っさ
えー四つですね
まー例えば
いい先生っていうのは
えーこう二つの検討も非常になっていくんで
テーマはなされていますこうすいいい先生
結婚先生に付いてましたが
この人はいいんですけども
えー話のテンポ
あの悪い
ま話す
非常に速さが
で払ったりす先生だってするんですけれども
あそういう風に
えー特徴が先生ってのも保育第一に
仕事で
本による違いっていうのますがやっぱりこう
こう自然性による
え違いがまー文です
んです
んでできる
ということをだと思います
て実際の音響特徴量を
でこれに関しては
きっちりと
えー
テーマ二十四日のモーラ数ん
とー小と方ず
でえーまー
話ように
えー視点分析を行なった結果です
もえー先生はよく
はいい先生も同じように
すワインに浸けてると思われっていうような結果になっております
まこれを見ますとアンケートではなく
えー音響特徴量っていうのでも
まるで文節の特徴っていうまーあのー分かってくるんじゃないかな
と思っております
三番目といたしましてえー音声認識率の関係
そういうことで
音声認識率を関係
後何かあるんじゃないかというな予測を立てました
えー明瞭な音声程認識率は高くなるんじゃないか
確かにそんなような
感じがま実際するかと思うんですね
後はピッチを変化させる
先程付けたと
進んでいると
低認識率が低くなるんじゃないか
確かに声の教授が強かったたんですねこっちがま二十一低いのかな
体の予測
あるいは
発音発声と認識しにくいのではないか
早過ぎて先生あ次において認識
二つにくいんじゃないかどうも
仮定いたしました
でえ次にすえーこの二つえーについても
えー
条件と言いますか
えー一発見として
え言語情報は考慮しない
ということで
こん言語的情報の
提供で認識率が変化することを
あのせる
えー実際にそのーす
えーで
音声にする時に言語モデルっていうのは八十二例ってを使っているんですけども
そのＣＳＪというのま音響学会の音声とか
で入っていましてそのー
根拠に関するうーとか後トマトとかっていう氷が
あー実際の
交流もありましてその
そういうこういい感じ
えー
まー
でもえ使ってやると実際認識率がまー上がってしまう
ほんでこれで以上があるんですけどもま今回の研究といたしますが
音響情報のみで家って聞くとでま言語情報は
母国
て音響特徴のみで比較を行ないたいと思っております
え音声認識の条件いたしましたこちらにある通りえ言語モデルに依存しない連続音節認識
二十リアスで
ま言語モデルはえー音節単位
結合確率は全て等確率
え言語重み〇それでなってい〇二言語モデルの影響はも指摘ように
考えております
で音響モデルはＣＳＪの男性話者から作成したトライホンモデル
で評価さくさくとは
ま一般的によく使われております正解率
で正解精度音節たいんですけれども
括弧二つをを用いていたいと思います
てまずえー認識率そういう影響が一番大きかったっていうのは発話速度だったんですね
テーマ
んーチケットのえー相関があると出てしまったんですけどもじゃその関係数がまー
〇．七例研究者と非常に
という大きな声が
挙げています
えー横軸はえー話速
その割合がこのグラフなんですけども
まず使用我々正解すとこ見ますと
ん右上がり正解精度だと更に
ではっきりとした特徴が
あります
んで
本当予測ですとえー話速が
速いこと
と認識率落ちるんじゃないかと考えていたんですけども
実際はおすぐ側各認識率が高いなんていう
いい結果出てしまったし
しまいました
ここら同士なのかと考えた時に
音響モデルの話速っていうのはもしかしたりってしてるんではないかと考えました
二十五四つの音響モデルっていうのをちょっと見てみたんですけども
適応モデルの
えーまそういう方がまー調査した程度ですね
でこの抗議と公園二ＣＳＪになりますけども御飯まそこの違い
ということでまー横軸が話速一秒間のモーラ数
で縦軸がまそれ
それがどのぐらいあるかっていうの割合
いーが
ております
でＣＳＪの講義を比較しまいたしますと
二十ＣＳでは全体的にえー右の方に
あるつまりまそこの二速い
っていうのは血管だっていうのはよく分かると思います
まず
で先程挙げますとこれ駄目だと思うんですけれどもえー講義音声
んー
ま
講義音声が最も多く含まれる
えーまー
ま凄く体っていうの大体八
ま八モーラ
んーま医療前後
後は八．〇から八．五でこちら七．五から八
でモーラ毎秒なんですけども講義音声をが非常に多い
グラフにしやつで
予測は
えー八．五から九．〇二
二ピークがあるってことでこの
えーこのまず対話
結構四千中でも非常に早い
えー講義が
んーこの一二一致しているということで
まその入る
えー講師の平均
後は凄く
えーとー
えＣＳＪにおけるま負のピークがまー一致しているということで
えー
まこれは限定
えー講義音声中でもまーその速いんー
攻撃が認識さたかったんじゃないかと
と思われます
それ以外にえー認識率を見る音声の評価これ評価っていうのはまー学生が行なったアンケートのえー評価結果なんですけれども
この関係ないのには
テーマ
相関は大体〇．六〇．六人ぐらいの
んえー結果になっております
ま正の相関はある程度見られたということで認識率は
先程
二三四聞こえるんじゃないか
考えております
で
そその人してる
とーその他の項目で
もうその上そこもあるかっていうのもこの音声を見てみたんですけども
これ減りますと
えー後はそこが一番
あ大きく影響するでこの国ってのアンケートで評価結果なんで
でこれはすぐもう早い方が早く
速い方が
て以上が高いっていう訳でもなかったんでまこのように
そこで何伝わりませんでした
んでえー明瞭度値が〇．六でまー
これもう一
というな結果なっとります
えーそれ以外に関係する
情報といたしまして
本人で
えーということで
負の相関がある
んでまー
やっぱりこう温泉があるんですそれと後やっぱり聞こえにくくなるもんなのかなっていうのは
結果になっております
二これがもしかすると
そのーＣＳＪの音響モデルがまー
そしての音響モデルの
てまー年齢とかってのも
形に見てみたんですけども
三十代四十代の人が多いかなっていうのを感じた点でもしかするとその音響モデルもまー
んでとかっていうのも一としてのかもしれないっですね
でそれ以外二として出しまして
えー抑揚っていう
こう先程強弱うまく認識さはじゃないかと
たんですけども
ま実際はそういうそのーそうか思わなかった
ただ一二九二回生相関が出たんですけれども
まー準備している方が
二日してる方が八
えー推定されので認識戦い何か
まー解釈もできるかと思うんですけども
それが激しかったとかまー
積極的っていうのはちょっとこれは学生が積極的に
増え取り組んでいるかっていう評価項目なんですけどもまこれの相関は
二番大きくなってしまったんですけどもこれちょっとあまり説明は
えーできない
感じなんですまこの終わっておりまして明瞭性
実は測定のもっと
えー影響が大きいんじゃないかというな結果んなっております
でまとめといたしましてえこうした特徴分析
えーこの二つ
とえー話におけるえ店舗二つで大体えー節の特徴っていうのは他じゃないかと考えております
本選に捨てずにえ
たちましてはその速いけど
えー認識高くなったっていうな結果なんですけれどもまー一つの音響モデルのま机の異常ないじゃないかと考えております
最後今後の課題なんですけども
えー音声認識率にか
関しましては
二十二名女性以外の評価以外の
えーパラメーターとの関係で四四では
調音結合と書いてあるんですけどまこれらのパラメーターとか
他にきえー
あるいはその認識ん実際えー出てくる本当の理由と
えー信頼度
これらの評価を実際にえー未決定と考えております
えー二番目は統計的な説明手法の方はもうってことでもう二決定木についてあってデーターも
えー信頼できるもんにしたいと思っています
最後データーの追加なんですけれども
え個につい四十困るんですけれども
星の数一一がえとちょっと捨てんーないと感じておりましてま他の
えー講師の方四千もちょっとえー録音してみようかな
考えております
よいしょ
えー
おーいう
#############################


#############################
# query = いるとねえー尤度とかまーあのーとかまそのフィラーって言っ入れますのでひあーの一つの感じとかまーわりあいとかまそういうものが後期とか公園の掛かり易い取ることま影響がいるのかとかま取る程関連なぜかのというのをちょっとま教えてほしいんだけどもまどうですかね
# rank = 2
# slide = 07-23_fix.match_word.jout.txt
# value = -2.83062037898534
#############################
あえー三四五とこだサイド度々質問で表わすと申し訳ありません
えーっと私のえー本日の発表の内容なんですけどもえーと音声認識の確信度と
ベイズ識別モデルを利用したえー音声から固有表現実まー想像な回転なんですけども
でえーお話しします
で初めにですけれどもま皆さんはあのー
昨日今日はお父さんが私だとえーんですが
えーっと音声データーをま重要な情報源とした考えますとま従来あのー自然言語生活がえーまニュースの記事だと扱う上だとかを使ってきたように
おー我々音声をデーターを使う
図面ニュースの構造であるとかこぶがそうだとかまーあのーまー閉鎖的にも全部つ通話記録なんてもうすぐになるのかなと
考えておりますけども
でえとアメリカの中のえーと理由プログラムというえー
緊急これで終わりますえーと音声認識して翻訳してそこから情報従属ような
ま結構大々的なプログラム実行しましてま我々もそうだ後に
興味が
んで
のえーそんなことを考える上で重要なタスクとしてえーと固有表現抽出というものでは考えますえーっと昨日もあり生成の
二五えー五講演Ａさんがなぜできたんですけどもま非常に重要なもの
でどういうものが来るとま人名とか地名とか日付け
な同程度同定するのだ
でえーま何か
すもう五月日と水になり何をした場合ですかという風にその個体名のものを
えー他の結果としときます
いうことをす
守ら情報中三アプリケーションのえー一番二つとして使われるものでえま音声学については皆さんも場合は言わないような一えー
情報処理のえーとどうして
えー考え
ことができる
いうことになり
で研究本研究の目的はえと音声認識結果
えーおま音声データー数ますね音声認識結果から意外な気にえー固有表現を一つということを目的として今
でえーと具体的な問題としてはえー音声認識を使うのでえーと音声認識誤りがある程度その家族が不快であるということが言えますので常に起因するえーとこういう表現舌の合間
っていうのをえー五日には先程考え
二代目には
えーと音声認識結果っていうのはまー何か音声認識誤りでノイズが持ってる
でそういったものを
えー考慮に入れた上で
えーっと英語四五想像なんですか情報を考え
え従来の研究なんですけどもいて自然言語処理の分野の方ではえーっと識別モデルＡとますの面倒Ｂですとまーサポートベクトルません
ま最近ですすいあれなんかを使ってえーやる方法では色々増えてましてえこれはあのＴ独立な映像色んな個性をま工場じゃ使います
えっと計算がえーまーだと思いますけどもえーっと二でえー例えば
固有表現一つの例で言いますとえただこの競争とか品詞の対話
であるとか町への単語は何だとか
後相関はどういう文字で例です分かれるかって絶対は
アルファベット何も疲れ書かれるのも七訳語が多くてそういうもの固有表現形や水とは全部日本語の場合全部片仮名で書かれるものはこういう形易いのかという傾向がありす
しますんで
まそういう画像法五六から〇〇に方々が択一ですが大体
でえーまの方が当然あの自然言語舌でやってたことなので入力は中書き言葉とかあまー絵を書いてございのもまでの準備誤っていないと
いうことを考えて
でそれでその口蓋の話損入部に誤りであると後で内で話し合いで
で一方その音声益々あの当然す話し方をやってきてますえー従来の方法ですとえーと生成モデルと言ってますけどもえーとーさえーっと昼間のモデル
人丸一たものも目線がう
ん実際感じる丸のモデルがない場合もあるんですけどまそういったようの
をあの同じ類いのモデル
ポーズだけを
でえーっとこうした方法ですとおーいうスポーツで二つの音声に字余りを考慮したモデル化する方法が提案されてまそこでもう五年以上前の一匹は
話なんですけども
さあ今日の五文字が
何かしらがえ二つの音声中の確信度を使って
何かそのー後あのー今日はある確率二重母音一つ
さああの五番としながらあー固有表現抽出ってのはえー千
音を使って
でえーっとーま音声認識えーと
えー
気をして学習をすることで何か誤りが入って既に出た時にそれをうまくせながら
えーこういうようにですというのも
なんですけれども
えーっと生成モデルの一般的なマザー点として言われ方法そしてえーっと独立うー
そのー
から情報を独立でないとこもある
いうあのえーことが言われてますねこれはえー一年言語というのをよく言われていることで最近
でそういったもうとにかくお酒
すいるかがえーっとー自然言語性が高い識別も二三使う訳ですけども
さすがに言われてましてまこういった問題が
でえー本研究ではじゃどうするかと言うとまいいところよ島というなります
えーと音声認識誤りを考慮に入れるっていうその音声や三の二十五をえーっとおー識別モデルを使うという
えーと自然言語する二つのえー方法論の方で使います
のことを考えますどうぞと何が嬉しいだという母音ですけれどモデルを使ってえーっとま強力な分類での音声がすることができ
えーまーそしてえーまどうやるかと言うと体温が生成色んなものじゃ二二を使うことによって
でえーこれの言説は精度を上げることは
って考えあえーっと音声認識の確信度という情報を上手に使った言えることでえ高い認識や間違いだと
その入力に間違いがあるっていうな状況でもそれ二十ばれないように
まロバストなあーこういう技術ができる
っていうことを目指して
でえーと具体的な話に入りますけどもまず最初にあの固有表現一つの文の中で一つを幼い時ます
で
二一般的にこういう言説の問題というのは
で単語をある固有表現のクラスに分類する問題として追加されますでクラスというのは何かと言うと
〇固有表現のカテゴリー三は人名等のえー×データーとかそう勧めだとかっていうことを
えーと単語の位置についてんですけどおえっとその単語はある本をアルコール例えば人名の頭の単語例えば三四つなかったら
データーとなります日本語だとそういう風な情報っての使う
第二に挙げてございますけども
どこにある腎臓す昭和っていう
えー文章
ありますけども
えーとま四つあるんですがまー手というのは人名の最初の単語を
えーと先祖は成人名の最後の単語を
えー後はえーちょっと言えないのが勝手に付けですけどまこういう風な
っていうのも
風にえクラスのえー分類するという問題とした時も
でえーと不まずえーっと
自然言語それで行なわれてる方えーとこの
こういう風にずっと解く方法としてまー
生徒も日本語を出す方も残してえーま一番こうま我々日本一と二三嫌なのはえーとーま強度差をいただきや
データー二千二年にえー発表していますけれどもえーっと三本目がませんを使って
固有表現中卒という方法を提案します
えーこれはあのー
でえーっとずまーサポート二文字の構造化えーと色に舌七構造化の話なんですけどもこれ使った方法を今回えーともう今日であると
でえっと先生としては単語の醸造法にえー二一五だともう一つですね先程申し上げたその片仮名で書かれてるとかアルファベットで出され出っ張ってるなと思った
んで
まーそこでそのま勿論そうな体系のあるですので丸の番号の情報ってな役に立ちますでえーと前後二単語分布の使う
えーベース音声のそれが三つであって
えーと自分の前後二単語ずつありますんで問い三は体重方法の素性を使って分類する
いう問題として
えーやって
でここが提案手法が全部入るんですけども
えっとーじゃ何が違うか提案手法は
先程のえーっとをさえー水槽だけがあのーえーと後もっといい家の
えー
こういう風にずっとこう二ませはか固有表現抽出方法において
えーっとそう強い子達まー
一ないようなあえー音声認識の確信度先生にします
情報をえー提案する
でえーここのえー確信度の構成って何かあると
この
単語が来るえー音声認識さ単語数が書かせ意外な確認時
えー〇か一八歳の
全素性値はえーっとー確信度スコアによってバスも出えーっとある閾値よりも
確信度は高い
場合は
えーまーこのこれ一
ま新しいものとして発話を使ってま逆ながら
〇
誤りとした後
まあまりあの人の要素外国へと素性ベッドの要素が一増えるようなものと思っていくと
でえーとこういう風に者はえー今一定の方法をどういう風に実装する形夏なんですけどもえーとモデルが通じないでいた
朝も二文字のガウス分布にするかって話をしも
まず最初に音声データーはあるんですけども
えー学習データーを作る為にちょっとあの書き起こし中骨導音の書き起こしの方でその
でそれにあの固有表現のラベルこれは人名などの方では知名度を行ない付けた気を付け
で最後に
でえーと各種の素性っていうのをこれはえー先程申し上げたそのー潜時はあー時代があって話をするんですけれども
えーと背景を元の学習データーの時代書などで後で説明しますけれども一緒に使うという人があのところも使うんですが
えーっとーま書き起こしでもえーつまり音声認識全部集めた百パーセント単語についてで百パーセントと思いまいるので
えと各固有の語のアクセントっていうのは全部認識が正しい
っていうようなもので
でか会話で音声認識の誤りの傾向が通じないデーターのえー音声認識結果をもう学生使います
でこれはおえーと音声認識さ結果
道をえっと先程のこういう表現ラベルを付けた素材の書き起こしとおーまーえ対応ずで
そして
えーっとーここは音声認識を間違ってるとかまー固有表現だというラベルをえー打つ訳ですね
その当時
で主にするのがすデーター
ができ
んで
そん二十年はついでだからどういう文過程のとこでお示してえーお話しますけれども
ではこれ書き起こしで作ったもんですまーこのＡのＢ面を見るとどういう方法過程の図一の文と思うんすけど
えーっと
まこれは全部正しいえーそのおー同じことある新聞に書いてあるこの表でですね五例がありまして
でえーと固有表現の概念も大和についてな二名ですから二音のラベルが付いてますし
えーっとネットってのはその時間およびえー日付けの上なんで音声というのが付いて
でえー書き起こしを使ってますんでこれをまー音声認識した場合だった訳無駄な姿っていう風に仮定をして全部一のなって
湘南
保護させたり喋っちゃう
で
えーとですね水や音声対話それを音声認識結果を使ったか触れた
のえー方で四つ谷のえーお見せします
でこちらにあるんですけれども
昼間なのは遅い音声に二まず誤り
なってまして
ごみについては四名についてなってです昭和するように
えー
使用ペアでもん
されてこういうあの状況をまー仮定しま
でその時にどうするかと言うと音声認識誤りで先程のモーラの本一ページ目を使ってるんですねで
これをまーあるな
もう図面を見じゃもうどう相手方は子供ができます
Ｐここ年以降ってのはま対話えーその認識魚こっちは他のことで
まこういうのがどういう風に学習データーを付けようかなということを考える時に
えっと本手法ではどうするかと言うと
えーっともうこれはまー今日中の完全な
でその
えーと発展されだとこういう風なこうもうこれない
分かってるのでもう草があ極めて高い
いうことでまーあのー部分的に正解精度もおーそれはもう捨てたいなとこういう例じゃない例をえー判定した
ことにして
ま構成
まー実際に実行した時に完全な固有表現混ぜた目的で何か
部分的に分けるのよそれはこれを一文じゃないよっていうあのことを学習させようということにしました
でえーと実験の話に入りますけれどもと速い
はいえーっと
えーとコーパスはえーと日本語の新聞記事データーでえーっとー自然言語生活がやられたその固有表現舌のコンテストがありまして
はいＸっていうワークショップでえーそこんて座ったんだそれの学習データー
の部分を使います
えっとーつそれが特別にあるんですがそこを色々気に関係二番目らしいんです程々にしたんですけどもえーと千百七十四えーま大体二一万文上位
あってえーとー一日まー千ぐらいこういう人があって二十六万単語ぐらいで品詞はえーとー三千語一番上のレベル訳なんだと思うんすけど六十五
あります
でこういうよう上のカテゴリーが八つありましてえーと人口組織バス人物で日付け時間金額割合で一つあのデーターにあったんですけどこれに分類する
問題
でえーとーまーどうも英語がえ音声えーからっていう話をしましたんで食べ読み上げ音声おります
えーっと×あ上でした二人ぐらいデーターベース百文上位読んでいただいたことになります
でえーと我々の音声認識エンジンの騒音計の練習をしたんですけどもちょっとあの収録環境がありますとだったようで
えーっと結構頑張ったんですが認識精度が発話一つを切ってしまいまし読み上げ音声と砂糖をだろうって話はあるんですけれども
まこの状態で実験をしましたで認識エンジンの語彙数は四十四十万語四十二願望で
未知語率は〇．六パーセントしかないですけど
で後いつでは七十五九ぐらいのまこんなもんかなと
で
えーっと行なうので後舌ですかなワンベストの音声認識いただけですんでそれの
フレーズ情報として
精度はねその中でえーと八十二パーセントの語彙表には一応人間だけで
えーでえっと釣りだとまこういう
二分かって
なのでえーとＢイコールはまー大体八割ちょっとぐらいあってあのー二どんなに頑張っても初めと個性がないとは言わ為と見てみてください
でただ実験の話をしますね
えーっと提案手法の方を調べる為んまーえーっと先程言いますのはん別音声認識結果が多いようです
問題をえー取りました
でえーとー
すえー正規化する事項についてですけれどまずベースラインは
えーっと
不満はその音声認識結果を丸を信じて
えー出てきその行為のですのをそのまま使う
いうことをしてますこれはベースライン
程度これは階層が来たん方法とまんま使った
認識結果に大したことになりも
でえーともう一つなんですがもう一つの付けましたけども多いと音声認識誤りが二えー含まれていることを
想定して
じゃ音声認識誤りれた相談をしてます
っていうなことをえ一と二比べますこれは
えーと認識結果の中でえーそうか個人母音がある閾値より低かった場合
まーこの単語は未知語三だろう図四本用嫌いだって
でまずを
そうするとその町はこういう表現と捉えてみますよねってことが考えられるんでその方法とか試して
でもう形提案することで
でもう一つの単語をえーあったらすしますとこちら違いますえーっとー
評価
えー評価セットはえ二次にしました
えーっと水を使いえ三十終わりにという風まお馴染みの方法です
で実験の条件なんですけどもえーとデーター一万文音声であったんですがそれをパイプをどうこう避けてえーと誰に全文書に分けて
えー言葉です
持っています
でえーっとー
提案手法はその一つ確信度一度より上だったらえーっとその単語正解と判定する形いじめでですけどこれあの後で高いので
えーっと
今回はえーっとその四えーとー後等分したデーターの中の一えーっと一
えーっと五分の一を
生徒てそれがいたんすけど
そのテストデーターの前半分を使って決めたスキー場使ってる面も評価すその逆をやるっていうのをやります
んでえーとアクセント砂糖をする中夏なんですけれどもえと今回ちょっと都合によりＳＶＭをまた使いましたえっと色んな方法は今住んで
えーそれはそれを使っても別にこの音素毎には影響がないですけどもまーちょっと都合にうこういうことに
が
でえーとまー五分五六データー数これはこの単語数認識された行動の関係の判定するようなもの
で素性としてはいる競争とおーえー分けて競争と品詞とを二三あ単語事後確率っていうあの
いーやる人フランスの一文にやってた訳なんすけどもまーあのー
結構有名なので
最近四つ全部使ってた結構有名なのでま一型の単語二合格だと思っていただけだけ
で基づくえ付加情報としますえーと書き起こしによく耳
書き起こし一つの音声二十八パーセントだったら
それがえー通じられるのかっての遊びにえ散歩と存じますけども例えば八十四パーセントぐらい
なのでま八割強ぐらいは
えーとテキストレベルで解ける言い方をえーっと一分後ぐらいの付き合いというようなもの
のえー
えー扱って特に思ってくださいで実験結果をこちらですけれどもいるベースラインえー基本観光客を提案手法の一になるで今
でえーとーま御覧になって分かる通りえーと一つのレベルで二ポイントぐらい提案手法ですがえー上でえー単語長に対しても一ポイントぐらい掛かっても
取り敢えず方がまーえーコイルを一つ一観点が最高の精度の中では
でえーと細かく見ていきますけれども
まーその単語をえーどんな音声認識誤り八単語っていうのをあの希望するっていうの考え方があるのかって話私なんですが
後こちらを見ていた学校三適合率単語をすることによってえーまー
容易に想像が付くと思いますけれどもま地方の精度適合率はあります
その彼対立重なります
ということはありますで一応これはその
ページが最大になるように閾値をえーと各データーを使って調整した結果なので
えー色んなこの場合
まこの中でフィラーな結果全てあの映画で言えばですけどもその状況で
てこのぐらいの改善が
いうことで単語の一つはどこでも
ま依頼を行なっ
二
〇．八三を八五三という
いうことは分かってますで
これはえーっとーま中のものでまー固有表現一つのモデルはもうテキストが入る入ってくると信じてる訳なんですけどそうではなっていてあそこの場合はこういう
恋の言説のモデル自体も音声認識誤りが入った文ま入りました者が入ってるんだとほぼしてはですねでそういう
学習がえーまこういう高い精度八五年たった理由であろうという風に考え
ですね
でえー
んで後一つあるかということはつまり音声認識誤りによってその町がこういう表現が二月にある固有の原稿方が好き生活にあると
それ恐らくですね
いうことですね
でえーとーもうその後まーそのー
提案手法はどこがいいのかって話をえー見る訳ですけれどもまず学習データーの違い
えーにお作用見ています
でベースラインよりはこれなんですけども
音声に通訳をえーっとーおー月で彼女音声認識結果が来るものだけを使うと
程度適合率が分化があるんですが歳ですが実差がある
いうことでえーっとー
途中でもう全て挙げて申し上げたそのー三千な固有表現をまず学習が要らないよって言ったように設定してしまったので
それがこここの平均モーラ数変調音を出すのをまい導いちゃってるのが主なという風に思います
でえーとー最初に申し上げたようなその先程の学習データーも使うんだよって話をしますけれどもまそうすると
えーっとー適合率と違います四歳〇二三ポイントが帰ってその
で
で一方であっまず何で何が良かったかと言うと書き起こしのデーターベースとその後色々サンプル数が増えるんですね音声認識結果だと
そのコモ湖のえ認識誤りの三分の一五つあってで学生では至ってるのでそういうのを関する役割を果たすのかなという風に思います
でモーラの信頼度先生夏の場合まーそうしましたけれども
えっと提案手法においてそのー
音声認識結果を使った学習データー使ったあ場合でも同様の傾向が見られました
でそのー
確信度の閾値はえとー今回この図バリエーションで決定さんですけれども
えーっとまー
そうだなってそこで一二どうなるかなという見てみた結果がこちらでして
程度想像があのはブームが提案手法でえ単語客家のそのさっきの真ん中の別にあっなんですけども
気をま内容とま長年やってたんですけどもそれがこれでして
決断をやるの方法というのはあのーつい
四か月花溢れ児童が若い頃は下がって後ここに当然ですが中傾向が得られたえー一日中でも差が出始めちゃっているものはです始めていること
んでまー
なので
これ後であの嬉しくない
んで
片や手法ですとえーとず確信度〇から五分によって
えーと固有表現します二とするようなその
この
行為表現一つの結果ってなってるのか町なるのかっていうのを女縁で
えーまー結構高いえーと八十五パーセントもう一でえーっとー最え四五割近くっていうぐらいの数字があー成立
でえーっともっとその確信度をえ音が五六二確信度を計算したんですけどもこれが
傾向性で精度で競争があってはま相互に高くなる訳で
で
今回そのー上限値を調べようということでえーと確信度によって音声に女性語判別があまり慣れてきたとかですうまい人良かった蔓をすえーこの二事例から集まって第一次世界を
与えた状況でどれだけの数字がえーあそこ二つが
てここみたい結果がこちらです
えーっとーまー見ると分かるんですが一二四本流れますし後冷蔵一本違ってますが
精度が良くなっても
ということで各地の計算配慮すればまだまだ十分改善できそうだってことがありましてこの辺は
あのー集まるのかっていう意味で
なかなか興味×結果だと思いも
でえーとんでも時間がじゃ今実魚がしますけれどもえーっと本発表では識別モデル三えサポートベクトルマシーンを用いてえーと音声認識データーから無関係な固有表現抽出する手法についてお話をさしていただきましたま私もまー程度確信の補正というその音声認識や価値が間違いだって僕は
えー
分かってま重要なんですよということ
以上で
#############################


#############################
# query = えーとま最近本人え音声認識が時こうま色々とこれ使われるなってきているそう第二成分多いような気がしているんですけどやっぱり雨がうまく認識されないってことは結構あってえ例えば空間Ｇが間違っていたりとかえーまそれよくあるんですけど後は思っ全然違う単語にと認識されてしまったりとは指定違うんでこうなくなってその乗ってもちょっとよく分からないですけどまそのようにいるその高認識が起きてしまうようなま原因は何であるかというのが次第です
# rank = 1
# slide = 13-11_fix.match_word.jout.txt
# value = -3.58948370405545
#############################
はいえー御紹介ありがとうございます
えー単語空間と音節空間を併用した音声と決めえーっと検索手法への
で潜在的に解析の適用という題目でえー名古屋大学の一日県が発表さしていただきたいと思います
えーえまず初めにえ音声だというような記録編集機の構成の文えインターネットにおける評価えーしなあーことキャストの九九により
えーマルチメディアのコンテンツは増大しているということが起こっています
でそこで問題となりますのは
ってコンテンツに使用された夢や
タイトル綿などのえ達成頼みによる検索では
え目的のコンテンツに辿り着くのが困難になってしまって問題が挙げられます
えー
でそこでえ話し言葉含むコンテンツに対し
で音声認識により
コンテンツの内容テキストとして書き起こし
でそれをメタ情報としてコンテンツに付与することで
でそれを元に目的のコンテンツを検索する
というです
え音声ドキュメント検索に
液体が高まっています
でそのような背景の下二千一二年現在の方作っとして
え音声ドキュメント検索タスク
が開始されました
え以下の三つのさ二つからなっておりまして
え講演音声から単語を検索するＳＤＴ
え検索時により
えー公園や講演文の一部を検索するで寿司屋
クエリー単語が最初声に出現するかしないと判定する
対立地域の三つからなります
って今回私はこのＳＤＲ
に参加しておりますので
でこれに関して説明したいと思います
政治家のタスクとしましてはこのような公園道がありまして
えこれを音声認識率により
ってドキュメント
書き起こします
えそしてえーこれに対してま例えばですが音源定位を使って研究を知りたい
里のようなクエリーが入力され
でそれに関連するテキスト
というのを検索する
タスクとなっております
えーっとえこの
音声ドキュメントは
上の式
音声認識率を用いて書き起こしてありますので
で認識誤りを含むテキストの建っておりますえー
えーそのような認識誤りを含むテキストに対して
え頑健なテキスト検索を
行なうシステムを構築するというのがえー研究の目的となっております
一停止される点では予め音声認識結果が提供されており
で単語Ｎグラムやえー音節Ｎグラムによる認識結果は
で提供されています
で我々はえー検索するにあたりえーベクトル空間モデルってデーターベースモデルを用いているのですが
知ってそれは検索対象となる文章を単語の集合と見なしてえー
で文章中における単語の頻度など要素とするベクトルとして表現するもので
で例えばプラスＹを表わすベクトルｄｉ
って言いますのはえ要素としてえー単語が存在するかしないか何人一
八
えーえ単語の違い消え二ＩＤＦ値
え四つの事例ＩＤＦ値などが用いられます
えっとな索引語の違いによりえ複数のベクトル空間を作成することが可能です
えー
二と述べ
それを
えこのように並べることで
えーコーパスを表わすえーベクトル空間を構成し
んー
すえーベクトル空間モデルによる検索ではえ検索クエリーを文書と同様にベクトル化します
そしてえ先程のベクトル空間に対して
えーえっくえベクトルを入力して
その文書ベクトルとクエリーベクトルの
距離後方に基づいて
検索結果を出力します
えー
えその距離尺度としましては
でこのように表わされるような
えーサイン
距離尺度が用いられます
えベクトル空間モデルの問題としましてでクエリーの索引語数が少ないという問題があります
えーええ鍛えると捉えられないんだと内乱の平均定位数はえー四．九五と
んえー少なくてえこのような問題に対しては
クエリー拡張を用いま
また
えーっとーえ三つの単語が
生の索引語で表現される
という問題が挙げられます
でこれ例えば車後自動車というのはま同じ意味を表わしているのですが
えーベクトル空間モデルベクトルの違う要素としてえ扱われてしまうので
そのような問題に対処する為にえ全体的に帰っ
後
勿論
でえー拡張の
流れとしましては
まずＬから関連文書をしようとするのですが
で例えば音源定位を使って研究をしたい
という整理が
えー入力された場合
その辺が名詞
そんでえー一研究を用いて
って別検索を行ないえ関連文書というのを
ＨＴＭＬ形式でえー人でしてきます
そしてえーその中に含まれる単語
というのを
えー取得して
あってえー整理するなどと同様に
って拡張ベクトルベクトルそしてえー表現します
えー
でそして元の定義ベクトルを
えーっとー
え私のベクトルをえまこのような式で表わされるえ特徴固有ベクトルとして
で最後精神でその拡張クエリーベクトルと
文書ベクトルの
えーくさい類似度を計算することでえ検索を行ないます
えっとえー一般的にこの線形補間係数αというのは
で全てのこれに対し同一の値が用いられます
ってしかしえー五つのαの値っていうのは
データー検索い
検索対象文書ごとに
で異なるという風に考えることができます
言ってそこでえーっとこのような式であられるそう年齢っていうのを
仮定します
んえ従来の手法では
でえー文書ベクトル
んああ一九五〇である
えベクトルがえ文章を表わすモデル
東なるの
に対しまして
えーえと我々が提案する手法では
この辺というのがえ検索対象のモデル
となるように考えることでえー
一え最適なαというのを求めていきます
えーってモデル平面とえー文書ベクトルが近くなるようにαの値を推定します
で具体的にはこのように文書ベクトルがありましたら
そのようなえーこの
超平面に対して
って水洗
えー
ボールをして
その生成なしのところに拡張クエリーベクトル
一の延長線上が来るようなαを求めるという
ってことになります
えーえーこのαというのは解析的に計算することが可能でありえそれを証明しましたのでえー
その携帯式に違う
で出力されたαというのもこの拡張係数として用いたえー線形補間形成として用います
一つにえー全体的に帰ってきた
えー
んえー文書により自由を
えー特異
分解することによってまこのような三つに分けます
えー理由はえ二．五からは生成規則起きて
えΣは二と一の対角行列
あるいは文章表現するって一言でいいです
え特異値が程言えると言えるで張られる概念空間へ
このような
気を持っていることでえー文書ベクトル
え拡張えーベクトル共に
え概念課題としたえーします
んーそして
っていう自然とえー削減された概念空間で
えー文書間の類似度を計算して
で検索を行ないます
えー
が提案手法の流れをえー見ていきたいと思います
言ってま隣り講演動画をえ音声認識し
えベクトルに直し
．してえーベクトル空間を
結構精神
で
でこのようなまクエリーが与えられた時に
えーＬＬから入ってるかと
小行って
で白色レベル〇作成します
そして
この拡張区切りベクトルと
えー文書ベクトル
距離を計算することによってえ検索を行ない
でまたで音節データーに対しても同様の
ことが行なえることができ
で音節ベクトル空間
と
フレームと
えー
もえー
んー
んー測ることで
えーえ検索を行ないます
更にえーと高専の×検索語を可能とする為に
えこれらの
二つの距離を
えー統合する
方法をえー提案いたします
えこのような距離一
えー計算される距離に対して
ある重み
方を付けることでええー取り方をします
一つのデーターなさいというのは
わら一となるようにえ指導で設定いたしも
また
そのような
えー音節空間の前に全体的意味解析を
って用いることで
え概念空間での
検索を行なうこともできます
で後元です
で実験条件はえー二される内の音声で決めた検索タスクに従いました
で評価を開発セットである捉え何と本評価で使用された方もあるのに対して行ないました
一えー対象となる音声はえー実際天皇がない際において使用された音声認識結果で
で評価尺度にあのピッチを用いました
で適応データーはえー対象講演数が二千七百人
えドライバーにおける系列が三十九
え本御覧におけるて一八十六
えーえ音声認識はこのような条件で現われています
え索引語の決定方法としまして
え単語ベクトル空間モデルにおける索引語は
形態素が名詞アルファベット
多感な語の単語を用いました
えー音節でする区間では
えー
音声認識結果のトライグラムを抽出しえー索引語としました
で索引語の数のベクトルの次元となるんですけれども
それはまーこの表のようになっており
で重み付け方法としましてはえ他の三つを用いました
え単語の認知につい
単語の後に二ＩＤＦ値
で音節の二回に二
で音節ベクトル空間モデルでは八ページは予め平仮名ですね変化して
でこちらが取ら選んで求める結果となって
えこの四つの
えー検索結果を求めるんですがまず一つ目に
え各ベクトル空間モデル
え重みや索引語の変化に対する結果
んー検索へ拡張に対するえー結果を
で単語音節区間に〇歳を適用した時の結果
えーええ距離を統合した時の結果
もう
えー求めました
まずえー重みの変化による結果です
えこの表はうまくが最も高かったＮベストのＮに対する結果を表わしているのですが
この表から分かるようにえー単語の境界ですし
二時が最もおー
えー精度が高い
ということが分かります
って常に検索入れた後に対する結果です
でこちらは線形の関係つあるかを〇．九と固定し
それで二つを変化させた時の検索精度で
で図からも分かるようにえ八から二十五文章
ってえー性能が高くなっており
んでこの辺りでえー索引語に
資料である
単語というのが十分に取得されたのではないか
っていうことが考えられの
また
で三十
文書近くなってしまうと性能が違ってしまうのですが
でこれはえー索引語に必要ない
余分な
単語までえー持っ
できてしまったことが原因であると考えます
ってついに文書数を二十一と固定して
んでαの値を変化させた時の検索精度で
えーえこの図からも分かるように拡張ケースがあるかというのは
まー
えー選挙があって酒というのは父の好きなえ的な線形補間ケースである
ということが考えられ
で次に新たな値を適応的に変化させた時の結果です
えー図から約二十文章までえ性能が向上している
のが分かると思います
でしかし一般化を固定した時よりもえー検索性能が全体的に低い
という結果となってしまいました
えーこのαっていうのは先程も説明し
回したいように書く文章を書くということに
最適なると
計算して
で用いているものなので
で結果あー
検索性能が向上することがえ期待され
単語ですが
ま結果下がってしまったということでもう少しちょっと検討する必要があるのではない
と考えています
え次にえー潜在的に解析を用いた時の結果です
えー左側の図がえー単語をベクトル空間モデルに対して〇歳を
適用したもので
えー見て分かるようにえー実験を削減していくことにえ性能が低下してしまってるっていうことが分かりまー
でこれはえー単語と名詞の共起関係を適切に捉えることができなかったのではない
と考えています
また右の図は音節に対してＬＳＩを適用したので
え図から分かるように
で七百六十八次元まで
で性能が向上している
ということが分かります
この音節というのはま元々いよいよのないようなえー
えーえ用いですえー
であり
まそこから何かしら潜在的内容
設定する
まこのように
性能が上がったのではないかと
考えているのですが
えーっとまだその軸にどのような単語が近似されているとか
など
えー細い
検証できていないのでその辺をもう少し見ていきたいと思って今
で次にタイトルの統合です
でこのまずデーターは分かり易いんですけれども
え単語ベクトル空間の一日
単語ベクトル空間がしえ二ＩＤＦ値
捉えこれは口調
を行ない
えまたえ音節
ベクトル空間
後ＦＩＤＦ値
で先程の結果から音節に対してはおける最大有効であるということが分かったので
で音節に対してはえＬＳＩたり後
の結果を
えー
求めました
でこちらが取り騒音の結果です
えー図から分かるように
えっとデーターはえー突然
が
てデーターで前に
の時がまこちら
えこのような値となり
で最も精度が高くなりました
え拡張のみの結果では
えー〇．三五四三
であるのでえー
このことからも距離を統合することが有効である
ということが考えられる
でこちらはえ音節に対してＬＳＩを適用したのです
ってこちらではえっとデーターはえーと数が八〇．三〇．一の時が
で最も精度が高いという結果が得られました
でこの結果というのはえー全ての実験条件において最も検索性の高い
という結果が得られました
このことからも
各ベクトル空間で
えー検索性能の良いものを統合すると
えーっとお酒に
って性能が高まるのではないかということが
えー考えます
父はえーっとどうなエラーの最適なパラメーターを用いて
てそうなんで
評価した時の
ものをえー示します
えーっと検索方法としましてはえ手法一では
で単語正解率でえページを拡張した紙のもの
公には
単語ＴＦＩＤＦ
単語二センチ
で音節ＴＦＩＤＦの距離を通したもの
って手法三は手法にに対して音節に
で連載を
適用したものの結果となっています
えいずれの結果も
展示されないによる影響されたあーベースラインの結果よりも
狭まっている
ということは見て分かると思います
でしかしえドライなんで最も
というのが高かった
えー手法三
の性能がえー低下してしまっている
ということがえー分かります
え考察としまして
って手法一二ではえっと×らと同じ傾向が見られます
でつまり困らにおいても
栗が口調と
で距離を統合が
有効である
ということがあって今
でしかし
本本ぐらいで最も性能が高かった
そのデーターの重み
というのは
えー空選んでお父さん〇．二に対して
〇．五〇．一の時であり
このことから
もう少し距離の統合は
の重みに関する検討が
資料である
と考えて
またえー手法三ではま距離統合時に音節にえー最適をしたものですが
でトライアルと違い性能が低下してしまいました
でこれはほん村における
音節ベクトル空間モデルでの検索結果に原因があると考えておりまして
で次のスライドで
示します
えー
え方がある欄における音節ベクトル空間モデルに
えー〇歳を適用したものが
この
結果となっているんですけれども
まー初めは
こうして行動しているんですが
えー
えっとー次元を削減することにどんどん性能が低下してしまっている
というのが分かります
でこの七百六十八次元というのは
でドライバーの時に最も性能が違った時の
でえーパラメーターなんですけれども
えーっとーま長さ一のかなり低い値となってしまって
でこのことからも
クエリーにより
そのー
ＬＳＩえーっと結果って言った音節内する結果ってのはそういうしてしまう
ということが
え示唆されます
ではまとめです
えー音節ドキュメント検索における音声側面と検索における
検索手法
に関する検討を行ないました
で単語対えー二ＩＤＦが最も良い
精度を
示しました
またえー検索へ拡張の有効性の調査を行ないました
で栗特徴は
て困るなそれらどちらでも有効である
ということがえー
えＬＳＩを書くかに適用することによれっていう構成の調査を行ないました
えーとイランの音節に関しては
えー有効で
有効だった
という結果を得ました
で
えまたえ複数のベクトル空間で計算された類似の
とうとう母音の有効性の調査を行ないました
えートライアルの最適なパラメーターでは
えー困るな
えーと評価を行ないました
ですなけれ統合する手法っていうのは
でクローズドオープン共に
で高い性能を示したので
え有効であるということが言えると思います
で今後の課題です
えー
とαの値を適応的に
変更する手法
というのはあんまりいい結果が得られなかったので
もう少しまだ検討しすみたいと考えて
えー
またはえー音節ＬＳＩでどのような定位精度が向上しているか
いや
で潜在的
内容物軸にどのような方が気にされてるのかっていうのを
で確認したいと思って今
えまたえー距離当時の
で穴データーなっての検討を持ちたいと考えています
え発表は以上ですえ合成処理音ございました
#############################


#############################
# query = えーとま最近本人え音声認識が時こうま色々とこれ使われるなってきているそう第二成分多いような気がしているんですけどやっぱり雨がうまく認識されないってことは結構あってえ例えば空間Ｇが間違っていたりとかえーまそれよくあるんですけど後は思っ全然違う単語にと認識されてしまったりとは指定違うんでこうなくなってその乗ってもちょっとよく分からないですけどまそのようにいるその高認識が起きてしまうようなま原因は何であるかというのが次第です
# rank = 2
# slide = 09-08_fix.match_word.jout.txt
# value = -3.62196884929979
#############################
えっとー資格をするのカメラと申します
えーとですねいたします
えーっと本日は
えーっと講義音声を利用した後
一九．三等分割と検索について御報告させていただきます
えーっと
えーま皆さん部分というようにえーネットワーク上に最近特に色んなビデオ教材があのー
たくさん増えてきました
えしかしながらなかなか学生さんがあのー使いたいという目的なもんなんなかなか少ない
いうことで
でえーまー実際に作らないとなかなかうまく教育とかに使い
でいざ作るとなるとね
え時間とか手間が掛かって大変
いう訳で
えー私共は
えー
登録が遊び行数は幾らまー普通の大学等の方で四録画したものを
えーとかをえー話題元に自動的に分割数いたしまして
えー
ビデオ教材作成のテーマを
減らしたい
それから更にえー分割した
んえー子音の音に
えーっと
実際にえー見る時にそれをまー検索したいってのはえー目的で二
あここで子音と申し上げてるのは
えー
トピックをモデル化を全く知らサブトピックの区間をえここでは四と呼ばしていただいて
で実際にはこういう風に
えー自動的に
えー
子音境界が求まったとしますと
でこの中から練習とか不要な部分を削除しますと
えー
最低限のビデオ教材化できる
いうことですがこの
新聞月一を決めるのは非常に
えー大変何回も
でえー同じところを見直してあここだっていう風に決める際の画面ということな
でえー以前にあのー御報告さしていただきましたえーこういう支援するシステムの内容なんですが
でまず最初ビデオ素材から音声の情報を取り出しまして
え音声認識をしてて
と情報を言って
でこれを元にして
えー子音の分割位置推定を行なって
えその中から
えふような身を削除すれば四状態ができ
まこのシステムにつきましては
えーここのＵＲＬの方で
で公開させていただいており
でこのシステムは
え続いていやい対応の
音声認識ソフトであればえーそれでも使えるようになっておりまして
えー
語彙音声認識を使った
やり方とえ単純にポーズだけを使った素早く
買うことができればちゃんとお二種類用意をしており
で実際の画面はこのような
えー関係して
えーっと
ビデオを指定してえ分割っていう風にしますと
えーこういうシーンが出てきます
当該の信用をクリックしますとおー再生されますので不要であれば削除ボタンをですだけで
最低限のものができ
いうのはえー理想でござい
でえー本報告では
あーのーこれまで進めてましたあの素材として使ってました石川高専のえー二料理を言いますか本にビデオ
に加えまして
えーと
はい提案しテニスがあって大学三のえーデーターベースをえー利用させていただきまして
えこの二つを素材として
でえートピックのえサブトピックの分割と検索について調査した結果を報告させていただき
えまずサブトピックを分割につきましては
で二つのサブトピック分割手法を比較した結果
それから音声認識性能と方に携帯の
影響について御報告いたし
それからえーサブトピックの検索に関しましては
えーキーは父を実際にえー学生さんとかが
日は父して
えー指定する
ものと
え実際の発話内容との関係
それから音声認識性能の影響について御報告さ
まず最初にソースｉに関してですが
え石川高専の傾向にビデオにつきましては五名の教員による九十分のおー
えービデオでござい
でこれをえー接話型のヘッドセットを使用してますのでえー雑音との駅は殆どは
え音声認識には二つの音響モデルを使ってまして一つは
新聞記事
による
えー二千状態一録音を捉え方を持って
それからもう一つは
えー
ＣＳＪ
の
でえーっとー
音響モデルを
使わしていただい
それから
え言語モデルにつきましてもＣＳＪの言語モデルを使わしていた
でえーこのビデオはえーっとそれぞれ平均しまして各五百文ぐらい
で
えー
変わり
なってきた練習どうも含まれてまして
えー少しゆっくりしたケースです
それからえー
共通性が良い評価五って書いてますがえこれは最終的に子音としてえー
好奇
切った正解の数が二十
それから平均して
でパープレキシティーは四百ってことでちょっと音声認識としても難しい
え未知語率は平均で三．四ません
で実際音声認識をしてみますとえ新聞記事
で学習した音響モデルですという非常に低くてえー単語正解率で四十三パーセントぐらい
それからえーＣＳＪでえー学習された音響モデルでも
で五十三パーセント
ということで
えーっとー
なかなか厳しい
えー認識結果
で一方
えー
クラス二が第三のえー日本語をこう利用性やコンテンツコーパスとしているし
後英語話者六講義を使わしていたら
で学校にはあの前半後半に分かれてらっしゃるようで
えーそれぞれ七十五分
な旅行に文を使う
言わしていただき
で
でえー大学院の体の大き
でえーこのようなもので次子音の
えー分割位置を推定する訳ですが
えー
と二つの方法試しました一つは
えーここですと類似法と呼ばしていただいてますが
えー隣接してる新刊が
えー似ていれば
もう一つ付きの非
似ていなければ新聞月一月
存在するっていうようなえー単純な方法
でえー身を比較する為にそれぞれの子音ごとに
獣をインデックスが必要になりますがま通常使われるなら一ＦＹ
先程ちょっと話がありましたけど
えーっと
これはあー五四へあのー独立成分分析を用いた指標をおー使いまして市場のサイズを役さんとしており
性能的にはまーほぼ同等以上
ぐらいの間
で簡単に申し上げますと
えーっと冒頭文の
英語の頻度行列を
えー
話題と文
またえっとー後
二分割するようなえー方法に最終的になった
これによりましこの話題数字に設定できますので
でえー好きな自分
でやることができ
先程一番こうだと一万次元になってますがえここで百円ぐらいすると百二年でお様
いうことで計算時間がない
それでえーと
その進化を比較する度には八名を使い
んー身が似てるという個体表現が大きくなるんですがえー二なければえー小さくなるということなので
えーこの
四年の総和が最小になるように影響って計画法でこの切れ目を決めてやるというのは二十です
次にあの統計的手法について
えーっとこれは打ち合わせの方から御提案アーティスト分野で使われている
提案されてる方法ですがこれをえーのんびり音声に適用した結果です
でえーまず
えー単語の並びの与えられ
でこの単語の並びからシーンの切れ目を決めるという問題で単語の並びが与えられた時にえーっとそのシーンの切れ目
が最大になるような確率
そう最大なるように身を決めてやっ
いうことで
でこの中のえー分子の部分が最大なるような
セグメント一を決めてあっ
んで
テーマ細々したところは省略させていただきますけれども幾つかの形で
例えば
えーっとー
確信
のえー
単語まー他の
Ｃには依存しないとかっていう独立性の
えー
買ってきます本来は成り立たないと思うんですが簡略化の為に幾つかの
えー過程をえー仮定しますと
最終的にはこのような式で
えーこの
確率が計算でき
でこれはえ一般になっプラスぼうっと
えー
形で知られている
で方法で
えーっとーが五人の
えー単語数暮らすこと大語彙数分の
えその
子音内での
同じ単語数プラス一
これで
えー
この確率を
えーっと
金水一は
で今の
ちょっと細々とした日はえこちらの方ですけどもう一つの
えーっとＰＲえすの方は
単純に聴覚
で
与えて
でこれも同様に
えー対数化してから動的計画法で
えーっと
この確率が最大になるような
えーえ数を決めてやればいい
でこのような二つのえー方法についてえー四分割実験を行ないましたま水しか合成のビデオについてですけれども
えー音響モデル一
で横軸がえ分割五で分割数を文の数で
正規化したもの
例えば
凸のえー講師が百文感嘆文百文だとしますと
でそのうちえー二分割したら
分割に連れて一っていうような形で
でえー当然文化率あ分割分割三つ挙げますとえーこれがあのー
再現率なんですが際に繋がって
でえこちら適合率です
でえーこのおー
我々のこの研究ではえーっと適合率
よりも
でえーこの再現率の方重視いたします
これは実際ビデオ編集する時にシーンの切れ目がないと非常に
その切れ目を入れなくちゃいけない計算量は非常につらいので
でえっと再現率はなるべく高い方ができれば百パーセントになるとい
これが五十パーセントしかないと
半分は自分でシーンの切れ目を決めないといけないということになり
一方適合率が
えある程度までなら低くても無視すれば良いのであんまり多過ぎるとなかなかにづらくなってしまいますが
ある程度までであればもしすればいいのでそれ程気になりませんが適合率は
再現率の方はなるべく若い方がいいということで
ですがちょっと
あの再現率の方を中心に見てまいりたいと
でこの赤色のグラフが
えーと統計的手法による菜園
それから青色が
えー類似法による
え再現率です
でえー比較していただくと分かるように統計的手法の方が
えー少し良い結果
で音響モデルについてもえーこれは
えーっとＣＳＪで学会講演で学習したもですが同じ傾向が出て
更にえー書き起こしテキストについても同様に統計的手法の方が
えー良い結果が得ない
ま以上
のことより
えーっと統計的手法の方がＢ地方よりも
えー良さそうだということが分かり
次に
え音声認識性能の影響について
えー
調べました
え同じ結果なんですけれども見方を
グラフを買いまして
横軸が
えーっと先程の分割率ですが
えーっとー赤色が音響モデル一
えーそれから
えーっと
次熱が青色のものな音響モデルに
それから
で紫
のものな
えー書き起こしテキストで
えーっとかなり音声認識性能かなり違うにもかかわらず書き起こしテキストとほぼ同じようなカーブを描いており
でこの原因といたしましてはえー今回適用した方法というのはあのー母音の情報を使っていない
んで
同じようにややもあれば
でまー問題ない
いうようなことが気にしているの方法もある
んでえー
それを確認する意味で幾つかのシミュレーションの実験を行ない
これは書き起こしテキストをおーまざっと
が誤りを持たせたものです
でえー当然置換誤りな
であっても
えー原理的には
えー性能が一緒ということを
え実際に試してみて確認
しました横軸が
えー置換誤り
縦軸が
で先程の分割一〇．五から〇．四までの平均の
え再現率
それからこちらの方は横軸が
えーっと挿入誤り
これは書き起こしテキストにわざと挿入誤りを
えー入れたもので
って挿入誤りについても類似の方ではほぼ同じ
えー統計的手法でも二十パーセントぐらいまではほぼ同じ
でまー
それ程大きく影響しない
それから
でえー脱落誤り
についても
えー二十パーセント程度まで暮らしていましたが
それ程変わらない
で更に
えー
とー
脱落誤りが二パーセントでえ挿入誤りが五パーセント五十パーセント
それから
えー置換誤りを付加した場合ですに混合した場合
ちょっと音声認識を
え真似たような感じですが
えーについてもまーどの
条件についても大体
それ程
で大きな変動はない
まこういうなことから
えー二つの音響モデル書き起こしテキストシミュレーションをいずれの実験を通しても音声認識性能の影響は
宮内っていうことが分かっ
次にあのこう二境界の影響をなんですけれども
えーっと
まず
これはえー四じえー子音による新聞かつ結果です
でえーこの赤色の部分な書き起こしテキスト
それから青色が
えー
と音響モデル一致による結果です
んんでえーどちらも
ほぼ同じ分かって泣いてまして先程の音声認識性能に相手をしないというのと
で同じ結果がえー提案し率が大学のデーターベースでも同じ傾向が得られてい
それから
えーこの図は
えーっと高い評価四十四．四日間で大学のえーこう来それから青色の方が石川高専のおー工程なんですが
音韻形態がかなり違うんですけども
えほぼ同じようなか方以外体を
ま以上のことよりいーこうにこう携帯の影響もえ少なく取ったいうことがあり水
んで
え次に
図はえー検索について
えー
まーこれまでの結果あるのでえー簡単に
いただき
えまず利用する情報としては
え音声情報以内にスライド情報などさまざまな情報を用い方法がまあのー提案されていますが本報告では音声情報のみを
えー使います
これはスライドを用いない方にもまー対話したいってこともありまして
え音声情報のみを利用します
それから未知語対策につきましても
でこれまでの御発表が色々あったように音素えー音素インデックスファイルを
えー生成ＣＤを抑える方法であるとか
えサブワードを用いられる方法であるとか
ま先程もございましたが
傾向に音声から上って一
体を検索して
検索キーワードから六ページを比較して両方を比較するような方法ですとか
っていうさまざまな未知語対策がえ提案されて
それからあのー最初の御発表にありましたようにえ検索テストコレクションが
えーっとそろそろこう愛されそうってことで非常に楽しみにした
まこれができれば
でこう色んな
えー
方法を比較検討し易くなるってことで期待させていただい
でえ今回は
行ないました子音検索の予備実験Ａでは
えー各子音についてえそれぞれえー指標を求めて
えーそれがキーワードについても指標を求めて両者を比較するという単純なもの
指標には一般的な二杯で二を用いて
材料こちらと申し上げました場合冷えてもちょっとやったんですが
あまりまたうまく行ってないって言って
ここでは出てき
それから
えーっとこれは子音検索実験の結果ですでえーと縦軸はユーモアがあるということで
平均逆数順位んをえー
がありました
でこれはえー一ですとえ全て第一二三
〇．五ですと
でえーっとー
逆す七で二ということで二平均的には二ぐらいに
その検索したものが出てくるというな指標でござい
でキーワードとしては
で一つだけ指定した場合とか二月から一つまで
え横軸が言わですが変化
でえーこの最初のピンク色のものな
えーっとえ足ですか大学の四てるＣの書き起こしテキストによるもので
んで
でえーこのえーブルーの
ハウスい水色のものは
え石川高専の書き起こしテキストまほぼ同じカーブを描いておりまして
っていうまーあるＲがほぼ一致にしたいってことで
えほぼ一致入れてというなことで
えー非常に
高い結果で
えーところがえーこれについ
誰の音声認識
えテキストを使いますと極端に
触りまして
えーどちらも
でえーこのぐらい顔をしてしまー
まーちょっと
見た目がかなり川するんですけどもＭＲＩをなのでえ健康で主にいー何やってるようぐらいの八十
それからえーっと次にですねあのー実際にはあの学生さんがキーワードをしていするんですけど学生さんは色んないわゆる
否定のし方をするので
で実際に被験者そして学生さんに対し過去数年の五年生ぐらいの
学生さんに
キーワードを
でえーそれぞれの子音ごとに出してもえー
でえー出してもらってそのキーワードを使って実際検索してみたのが
えーとまずこのグラフですこれは書き起こしテキストなんて光っとしてはこの一番上のものとおー
このぐらいで
このぐらい触っ
いうことですね
で音声認識についてはこのタームから
この確認をしてしまう
でえーどうして落ちるのかなっていうことで
えーちょっと
調査したのがこの表です
でえー最初は当然未知語があるとそう分は確実に落ちてしまういうことでこれが
わりあいとしては平均的二十三．八パーセント五歳
一ワードの総数は
ここに書いてあると
これ百パーセントとしまして
えー一三．八パーセント程度の未知語で音です
それからえーと二視覚音声の場合にちょっと特徴的だったのは抽象化
でここであったさしていただいてるんですが
これは何かと申しますと
えー直接発話していないんだけれども
で発話内容を総括したり
ほイベントを表現したい
するような言葉例えば練習とか実習とか説明とか
例えばそれからこれこれを説明しますっていう場合もあれば言わずに説明する
んとま
それ説明っていう言葉は
でえー頭の中に出てこないんだけどまーちょっとした何とかの説明になっ
何とか飲酒
練習これからします理由が珍しくて
えーこれやってみましょうとかっていう場合が多いそういうことですそれをちょっとここでは
抽象化という表現で表わさしていただい
でえー交通の場合はそいつが多いもんですからって求まって
えー一一パーセントぐらい抽象化あるいはえー
まー内容をある程度理解
えーできると
えーより
あのー
感覚的には
体の概念的な表現をするのかなというのも
えーちょっと
そういう気もいたし
それが表現の揺らぎってのは
で表わしますという表現ていう言い方
あのーそういう表現の違い
んで
でこちらがあってただしえーい一日で大学の方の
えー
実際にどういう割合であったか
でえー未知語をは一一パーセントぐらいで
って抽象化は非常に少なくて
って言って八パーセントです
でこれはどうしてかって言うとま練習とかするのは少ないということと
えーそれから
えー多分
あのー
学生が五年生なんで大学院の推量いきなりＴでも
マイナスというよく分からなかったこういう
要するにそのまま
えー出てきたことをそのままいーワードとして書いた割合が多かったのかなというしない
後でしょうからですから
種抽象化っていう表現が出てくるのはこう三によってかなりこうばらつきがあるのかな
できない
そのデーターとしては
まだ少ないので何とも言えませんけれどもそういう傾向が
で以上まとめますと
えー
とー
えー
統計データー丸四の分割に関しましては統計的手法の方が類似法より良い結果でした
でえー音声認識性能を八五に携帯の影響は少ないということがあー確認できます
それからえー検索に関しましては
で三四五ばかりではなくて抽象化表現への対処っていうのも場合によっが必要になるかもしてます
それからえーこれは前から言われてることですが音声認識性能の影響はやはり大きい
えー
っていうことが確認されも
はい以上でござい
#############################


#############################
# query = えーえーとあのー言語モデルのパープレキシティーの話なんですけどあのーま言語モデルの性能を評価する時にパープレキシティーでギャルとかまパープレキシティーでいうのは確かでえーっとーま直感的にユーザー次の単語の予測能力ってことでまー小さい方がいいとかそういう値だったと思うんですけどまず勉強したと言うかまーえーまそういう知識まーあるんですけどまー実際の研究文の分野とかま応用場面で言語モデルってが出てきた時にパープレキシティーはうーパープレキシティーの値はそれぐらいなるのかなというのを知りたい
# rank = 1
# slide = 11-02_fix.match_word.jout.txt
# value = -5.7343625950828
#############################
小学校事業の音声認識の為の言語モデルの検討という
項目で
えー二分ぐらいあのー先データーえー発表させていただきます
近年音声ドキュメント処理の
研究が盛んに行なわれてあります
大学長野高等教育言っては
無事用のえー時代の教材や
聴覚障害者の情報保障として音声だけに他社員の人が
注目されています
一方学問が必要なのでその教育
特に小学校におきまして
はいＣＤをええー解析および良さ教育の
えー
えー導入が推進されております
しかし音声の検定社員が
処理に持たずえ教材の一．七を御覧になっ行なっておりません
本研究では小学校二あの音声を対象とした音声だけ面で処理にえー重要な音声認識について研究を行ないます
具体的に言いますと
小学校二あのー
言語的特徴をモデル化つまり言語モデルの学習について研究しております
まずえーしょうが個人であのー特徴について述べさしていただきます
えー小学校二やっていますのは子供は理解できるように勧められたね
子供に馴染めないとは
基本的に使用されません
教師の発話スタイルとしましてえー自発的な発話
えー話し言葉
えー呼び掛けを確認を多く含む傾向があります
これらのことから子供に大水
イタリアさを提示された発話であると考えられます
えー
これらのえーそのえーまー話しえーこれまでの話し言葉の音声認識を大切さ異なる下の
音声とは健康的にも音響的にも異なると考えられます
その為
従来の音響モデル言語モデルそれらを学習する為のデーターを使用しましても高い認識精度はえー得られない可能性があると
その為えー本研究では昭和五十八音声に含まれる
このえ話し言葉表現や子供向けの表現
の言語的特徴をモデル化する為の言語モデルについて研究をします
こちらはえー本研究でえー
用いた事業の一なくなってまして
えー今回
地下をえー全体で一三件の
治療を使用しております
その後
一意見が特別進学校での字形なっていまして一部は中学生や高校生を対象とした次元となっております
火は小学校二秒の音声認識用言語モデルの学習について検討していきます
先程述べましたように小学校事業と言いますの話し言葉この下の表現
が
が生まれております
これら二つの表現をモデル化する為の
部活えー学習テキストをまー生成します
そしてえー言語モデルを作成にするあっえーするにあたって必要な語彙
もう
検討していきます
そしてえー言語モデルの作成
評価を行なっていきます
まず最初にえーこの文的表現を学習する為の学習コーパスについて検討していきます
今回
この結果を
表現を学習する為に
えー
この音源ウェブサイトを用いました
今回えー収集ものとしましてえー
えーでね地形集団子供ですとやる気データーの方から生成しております
まずにえーＮＨＫ性が子供に思っていて
説明していきます
こちらはＮＨＫが子供向けに行った透明番組の内容が公開されております
内容としましてはニュースや出来事についあー出来事ような話になっについて
大体あります
えー
九番部分え形式でえーテキストは
表現されております
その中でのま呼び掛け表現や
僕のケースがあります
っていたしましてまこちらのようにまー
えーっとー入れます
九は体が掛けられ
があってえーそれの回答と言った後になってます
鉄の
えー
質問えー項目があってそれの階層的なものがあります
自分の中にあり自分二十一が話し言葉表現を含まれてあります
収集機関としましては二．六年一月から二千二年一年次になる前まで
えーとなっております
次に約一について説明さしていただきます
こちらは表一年生の為に得られた方食べたいとなっていまして
この結果して適切なデーター組まれておりません
比較的な株やえ元の形式の運転手が多いようになっています
っていたしましてこちらが今クイズ形式の文ではえー
って言うんですでえー私えーテーマ
があります
しかしまーこれらは画像データーえープラス一で作られている為ここからえー
適当であるのは困難であります
そこで
本研究ではえー時代でのまー二つの
に着目しました
日本語がこちらのようになっていましてえー
こちらは小学生真で
となっている為え基本的には
話し言葉となっております
収集機関としましては二千一年九月から二千一年中にはなかなか分かります
ん次に日本えー話し言葉表現を学習する為
日本が日本語話し言葉コーパスとしましてあります
こちらは日本でできる第一語な話し言葉コーパスなってもありまして
僕はあの
講演前なえー人間を忠実に書き起こしテキストとなってあります
ではえー小学校二四の音声認識の為の要件としていきます
今回音声認識結果は小学生な利用すると考えられますので
えー未知語はえーまず
三学習の
感じがあ音声認識結果に生まれますと
．ま〇．七分もしないと考えます
そこで今回声が全て
かなり起きてるようにしております
声を作成するにあたって今回は形態素解析には
んえー戦前によってやっと
えーこの二つには見に行く場合を一．三一二を使用してあります
地名は二名はそれぞれ一つのクラスとしてモデル化しております
まず教育基本語彙内容について検討していきます
今回は小さくまた教育基本語彙を利用していませ
後は
装丁があって
それで学校での教育以上でえ基本となる声成人したものとなっております
それぞれまー小学校低学年
ショウガをこう違っていたえータグが付けられております
その中の本研究では小学校って訳えーっと
ショウガを高学年のものを四つあります
こちらの表はそれらしょうが固定学年高学年のえー
こういったえっとー
えー
企業の一だけな地形
の場合水を表わすものとなって
小学校って訳なんですがまー七割程度
小学校は熱ど八割程度のカバー率となっています
これらの語彙にはまー話し言葉表現のカバーされていない
ついだことや
話し言葉表現以外のまー子供敬意表現
のまー彼はできないとできない子がすありますのでカバレージが低いと考えます
次にえー保存形態素コーパスの利用について考えています
今回設定したえー七十一万単語から異なる単語を抽出し
声を達成してあります
先程の教育基本語彙よりも媒体のおー中でえーカバレージの
高いんですが
話し言葉表現が分かれていないんで
あー場合えカバレージは
自分ではないと考え
あります
次にえＣＳＪの利用について検討していきます
今回えー単語出現頻度Ｙって書い
以上の単語を選択してあります
それが今こういう時代えーっとーカバレージがこちらのようになっております
出現回数が五十九回以上の
後でカバレージがひ
ま九割
単語出現回数が五百七十九回以上の場合で
えー
カバレージが八Ｙとなっております
こちらは話し言葉表現も買わされている為日本えー小学校自由でえ用いられる
後は二十四次でえー学習不可能である
ないかと考えられます
更にえー健康は体分野設定について考えています
括弧五つのテキストベースで混合しますと
コーパスサイズが大きいＣＳＪの出現頻度の影響を受けると考えられます
その為今回は
ございますが五終わってから
作成した後にはこれが〇になってる形で
えー
後夜にあって今
残していきます
まずえー刺激での単語出現頻度にも
元に作成した文を用意用意します
次にえーその
遅延事例から発声した
各母音に
子供コーパスの声を加えたものを用意しました
更にえーこのＣＳＪ
に子供コーパスの語彙を加えたものに
更に教育基本語彙を書いたものを用意しました
そして各えー
えー母音
の日後
水こういった画像を調べました
こちらはとの関係を表わしたグラフとなっていまして×という方向に一日後
Ｘ一二方向にこういったえっとー
を表わしております
各個体で
えー
後後五歳で各
語彙語彙を比較したところ
ＣＳＪと子供コーパスから五四混合した場合えー未知語率が低くなる傾向があります
次にえー従来従来の新聞読み上げの音声認識タスクになりまして語彙サイズがこう全体二万程度で
後四文政治
えー音声認識用の言語モデルを作成していきます
まず午前の方なんですけども
知恵でえー考えて作成した文の中はします
次にえー二万ところなんですけども
最も未知語率が低いえＣＳＪでは子供もまえー
から達成した五四
使用します
これら二つの声でえ言語モデルの学習を行なって
きます
本題へえー人名等を地名はそれぞれ一つのクラスとしてモデル化してあります
バイグラムトライグラムの父は
ん設計となっております
括弧二の友人は鼻音れる方法を用いております
えー
これらの言語モデルは一単元の次元に対する
テストセットパープレキシティーで評価しております
この際に二語の確率は三四つに含めておりません
でそれぞれのまクリスティーの結果がこちらのようになっております
まずこの六形態素語はえー
の場合ですと語彙があー午前の場合ですと
四百六十七文
二万の場合ですと七百二十四．五となっております
今回えーこの形態素語パターンにしてるのでサイトから
振られているので
それぞれのパープレキシティーも調べました
その結果ええー研修が子供を二つの場合ですとをえーこれが古典ですと
五百二十．一
二番の場合ですとえー
はっていうようになっています
日本一の場合ですと
声がこの場合えー五百七十九．八
声が今の場合ですと九百二十五．一だなってあります
で一週間程ニュースの方には話し言葉は若干でも含まれている為
えー
二八二次元の確率が低くなったと考えられます
次にえー
ＣＳＪの前についてえー見ていきます
ＣＳＪの場合ですと
えー声が固定の場合ですと
三百文字にでも
二万の場合ですと百四十二．三なっております
やはりＣＳＪの方が
話し言葉表現を多く含む為子供時代とこは体の
パープレキシティーは低くなっております
次に
このリサイクル法この文形態素コーパスとＣＳＪは両方からこう言語モデルの
学習を行なっていきます
テキストベースで混合しますと
テキストサイズが大きい事件の影響を受ける為えー今回各言語モデルをまず作成してありそれらを
混合してやりました
こちらがその結果となっております
この結果を見ますと
ＣＳＪを七割
この文コーパスを三割でえー今後てる部分においてえー音の後歴史が低くなっております
各Ｎグラムでえー各年齢であのカバレージについても調べました
えー
皆様は語彙サイズ五千の場合
その他えー表は
語彙サイズが今の場合でなっております
共にえー
とえー保存形態素コーパスの捉え方は
他の二つのものと比べて低い値となっております
これはやはり話し言葉表現が
名前組まれていない為低くなったのではないかと考えあります
一方指令推定の場合ですと
話し言葉を得る為
この日表現
子供の時代と後は
のものよりも
トライグラムのえー
いートライグラムの値は変わっております
そしてこれら二つを今後はしたものは当然最もよく
なっています
これはもう
言語せることによって話し言葉表現やあー関係表現な旅行はモデル化できるのではないかと考えられます
次にえー先程のパープレキシティーの低かった
えーこの言語モデル
でえー各自の方に
で評価を行なっていきました
こちらがその表となっております
こちらはえー
語彙サイズは二万の場合においては歴史が低い順にソートしたものとなっております
まずまー今回後歴史が三千
三年生の国に
パープレキシティーが高いものとしていまだに
分けるとこのようになります
まー
パープレキシティーが低いものですと
医学的に頭では二パーセントえー以下
二パーセントですから一パーセント以下となっております
一方えー買い物ですと後歴史は三パーセントもしくはそれ以上という値になっております
発声えー未知語率が三パーセント二三パーセントいると
次に各次元ごとに見ていきますと
社会や算数
でまー未知語やあ歴史が低くなっております
え一方ちょうどホールや考えたので
高い道具を
といった場合でまー未知語率やパープレキシティーが高くなっております
これは今回設定した子供の形態素コーパスがニュース記事である為
社会え理解に関する情報は
後
四本筋がこう生まれる為
社会あーのパープレキシティー未知語がんーなったと考えられます
その為今後まーそれ以外の二
そんなにまーそれ以来の事業に近いデーターが少ないので
国語ええー関係者とホームのモデルがあーの結果が今後の課題って言うか
まとめです
今回小学校二あの音声認識の為の言語モデルを検討しました
ＣＳＪを用い用いてえー話し言葉表現をモデル化し
保存形態素を用いて
この研究では
モデル化しました
その結果
今後もまーこの表サイトを言うことによって
社会え三つの地形はモデル化可能ではないかと考えられます
一方国語や大変なので
えーちょっとホームランモデル化が今後の課題と言えます
さいえー音声認識による評価行なう必要があると考えられます
発表以上です御清聴ありがとうございました
#############################


#############################
# query = えーえーとあのー言語モデルのパープレキシティーの話なんですけどあのーま言語モデルの性能を評価する時にパープレキシティーでギャルとかまパープレキシティーでいうのは確かでえーっとーま直感的にユーザー次の単語の予測能力ってことでまー小さい方がいいとかそういう値だったと思うんですけどまず勉強したと言うかまーえーまそういう知識まーあるんですけどまー実際の研究文の分野とかま応用場面で言語モデルってが出てきた時にパープレキシティーはうーパープレキシティーの値はそれぐらいなるのかなというのを知りたい
# rank = 2
# slide = 07-12_fix.match_word.jout.txt
# value = -5.74888523227557
#############################
でここでございます
えーっと．二五各大学のえー特徴と申します
えっと本日は
えフィラー予測モデルに基づくフィラーが好き言語モデル
の構築という題目で発表させた
えー
えーと一番最初の背景なんですけれどもまーあのー嫌いに参加して出してみ字のことはできはないかもしれませんけれどもま
話し言葉に対する処理あのこれまであのーびっくり定常音
えと読み上げに対するま守備がまたその後も困ると行って活動の方がま話し言葉に対する処理ってのは主流になっていくでしょうってのは
えっとまー皆さんの相手喧嘩の一致するとこれはその
で
ところがですねその話し言葉を対象といたし理由を実現しようと思いますと
そのまー書き言葉と違いましては非常に上がったようなそのフィラーですとか言い直して使いより三まそういったようなまーあの
え文法的にあんまり正しくないまーそうでないあのーまー
そういうえーっと色々なさまざまな
えーと現象が発生しまして
でそういう現象の為にまそのえっと音声認識が非常に苦労するところであるというのはまー
んこのまタイトル皆さんの喧嘩にするところだと思い
でえっとーおそれですねあのー現在の音声認識システムいうのは
まーあのー統計的なえっとーモデルに基づくものが主流になってますから
でそういうその対応なえと話し言葉に対する現状取り扱う場合であっても
やはり
その大量な話し言葉の現象さまざま色々なものを全て取り扱っているような大規模なコーパスというのも四
仮に存在するのであればまー話で非常に簡単で
ペットそういうそのえっとーコーパスからまーあのー
話し言葉のような現象に
えっとー対応したえーっと言語モデルのまー作ってやって
でその言語モデルに基づいて
えー
音声認識というの行っていれば良いと思われるんですけれども
え現実にはそういうことはありませんでして
例えば一九九ＩＰＡ最大のその日本語話すことの方はそのでしてもう
持ってきましても
えーと講演音声す二千七百見て
ちょうど二五百二十三件で合計百七十五語一万語と
でそれがしまして例えばしあのーこれまでえーとー疲れて新聞記事で見ますと
まこのぐらいだ監督四十三つありまして
で最近ではもう上はから収集することができますからまー
この差というのはえっとー
開くことは気もする言語町でまロボットはかなり難しいと
でそれは深いどこに大きな原因があるかって言いますと
まこちらの日本語話し言葉コーパスの方は
えっとーおー非常に
日本語話すこと五千円あその話し言葉コーパスの構築というのはま非常にこうこうそのせいであるというところが問題なくて
でえっとそういうような背景でま対象とする為のコーパスを十分に得られない
まそういう状況でどうしていきましょうがあることがえー混合研究課題なってると
で
それでですねえーっとーという訳でまー本研究の目的なんですけども
まー太陽の日ごとのコーパスから
その話し言葉言語モデルはえーっと構築できればいいんじゃないかということを研究して
で
ただですねえっとー現段階ではまーもう少しここまでは言ってませんで
えー
体あの書き言葉コーパスの代わりにですねえー不正確な話し言葉コーパステーマに注目してる
えところは一体どういうものかと言いますと
えーとビデオとかこうへの結果形で作成されている
であのー
え成果のフィラーなどは話し言葉特有の現象までは書き起こされてないけれども
でその公園の内容は十分に書き起こされているような
そういったようなええーコーパスを想定して
んでってまそういう風その程度のコーパスであってもえー正確な話し言葉コーパスに比べれば
えー十分にえーと撮影コストが低くて
えーのんびりとこう色んなまーあのーかなりたくさんあの作成されておりますから多分それは言えると思うんですけども
それであのコーパスから
話し言葉言語モデルを作ることができとまー一十分に有用であろうと
でえーっとそういう訳でえーっとー本研究では
そういうえ不正確な話し言葉コーパスから
でフィラー予測モデルに基づいて
フィラーに対応した言語モデルを作りましょうということをおー試みを報告させ方
えっとまーあの関連研究ま非常にえーままずあのー
これまで存在するんですけども
えーそれともうどうして例えばえっとー一番典型的な例としては
えっとーおー何皿によるえーと第一語の日本語話し言葉データーベース文字が講演音声認識という研究では
で例えば
で話し言葉言語モデルに対して
え対象為の言言語モデルをえーと混合して
でそれ対象駄目に適用することやっと
テーマがえっと赤河原らによるえーっと二千五年前統計的機械翻訳の国に基づく言語モデルは話し言葉スタイルの変換という風研究では
えーと書き言葉から話し言葉への変換規則というもの
その統計的な機械を翻訳モデルとして表現しまして
でそういうえっとー各他のモデルを
えー
後もう一つのえー
ボイスの内容に対する
話し言葉と
書き言葉の両方のえっとーコーパスをえーと用意しまして
でその両方のコーパスから英語の翻訳モデルを学習し
で
そしてそのほ翻訳本を使ってえー書き言葉言語モデルを変換して考え話し言葉を言語へ変換するということであると
でまこういったようの取り込みがあるんですけども
えと我々の提案手法などちょっとえーっと方法が違いまして
えーどういうことやるかと言いますと
うまくえーＰがま正確に書き起こされた話し言葉コーパスと
一部屋あ応募は
手続き等の話し言葉のについ何でじゃ不正確に書き起こされてる一二六と記録もそういうあのコーパス
この二つのコーパス両親
でそしてえーフィラーが正確に書き起こされた話し言葉コーパスの方を使いまして
えーフィラー予測モデル
どう我々が見るものをえー
学習します
で
このフィラー予測モデルというのはえーと我々のページの表ではえーＰがあの
そういう箇所を決定する
フィラーそういうモデルと
その
せされた方に置かずに書いてどういうフィラーを生徒のニュースのよろしいかということを選択する
フィラー選択モデルという二つに文化として定式化して
でこのようにしてえ日が正確に書き起こされた話し言葉コーパスから
部屋と後モデルの学習しも
で
そしてそうしましてもう一つ四つのてましたこちらの
えー話す言葉に対するえー現象は正確には書き起こされていない
二二六はそう記録というような形の
えーく正確な話し言葉コーパスに対しまして
このプラントモデルを使ってフィラーの挿入すること行ない
でこうしますとえーこの
えー対象とするドメインのえフィラー付きのコーパスをいることができ
でこうしておきまして面が付きのコーパスから
えーまー通常の言語モデルを構築する方法をま適当にまトライグラム何でも構わないんですけどもそれでもあって
えー言語モデルを得るとでこれでえっとこのようなことやりますと
えー
本来話し言葉に対応していなかった
温泉正確な元のコーパスから
えーと結果フィラーに対応するモデルを作ることができると
これがえー我々のえーっと提案する手法になります
でそうしますでえーっとおーそれでえーっとじゃ実際のおーなりますかってことでえーっと日は予測モデルは
えーっとその
糖尿箇所を推定するモデルからえーとこれは仙台市で語彙を推定するモデルのえー二つに分割して定式化しており
で最初の方は条件付き確率はえー四Ｒと呼ばれるもので学習しまして
本の方はえーと普通の悪条件付き確率で表現しており
でえーそうですねえーと六つがこういうモデルの方は九二回検討しますかと言いますと
例えばえー例外としてえーこの場面を見ると．三〇六．三七文を考えていただきたいと
でこの場面を見るという点で丁寧語に対しましてえフィラーを導入しましてえーこの場面をでえー見ると絶対に風に
えー
えフィラーを購入しますそういうするという風れるのかな
でこれに対しまして
えーこの
最初に与えられた文
のこの部分をま手が〇．一分解します
で
その形態素列に対しまして
このフィラーの挿入されるかその
そこであのこの女子高に
この後に対しては
そこにフィラーが購入されるというラベル
このラベル五五つ半あのー
アプローチも
それ以外の形態素に対しましては
えーとここにフィラーの方にありませんからえここでえーとフィラーが挿入されないという字は四ということで食べる方あのー付与してま
でこうという風にしてえっとフィラーの方にありますそこでには得られる画像を与えるような形いーそれ以外に溢れラベルを与えてるような形で
えフィラーの方にお活動をえーぶんあの各形態素のえーラベルへの分類問題だって言ったような形で形式化し
へこんえ分類問題を解くというモデルをえ知られ方を使って学習すると
そういうようなえーっと流れになると
でえーまー水とかにつきましてはまーあの最近のえーと大自然言語処理もいる音声認識がま非常に
あその研究例があります
けれども
でそのーえーっと識別モデル
でこれでこの識別モデル使いますとえーま非常に
で一七十成績ができるということが特徴ですまこれは今回あのー
んえーとすいませんとその柔軟なえーとー素性設計ができまして
せっかくえーとまわりと少なめのえーとデーターにあの少なめの学習データーに対してマイクを良い
性能が得られることが知られてる
でそれでま今回の研究に適しているでしょう
いう風にして知られ方とか
でまーえーと一応ねその
形式とした効用が始まりますあのいわゆる普通のえーっとあの
ですあのエクスポネンシャルなあのー
表現形のあの典型的な形なと
で者としましてえっとこの四八個でえーとまー学習する
でじゃどういうえーと実験のあの構成しましたかということを説明し
えーと先程のえーっと我々の提案手法
遠いと殆どずっと司会者なんですけれども
学習コーパスとしてはえーと正解えっと先程で言いますと
正確な話し言葉コーパスに当たる部分ですけれども
えーこちらとしましてはえー日本語話し言葉コーパスから二千百五十二講演をえ文法気がして使いました
でもう度数疑似旅行へのえ当たる部分なんですけどもでこちらの方は本当にいいのここ五六を使えばまー今本当は一番都合がいいんですけれどもするとあのー
まだあのーん
えーデーターとかの関係難しかったもんですから
えー話し言葉コーパスから
えっと五百講演取り出しまして
そこから
えっとフィラーを取り込んで
でケーキが私のコーパスを作りました
これでえと先程の提案手法で言いますと生地のところこの部分は
こういう風に少なく八月のコーパスでもねえー少しだなとしていタイトル
でそうしまして
でこちらの学習コーパスから水があるうでえーっと実はそういうモデルを作ると
でこのフィラーそういうモデルをフィラー話のコーパスから
えーっとプラスの開発コーパスを作ると
別フィラー月の開発コーパスは言語モデルを作り
でこの言語モデルの性能というのはえー日本語話し言葉コーパスがやはり解けました五十講演のテストセットを使ってえーパープレキシティーを計算して
えーっと評価すると
そういうあのこう水な
でそれにですねえーっとーおーんどういう官能評価してみたんですけれども
まず
えーっとすあすいませんあの
えー
マイナスａのこのここの開発
コーパスの時に
えーＰが置いてえーこれのほいでもう一フィラーの方になりました
ですから
えーっとここのところでえとどのぐらいフィラーが
正確に
再現されたかってのは重要なとこだけ
んで
えっとー
その再現のどのぐらいで
勢力再現されたかというのは
で目標としては
この話し言葉コーパス元々フィラーを除去する前のコーパスある
このコーパスはあのまー
缶詰め正解データーはずですから
このコーパスを使って
言語モデルを作りまして
その言語モデルを作って得られる性能というのは我々の目標値ということになると
でんーそうしましても自分とこの表を見てい高いんですけれども
えーこの一番下の行
に書いたものがですね
でその
えー開発コーパスえっと
ＣＳＪのんえっとー後えーと五百公園から
えー
フィラーを全く除去せずにえートライグラムを作成した場合の性能で
でその場合えーテストセット単語列が七十六．七五なりましたこれがえ我々の研究の目標値になっ
でそれに関しまして
その開発コーパスから一旦
フィラーを取り除きます
ぼっ
その上でやはり除いた上で
フィラーがあ勝てば十分の一辺で怪我が発生するようでしたらそれ十分の一の確率でランダムに気が放映します
でそうしたえーコーパスを作ってやりまして
でそのコーパスから作った言語モデルってのはえ八十六．二ページですが生徒は別なりまして
こちらはベースラインになり
別としましてじゃえっとー我々が止まってますかって言いますと
えー提案手法その位置はですね暫くで
カップ
直前に形態素と思い形態素小売り店が形態素素性としてえーと予測モデルは他の方に面であのモデルを学習しますとえー最後の五七十七．三〇型が得られました
つまりこれはどういうこともあるかと言いますと
えベースライン
後ランダムにコンテキストを考えずにえーっとフィラーを購入した場合に比べますと
結構よろしいと
で各
えーその開発方向性発声される一番有意与えないと結構使いと
ということでですねえっと我々の提案手法はまーかなりえーっといい感じでえーそのフィラーを再現することができるよって異なる
でもう一つその音声認識っていうから考えますと
えっとー方もその問題にやらなければ決まってないかもしれませんので
でえーっとその
後ろの
単語の形態素というの行動しなくても
スポーツなかった場合どうなるかということが興味あるところを見ますけれども
そちらをちょっと見てみますとえ七十九．四という形になりまして
んで
でこれはえー文法全国から
そこの契約を見た方がとー男性の多いんですけれどもまーあのそれなりにえっとを
そのえーとベースラインに比べるとま結構古の持ってえー再現することができると
という訳ではこの表ではそのー我々の提案手法というのは
ベースラインに比べると結構いい性能が静的四の生活を目標条件が結構使いあ文ということが主張できると
でもう一つですねえーっとーお
えー
て学校にモデルの個性を比較なんですけれども
えーすまずえーっと
えー
えー
と
素性としましてえ先程の二形態素数で使ってたんですけれどもえー気が説明使って摩擦音ドメインに依存した形態素に使ってしまっていますからそのドメインに依存しない形態素のどの方も多いんじゃなあのドメインに依存する形態素使わない方がいいんじゃないかということをえ検討しました
で通しますと
えーと七十七．五ということになりまして
えーこれはえーっとそのドメインに依存するものも含めて全ての形態素使ったバイグラムや何らかをしてますけども
そのベースラインに比べると結構いいよということになっ
で後そのえっとー学習コーパスその二人フィラー予測もフィラーはそういうモデルをえ学習する学習コーパスの分量がえーと両方とか二個あなたどれぐらいいいかということをちょっと検討しました
でそれでえーっとおーだんだんを少なくていたんですけども二百公演ぐらいまではまー殆どえーっとーテストセットパープレキシティーは生活ません
でえーそれから千二百からずっと下がってきますとどんどんどんどんとのこのテストの歴史がえーと悪くなってきますので
最適なそういうモデルを学習する為ま二百公演が少なく必要れる好みで
でえーともう一つえーとー講義音声データーベースに対してえーとテストセット単語列どれぐらいなりますかということ評価しましたけれども
この場合もやはりえっとー目標値に結構近い値というのを体験することができると
いう風なことになっており
でえっとこういう風な形で取り敢えずえっとフィラーえー挿入モデルの方がえーっとをうまく僕よることが示せたと思いま
で次にえっとフィラーの語彙えーとーそういう言い方する数が決定されたとどのフィラーは挿入するかということをえーっとお花の推定するモデル二です名詞
でこちらの方は実はあの非常に簡単でして何えーとちょっと前に
えーとこういうあの情報はられた時に
フィラーがどのぐらいなるかということをえーどう考えるというまー条件付きのえーと確率でえっと表現しており
でそうしましてでま色々のえっとーお
やってみたんですけども
で後そのフィラーの導入フィラーがいいかって言うとおーその直前ポーズがあったりとかその口の形的丸四とセット二に色々さまざまにえーっと
素朴な仮説というのがあると思うんですけども持続が不十分でしてやっぱりえっと直前の形態素ですとか
それでもま考えた方はえー生の声を知ることがあって学生で
でただえっとーおー
Ｋだと思う疲れてしまいますと
そのドメインにえーと依存してしまいますので
でそのドメインに依存しない
であのー素性を使ってるなと思われますかと言いますと
その名の自然と体を使いましてもまーそれなりにはちゃんとえっとーお推定できるということが分かり
で後えーそのーバイグラムとトライグラムでは比較してありますとやはりそのまトライグラムを使った方よろしくでですねえーとまーそのー
んちょっとその日が安定なてあのーそこでなされてそのー
そこすそこそこでのものができるまでの五七十個から五取り上げとトライグラムを使った方はよくき
で通しまして
えっとーおーまそういったような条件付き確率でのその学習セットからえーっとー
えー
学習するそのフィラーこういうあのフィラー合わせて
水が選択モデルを作るということであります
でそれでこのフィラーがそのモデルを統合しましてえーと言語モデルを作るという実験ありました
でそれで今度はですねえーっとおー
目標値に対しまして
四通りのえー実験を行ないました
我々の提案手法のえーと一番
えー提案したのこれです
つまり
風なそういうモデルといたし歩くを使ってコンテキストを使い
でかつうーえっとフィラーこの選択の方もえーやはりそのそこであの二例八歳な形そのコンテキストを使い
でこうしますと
えーっとー手創作パープレキシティーは八十六．五ということで
でこれはあー開発コーパスなんかに十分使って
まずベースラインよりはかなりあのベースラインから五回転している
という訳でえーっとーそのー
フランス等にも出ると日が選択モデルをえー統合した場合であってもやはりフィラーはそれなりに再現できるということが示すとこの
んで
それに対しましたこのところちょっと見比べてだったんですけども例えば両方共にえ二グラム使うつまり全然分からコンテスト付かないでまベースラインで
でえーっとここの
えっとＢはどう使うかと言いますと
フィラーそういうモデルはコンテキストを使って
フィラーは選択モデルの方コンテキストを使ったり使わなかったりという風にパラメーター間
でそうしますと
がえー一つの例ですがえーっとここで
日本と性との
で
それに対しましてえーフィラー語彙選択モデルの方はコンテキストその使いまして
四ｒプラスこういうモデルの方コンテキストを使わないという風に変えますと
えーテストセットパープレキシティーはえーっと七ポイント程えー差がある
という風に比べますと
えークラス高二のモデルの方が
えーっとテストセットパープレキシティーが有効であろうというところがえーと見て
でえー以上をまとめた二が来ますとえー本発表ではこの二で囲ま話し言葉コーパスからえー話し言葉言語モデルを構築する方法として映画予測モデルを用いの方法を提案しました
てＣＳＪの対象とする実験にありましてえー実際の話し言葉に近い言語モデルを構築できることを示しま
でえーっと今後の課題としてはまーと存じ前の二十九個使った実験ですが他ドメインのえーコーパスを使った実験とかセットごとえっとー検討していきたいともっと
え発表は以上に
#############################


#############################
# query = えーそあのー最近よくありませんがあのー雰囲気あのーサブレッドとかすまー言葉であのー僕力を凄く五六てったのか畏まったけどあのー毎日付けたりとか生活のあー談話管理をするとか何かそんなにあのーまその方とか後うまく使おうみたいな話であのーまライブログとか言ってますけどまそのようでのくだいぶログって言うかあのーまーそういう手軽に持つ出すようなコンピューター買えなかった頃の後まライフ六です方で力と言えばま二十一課程小とか何かそのだったと思うんですけどあのーなん新しくで後そのーそいのその発足はでやるメリットってどういうのはあるのかなと精度を知りたいすねあのー二日後何が駄目で番番それでなおかつまー殆ど後何ができるなとかっていうのを知りたいし
# rank = 1
# slide = 10-05_fix.match_word.jout.txt
# value = -3.53936585448488
#############################
減ってはえーっと楽曲演奏されて中の文章特徴量と音響特性の対応付けということで八話題のあのー
まこれ自体が
が発表さしれるようだったんですがあのーそこの
でそしてだと思い
でえーとーまこの
ここでの発表と言いますかあのこの内容なんですけどもまーちょっと
ちょっとこのとあのおんんもう少し上のところに話し掛けてやりたいと思いますけれども
えーっとー
まずが改善されのお単位はどう検索という風に書いているんですが
あのー我々の方はですねあのーま対話の研究なんかもやっている訳なんですが
あのー
人にがよく最低まそれに限らず検索タスクというものに関してなんですがあの我々は音声対話によってえさえあの色々おー
ものを検索してくれ本がこう再生するといったようなことをするっていうことを
すると後あのー普通の人間同士が喋っていて何かこう一ですがあのー何かえー興味あるものを
持って頃よくあのー見つけ出したいよというようなそういうものっていうのっていうのは
なのが
基本的に作成目標は同じであろうと
いうようなことそういう考えが入りましてえー最近ではえーと対話
動物は人間同士の
対話と言うかま人間の
お洒落に
そういうのにあのーアイデア
おーなることから音というようなそういうようなあのーシステムの
猫と考えて
えーっと色々なあー基本好きの指導の程できるのはこうやろうとしています
でえーそういう中の一つの例としてえー我々分かっておく
イエスというのが一番まーあのー許可に分かり易いということで
あのー
かなり
え特にこういうあのー
で会話とかあのお喋りとかから赤い方が何ですかの特徴を抽出してえー
再生を
結構高校出してきて
で提示するっていうな時にはあのシステムと構造だからするよりも
場合で人間同士のその
長い時間の一人という話とかまー立場からしているか
そういったところから持ってきた方が
あの家が直接システムに対話して持ってきてもらおうとするよりも
もっと
フォークの情報を持っているんじゃないかと
そういう
人が
あのー少し彼の方でもこれはやはり
ということであのこのあのーワークショップの方にあの
ちょっとまーちょっと問題という人の声でえあのこれ
私だという風に
古い
で経営まではあのおー本題のと言いますかあの今回の時二の話
ここちょっと音楽あーあーもう一つの音声から少し離れところが
あれですねそそこは
あのー
明日来ましてえー研究背景
はい
で研究背景になったんじゃ先程の枠と思っておりよ形で
って思わ配信サービスが非常に充実してま
どこからでも音楽が色々入って
ええーそれから個人がやはりそういうが入っても絶対量だと語ＢＣという設定なあのー作業の方残ってますけれどもあの今の若い方は大学の一つ
とてもするものとしな違いまして下共あのー学生さん
とかに聞きますとあのー楽曲に四四モーラ語っていうのとかいう風に聞きますとま普通に溢れているのをあ学生が選択内容答えが
そのぐらい
既にあの頭が大量にＰＣに仕事を持ってくのが当たり前
な時代です
ただそういった七十五どういう風に聞いているが
って言うと大体まー
あのー特にえーとまーテストをあのー自分で選択してちょっと
あのーアイデア
あるいはあるみたいでこう
現在
ともしくはもうもうこういう島に来ましてくれる人作ると言って
でそれを
あのー
その順番でえー猫って聞くと
ま全てのことをやってる
でまー後ランダム最低二者のままあったりする訳ですけどもま本当にだんだんあー
まそういうながえーことがある
なのでえーそこではなくてもう少し昨日来たことをこうやっていただいて
そこでえあの考えているのが新しい楽曲
検索まーどちらです二千手法
についての検討というのを行ってきて今
で
えーこの推薦のあのーシステムなんですがあのーちょっと今あの先程見ました通り音声たりし離れて
えー人っていつでは今
例えば一万資料ウェブページ
に今あうような楽曲の検索しえそれが五グラムに二つとして乗せてやろう
いうなことを考え
でえー例えばあーこうやって
えー
たまたま見ていた
んでページがあった今示しました彼は三つであるとです四かかわりの中にある日本庭園経験して音をねあのいい経験をしてましたみたいなところをちょっと見て
しましょう
でそうするとこの時には二つの文章を解析して何か候補を選択してこれにあったような音がこうなります
ということがまー一つの例として考える
でま例えばこういった記憶が流れてきたらいいなみたいなのはまー何となく
分からですがじゃどうやったらこういう曲が推定できますが
っていうそのことを考えた
で後ですね
で
という風になっ
で
テーマ何々のところは当然あのー問題でしたえーでえー語意と格との関連性の従来研究ってのか幾つかあります
でちょっとあの梅干しところでちょっと
感情結果っていうような
あのーおー手で刺激
てもらうといったような
こうして
で
で
後次にあのー流に実現する母音と後だってことを関連付けてをを
とするとレベルの語彙が出てくればその曲を書きましょう
いうなことや
まあるいはあのーま同じ所在地
なんですけどもあのーそれを
まー
理由に限らずまー例えば何らかの方法であのー
楽曲地震のえー七八分とか色んなのでしょうんー他のところからピアノ現場とかそういった行為を使って
でその母音に合ったものでこれはそれを掛けまし
全てのことをやるっていうのがまー
宇宙の音楽家
でした
でところがまー雇用すると何が問題かと言うとやっぱりこういう注意を限定する必要があったかということが思うようここにできたら
後以外のものに関しては
特徴的な
えしかしえー平均年齢がということ単一の語意との関連付けということに
え四五られてしまう
で更に楽曲
ある一つは厳しい出せばできるんですがその卓球部は二十二日ぐらいになる現実的なとても
これは考えるって決まって母音あとおうちが
やってない
でえっとそれをまとめますとあの今の為に次の話と関連し方ではあのこあのー漢字表では行為タグに対して何かこうどこに対するこういうような
あの七日の語彙空間の中に色々生えててでえーその中に
でこの
を入れてみるとこんなところにあるねっていう風なことしかでき
ただし
ですからえー評定語が違えばその
使用する母音ずれが生じ
テレビで記述されていないかという風にベルはそういったもう一のものも元々そんなした後まーが
これが凄い風がね何とか四分の後に
でま最後にいましえー学部の日本教的な類似性ってのはんこうは
いうことになる
で我々の方はじゃそれに対してどういう風に体質とか
ということを考え
でそれは
あえー考えてその方法というのは七元々の角が一つここの先程のこれはえーとある曲ＡとＢとかいうこういう
えー
語彙に早く元にえー
まーですがえそれができずに音響的な今日空間というのをえ死を引きます
で同じ曲い言い出し方があるんですがそれがあると曲感情に
置かれて
こういう状況が
でこの七たという説明しますが固有空間を用意しておきましてでこれらの間の関連付けが何らかされているいれば
で今のようにこう一九九の相手が一つの文章から得られた
ある程度というのをえーこの楽曲の方へえマッピングするそしてまーそのマッピングされた音響的な空間の中で類似してるものを選んでくる
とこういう
基準が見えると
いうことになる訳
で最初になってくるとそしてえーやらしていこうかと
いうんない
でえーその
手法の概要なんですけれども後これあのだけをどう体舌先と逆に見せて申し訳ありませんえーとこちらが高いですからです
手書きの方は何何らかのあの音響的な音響的な特徴が先程の文でありましてような特徴は考える訳ですがえーっと音響ベクトルというのを
何かえー用意しますとどんなもん並べ方にしますが
するとえーどんな曲を解決したテキストま色んなものこれは認知的な
でこういう名前に関してこれを文書ベクトルという形で表現することは可能で
でこれらの間の線形変換まこういうあのーどの辺なんかでの韻律がま一番単純になっていて変換を考えましてえこれについてだけができると
いうえーことを考えて
えー
これを突いて
こういった方法と
これをこうすれば良いとえこうすることによって複数の単語コンテキストは入力を可能な
ここでえー真ん中の二つ目となれば
で後音響的特徴の類似度を考慮することができ
空間上の近さというま定義できるのでそれが可能になる
でじゃあのーそれぞれの
空間でのあの父など
えー使って後で
え文章えっと二ですけれどもえーとこれの方はえまずは特に今一番簡単になる女の子で二つの単語の頻度に基づく文書ベクトルまこれは普通の
あのいわゆるあのーえー
英語を作ります例えばこの楽曲二十五回こういう形まそこ中に色々
娘がありますのでちょうどあのー
特徴的な語が選ばれてる方と思いますけれどもまこういったこう
をま発表ベクトルでえ非常尿に重みを付けますけれどもその重みを付けますけれどもそれよってえこういう風な
ペットロス
まこういう
これが
先程
でまたこれはあの非常に語彙がの数があのおー行なって七十はしないものな時代はそうで遊び気分が今えー
配列によって
一二と三時間目の文としてやるということでえー文書ベクトルと
いう形にすると
これがまー決定木な文書ベクトルを作り
あのーこれところを考えてもあるし
で
それから後何度形であのー品詞を使ったらうまく
いうこともちょっと考えています
ペットとし始め用意しておいてそこからえー使って
そういったこと
ですがまそういった子供を考えて方がいいかもし
まそういうところを考慮してちょうどそのイメージ研究がもう
一つだと
え次に音響ベッドの話ですけれども音響ベクトルはまずあのーまー
二基本的な音響特徴量を抽出します
であのー今回の
方はほ殆どの場合がえーとフレームを相手に特徴に間接的東京ででそれらをえーく量子化
まず
でえー特徴量として表現するんんちょっとある程度距離を表現します
でこれは一にやりましたで非常にたくさんの数のそのえーこううあのー行動が生活できてる訳ですがこれを
でえー基本的にクラスタリング構造二クラスタリングした結果をヒストグラム出してこの一を御覧行ったこれこれ自体が
えー
音響ベクトルと
いう風に
呼ばれるもの
いう風に私我々は定義してこれを根拠とし使って
まこれにはま色んな方法があるともんですけども我々が使ったものとしてはま御てるというこの音色を
つまりえーそれの結果を表現するようなスペクトル重視されてる花とかまーえー頃まーちょっとまた今回は説明いたしませんけどもまこういったものがありま
そいから音量ですとかリズム
後
〇．
そうすねこういったものを使ってえー先程のものを表
テーマ
でえーまメールのコードブックサイズをしたまー基本的なこのこのぐらいで試しました四つの種類安いよだから
いるあのーが
またりあのー実験が身に行なわれて
の移動とまー
でえー
えーえー先程のあのずっと出てきた後また
句中も兼ねましてでえさ今のような音響ベクトルへという訳ですに非常に
にえー
集団ですがそれと後二十利用法
これもあのー特集があって
以前は単語数とがあのおーＮグラムまバイグラムぐらいそんな真となるですがそれを
えー設定して認識をする
いうようなことおっきな
で
すこないだの関連付けて付け共あの基本的にはどの文章とおこの音楽っていうのは結び付いてるってのも分かっているそういう条件の下で学習があの
なものってなったの入手できますのでえそれを使えばえあるえー文書ベクトルと音響レベルの組っていうのがあってえそれの間をこう関連付けた時の誤差項ですね
このボタンはえー
最小化されるような
形で神様が一つは
こんな家はまーあのー
このようにえー解析的意図結局は分かってますのでえこの形これを
まえー
この式をその中で
これでえーＷが推定
二誤差が最小化のえー条件の下で
いうことになる
ということがえー
でえーこういう風にしましてえーじゃ実際にじゃどのぐらいこれでうまくいくんだろうということをまー
で評価した実験ですとま評価方法についてもえーし
でえー例えばあのーおー大ブロック人がなるかなという文章入れますでえ文書ベクトルを
日系だ曲を検索した時のえーと結果あ曖昧な二節のところまーあの反応率ま政策四十五分三百四十九のあの音響ベクトルがあの廃棄されてましてでその中のえーされて船を
こう全てをこの
えー理由を変換したベクトルえー環境に
そして順位付けします者の過程についてしまう
でえー勿論その対応する語が一番上に来ることが望ましい
訳ですね
でそういうことでえーその他
えー対象となる曲が一体何なのか
っていうのをあの全部評価に関し数え上げましてでえーそれのえー
この月からえ四八はあのー
えー各
曲のおー
二十五のえ逆数の平均いわゆる三でしょうからと言われるならこれ評価いたしました
ですのでまーまー体があのー大きい程良い
で後ですね
ということになり
でえー結果です
でこれがまずえーっとー
どういったものを比べたかって的な文書文化による検索っての本当にあの先程言いましてテキストをしかないという状態ですとえ空間を発表いてその
単語で一番近い
結果単語がある
ですねそれを
それをきっかけに言い方単語があるべきかという相手の方
でえー提案手法では×の方であの
んえー変換してやってえーと音響空間上で近いものを持ってくるという方法
それからバイグラムというのは先程の文章二メーターの文指導をベクトルの方が幾らまで作っといて帰ってきた
いう結果
になります
でまーあのこれを御覧いただければ分かるともんですけれどもあのー電車の音をどんな
あのー
文章を使って先程んＷを推定した後
いうものになるんですけれども多分この結果を見ますとま基本的には営業の菓子とか後
まー風呂記事であのー曲を
評価しているネットが一般のですねですとかがあるんですが実の一回使いますとえ店売っていけば
結構良くなりましてえーまこの辺ですね経験も今は〇．五ぐらいまい
えー
三百七十四ぐらいでしたら
えー得られ
いうような結果
がえー言えます
でえーと分野別にそのどんな風にしを使えばいいかってことを検討しないといけないねって話だったんですがとそれをえーとその結果ない
でえっとクローズな方法二の方と両方こるこ怖いをしてますけれどもえっとこの結果なんですが
えーっと
ん名詞がはやり出していますねたらあのー世間あなたも今説明しては非常に曲を
あのー表現
するのに良い
なん何らかの文章特徴的な非常に
で後ですねトピック
には
あのー定義して
みたい
んでまーそういう結果でまこうずっともうほぼ完璧なんですけどもまー高校二であのーこのぐらいのことであのこれは単語ベースなんですけど
でそれも〇一六ということはまー五分ぐらいだと
うー
入ってから
で以上ってが〇に近いのでまー六ぐらい出すかその話ができるかなと
ゆ
そういうな結果がいや
でえーっとまこれを使いまして
えーっと実際にえ文書の演奏を再生システムインターフェースというのを作りましたでこれ実はあのおーいえ今国で生活と分かんないですけどあのーまー実験用に作ったもんですんでえ
こういう
って規則三掲載されて作りましてえここに
中一書いてもらって結局終わらしてもらって評価をするということをやる
で実際に
曲をあの表のようなちょっと一つぐらい決めましてあの方にある
あのー
痛みを行なうと思いますけども一つを入れましてでえー今日声出してまーあのー出してもらってえそれが合ってるかどうかっての主観評価しました
でそうしますとま大体以上あのおー上位リテラルされるものとオランダの絵ができた忘却
それからえーと入っゴルフになったもんつらさを見ていますとまー基本的にはなく
選ばれてしまう
良い
結果です
ただまーあのー特にはあの曲かのおー単語がなくなってきたえー形で
ちょっと
メディアというものが存在するのは存在するというまそういうような結果
また成人してですねそうちょっとなっていうまそうそんなに
あの痛い訳ではあります
でこれが頭
えー
んーこれ
私の生まれる前の町としています
えーとー
んでえーどうんーこれ何かこう
んー
うーいう気はし分かんないんですけどんーこれも僕ゆなのをあー内容を家の時代に選ばれたのはこれと
いうことでえーうーまこの差が二ではえー選ばれてえーこう抜いてえーこういうことができるというあのこれ今回の旅行がお分かりである私と私の
その上の子なのは七五つの課題ですけども
第私もよく知りませんしかし
でまた出したそうで
えー
はい
でえーレートとえー後えーとか月による評価を幾つかあのーしたいと思います
えーっとこれはですねあのが
その楽器を御説明した頃起きてはやはりがありましている訳じゃないんですねでそれがえーそのんん
のおー家にいるとどうなるかなっていうのっていう
でただ一つだけこううまく行くんですね
なん結構うまくえー経営してきますがこの二つをあー二であるとちょっと落ちますがまー
それでもですね
例えばこの
これを使う
値にたい関して
え何か評価してるですががそんなに大語彙分析の結果こちらを使い曲があってあの
推薦されるとまこういったような結果も得られて
後
えーっとー
まーこれ
こういう頃合格したっていう意味ですねあの今日この二次会っていうの中を第二三でえそれに対してこの日常の
それにえまそれに合うように自分のことを書くと
いうなことを
私は今水は体や
で最後はあの極大値一つ関係がい一時なんですがまーちょっと分かってる方にはいつも
結局木もま空間がここの頃五記事を入れてやるとつまりその曲ができるかと
っていうようなことをまー
後まー
ままま
あのー上の方には出てくる
ということが若い
ま色んな苦労と三番はまー
わりと
行くのかなということなんですねま何でももう少しほしいなと思うんでまだまだもう少し学習データーとえ提示する必要があるのかなという風な
であります
でなど
これ括弧ができないと特に考えてどこで
あーえー今みたいに部分生地を
っていう風にやってましたけども
いうこと
それのま一日現在の問題ですねこういった
後もうんー
んー
んー
んー
えー
んー
んーえーんー
分かりになることはこの逆に比較的若い方はですねですけど
ま付き合いみたいすあのーんことに対する
あのー
って指向性のえー本当の会話です
本物の会話です
えーこれあのたまたま
んー大事じゃじゃ
の
ましました
泊めて
また
えーっと第一著者の
妹さんが本当に彼らの録音したんだそうですけど
で今みたいな
ことを
喋っていたと
します
でえーっとこちらが
別に何を喋ったとそういうのに対してどのぐらい
でえーできるかっていうのを評価したらこの結果に
ない
でえーとーこういう風にえーっと何だね言葉喋っている
えーとまー
あのー雨ではえー作っとかそういうのは
で結構
んで
何かこう喋って中にこういうあのー車で八
そういったようなものができ
いうことを
まず音声に関してあのこの辺りでまー後二つであると三大会に出ますまこれ定義音質に関する
黒く記事がありましてこうしますとまやはり結婚してい関連の影響って言いますと大体
である
で
えーっとまこれ妻が思い切り即ちえここ
前の音を各人って結構いますね
でえー
五年何かま話したいことがどうなるかっていう
で結果と
後おー敬語もどこ行く
まこういう風に同様な捉えてるか分かりませんが少なくともこれに対して馬ばかりの二がですと
いうようなことはえー
こういうことができ
でＳがこれがあのまー書き起こし文でなくてあのー実際のプロに値する訳ですねまこういったところからあーの音声をえーとってきえー音声をあの認識することによって
えーこういったことがえ推定に立てればあー反駁では名詞句としてあのーうまく
背景としてうまく後競馬
あのー何か
こう
何か感じでえーまー木ものが作れるんじゃない
凄い今
えー作れるテントを
で車でねますとまーあの×の語彙と答えてるので
東京関連付けの方法
え提案します
って文書空間のが指摘されるようなものを使っの記事なんかを使っていただく
撤退しないので三ではこういう二つの主観評価としてあのー結構似たもの
あのーうまく出てくるということを確認しました
取っている
以上で
#############################


#############################
# query = えーそあのー最近よくありませんがあのー雰囲気あのーサブレッドとかすまー言葉であのー僕力を凄く五六てったのか畏まったけどあのー毎日付けたりとか生活のあー談話管理をするとか何かそんなにあのーまその方とか後うまく使おうみたいな話であのーまライブログとか言ってますけどまそのようでのくだいぶログって言うかあのーまーそういう手軽に持つ出すようなコンピューター買えなかった頃の後まライフ六です方で力と言えばま二十一課程小とか何かそのだったと思うんですけどあのーなん新しくで後そのーそいのその発足はでやるメリットってどういうのはあるのかなと精度を知りたいすねあのー二日後何が駄目で番番それでなおかつまー殆ど後何ができるなとかっていうのを知りたいし
# rank = 2
# slide = 09-20_fix.match_word.jout.txt
# value = -3.56658647898304
#############################
えーと日本大学の何度です表記のタイトルで発表します
んー
えーっと研究の背景なんですがまー気にえーっとーまーこの
一回の音節なんですがま恩恵音声ドキュメント検索ってのはまー盛んにやられてる
でま公園とか行為などを持っ検索対象として
まそれを検索するということをんがやられて
でま音声だけネットワークグループというのに私も所属してましてえーとそこで
えま色々タスクも作ってるというな状況
で一機能の
間の先生のおー話にありましたけども
不満のＮＴＣＩＲとかそんなところではまー言語の音声ドキュメント
検索というのが行なわれてる
えーＴＤとかでは
ま世界
ミヤブラウザーというのを使ってまして
えーと多言語の静的面倒検索ということをまー何かやろうとしてくるというような状況にあり
いい時のあの話でもありました通りまた言語を対象とする場合は
まあのークエリーを翻訳するとか
検索対象の精度を検討応援するというような丸四五つのあるというな話なんですが
まやっぱり検索語
検索した後にまそれを見た時に分かり易いというような観点から考えますと
ま検索対象
ま翻訳しておくことが望ましいということがあると思い
でえーっとまー検索対象の程度決めるとま翻訳しようとする訳なんですがま大体においてまそういう音声ドキュメントは
後方性の高い部分です
でそういう先生の高い文に対して
現在の機械翻訳ってのは
ま結構難しいというような
感じです
え四で一方自然性は低い文書に対しては
ま比較的容易な
翻訳んができるというような状況がありますこれはどういうことかと言いますと
ま二重性の高い文というのはまー
実音声ドキュメントの書き起こしみたいなものでして
で二重性の低い文ていうのはここでは
ま直訳調の文章ということを想定している
で実際の例なんですが
まーあのー毎朝犬の散歩に来ますというような
文章用翻訳しますと
第四五相談を
お婆時計貧乏人とかいう
ちょっと変ないようになり
で一方町で性の低い日本語私には朝私の犬の散歩が一つもあります
んーこんな風な
えーっと文章にしてやると
まー英語にしてあるとはえ用例坂が多くお前とかビザモーニングということで
ま結構うまく翻訳ができるいうことがあります
そういう訳でえーっとーこの
ほい焼く前に
変換細い編集と言うんですがそしてあることが重要度
いうことでここでは
私え性の高い文を
ま二重性の低い音契約書の文章に変換してあるということを考えます
つでえーとその機械翻訳の前二つの問題なんですがま色々まいやられてますが基本的には
前編集をどう行なうかってことを
まモデル化しないといけないんー
でえーっとまー今までの研究ではまそれは
後でやってる訳なんですが
で基本的に値を水が自然な文とま直訳調の文
×という方が準備する必要があって
まそれ人手で集めるのは結構すぐ
それから
直訳調の文が集まったとしてももう
最終的な翻訳にとって必ずしも
観光地の文の方が
自然な文よりもうまく翻訳できるという訳ではないですので
まそういうものは
学習データーから覗いてやるということが必要
でその上でまこういうペアのコーパスが集まったとしてもうそこから
まー毎日え規則をですね獲得するってのは
えーやはり大きな問題
という訳で本研究では
えっとー
この
直訳調の文と自然な文の対応っていうのを
まー自動で獲得して
そう思うから毎日え規則もま自動で
獲得しようということが本研究の目的です
えー
でえーとまー実際にやっと型で聞いた翻訳の枠組みを用いてえ前えー使用することを考えます
でまー統計的しか親がま音声認識で同じ枠組みでしてえーま原言語
えー単語列例数与えられた時に
まそれを最もよく説明する単語列Ｔ易い
おー求める問題としてまこんな式を変形してって言ってるこの式を求める
んで
えーっとこの
確率を与えるモデルは変換モデル
でして
こちら確率与えるものモデルは言語モデルになっ
いうことです
で毎日一を考えた場合には
このＳの方に自然な文の文字列を
でこちらの二の方にま直訳調の文の文字列ということにしてやって
まこっからこう声が聞かれてやればいいというような問題になります
道をちょっとあえーやはり毎日があって困りますのでここでは一応このｐｔを与えて言語モデルを直訳調の言語モデル
とー
呼びます
でこれ食べアクションテキストで学習します
でこちらのえーっとＰのＳＴという
ま返還確率与えるモデルを前にして変化モデルと呼ぶことにします
でえっと学習データーをまー自動で獲得する
獲得のし方についてお話
で今回は
毎日翻訳を対象として実験をすること
にしました
という訳で日本語文の前研修を行ないます
えー学習データーの獲得なんですが今日本語文と
日本語ちゃう訳文がいるんですがまそれは日英対訳コーパスを利用して
日本語文と
ま対訳例文をＭＤ翻訳した日本語直訳
とーす今
後分かりにくいので図で説明しますと
ま日英対訳コーパスがあってまそん中には
えーとたくさんの対訳ペアがある
いうことです
でそっからえーっとウェブの方
毎日機械翻訳に掛けてやって
まこれ色んな本焼きがあると思うので色々
栗
で一方まこちらそんまー持ってきて
でこちらはまー自然な日本語
こちらは直訳調の日本語文と仮定しまして
まこれこのペアを自然な文と直訳調の文の提案
てやるということをします
んでえーっとまーこのこん中で全部は使える訳ではないので概要ですと選択するんですが
活動しますどうするかと言いますと
えーと毎回ま最終的にはあの英語にしてい言い方を選びたい部分で毎日えー機械翻訳機にもう一度掛けます
そうしましてえーまこちらも全部掛けて
んで
これとこれを比較して前編成しない場合のえー母音より
まこっちの方が潰れていった場合には
二十四
歳
んでまーそのえーっとん何が優れているかというのは
もっともっとこれは
この
対訳コーパスのえー文から付けましたので
これを持ってきて
でこいつとの距離を
ま何らかの尺度でえー
計ってやって
こう一により近いやつを残してやるいうことをし
でま残った五文がありますからこれを生み出した
えっと元の
直訳調の日本語文のみを残してやると
いうことをします
でそうすると
過去の日本語文を前編集でこちらえー書いてやって翻訳するとまこれよりは良くなるということが創作
ということになっ
つまりこれをこう書き替えてこういう翻訳してあると
直接翻訳するより良くなっいうことですので
このペアを
学習データーとして
もう何か
学習データーの使用に追加するということででこれを
まーコーパス中の日本語程度の対
えーっと色んな対訳
文提案に対してやり
今こうやってやるとま色んな部屋が集まるんですが
でえーもう一度二おさらいしますと
九枚平成変化モデルは
この対訳提案しようから学習します
でこちらな言語モデルの方は
こちらの
直訳調の文から学習し
でえーっと実験なんですがまず学習データーの自動獲得をしました
で実験データーの板のえー二つ対訳コーパス三万一千五百八十文釣りを使います
でここはえーっとー色んな
二日後約一は使えるんですが今回は一個にしました
結婚など
最後にえっともっと前文との
距離四
掛かるんですがその類似尺度は二つと通します
で結局
また約八音を決定文の方は
二日翻訳四．一え翻訳して
でこの
日本語音の方はえー文に翻訳して
でこれ共に一スコアを計算して
文字こっちが違っていれば
これとこれのペアを学習データーに使うということをします
でえーっとこのペアってのが三万一千五百八十文についやって
実験これとこれの部屋が使えたというのが
五万九千五百九十六
いうことで
ま九十四パーセントが
ま高齢をこう書き替えてやると
いーえ文になるということが分かります
つまり前平成
でまーま殆どの
ま日英対訳コーパスのデーターが
毎日絵に使えるということがまーこのデーターに対してはえー
行ないます
で実際にえーと学習
データーが集まりましたのでま前編集システムでのあちょっと少ないんですけども統計モデルを学習し
でデコーダーはもうぜー
数を使いましてまえー因子モデルは銀座で学習しました
でえーとフレーズトランスでしたモデルを使います
んで直訳調言語モデルはえーあれＳＤへ電話する
後で学習した
えーと五グラムを使いますとま大体専門家ででは魚とかあなたが救われることが多いみたいです
で変化概要は今回はえーっと単語と文節をえー使用します
で今回日本語日本語の変数変換ですので
ま付属語のみの変換というのはまー
何かこうもう動詞に対する各格はまー
へん化してしまう可能性があってまそういう変化は考えにくいですので
ま文節単位であるということも考えます
まー実際にはフレーズトランス依存モデル使ってますのでえーま単語単位に変化してると言っても
ま一部はフレーズなってるというような感じです
でえーっと実際に結果なんですがこちらが文節単位にやった結果でこちらが単語たえーやったきっかけ
んでまず
えーとクローズデーターの評価なんですが
あまり新鮮な水の場合ですと
まんま決して悪い
タスククローズデーター全部に対しやった結果
えーっとまー明らかに
文節単位でも単語単位でも
まよくなってるということが分かり
でま枠組みとしてはま正しく機能するということが分かりました
二階でした文の割合はこちらのまある六十七パーセントぐらい
いうことで
ま文節の方がクローズドデーターに対してはいいという感じで
で一方まーオープン正当なんですがま平均で見ると結局改善は見られますです
んでまーよく見てみると返した文の割合ってのは大体同じぐらい
あるというような結果になります
でまー平均の精度で見ると
んまーオープンあの分節単位でやった方がいいんですが
破壊です多分という単位で見ると
って言い単語単位にやった方がいいと良い結果でま今回は文節と単語どっちがいいかということは
ちょっとあのー判断は
付いてます
ただ
まーあのー
クローズドデーターの
開店のし方とかを見ると
まー文節単位ってのはかなり
えーっとー学習データーに依存してるのではないかと
いうような
缶詰め
んでま全体的に学習ぶ
データー不足してまして
ま特に文節単位は
なかなか学習してるんじゃないかなということがま考え一
でまー実際にえーっと単語と音節の他あのー
統計量なんですがまな
単語の場合は
ん延べ単語数はま大体一名が単語で異なり語数は
ちょっと二十二型ぐらいなんですけど
文節の場合は
斜め文節数は
苦なくっていうことなり分節が多い明らかに送っている
殆ど出てこない一回ぐらいしか出てこない文節ばかり
ですので
まーマリちゃんついでに弾けないなというのはまーそれでも意外とオープンデーターには多いというな状態
でそれからえっとー
機械翻訳のデコーダーというのはまーパラメーター値人数ができまして
まそれも木の付いてましたんで使いました
で実際に何やったかって言うとま直訳調の日本語文を参照役として
毎日ような日本語文のブルースコアを最大化
ま書いてますけども
結局まい編集した後の日本語文があっ直訳調の日本語文
に近くなるように中デコーディングのパラメーターを
二十合成します
いうことで
で開発えっと二百文に対して
まやったところ
ま少し良くなります
んでえーオープンデーターに対してもま同じような結果で
ほんの少し良くなったんですが結局やっぱり
前編成しなかった場合に比べて
の改善は
六月と言うか
得られますんです
で町に都があるんですが実際にはまー
えーっとまえー
日本語母音お前編集して直訳調にするように知覚してませんので
最終目的や日英翻訳ですので
毎日翻訳が良くなるようにまーこれも睡眠ですてればいいかなと
いうようなことは考ええー
でえーっと実際にどんなあのー学校が見られたかという例なんですがえーっと
例えば道は偏りスタートを苦心し
大半の人率がこの一の高い子付近でしてたというような
ま携帯のやつなんですけどまい編集してやると
まどうはより高く開きました
登り続けていて殆どの契約は一日後また彼の近くで結ばれました
ま大体三家に切るんですが
で後例文にしてみますと
まー明らかにこっちの方が
点もありいー英語になってるんですがまこれで意味が通じるかどうか差別問題なんですが
こっちやよりはかなりいー
良い文になってる
思われる
特にを終わりの方が
結構
分かり易くなってるような気がします
えーっともう一つは何かこんな一つで
四人の国えー
んどうこうしたこのでる娘さんの生命によると
何とか二という数がやっぱりこれも
何かこんな風に変換できまして
何かこの辺に
によると側ではあーになってまして
上位に下がまサインしましたぐらいになってるんですけど
もうこれぐらいにもう
だいぶ違いまして
まこちら講演雑誌理由は場面となん
こうパブリックここれ子音とか
ちょっとよく分からないで出しなんですが
こちらのまで出すから結構分かり易くなっていて
ま特に終わりの方の文数を
間違えではなくてま多分
日本でもある状態になって
んで一方うまくよいかなかった例なんですけど
ま何かこんな文章ですが
となっなぜかこうプロジェクトは終了二千年全反応を計画してますというような
ちょっと変な
日本語になってしまいまして
まこんな風に
現代日本語は勿論現代英語に
なってしまうというような感じです
まこれは何か
多分学習データーに一体引きずられたんだと思い
え以上で数がえーとまとめますと日え翻訳における統計的前編集をします
で学習データーを自動獲得して
毎日対訳コーパスからほぼ同サイズの学習データーを自動獲得可能であるということが
分かります
て翻訳対話
んま文節単語についてはっつってこう
分からなかったんですが
まーあのー
レベルコメントセットでえーっとこれに
クローズドな実験見る限りはあーデーターが多ければ行なうのかなというようなえーそうで
二年四十パーセント程度の分類
えーっと
英語の品質が向上したんですが
ま平均的には一項では見られませんでした
でまードキュメント検索の為の翻訳としては
まーい編集があった場合とない場合の翻訳文から
ま利用法から
えー索引語など作ってやればいいということも考えられますのでま半分ぐらい
よくなってるということでえーま要素によっては利用可能な精度ではないかと
いう風なことは
見えますがままやってみねとかいうこと
て今後の課題は
んーまとっ毎日の学習データーをま複数のＭＤシステムなど使ってですね
増やしてやるま実際もっと
日英コーパス持ってくれは
人ですがまそこで
そいから
えーっとまえー編集でデコーダーを
ま最終的内容が良くなるようにパラメーターついに
でやればいいかなっていうことを考えています
発表は以上です
#############################


#############################
# query = 論文の中でえっとーアラインメントをについて二名ているところがあると思うんですけどえーとー論文の中だとえっとー統計的機械翻訳仮説二のところで一回目に共アラインメントについて角が挙げているんすけどんでそこの説明のところの種えーとー話でんえーとその論文のなかなか挙げたととで確か私は本を借ります一つ目を取る後ですが結果を説明していると思うんですけどこのところのとースライドでは説明がえーはい
# rank = 1
# slide = 12-18_fix.match_word.jout.txt
# value = -2.30325542079912
#############################
えでは推定された書き起こしからの整形成形部分の都合テンスと題しまして
八八十五各大学のおー他言語が発表さしていただきます
ってまず本研究の背景といたしまして
え話し言葉の正確な書き起こしというのは
生活の音声言語処理なアプリケーションにおいてえー非常にえー不可欠なものとなっております
え例えば音声認識処理の例に取りますとえ話し言葉を対象とした音声認識を行なう際には
え話し言葉の特有の言い回しに対応した言語モデルというのはえ必要に
なってきます
えー従来はえーこうした場合にはえー認識対象と同一母音
であり平滑話し言葉特有の現象を含むようなえー正確なえー書き起こし
と反映にも使って言語モデルを学習すると
ていうのは一般的な方法でした
え以下の側とこれの
えーとこのように話そうというのはえーと電場を作るんですねえー書き起こしは非常に
まー不可欠で
あると
えーいうことなんですが
えーただえそうした話とは音声を正確に書き起こし作業というのは
ページ関連キーを面の両方においてえ非常に高いポストが必要となってきます
え具体的に申しますと
えま正確な書き起こし
テーマけど五つの制約というのはえー二時間もえ従来が通じる前の時間がえー必要となっています
えこれはなぜこんなに二十尚子と言いますとえまず一階がいいよと三今は水といったえーとこれの現象が発生すること
えそれから話し側というのをえ今は視点が存在すること
即ち挙げられますえこちらはえ国会答弁の例になりますがえこのように話すことく話すことこれのえーところがですねと言いましが
後えー出現したり
えーフィラーやえー飲料水などは
て出現しますのでこれを正確に回答をしてま非常に
えコストが掛かってしまうと
っていう問題があり
一えそれに対してえっと記録八回六といったいわゆる正確な書き起こしというのはやはり幅広いドメインで
え存在をえーしております
え例えば二はえーこうか五回六の例になりますが
で公開透明の実際の音声でこえーこのように発声されているのに対してでそこ海外６ではえこのように景気がやり直しがえー削除されって花側とこれの言いましも彼とその町日間をされえ助詞が保管される
なるなどといった生起がえーされてえーおります
えこうしたえー指摘された形た形のえー会議録等は
えーさまざまなドメインで適用が可能となっておりえまた最近ではえ山の中にかるたとなどを利用して
って一えー一専門家によるなかなか塩を水を作るといった動きも
ありますしまたえー音声とはこういったえー見られたデーターもえ益々増加しておりますので
今後このようないわゆるえー正確でない生成された書き起こしというのは増加していくであろうと考えます
えーコース排気行なわてましてえ本研究の目的としましてはえーして設計された書き起こしというのをえー正確な書き起こしに半自動変換する枠組みというのを
開発を目指しております
えーこの程度依然としましてはまず第一に制限された書き起こしから静止画像を自動検出すい
え次にその設計された世紀がソフトで正確に価値をこうそうとことで効率的に正確な書き起こしの作り出します
えこの枠組みに
体に関しましてはえー昨年のこのワークショップでもう一度発表させたい為生きてきましたが
え今回この推定された書き起こしから世紀二十六件するという点において
えー改良を加えましたのでえそのえー部分に担いでえー御報告さしていただきパス
．んんちょうどえーえ女性させて出ますとえ本研究の目的としては平成九された書き起こしを正確な書き起こしに感じどうで変換を
設定が言葉と話側のパルコがするというのを効率的に
構築を
すると
でこうすることができますと深い言葉から話し言葉への変換ルールというのは抽出可能になり
でまたこれえー言語モデルの再編関東に応用がえー可能となります
えまたえー検出された時成形部分というのをえー話者適応用の発音なるとして利用することも可能と
なります
杖を
で第一二としましては捉えるコーパスのこの構築作業というのを三倍以上効率化できればと考えておりま
二えと出たえー香港提案想定があり段階からなりましてえまず第一に推定された書き起こしと提言を生徒の間でこう差アラインメントを行ないまして
この方触れずによって得られた素性に基づく検出器を使って
定型過疎というのを自動的に検出をするというで手順になっております
えまずえー
第二段階としてえ推定された書き起こしと言を生徒の交差エントリーついて説明をさしていただきます
一え今回この方をされてにつきましてはえこちらの図のように
店へ
え×がま言語モデルに基づく平成薬をあえー加えてえー使って平和を実現を行ないますでえ御覧のようにえーこの制約ではえー書き起こしの単語列ｗ使う為にえー対して
えー
まある単語ｗｉ
に大した立てないからえーと
田村プラス一の中ではく
とえー左だけだとでスピーチましょうと母音の計画の三通りが
で
ございましてでこれは即ちこのえーと
ま出会い方だぐらい数一の間にえーフィラーとポーズの挿入オイルした制約と
なっております
えーこのえー
ようなえー制約を波形を用いてえー大語彙連続音声認識をデコーダーを駆動しますとえー人に六単語間にフィラーとこうショートポーズの総理を許したハールメントクリームを行なうことがあーできます
．八五のような知らない面倒実現えーいたしますがただ問題点といたしまして
一えー書き起こしと方はえー原音声との間で対応関係が取れていないと
いう問題があります即ちえ書き起こしクっていうのを程度の
精度がどの単語から文単語までが言語性の音声区間のところまでかという対応付けができ
えー多くの場合されていない
いう問題があります
これに対して本研究ではえー以下のいえー四つの手順で
えー対応付けを行ないます
えまず
えー
ですがこの先行部分に関しては書き起こしと原音声でえー対応してると
えーいることを考慮してえー原音声の先頭から二約一秒間の発話区間を気がします
言ってこのは発話区間に対してえー連続音節認識を行ないましてでその音節認識結果の
えー音節数に基づいて
発話区間に対応する書き起こし区間の長さつまりえー単語するというのを推定しますで具体的には
でこの
えー御説明し結果の音節数を
えー単語の平均を音節長で割ってへたの数を推定すると
いうことを
行ないます
えーそしてえー発話区間とその
で推定した書き起こし関東へ
えアラインメントを行なう訳ですが
えー
今申しましたようにでは一書き起こし管の長さは音節認識から水で自動推定したもですのでで
一定の誤りが含まれてしまいます
えしたがってえこうしてえアラインメントを取ったうちの
えー特にま違う部分というのは
えーアラインメントをの側へがえー謝ってくれた六
っていうことが考えられますので
えー
今回はこのアラインメントを取った中のえー前半え約六秒間
えーのみの会話の時ってこう存在してえ採用すると
えいうことを
えー行って
えー
えそしてえアラインメントを行なったえー一つの例がこちらにありますが
テーマ今回のようにえー指摘された書き起こしとを言語性では書き起こしと音声の内容が一致しない部分がありますから
そうした不一致部分つまり正規化されている部分では
えー実際の発声とは異なったモデルは強制的に対応付けられてしまうことになりますその結果
白いの音節の体を考える駄目あれで
えーまた音響スコアも低下してしまうということが起こります
え今回のこの図の例ですとえ音節水の区間が不自然に
で延びてしまっておりまたえモデル体が安定
音節前提に
でえー強制的に対応好きられて
います
えこのような現象が起こることから
えー音節間な極端に長いあるいは短い部分
それから音響スコアはえー極端に低い部分というのは指摘箇所である可能性が高いと言えます
一二って続いてえー第二段階としてえーこう実などによって得られた素性に基づく二．五月
本を追加世紀がその係数について御説明をいたします
えー
あ
えー
今回はえー生起とその子の検出というの書き起こし中の各単語理解するに自分で問題としてえ形式をします
例えばこちらの例ですと結果として財政的に豊かになっていても三の部分が適用されているんですですのでえーこの程度えーいるの二つの単語をま世紀部分として
であるとしてえラベル一応
それ以外の部分はえー正確に対処をされていてえー
二あのー素敵されて今生きてき部分であるということで調べる〇
ボトルでえー苦労しまして
えこうした辺に自分でもない
を計算方で二マッチングを用いて検出を経て
変化する問題はえー下に問題を解くと
でいう風二年
ことを行なって今
知ってそのて
さて系その他の素性としましては今回が今回はえーっとー当該単語え直前単語をこういう証拠に単語に関する
でえー
本当て一成分言語的素性を組み合わしてえー用いると
っていうことを行なっています
えーいかえー活用を説明して
参りますが
えまず音響的女性の用いて単語単位の音響尤度幅について御説明いたします
でこちらはえーアラインメントによって言われた
え音響スコアつまり対数尤度えー使用いたしますが
でただしえー単語の時間長によってこの海水を統制時期はあー方を行ないましてえ更に連続音声認識によってあるか音響スコアとの差分を使用します
えーこれにより話者間の尤度の差もえー正規化をされることに
えーなります
えこれは即ちえーこの三式のようなえー対する事後確率を素性としてもせることに相当しています
でまこれに加えましてえー今回は音節単位の祖先を使用します
えー単語単位の音声えー素性だけではえー音節単位での調査研究するにはＦ０な場合というのがえありましてえー例としてえーえ
一と書い採録ではところがと書き起こされてるのに対して実際の音声ではところがですねが発声されている場合というのを考えます
えこの場合最後の音節映画
のえー部分にな日本という音音節長に異常が現われます
えーしたがって単語単位でえーと
が
考えてみますとえー日本の異常さというのはえー四分の一にえー音声られて
てしまうことに
なります
え例えば
えー
んー昨年のえーえー発表ではえ単語の三日前オンセットの平均値など
ま単語単位の素性項を使ったって感じで御説明後あのー御報告させが来ましたが今今回はこの問題を考慮しまして
えー単語中の
音節で最も以上と推測され音節の
え音楽〇の色で素性というのもえ使用いたします
でえーその本当素性としましてえまず一つ目に正規化音節長というものをえーそうします
えこの最初の成長期のはえー具体的にはえまず原音声を正確に書き起こした音節列です一からＮ
というのと二原音声というの
ずっと働いアラインメントを行ないまして
えー各音節の音声長ＤＦ材料を求めます
え次に音節の頭Ｘ音に
えー音節長の平均２ＢＸとえー文寒い日Ｘを
えー次式のようにそれぞれ求めます
歯もいいＸとＢＸを用いましてで実際実現した音節列で引退してえその音節長を平日のように平均〇分散一に正規化を行ないますこうして正規化された
えー
本節町でいずれが一で要請した音声長として使用します
えこのセッションでその考え方をしましては各音節の処理音にえー成長ないいわゆるＡ標準的な音節の長さというものがあるだろうと
仮定しましてその商店的な音声長からどれだけ一だとしているかという異常さを
で示す尺度になっております
んー
続いてえーもう一つも本当テストセットして正規化音響尤度について御説明いたします
でこちらも同様にえまず原音声を正確に書き起こした音節ですねえー水しかないねと言を生徒でアラインメントを行ないましてえ各音節の音響尤度ＬＳＩというのも取れます
って続いて音節の音素えー九外にえ音響尤度の平均ゆＸを
えー分散ＶＸというのもこれまして
でこれを用いていて実現した音節ｓで五の音響尤度というのを実践を三
平均〇分散一に正規化を行ないます
で構成精緻化されたセッションと言うとえー二階に住んでいるのは先程のえ正規化音節長と同様に
でそのえーその音節の処理ごとにそれぞれ
で存在そその標準的な音響尤度に対してどれだけ以上であるかという異常さを図で示した尺度になっております
んー
定常音二のようなえーと水が音節長と石炭と移動を用いて行く訳ですが
えーここでえー効果が五六において最も多い生起するというのはえフィラー言い直し利用度の尺度であると
いうことをえー頃
しますとえーっと五回かいる来る
とあの書き起こしというのはピザの原音声のＡに比べて
まー短くなって
いると
古いことがえー言えます
一伝わって
てえー
で世紀がなされている部分ではえーと
都会体力の方が見えま短い方でえー二次元二式はされてアラインメントを
えーんがなされている場合が多いだろうと
考えられますしたがっ
でしたがいまして生成した音節長は最大であるような音節
えーとまたは正式な音とＬはえ最初であるような音節列というのは最もえー単語中で最も異常な音節であると
いう可能性が高いと言えま
というなことを考慮しましてえー今回は以下の四つの素性をえー六音節で俺の運動で素性として用います即ちえ当該単語中の正規化音節長の最大値それとえー当該単語長の正規化音響尤度の最大えーす
これ
で最初落ち着か
えーそれとえー当該単語中で生成した音声長が最大である音節の政治家の帰ってきた音響尤度
そして当該単語中で正規化音と言わ対称な音節のセッションがえー
あえ音節長
ん
をえそれぞれえ素性としてえ使用します
またこれに加えましてえ言語的素性として
えー
えー
えっとの
えー指摘がされ易いターム本をまされにくいかもそれはあるだろうということを考慮いたしましてえー単語情報と品詞情報そして
えー
単語に含まれる音節の総数ってのをそれぞれえー言語的素性としてえ今回使用いたしました
んー
え以上説明しましたで場所をえ今回こう海外旅行を用いた評価実験によって評価を行ないましたえ今回は衆議院の実際の公開体力の一部をデーターとして使用しましてえー学習データーには
え四人の話者によるて四十二年間の体力
でえそれが二は一一の話者による
え計六で短歌の回路こうそれで使用しました
また正規化その形式としてサポートベクトルマシーンを採用いたしましたらお砂糖でも楽しいのは主として体にＳＶＭバージョンれてんで気を使用しました
パネルはえー下降し金を使用しております
えまたアラインメント八連続音節認識のデコーダーとしましてはえ本研究室で開発をしておりますプラスプラスプラスを使用いたしました
根拠モデルはＣＳＪから学習した音節モデルになっております
一例ということでまずえー成形箇所のえー検出の
んえーリコールとプリシジョンで評価をした結果
なおこちらになりまして
えー今回えーとーまず音響的素性と言語対素性の両方を使用した場合と言語的構成のみを使用した場合
多くて支度を行ないました
あるのに
えー
御覧のように音響的素性と言語対祖先を両方を使用した結果のその実践と比べて弊害ん言語的と性のみを使用したまへの点線が非常に低いけどとなっておりまして音声の魚と今回えー採用した音声で素性というのは効果的やるということが分かります
またえ本提案手法を経るＶＣＳＲ
誰方法を用いたえー結果と比較的いたしましたえ具体的にはえーＬＶＣＳＲのその認知結果とえーと一世紀えー整理された回路こうしたとしまして
え一致する部分については否定形部分である
で一致しない部分に一月一部分であると
えーして判定するような方法
と判定
本提案手法を比較しましたまた
本当やえーそのえー
ＬＶＣＳＲ
後そのを用いた方法の結果が
えここでグラフのこのこそのプロとのようになりますがこれをえ提案相当
警報をえ変わらない結果とえーなりました
えー
またそれに対してそのＬＶＣＳＲのえー結果をも知る方法とえー提案手法を併用した
方法についての評価を行ないましたその併用方法といたしましてはえい鉄の方法となっておりまず第一段階に
えー指摘された書き起こしと
でテレビ性差の面し結果が閾値以上に伝統を指摘した部分を一正規分布を仮定いたしますえ続いてそれはの部分を対象として提案法による判定結果を採用する
え元気な解の方法
なっている
おります
一二つがえーこの赤い線のえー
んになっておりますがえーこのように
えーと提案手法とを比べてえーほぼまお同様の結果となっております
えこのようにえ二四八つある用いた方法と後その形容の効果がえ小さかったまー原因としましてま
えー今回はこのようなえー
国会答弁
などのえーあ場合にはえー類似差なんですけどが比較的低くなってしまう為だと考えられます
また本提案手法を逆に適用しまして
えー
指摘されてで
つえー推定されていないかそえーつまりえー正解書き起こされている人生ケーブルんの現実というのを行ないました
でえー
今回は音節単位のプリシジョンで評価をしておりましてえそれでＬＶＣＳＲを用い方法と兄はちょっとその辺のことでまたえ評価を行ないましたが
えこのように
えー提案手法によってえ設計された書き起こしの
えー六十パーセントを選択すると
えー
提示音ま検出量としては八十電磁波先頭から二十五六．五パーセントに改善がえーされました一
すまた水はその声で火政策を併用した場合には
え再現率が四十パーセントから六十パーセントの区間においてえーやや再現するという結果が得られました
ってねまたこう推定されたって指摘箇所を
んえええ話者適応の適応データーとしてえー使用した場合とかもえ今回行ないました
え結果はこちらの良くなっておりますがまずえー話者適応話の低持っベースラインのテーマ元に再生させますで今日なしのお陰け残しはまこの程度
ずっとなっておりますがこれに対して単純にこう海外旅行そのま適応データーと成長した場合にはこの程度の
千音なっておりますこれに対して
え提案法を用いて生成さ一世紀部分を
適応データーを設定しをしますとで
その他色々こう単純に利用した場合よりも高い性能が見られましたＬＶＣＳＲを用いた方法に関しましては
え発音バベルの精度は非常に高いのですがえーとまー率が
え低くなってしまう為
っていうえー十分な適用の性能が得られませんでした
て正確な書き起こしの音節食べるを使用したえ場合つまりその戦後のパワー体は席をそのパワーのに対して
え本提案層はえーと
プレース何かにも
えＡ近付いておりますのでま本提案手法による話者適応が有効なので
ないかと考えられます
ってまこれます推定された書き起こしから水がそう自動建設相を改良しました
んえー今後はこれに対して二書き起こしの構築作業をどの程度法律ができるかというのを被験者実験に私を投資したいと思いますまた提案法によってそれが歴史的部分を最適よりをしました
提案法では発音の上の精度カバー率の間にそれどこが
ありましたので今後はより大規模なコーパスを持っていることでカバー率の低下をいがいるかどうかというのを検討していきたいと考えております
え以上で発表終わります
#############################


#############################
# query = 論文の中でえっとーアラインメントをについて二名ているところがあると思うんですけどえーとー論文の中だとえっとー統計的機械翻訳仮説二のところで一回目に共アラインメントについて角が挙げているんすけどんでそこの説明のところの種えーとー話でんえーとその論文のなかなか挙げたととで確か私は本を借ります一つ目を取る後ですが結果を説明していると思うんですけどこのところのとースライドでは説明がえーはい
# rank = 2
# slide = 08-12_fix.match_word.jout.txt
# value = -2.31445869090853
#############################
んがございます
それではあの時間がありましたので
二日目のえー音声ドキュメントすればそこ始めたいと思います
で最初のセッションはあのー検索という
えーセッション名であのー
先日えー昨日の検索一からの一人での検索の発表が三軒ございます
えー一件目の発表はあのー力の一本という二つが
えー
えー認識候補から正解テキストへの翻訳モデルに基づく
えー講演音声ドキュメントなど検査というタイトルであってですね
はい
まず背景ですけども
あのー
んーこれをこの図あのー
あのー昨日もお見せしましたけども
えー音節六年とそれというのが
あのー
大語彙連続音声認識の高精度化実用化に伴いと思いますまず
でその為に音声データーをドキュメントのように扱うことが可能になります
で
まそういうそれがあー可能になった三つとしてえー音声データーえーする検査とか要約とか
ノート
えー従来でその為の
えーす
母音全体をすると
えー
えー必要があります
でそこでこの研究は
えーその水の中の検索に焦点を当てて
えー
えー
定義を行ないました
でえーこのえー発表ですけどもえーっと音声ドキュメントを対象とした認識誤りとか
えー後である二
んー関係などを検索手法を提案いたします
そしてえーその手法
あのー教えて
えー
テストコレクション
読んでいますえー
評価読んでストレートで評価実験行ないましたんでその方法とこう
させてくださいと思います
でまずあのタイトルですね
などを検索という言葉が使われていますけどもこれは
あのー
えー
んまー検索者はですね
えー
そのー自分の水文章を
キーはどうかあー自然言語とかで
えー表現しますけども
えーその検索者が欲しい文章
常検索要求に
適合する文章を
思い付ける多数の言う方えーっと
うん
ですから
あの必ずしもその
えー
えー検索質問の
に現われるえー単語
が単語などが不一致する必要はないのです
んーんえー
そのー
こう水ってを
もし文章が本当に付けたらどうかと
それをえー見つけるというタスク
で
音声の検索
音声の分野で検索と言いますと
あのーキーワードが
完全一致している数を見つけるというは受けた考察とか
こう言うんですけどもこれ
対象とする検索はそうではなくて
えー
こちらはこちらのあのーけどもうあのー
対処して
でえーっとその音セグメントを対象としてあの検索するということはあのーま簡単に
えーやろうと思えばその大語彙連続音声認識を
あの対象
二つ
最初の
まーそのーま音声データーに対して影響してあって
あのー書き起こしのテキストを作ってあれば後は
そのーテキストの
えー検索の問題
反応検索の問題で帰宅されますので
えーまー
えー通常が使えるだけれども問題点としましては
あのー
そのー
書き起こしの再認識誤りとか
えーそもそもデコーダーに
えー
組まれていないボキャブラリー
テーマ
その為に
えー書き起こしにえー未知結果が現われない
いう可能性がありますその為検索精度が低下してしまうという問題があります
これに対しましてあのーここでは
あのー音声認識で自動書き起こしテキストから
本来あのー書き起こされるとはずだった正解テキスト
予測してあってその予測
うん
テキストで
えー文章索引付けてやるということで
あのー
時期誤り等に対応するという方法を提案手法
あーのー提案いたします
でその予測ではあのー動的翻訳文のあの翻訳モデルというものを利用します
これは
あのー
一Ｗ分の一という形で表わす発話
えー
きえー認識された単語が得られた時にそれが本来
んー何だ
そのえー確率ですねそのーそういったモデルを使って
えー
あーのを予測して発展てをしてあのいう手法です
えイメージとしましては
あのー説得ネットワークにえー
えー大語彙連続音声認識で書き起こしを起こしますけどもここには認識誤りが含まれる
でこれに対して
あのー翻訳モデルで
えー
本来
えー
新しい固有の予測である
でえーっと色々な確率であのー
あのー
ま色んな方がそのー
えー予想される訳ですね
でえーそれは
あーの確率の大小で色々ありますけれども
ま今後これらの単語を
方法の確率を考慮して
えー索引付けをさしてやることで
えー
まー
基地が何かを取った場合でも
検索ができるという方法
ところを見ましてえー
んでえーその元の翻訳モデルを推定方法ですけれどもえー今回は
あーのー
音声認識の自動書き起こしテキストと
えーそのー世界の書き起こしテキストを追加なるうパラレルテキストが存在すると
いう観点のものでそこから推定すると
いうことをやりました
でえーっとー指導としては
あーのーまーそのー
母られる存在する文を読んでいる町に取りまして
えー何らにとっては
でえーアラインメントが価値内容に関しては
あのー
数やえーの差異部分的な方はえーと
いうことで
えー関東推定して最尤推定で求めるという方法を取りました
えーんで
後で説明しますとまこういった
えー自動書き起こしに対してま世界の本場の
カップってのが
えー与えられ
んでアラインメントを取りますと
あのー
正しいところに関してはあーのいただいて対応しますんでここに関しては
あのー
それぞれ一一帰っ
えー現われたという風に
えーカウントする
んでえーっと問題はその認識誤りを起こしてるところでここに関してどうやってアラインメントというところが問題なります
でこの問題に対して
えーっと
今回はですね
えーえっとー
ま二つの方法を使ったりですとかえーっとなんでまー五分法と呼んでますけども
あーのーまー
その
えーっと分からないところそれをえっとー二五四
関東に関して三通りの
更に評価の差がありますで
えーっとこれを
えー三分の一つえー
現われたという風に見なして
えー
簡単化させあーいう方法です
でえーまー
んー的な環境
コーパス全体で
えー設定して三つ一つである
もしの方法はあのー飛行さは
んー考慮してあるという方法で
えー
そのー
今の場合ですねこの部分に関して
交差のアラインメントを考えてやっと
えー御覧の通りの一通りの可能性があります
でこれあのずっとやっそれぞれ一すぐ
あのー表われという仮定を置いてある
んで例えば感情が
えー患者にアラインメントされる
いううー可能性はこの二通りのちょうど二通りありますので
えー
環境をえー自分もいう風に
与えて
えーことですね
で後はですね
えーコーパス全体で集計して
えーモデルを推定して
という
方法を取ります
でえーっとこのこのようにして求めたえー単語訳ですけどもこれをあのー
えー
本問題の単語の
えー
ＴＦＡ
単語頻度です単語の節に現われる
えーヒントを予測する為に利用します
んーこれはあーのーこちらの式で
あのー
団地ですねあのー
本来現われる単語の
えー子音の期待値を計算できますので
えーこのテープを使って作品ですという方法取りました
でえーその時にですねえーとあまりその
えー頻度が低いものに関してはあの比率で索引付けには
あの使わないということやりました
で閾値が
あのー例一から〇．〇一まで
あのー
色々変えてみて
あーのー実験をやるとなっております
えー
んでえーっと評価実験ですけれども
えーっとあーのー
テストコレクションとしてあのー
えー情報それが可能にするえー研究して今
えー構築するの
えー一つで絵を対象とした音通過音と検査ってところと
と
いうものですねこれを使って評価を行ないます
えーそして
えー自動書き起こしと一つだけを用いた国検索手法とあのー提案手法のえー比較を行ないます
でまずそのＣＳでえとこれ一について簡単に
喉頭化いたします
えー生成ですとこれですのはそのうち一つ前の中の
えー学会講演共にこうえ全部で一つは二千七百公園
えーありますけれどもそれを対象としたテストコレクション検索のテストコレクション
んで
えーその国ですねあーの講演方を検索する
というタスクではなくて
講演の一部ですね公園の中のえー
別英語発話程度の間
で
あのー
検索の
えー適合文書適合するかと
なるような
えー警察も
こうえー
んーに対するってところそれなってます
でそういう九月の三十一日
んでえーっとまー
あーの二つについて詳しい
っていうことはこちらの三本あのー
あのー御参照いただければと思います
であのー大体二匹を
御説明いたしますと
えー例えばこういう
そのですね情報検索性能を評価するなどの方法は主体
いう
質問がありましてこれに対して
あのーＣＳで
あのー書き起こしテキストは発話単位書き起こしが得られています
で
あのー普通文に対して
あの適合文書というのがそのー
えー
講演の一部として与えられてこちらの
えーっとー
爆発なってるとこですねここが
この質問に対する適合であるとまこういうタグが
あのー付いてるということ
でえーまー一つはこういう箇所を
えーに付けましょうという検索タスクになって
でえーっと
えーっとー
そういう検索テストコレクションとしてあのー著名なものにそれであのーＳＤＲというものがありますけどもえー今回
その生成さコレクションというのはあの基本の面ではこれに
え相当するような
えーものが出来上がっております
で最初はあのーニュース音声とおー四つうかなり違うんですけども
えーまー数を
んそのーあのーもう二としては
えー大体あのー同じようなものになって
えー
えー
でえーっとー
このえーそこら二つの実験に用いた訳ですけれども
えー
と
えー
そのます検索数の設定を
少々あのー
あーのー
後は検索変化するように変更しました
で
えーっと
ま本来はそのー
えー
海とか思い付けるという易くなってるんですけども
それを
えー固定長の区間に予め
あのー対象文章の方を区切っておいて
でその固定長の区間を
見つけるというような検索タスクに定めます
でこれはあのー講演をですね自動的にえー上から
あのー機械的にそんな発話が〇
えー
区切ってあ
でえーその区切ったかあ汗を見つける
深くえー検索の文書だと
え私の分野と見なしてその文章に付けましょう
いうタスクの設定にします
でその時のえーこう低区間をえーと今回は中央蓮は三十発話六十発話の三通りで
えー調べって評価を壊し
えーっと
んーイメージですけれどもえこれが生成の書き起こし
挙げられます
でこれを先頭からえー自動的に
えー例えばを発話でえー
あのー
ん区切りであると
でその一つ一つの区間があのー検索対象の文書ということであり
でこれに対してえーと本来は正解が反映されてるんですけども
えーこの部分が少しでも
えー重なってる
がですね
それを世界の息子だと見なしまして
えー
そのえー空間を
えー付けてあのー
この文章重み付けであろうという
検索タスクを設定
が
えー
えーっと評価尺度としましては
えー実験Ａ型精度というものを使ってますこれは
あーのえー再現率こう出て〇から１．〇まで一一点
えー取りましてそのから再現率母音とでも
えー検索精度を調べてそれを平均したものだっ
えーこの値をえーす警察も全体でできると
ものが評価尺度になっ
でえーっと実際にはあーのー各検索クエリーであのー検索システムによって上位千件の検索結果表
えーこの
でえー計算量を計算し
んでえーっと
それでえーっと学習データーと評価データーについてえーお話します
えー
で今回そのー
おられるテキストが必要ということでパラレルですとあのー
んあのー
実際に付いてそこへそのー
えー
で
あのー
世界の書き起こしとあのー認識結果が挙げられますでまそれを
あーのー町であれしたいんですけどもまそれが今回の
えーっとー
検索の
対象と重なってしまってるんですねそれをちょっとあのうまく使いたいということで
あのー
まその方が辛い料理
えーうまく
んえー
調整しますでそれはあのー交差検定
んー
えーまならもうこれ索引付けをするという方法で
対応しました
出ることやったかと言うと
あーのー対象文書
最初のえー
えー別ですねユーザーがえそのこれその文章を
一えー一個に分けてあって
んでそのうちのまー一ブロックを
えーま今回の方これ索引付けする為に
残りのブロック
の
えー文章を学習データーとして使っ
でえーっとそのえー翻訳文での学生の頃ブロックを
そこの九九六でこのモデルを
まそして
その翻訳モデルを使ってえー
ある
ブロックの削除して
でこれを二通り繰り返すことで
あーのー学習データーと評価データーは
えーうまくだったように
えーしました
でえーっとまずあのー後えーっとその翻訳モデルを使うことであのー認識誤りがどのぐらいカバーできるのかっていうのを簡単調べてみました
でこれは
えー
とー
えー
あーえーっとですね
えーっと
ま一番
んえー左第七ポイントですね〇のところポイントが
えーと本来の単語認識率になっています
でこれに対して翻訳モデルを使うと認識誤りのおこうした数に関しても
あのー
正解がま予測できる
んでえー
それ
そのその単語が親のモデルで予測できたというのを調べて
でえーっと確率
その時に確率が
えー〇．〇一二以上ですねこれはあのあの係数でえー
ただ身に付けする時の閾値に相当するところなんですけども
えーえそのえー
確立されて〇一以上で
あのー
正解単語が現われると
っていう時にあのー
ん式でしたいう風に仮定してあると
また分布モデル使うと
えー大体八十六．二個ぐらいまでですね
ま学習データーの
んように
えー
なら
えー
えー認識率の方ですという
んー
んでえーっと
んこちらは
えー
とー
えーとこんな検索の成分についてえー
調べたんですけども学習データーの量との関係を
調べました
でえーこれは
えー
と横軸が学習データー量ですね
でえー縦軸があのー
先程のえー実験Ａっていう
っていうことになり
でえー
文書サイズを六十三十一本あのー
えー三通りで
あのー検索の制度を
あーの求めております
でえーっとー先程のあのー
交差検定で一分割するとま最大でですね
えー六百万形態素ぐらい
反映させて使えるんですけども
まーあのーできればかすれた少ない方が言える訳ですねどのぐらいまで
えー耐えられるかというのを調べたということ
でこれを見ますと
まーあのー比較
ん百万ぐらいで大体
あのー
えー
んーま上映会に出して
えー
んでそうですねまそれそれいる訳でもそれ程
専門性分からないということが
んー
でえー次にあーのー
下りの閾値ですねあのー
どのぐらいまでそのー
えー
家二を使ってやると
いうところを調べました
えー
あのー
あの閾値を色々変えてみて
えー検索性能がどのような
いうことですね
でこの調べてみますと
えーえっとー
各
えー検索対象のえー
もう草ですねそれに
あのーて随分違って
で一は発話の場合つまり短い完全に帰るか区間を物が出出した場合には
あのーなるべく
その閾値をされてあって
あのー
ま多くの
えー
いうふあのー単語をあのー予測してそれ作為に使ってる方が良いと
えーいうことなります
ただし
えー三十発話とか六十発話になると
えーあまりその索引語を増やすと約二の水なんです
えー何閾値の設定によって
あのーまー
有効なポイントがえー違うということが分かります
えーっと次にですねもう学習データーに
あのー
まー別だけを使うかってベースを使っ
っていうあのー違いをあのー調べて一つこれは
えーっと
んえーと認識認識の方法としては
あのー
何ですとか鍋
んでこう誰だってますので
んでそのー例えば年齢つまり使うとするとこの懸命ですとと
正解単語の
あーのーパラレル
後はそれぞれできますね一枚の学習データーが得られるんですね
ではですだけを
あのーパラレルですとして使った母が例ですと思いです形で
えーまーその
精度の比較を
センターという
んで
えーっとこれで見てみますとまー
二つを入れる違いは
ありますけれども
ま概ねえーそのやはりえーですとま例使ってやった方が
あのー検索性能は色々
いうことが
んーすえーとこれは
横軸は先程の閾値で
えーっと各
えー発話モデル一点ですとは別であのーそれで私共の
になってますので
えー
ここのところで
兄弟でその方があのー上を言っているというところ
えー
挨拶それでえーっと
ま本提案手法をベースラインの検索すると比較しましてあのー分析のいうところ調べました
でえーっと
ベースライン手法としては
あのー書き起こしテキスト本来の書き起こしテキスだけを用いた一般的な文書検索手法を実装して
えーそれとの比較を行なっ
ありました
でえーっとさというでにはあー形態素を用いてえー検索モデルとしてはあのーま提案手法も
で債務者ですけども携帯で二
ですね
あの重み付けを使ったベクトルのモデルを使っ
でえーっと更にえーに観察させたんですてまして
一つはあのー書き起こしの番ですだけを使って
削除した場合
で二番目はＡですと
今まで使ってえーそれを
全て使ってあのー
あ作品です
でもう一つは
あのー
えー本来は
新しいものですねそれで発表したテキストを使ってたという二つの本当にその
学校行ないます
で提案手法は
えーっとーま翻訳モデルを使っ
えー
えー
えーとその中の
えー今回えー別ではなくてはん別二番目その方
の
えー
んー誰テキストだけを使った場合と音声の方の比較を
えー実験結果ですけどもえーっと
んで軸が
あのー
先程出てきてございます
えー
それでえーっと町を一個三十六一で書いた場合の
えー性能差を示しています
でえー各
えー発話長に対して
えー左から
えー
ベースラインとは別だけを使った場合
んでその次が点滅を使う場合
んでえーこれ〇のところが
えー今回
あのー
えー提案しました親子モデルを使った場合
でえー一番
えー左側が
えー書き起こしの方がえーになると
んでこちらを見ますと
えーっと一五発話の場合はあのー
まーんえー提案手法の数を
んーが
えー
非常に良いと
えーっと従来のワンベストテンベスト
二よりもえーまー
関連性を持たない
で更にですね書き起こし
もうそのまま使った場合よりも
あのー
高いいー性能が得られたいう結果が
得られていますでこれは
あーのー母親のモデルを使うことによってあの二城下町駅の方から
あのー笑われたりするのではないかと考えて
んー
でえー三次の場合ではえーっとまやはり多いんですけども
えーえっとー六十
の場合にはあのー
まー従来手法とそれ程変わらないという結果がえー
えーっと
まとめますと提案手法は二一が小さい場合に効果が認められました
でえ特にえー
自分発話ですね一文発話の場合は手を一パーセントの改善が
でえー大きい場合には
効果が得られませんで
えーまそれはあのー
翻訳文文や学校
えー推定したでそのモデルが
増大お六十発話ぐらいあるとまその文章文章の認識結果ぐらいで十分冗長で
えーまそれ以上暮らしてもあまりこう何という結果帰っ
で今後の課題としてはまー
あえーと翻訳モデルの精度化でで特にまー
えー八つの単語
の
対応ですけどその方のえーとこういう三のものを考える
えーえー
でここが考えられると思います
えーもう一つ
検索情報が単純なあーいう形を使いましたけども
えーっとその
もう百モデルを使う限りあのー
方法が取らという風に解釈をし直して
えーデーター一二
えー適用したんだけども
まず
その方法や
あーの結局そういう風に翻訳し直すと
いうところであの翻訳モデルってのは何かす何であると考えて
てこれ以上
でアクセントは元々
でえーっとその
えー翻訳モデルを直接えーその利点を直接利用する
で方法としてま言語モデルのも検索手法
今
えー考えられてまそういう方法使うと
えー良くなる可能性があるんではないかと考えております
えー
以上
で発表終わりますでその
えーうーそのー
まー
#############################


#############################
# query = 同じかなり論文なんですけどえーとここえーとーこの研究でＩＢＭのモデル言語を使っあげるところがあるんですけれどその中のえーとえーそれ気年齢者をモデル二十一メールとこうあのーが腰分かりにくかったのでそこの説明えーまず回路が一つ目が教ええーととーまず言い替ええーとあのー本当にえー場合とおーくって聞い言語の単語にはい要するに原言語の単語がない時にえーと神の単語を対応付けるいうモデルだったとけどそれのモデルのスコアあー結果的でところがちょっと仮に掛かったのでこのところな説明後詳しくでいいと思います
# rank = 1
# slide = 07-22_fix.match_word.jout.txt
# value = -3.07295796093972
#############################
はいに神戸大学の男女です表記のタイトルで発表します
えー初めにですがえー研究背景ですがまー皆さん学校に来られて皆さんもずっとこう刺されてると思うんですがまマルチメディアのコンテンツま音声だけという眠いですが
まそういうものの方は開封して
まそれを検索しようと
いうようなえー
いう気がま非常に高まってい
でそこでですね話し言葉の
音声認識というものは
ま必要かつ重要な二つであるということで我々の研究をしては決して
で実際にはですね話し言葉
ま公園とか痒いとかですね
まそういうものの音声の認識の認識精度っていうのは大体
ま六割ぐらいから
の八十八パーセントまＣＳＪとかではこれぐらいになっている訳ですがまこのような認識精度になっている時
えー
そいでですねまーどういう音を使う
んかということを考えてみますと
毎日新聞とかですね我々なったんですが重要文にあのインデキシングとか
ま情報検索まこういうことやる場合にはですね
ま必ずしも全てを書き起こす必要がまーありません
でキーワード
本
とかですねま重要な単語っていうのがあ認識実際すれば
ま現状の認識精度でまある程度こういう問題利用可能というような状態になってると思い
一方ですねま放送ニュースの字幕付与と月二回力の作成まこういったものを考えますと
ま特に放送ニュースの字幕付与は
ま昨日の話にもありますように日本ではまー
でまかなりの精度が求められるという話もありますし
ま会話文の作成
となるとですね
今言ったんですね
まー
後程後で人が生成する訳ですから
ま必ずいたん全てをテキスト化しておいて
んーまそういう必要が要求ある訳です
でま音声認識の構成とかっていうのが必要になってくる
いいような
えー父が
に
でですね放送ニュースとかですね体力ま今国際化の時代でして
でえーまそういうところ考えますとま丸二チャンネルの音声が利用可能なケースがま多いと
いうことで
って帰りに見ますとま二つの場合ですとまた国語で放送する
ま放送があったりですね
後はま国際会議とかですと同時通訳物なんかがありましてそこへ同時通訳の音声が
まー流れてくるというような状況があって一
ま結構あるというような状態です
でして
まそういう場合はですね
まーあのーチャンネルが複数ありまして
その複数のチャンネルに
ま異なる言語で同じ内容が入ってくる
そういう状況が
ま仮定できる訳ですね
で従来このような真ん丸チャンネルの入力を仮定したような研究っていうのはま今日の発表にもございましたけども
ま基本的には同一の設計の仮定してましてま何をやるのが目的かと言うとま雑音除去とか
ま方位推定とかするのがまー目的
全体をする訳なんですがま本研究ではそうではなくて
えー全てのチャンネルに入ってくるのは複数の異なる言語
ですが同じ内容の発話
いうような状況家庭
でこの認識をやったいよということで
考えて
明確チャンネルの音声の認識をま情報にないながら同時に
実行するということをえー一体
ことを考えます
説明えーっとーえ具体的には機械翻訳ま本当翻訳モデルなんですがま父的なモデルを使ってえ音声認識をやってやろうということになる
でま色に一一二年のまー二千五年のところでもん何では発表があった訳なんですが
まこれはえー
旅行が音声であったりする場合にはなくてかっ解答がテキストデーターというな状態
を仮定するようなものも
組まれてますま旅行が音声の場合もありますが
また両方をえーヨーロッパ系の人語でして五十も視覚的に行けますしまー近い
ですがま日本語英語っていうようなこういう機械翻訳がまー困難であるようなタスク
後ですねえ対象として研究ってのがまだやられてないということでえーまやってみました
いう風な
でえーちょっと皆さんあのー例えば一日
変なんですがずっと付き合ってる
初めに統計的に
音声認識を話しいー申しますと
ま音声認識ってのはえ音声が与えられた時にそれを最もよく説明する
単語列を求めるま式にはとこういう
プロセスな法ですが
まー展開していって結局はこのこういうような
で一方最大化するような
単語列を求めるということになる訳なんですがでここで
何品のダブルスを担った得るものが言語モデル
んでＰのＸは多分声ですねこれ与えるものが
音響モデルと呼ばれます
その辺が当たり前なんで
軽く延ばしまして
でえ統計に機械翻訳の方の話なんですが
これも同じような考えていきまして
まある人の原言語なんですがその単語列
が与えられた時に
それを最もよく説明する
別の言語の
目的言語なんですがその単語列を
あっ
それを最もよく説明する別の言語の単語列を求めるプロセスと
てえー定式化され
で次に掛けますとこうなりましてでこのモデルを翻訳モデルと
えー四人
であっこのモデルこの確率は楕円モデルを翻訳モデルと呼んでましてこれを翻訳スコアとか
またえーえ
単語の太陽とですね文の太陽とかあってで今
んでえーこれを使った音声認識についてずっと定式化をしてる人
でここではまー複数言語と言いましたが二か国語をえー考えてみます
で日英の同時認識してえーま日本語の場合の認識
の式を書いています
でこの場合はですね日本語の音声Ｘと
ま英語の音声Ｙが与えられた時に
それを最もよく説明する日本語の文字列を求める問題として定式化できまして
んでま色々
変形していくんですが
まこの辺は
ちょっと
走りまして
えーっとー
まここで英語の可能な単語列というのを
ちょっと
どうにえーしまして
三ちょっと整理してみますと
まこんな感じの式になり
んこれよく見ますとここが
日本語の音声認識のスコアなってまして
ここ外部の音響モデルのスコアですね
でこれが翻訳スコアなんですがちょっと見通し悪いのでもう少し変
金
もう少し変形します
全ての
はいなんですが対数取っていまして
ま重み入れてみますとまこんな好きで
なります
でここ
ベイズの
って言って展開してみますと
まこんな感じになりまして
でここにみんなでえっとここにみんなでありますので
まこの重みを
え一二三四αと言って
Ｂを元はと言って整理しますと
ま緊急こんな感じの式になる訳
でこれ見ますと
この部分が日本語音声認識のスコアなってまして
ま対数取ってるんですが
でこの部分が英語の音声認識のスコアになってまして
でこの部分が翻訳モデルのスコアになってると
そういう状態になり
違って音声認識日本語の音声認識を行なう時に日本語の音声認識のスコアと
ま英語の
中間
構造みたいなものと
翻訳モデルのスコアがあれば
音声認識が行なえる
いうことになり
でえーただ頭でかって書いてみますと
ま日本語の前求める場合は
日本語の音声認識の
システムどういうあの音声認識のシステム用意しまして
電話中間表現ですねＮベストリストだっ
あまり
ま単語グラフなんかを出して日系
それからもう一つ翻訳モデルっていうのを用意しまして
でここで
まリスコアリングをしてあるこの式に基づいてリスコアリングしてやるというようなことに
形
でこれが一応定式化した
ものですでこの枠組みが正しいかどうかっていうのちょっと予備実験をして
評価をしてみました
具体的には
えーえモノホンの音声認識を行なわずにつまり英語の方はまテキスト与えて
音声認識が百パーセントできた状態を仮定して
ま日本語の音声認識を行なうということをしてしました
んで
まずえー見ますとこれ先程と同じ図なんですが
ここのところが
英語のテスト三になりまして
んでえー式はこの式になり
ってのが好き
もう一回見てみますと
ま日本語の音声
後
上のテキストが与えられた時にそれが最もよく説明する
日本語文字列体を
求めるプロセスで
典型性と行ない
でこれを
えー後の音声与えた場合なスピードを比較してみますと
まここ見ますとここで
このいいなＭっていうのが英語の
あの可能な文字列全てなんですが
まこれが一通りの場合とですね
評価になるということが分かり
という訳でまー枠組みとした同一ですので
こちらを使って
えー
評価を
まーあのこの枠組みが正しいかどうかっていうのを
えー検証してみた
そういうことになり
即ち日本語の音声認識のスコアと
翻訳モデルのスコアでリスコアリングした
そういうことになります
で次にあのこの馴染みがあんまりいないと思われるこの
翻訳モデルの方について説明します
で翻訳モデルですがこれは異なる言語の文字列
ここでは二五三と書いてますがその対応そこは
ま翻訳スコアと呼んでもいいですがそれを
与えるもんで
んで
でここで問題になるのは
多分
に例がありますように
ま語順がそもそも異なることがあると
殆ど異なるでしょうそれから
言語間でのたい単語の対応はですね必ずしも一大事ではないという問題があると
いうことになる
それから
正しい対応付けまこれ今人間が書いてる訳で
正しい対応付けなってる訳なんですが
まそれがコンピューター的には何が
正しいか自明ではないと
いうことで
その確率モデルとして全て
の可能性を考えてですねそれを
全部足してやるというようなことをして
でこの一つの対応関係をアラインメントという見まして
それをまＡとして表わしますとこのような
確率を全ての可能な
アラインメントで
えー
三年住ん取ってやれば
いいということになり
でえー具体的にはＩＰＡのモデルスリーというものを利用しまして
採用しましてこの確率を計算し
×について少し説明し
大人のせりふのＳＤでは
えー
内容スコアを
四つのモデルでモデル化します
で
二つ目は
ここにありますここここの対応スコアを与える
パパに良いモデルなんですが
これはある
原言語の
単語がですね目的言語の
前の単語に対応する確率を
またえーとモデル
その場合は丸二
二単語に
えー繁殖してますこの
この値を
与えるような
隔離
すーモデルです
そいからも二つ目のモデルは
ここなんですが
低年齢自然閉鎖音モデルにまして
これはですね目的言語の
単語例えばは国家を使いたい要する英語ってのが英語の単語はありませんので
その場合はぬるというものに対応してると見なします
即ち音の前にえーそのするモデルが必要でして
まその
モデルって
で三つ目は
まこれは直感的に分かり易いんですが二十四個モデルで
ある
言語の単語がもう一つの言語の単語に翻訳され
そういう確率を与えるモデル
で最後に
語順の入れ替えを
いいですようなモデルでして
プラス一つのモデルで生まれまして
それは元の
言語の丸一の単語が
目的言語のある一つの単語とま採用するという確率は却って
でＩＰＡのモデルツリーでは
その
一応絶対値で与えてるとそういうような状態になっ
でえー評価実験を行ないました
で先程もまーおんなじ説明あるんですが
まこの式に基づいてえー
つまり
対訳英語テキスト与えて日本語音声認識を行ないました
んで音声認識でＮベストリストを生成して
の方訳モデル
のスコアを
用いてリスコアリングするということを
やりました
で評価実験のデーターなんですが
評価データーは
で今回は日英対訳ニュース記事
を持ってきましてそれの日本語の
部分を読み上げました
日本語を読み上げたのは日本語母語話者三名
が五十分ずつ百五十六二三挙げました
で基本的に言うと読み上げてますので
ま御読み上げ音声認識システムを使いました
暮らしＳＲ子音の最終マンに入ってるものをそのまま
買いましていいやつは三．辺に
で音響モデルは
えー何て言いある多数話者モデル
んで
それから言語モデルは新聞記事から学習した
単語トライグラム
モデルこれを使います
で翻訳モデルの方は
先程説明したはい三のモデルツリーを
にはプラスプラスというもので学習しました
で学習データーはどういった記事一対訳コーパス
でしてえーこれは五万六千人
日本語が
約
六十七万単語で英語が百三十二万単語ぐらいです
んでこれで
先程の
ＩＢＭモデルスリーの四つのモデルを
学習しました
で実験なんですが
えーっと音響モデルの方についてえーまモノホンとトライホン使ってみたんですが
ま結果三名ずつなんで
えー
六割
で縦軸がえーと認識率でしてえ赤色が
普通に音声認識を行なった場合です
で青いのが翻訳モデル使った場合
で見てみますと
翻訳モデルを用いた場合に
まあのー認識率が
でこの辺の食結構女性ということが分かり
で特にまーこの辺ですね元々認識率が低いようなところで
精度の向上が
ま見られるというようなことがありました
え実際の話し言葉の音声認識っていうのはもっと元々認識率低いところに
あるんじゃないかと思われますので
漫画がこういうことをやってやると良くなる可能性があるんじゃないかという関数多いと
でえその次に
今この
言語島民の頑張って掛かってるんですがこれを
ま事後的に良くなるように決定していったんですがこれを打ってみたらどうなるか
いうのを
えー
でこれモノホンの結果なんですが
ま〇．五から〇．〇から一まで
〇．〇五刻みでやってまして
ま三ミリありまして
疑いようがベースラインで
の色が
えー提案手法です
んでま見てみますと元々認識率が低いようなこの二つ
の結果はだいぶうー何やっても良くなるんですが
元の二太陽熱はちょっと
えー
重みが高くなっ
まー
と翻訳モデルのみを強くすると
逆効果になってるというような効果があっ結果が見られました
これ何か大会という訳では多分ないと思うんですが物と実験が必要と思い
それから
トライホンの方なんですがこれはちょっと思ったえー作って
何かあんまりどこがいいのかってのよく分からない
で調査した範囲にもま対立というのがよく分からない
いうような
先程するような対立ってのはないん何なかったんで
もうちょっと頑張って調べなっていて
んで
ま以上調べてみたんですがまー元々
認識率がトライホン使った場合高いので第一候補が
一番いいんじゃないかといういうのもあったのです調べてみたんですが
まＮベストリストで二十
ベストぐらい出してですね
えーっとーそん中から一番いいものを選ぶということやりますと
こっから五パーセントぐらい全部上がるということが
分かりましたので
ま何かうまいことを選択が
できればまだまだこれは改善するよう違う
なるなというところは分かって
ただちょっと
本なぜこうなってるのかってのは今検討して
えっとまとめますとま国際会議とかニュース
二日で丸二チャンネルですね異なる言語で同じ内容の発話があるような
場合の音声認識をについて検討しました
でえ予備実験としまして
日本語音声認識時にま英語の方は認識しなくてテキストとま機械翻訳を用いて
実験してみて
そういう枠組みがきちんとうまくうーことを確認しました
で今後の課題は
ま実際の話し言葉での実験および評価することと
ま日本語と英語両方ですね
今ここ敬語の方が誤りがなかったので
よくなってる可能性も
まずではありますので
で音声認識してみる
でそれから
ま今は
自分の
太陽っていうのは先に付いてるような状態ですし
まー同時通訳
とかとは少し性質が違いますので一体よこしたものですので
ま同時通訳とかを音声認識してみるというなことも
ま必要だろうなということは
って考えて
でそれが最適なと思うんですね先程の
ま振ってみたんですが
まあんまり分からない熱でこれこれをちょっとどうやってき見るか
いうところを
検討していただい
思って
発表は以上
#############################


#############################
# query = 同じかなり論文なんですけどえーとここえーとーこの研究でＩＢＭのモデル言語を使っあげるところがあるんですけれどその中のえーとえーそれ気年齢者をモデル二十一メールとこうあのーが腰分かりにくかったのでそこの説明えーまず回路が一つ目が教ええーととーまず言い替ええーとあのー本当にえー場合とおーくって聞い言語の単語にはい要するに原言語の単語がない時にえーと神の単語を対応付けるいうモデルだったとけどそれのモデルのスコアあー結果的でところがちょっと仮に掛かったのでこのところな説明後詳しくでいいと思います
# rank = 2
# slide = 07-13_fix.match_word.jout.txt
# value = -3.08507302779611
#############################
えーそれでは京都大学の根本が表記の題目で発表させていただきます
でまず最初に研究の背景についてえー説明します
定期健康にはそのデジタルアーカイブかと取り組みが活発になっており
でそういった中でえ要約テキストやインデックスにより人に利便性を向上することが望まれておりますが
って人手によるこれらの作成は非常にこう子育てを今
でそこでえー音声認識技術の活用によるえーこれらの
半自動化にえー
検討されており半自動化が検討されております
えーそこで本研究ではえー購入音声の認識に取り組んでおります
で本研究で対象とする購入音声の特徴と課題について説明します
えまず本研究ではスライドを持ってる購入を想定します
でここでスライドで申しますのはまこういったパワーポイントの使用のことです
えー
スライド対を用いたさまざまな項目の説明がこういった行為が行なわれるのですが
えーここではあって
スライドにえ専門的な内容が多く含まれる為
抵抗に全体としてえー最適な話題が存在します
え更にえー表示づらいのに関連する発話内容がたくさん現われたり
えースライド前の重要度スコアが反復が起こったりすることから
で局所的な話題の偏りが存在します
えこういったことから
共通の言語モデルのによる認識はＦ０となります
で具体的にどういったことが起こるかと言いますとえー話題に特有な表現の予測能力が低くなってしまう
で更にえ専門用語が未知語になり易い
といった問題が生じます
えそこで本研究ではえーこうに面移動を手掛かりとしてえ言語モデルの適用を行ないます
えこれまでにもこういう音声に対する言語モデルの適用の試みは数多く行なわれております
え代表的なものを御紹介しますとえ関連テキストを利用した方法としてまこういったものが存在するのですが
えーこれらは
影響関数がこうに音声の書き起こしといったテキストデーターを使用しております
ですがすえーこういったテキストデーターがえー電子化されていてかつ利用可能な係数というのは
テーマ限定的であります
でこういったことに対してえースライドするようを用いたえー言語モデルの適応の手法も提案されております
え具体的にはえーつらい顔のＮグラムの他による手法
が提案されているのですが例えばこれは断片的な絆知人となるえーこう二スライドではえー効果が奇麗に出てきたなと今
んー
えまた話者するモデルを用いたえースライド全体のテキストを使用してえ適応を行なってあるという手法も提案されているのですが
でこれはえー行為全体の話題に対する適応のみが行なわれております
でそこで本研究では
効率ライトの特徴を考慮した手法を検討します
えー
で具体的にはえー効率ライブにおいては
キーワードを中心とスター断片的な絆が中心であるといったこと
え更に二系列に沿ってこうに内容が記述されているこういった特徴声を使っ適応を行ない
えそれではえー本研究で行なうスライド映像を利用した適用の概要について説明します
えまず最初に
えー
でえーつらいこう二スライドで使用された面間の全てを用いてえー言えるえー性能持っていることでえー具体的な話題対する適応を行ないます
えー更にえー
学校にスライドからえー一つずつえー検索えー四一つ一えー空を用いてえー検索を行ない
くえー通常されたテキストを用いてえー適用言語モデルを構築する
といった手順で
えーこれまた一的な話題へ対する適応を行ないます
えー更にえー話題の局所的な課題をいへの適用としてま適応としましては
えー
各スライドのテキスト情報を用いてえーその面以外に
えー時間的に対応する発話に対してえーじゃすモデルを持っていることで
え局所的な適応を行ないます
えまたえーこの言えるえー前による大域的な適用
それとえー気圧モデルを用いた局所的な適応えこの二つのえー組み合わせることにより
えーえ帯域的な適用さ局所的な適用映画痩せることを行ない
んー
えそれではまずえー言える性を持っていた最適な適用についてえー説明します
でここでは
えー
五につらいあの単語頻度情報を用いたって言える衛生を用いたえー単語確率の推定
更にえースペインが
といった二つの手順でえ適応を行ないます
えこれまでのＰＬ衛星を用いた研究はえーさまざまなものが行なわれておりますがえーこういった枠組みに基づいております
でここではえー
単語確率をえー部分空間への際に基づきえこちらの好きでモデル化します
えここでえーこの潜在変数の時
というのはえー話題に対応するもの
え突然
え家なアルゴリズムによりえーこちらの日なバブルって言っＰのＴＤを付いてきます
えーコーパスからこれを推定することにより
えー人手によりえー話題を事前に定める必要がないといった特徴が今
え更にえー適応用文章おーまー持ってきてえーそれに対する潜在変数の生起確率の推定
を通じましてえー単語の生起確率を推定することから
で適応用文章の中に出現しない単語の確率の推定可能となり
でそしてえ本研究ではえー次のようにしてつらいと像を用いてえー単語確率の推定を行ないます
えここではえースライド全体をえー先程申しました適応用の文書として
えー単語確率の推定を行ないます
えこういった推定を行なうことで
でまず単語頻度のみに基づきえーこの確率が推定されます
えーその為えーこう二スライドなどでよく現われるえー一番あのキーワードの羅列などからえー確率を推定できま
えー
え更にえーコーパスから学習した潜在変数の生起確率を通じてえ最終的にえー単語の生起確率を推定することから
えーつらいの中に現われない単語の確率も推定されます
えこういった特徴があることからえー総数の間にられた単語によるえー断片的な記述が中心であるえーこうつらいと思っている場合に言える衛星が有効であると言えます
でそしてえーこのようにして求められたえー単語確率を用いてえー家からマスキングを行ないますえこちらの好きならされるのですが
でこれはえートライグラム確率全てに対してえー先程の推定行なうまーえー計算量が膨大なる為えーこういった計算を行なうことにして今
えまたはえー
スライドには主に話題に関連する傷が中心ですのでえー話題の三への適用を行なう為に
えー話題の人の語彙を限定してえーこちらのスペイン語を行ないます
でこのようにしてえー言える衛生による影響が行なわれまして次にえーテキストを用いたえー最適な適応について説明し
えこちらではえーまず
あ失礼しました
まず最初にえーこれの抽出とえーテキストの生成そしてえーそのテキストの収集道具の選択という二段階な手順でえー適応言語モデルの構築を行ないます
でまず最初にえーかつらいとからえー検索色を生成します
でここではえーＴ会とＩＤＦ値除いた名詞をえー各スライドを元にえー選択します
えそしてえーこれは検索をいたしましてえ検索エンジンをもついてえーれるテキストの生成を行ないます
えこの際えーまずえー十分な数のえーテキストを用意したいのでえー
マーカーと移動するとえー
ごみが増えてしまうのでえー二つの町にはえーくえー一つ当たりえー五百件
と定めました
えー
でそして次にえー集められたテキストにはまー
類ＩＴをえーま相手の長さより短い文や
えアルファベットがえー殆ど全て言わない言語モデルの学生にあって汚いと思われる文がまれるので
えーこれらは付いてしまう
えっとですが
えそしてえーベースライン言語モデルに対して
えーパープレキシティーを計算しえー猿がスキー場したまた文をえ学習用のテキストを
として選択します
でそして最後にえーベースライン言語モデル
のえーこの
適応用にえー集めたえテキストの今後行って
でえー適用え言語モデルをこう
え以上の手順で
テレビで傷を用いた言語モデルの方もえー適応が行なわれます
え次にえーじゃそのモデルを用いたえー局所的な話題への適用について説明します
でここではえー
じゃすモデルの枠組みでえーこう二つられたデーターを使用することで
で最終的な音声に
結果を得る
そういった手順になる
でまず最初にえー提案するモデルについて説明します
でじゃすモデルというのはえー直前に現われた単語は再び現われ易いという仮定に基づき
えー各
各単語の直前の単語履歴をえーチャンスとして記憶する
といったモデルになっております
えー突然
えー単語確率をえーこちらのようにえー
履歴の中でのえー単語頻度に基づいてえー推定します
えこの単語履歴はえー最初に自動音声認識を行ないますでえその結果を用いてえー得られ
え次にえーこの二話者モデルにえースライドを情報を利用します
でここではえー自発モデルとえー同様でしてえースライド中の単語はあー現われ易い
という仮定に基づきまして
で先程の式の影響するのを元にえーある発話に対応スライドをえー
スライド中の単語頻度を用いてえーパルスライトの下での単語の生起確率を推定します
て更にですねえー先程のテンスモデルで用いた単語履歴とえースライドを併用する
でこうしてえー総合の中での振動トータルしましてえそれを操作ではある
といったで前によりえーこちらの確率の推定が行なえます
えーこう捨てられたえー単語確率のいずれかをえーベースライン言語モデルのえートライグラム確率とえー
線形補間することによるえー適応単語のえー言語モデル確率が推定されます
でこうして得られたトライグラム確率を用いましてえ最初に行った音声認識結果のえーベスト仮説のリスコアリングを行ないます
で構成財政的なえー適用ものを低認識結果が得られま
でまた
でえー先程ベースライン言語モデルを用いて最初の音声認識を行なうと言いましたけれど
えここでえー最初に説明したえー言える衛生による適応言語モデルを用いた
えー音声認識部を組み込むことにより
え大域的な話題Ａに対する適応度をえーこの局所的な話題
えー
対する適用をえー組み合わせることができます
えそしてえーこれらの機構に対してえー評価実験を行ないました
で対象としたデーターはえー二千四年二千五年にえー京都大学学術情報メディア全体で行なわれた
音声認識音声対話字ずつこう社会におけるえー一二回目の音声となっております
え更にもう一種類のデーターとしてえー京都大学で行なわれたえー通常の後に三回分の音声を用いました
でこれらは全て時間はほぼ全て九十分となっておりますでえー五つの重複は五名のみ
でそしてえー全ての五人においてえー使用された効率ライトと
そのＴがえ時間情報が利用可能となっております
え音声認識は映画の強い検定を行ないました
でデコーダーはＪｕｌｉｕｓ三．五．二を用いましてえ音声モデルはえＣＳＪの学会講演からえー話者適応学習を行なったえー状態共有トライホンＨＭＭモデル
に対してＭＬＬＲ教師なし話者適応を行なったものを使用しました
えー〇づらいん言語モデルはえーＣＳＪの学会も二講演からえー学習したので
で語彙サイズはえー五万語のトライグラムえ言語モデル
でまたえー先程御説明したそうにおけるえーパラメーターはえー一二のように設定しました
えまず入れる前によるえー部分空間の学習ですが
でこれは
えー話題をカバーする為にえーベースライン言語モデルの学習に用いたえー結果赤い講演のえーテキストを使用しました
え潜在変数の数はえーテストセットパープレキシティーが最小となった時の値であるえ百と定めますが
またえーできるとの生成にはえー検索エンジンツバキを用いますが
えー
更にえー国の選択の際にえー用いるＴＦＩＤＦ値の計算ですが
でＴ会としてはえー彼スライドにおけるえー単語頻度
でＩＤＦはえー二つ前のえー学会主に講演の一講演を一文章と見なすか値を使用しました
えそしてえーＮグラムの頻度の今後はえー重み歩いて五つとしますが
で更にえー局所的なクラスモデルにより適応の際のパラメーターですが
でこれはえーこう全体音声に対するえークロスバリデーションにおい決定しまして
えーじゃその長さがえー六十え線形補間の重みはえー気圧の方もあるえー一五
えベースラインモデルの重みがえー〇．九としました
で更にえー適応を行なう際にはえー単語辞書にはえこう二スライド中の未登録語をえー追加しておりました
えまず最初にえーベースライン言語モデルを用いた場合の音声認識結果を示します
でこのようにえー講習会で七十五．六パーセントえー大学を二でござい発展六十パーセント
都営号仙台の方がえー認識精度がえーま大まかに高くなるといった結果が得られます
えこれは
でまー幾つかの要因が考えられるのですがえー
重要なこととしては講習会はまー学会講演に従って一回生の発話スタイルである
でそれに対して大学のこうのというなま教室で学生を相手に行なわれるものなので
で一分くだけたスタイルである
といったことがあります
でまたえー先程えー未登録語単語辞書に追加した場合はえーまーその改善はえー×となりますが
えこの実験ではえーこの三道路が追加された単語辞書を用いてえーすモデルの適応を行ないました
でえー次にえー冷静によるえー具体的な研究を行なった場合の結果を示します
えースライドを用いたところえー改善が得られたのですが
でえー認識結果を用いた一度の三ＬＳＩを用いた場合でこちらの値ですね
でこちらに比べてえー
番号に精度のせえー改善は三割結果となりますが
えこれは認識結果にはつらいのに困らない情報も含まれる為
で七ですがえー
ただえーつらい共付ける場合えー合成音二は一の間で行ないば良いので後続なそれがあの都内
でまだ一単語としてえー
認識結果をえーベースラインのモデルの学習テキスト二言語して
えー
認識を行なった場合をえー上回る結果となりました
え次にえーテキストの生成によるえー適応を行なった結果について説明します
でここではえー
やはりえー単語に精度の改善が見られましたが
でこう社会ではえー一パーセント酒
の改善に止まったのですがえー大学を二ではえーま二パーセント
今日の改善となりまして
部屋の改良になさそう舌を出ました
えこれはこう一回の話題はまー音声認識関係のものが多いのでえ話題がある程度カバーされているのに対して
声帯学校には全く関係のない話題なので
で話題関連のえテキストの収集によりえーこういった
ベースラインのコーパスでカバーされていない話題がえー適切に音になるかと考える
別にえー気圧モデルを用いた場合の
結果について説明します
でこのようにえー
通常のジャズモデル用いた場合えースライドを用いた場合
更にえー
つらい時や調整をした場合
でそれぞれにおいてえー話題の局所的な形に対する
適切な適用が行なわれて
え認識精度が改善されました
でその際表示されているつらいどん底があって急に有効であったと考えられま
で更にえー具体的な適用と局所的な適用の組み合わせを行なった結果を示します
えこちらがその値ですでえーこれはえー二衛生えーじゃすモデルそれぞれ単独で用いた場合の結果となっております
えこのようにえー具体的な適用といっ局所的な適用の組み合わせによりえーほぼ客観的な効果が得られました
えまたえー各
五年ごとのえー単語認識精度を見てみますと
え例えばえこちらの方にではえー例文の説明などの影響によりえーＰＬ衛生の交換はえ非常に小さくなると言うか悪くなっております
え更にえーれるテキストの生成の手法に注目してみますと
えこれらでは
えー
二つ精度の向上がえー低くなっておりますでえーこのようなテキストの青春が起こってしまった
ということが要因として考えられます
でまこのようにえー全体としてこう人内容やスライド後です形式によってえー適応の効果はえーばらつきが大きいという傾向が見られました
え第学校に対してはえーこのようになっております
猫面でのえーこの二つの語にはまず次の文記述が多い為にえー言える衛生による適応の効果はやや小さくなるといった傾向が見られますが
えまたえーこちらの方にではえーテキストを生成によるえー大幅な改善が見られました
でこれは英語の方にはまー画像それに関連する話題がえー話題のページなどで
えー
テキストの収集がえー高価で現在大スターと考えられま
え更にえー話題語の二つ精度による評価を行ないました
えここではえーこれらの語をえー話題ごと定めまして
でこれらは高二の内容理解の為必要でありえー認識結果表だとそれが正解要約をする影響が大きいと考えられます
えこちらはえー再現率適合率による評価を行ないました
えー交通書い音声に対する結果をこちらに示します
で言えるえーせえー年齢えこちらの値って言っなってきをですねそれに対して局所的な適用他にえーその二つを組み合わせた場合
についてえーすっえーを示しますてるとえこのようにえー失礼えー
八．〇．八五から出て二十八
といったようなえー改善が見られました
え大幅にえー再現率が上がっていることが分かります
えまた大学校についてもえー同様な結果を示します
でこちらも同様にえー再現率がえー大幅に
とそうしておりますで
芸術としてえー〇．七から〇七八分の改善が見られました
でこのようにえー
先程えー御
えー先程のえー手法によるえー適応はえー話題の何精度の改善に燃えおいしく固定しました
えそしてえー特に話題もあの認識率でえー特にええ再現率においてえー大きな改善が見られました
で以上まとめますと本研究ではえー後に音声に対する面の情報を用いた言語モデルの適応行ないました
で具体的にはえー具体的な適応とは局所的な適用を行ないそれを組み合わせますと
えーそしてえー
実際の声による評価を行なったところえーこういった改善が得られますが
え以上で発表を終わります
#############################


#############################
# query = え講義の一つとあー更新の話し方がの関係性を研究したもので特に声の一後えーあのーの明瞭性の関係を説明しているものが知りたい
# rank = 1
# slide = 07-02_fix.match_word.jout.txt
# value = -3.06046369487185
#############################
はいそれではえーっと講義講演音声自動評価の為の
音響言語分析という訳で
二電話した訳工学部のおーコンピューター部屋工学科
でそう港区は周波決定します
まず簡単に全体の流れについての説明なんですけれども
えーまず研究内容目的
えー
研究背景と目的概要
音響分析こちら上の方
できる背景になってかと思うんですけどもこちらについて私まして発表させていただきます
でこう関係の分析まとめ方については夏休みあの発表さしていただきます
でまずえー上の文
研究背景目的から見ていきたいと思うんですけれども
まず研究の背景目的訳なんですけれども
悲しいというものは相手に伝えたいっていうのは当然伝えるってなかなか難しいことでありまして
悲しかっ話し手の話し方において
ではさまざまな印象を受けるかと思います
カボチャ載ってますように
ま印象良かったり
ただ
印象は良かったり
あるいは
ま理解し易理解し難いなと思ったり後は体な印象受けたと思うんですけれども
私達は今回はこの音声に関するえ音響情報言語情報について
後着目しまして
その音声もう一．二度ならどうやれば引き易く分かり易く
できるのかということを思ってそしてえー
で研究を進めました
って凄い研究の概要についてなんですけれどもま話し手に
えー
対象とした音声講義講演音声なんですけども
え講義講演音声というものをまー録音あるいはデーターを持ってきましてえ音で音響言語情報の分析当然まー
音声何空き地とか川とかフィラーとかま色んな情報があるかと思うんですけれども
で同時にえーその
講義講演というものを別に
いかせてアンケートに解答してもらいました
少ないアンケート
方針といたしまして
ま発話速度と蛙なフィラーとかもあるんですけどもそういう情報を
えアンケートの結果と
えー
音響情報言語情報抽出した情報の
えー比較
評価していくという流れになっております
って対象とする音声についてなんですけども
じゃ講義音声えー
老人会図を面白く行ったんですけど山梨大学おまけで
コンピューター京都和歌コンピューター歳いーすコース
こちら最後の発表にあったえ山梨大学の講師なんですけれども
でこちらは四十五期二十八科目って行使は一一名
フレームで
手元の部分にえ先マイクを装着
でまた納豆もしくは一デコーダーに録音また後形式また別景色なんですけども
で一生録音条件といたしましては三．一発話中六キロヘルツ量子化は収録人
また
講義音声以外に講演音声もえー対象としましてござい日本語話し言葉コーパス
らしいですでこちらを対象とさせていただきます
まず音響情報に関する分析についてなんですけれども
え音響情報は
以下の
一つの項目えー発話速度
西洋
抑揚を利用性を作ってこちらの五項目についてえーっと音響分析を行ないました
まアンケートはえー二の方に
理解をしたアンケート項目あろうと思うんですけども
まそれを五段階評価いー
一から五の家はい
というような形式でえー小学生に
行なってもらいました
両者の音響情報
のえーここの分析などに講師の特徴は
このま中心としてやっていたいと考えております
でまず発話速度についてなんですけれども
横軸は一旅館のモーラ数縦軸はその評価学生の評価
の平均値についてなんですけれども
こちら見ていただきますと大体七．六から八．四五五段階評価
え四以上の講師なんですけどもござい量も大体四五の一が占めておりましてこう変な評価いいんじゃないかという結果になっております
えー八．五モーラ毎秒以上
まー
かなり速くてま聞き取りにくいという結果なってまして七．五モーラ
ま五秒にはもう
評価はま一体
講義はないってことでえー八モーラ毎秒
戦後がやはり
テントって
と後取り易い
で
早さなんではないかと考えております
次に整理をえ声の大きさについてなんですけども
本社行為の対象としてまして
えー前の小屋も
過去も気に相関が高いってことに間違い下の表みたいな分かると思うんですけども
で水をよく読む
まず億年なるんですけども
西洋の声の大きさに関する
このアンケート評価あっ
で平均値これ四．三三で他の項目は三点台
二三四五番四点台という
ことで
まー
戦後の講師大体四点な記録しておりまして
てこの種ってのはあまりんが大体
声の大きさんじゃないかとかしてると思うんですけれども
テストにあるように
あまり今四数に発話している講師の場合
えー
学生のｈがここなるほど評価が下がる傾向があるんじゃ
ないかとえー思ってちょっと調べてみたら
結果なんですけれどもまこちらｄがすちょっと少ないんですけれども
え横軸がうまい子を入れて発話した時間の我々
えこちらまー
講義の六一が行ないまして凄くが
彼はえー
こうしが
前向き発話してる時間などを調べました結果なんですけども
名前をし
で縦軸がここの減衰量ということで評価方法と前方あるんですけどもこう方が前方よりそのぐらいなって言うか
ことなんですけれども
ままずマイクあえっとマイクなしの方にあったんですけども
ま行くタイの項についてはえー方法を一一一二減衰が一五
金ということでまこう行っても
ま行くならやはり
音声は聞こえるというな結果なっております
でマイクなしについての行為なんですけれども
こちら前を見て発話している時間
つらい思いには
につきましては大体〇．九〇．八五と若干高校の方が評価下がる傾向となっております
でこれによって
手前の八
まこういう高校この評価低いコーヒーがあるということで
前の六発話することは望ましいんじゃないかということは考えられます
次奥様なんですけどもこちらピッチえー声の高さの標準偏差が高い程
えー評価は欠かせないかと考えました横軸がえー一つの標準偏差ってことなんですけれども
まこちらが七標準偏差
大きなこと評価が高くなっております
体力につきました声の高さというものをが重要文などでえーこれから先書いたり
まそういう価値もってことでよく言われ
確かでできるという発話考えてんじゃないかと思います
次にえ要請
でこれが明瞭さということなんですけれども
こちら二十一名女性の間に大きな関係があるじゃないかってことで
炒めたんですけどもえ横軸キッチン
声の高さということでえーこの長さ最後はやはり
えー学生聞き取りにくいというなまー結果
になっておりますけれども
こちら四角
の講義ま同じ先生の
えー中学校木なんですけども
白三角形を
まそのピッチ一二の傾向から外れた抗議というものがあります
八三行政というものは
ピッチえ高い方もちょっと言いにくい
手書きにこう現われるかと思うんですけどもえ
決してそれが気が関係してるのではなくてそれ以外にも関係性要素があるんじゃないかと考えております
で次にポーズにつきましては
えーこちら一発話中のえー平均ポーズ
が少ないこと
こう教官があるじゃないかってことで
こちらショートコースはえーＪｕｌｉｕｓの認識結果におけるＳＰショートポーズ
のえ数なんですけどももう一発話中のポーズ数が
食行動評価者間低くなっているというな結果になっております
まこれあのえー
腰の特徴拍ということでま間の関係との評価結果こちらを用いた主成分分析も行ないました
判決の評価項目の項目語は二つ二次元で結果が一つ名称じゃないかという形なってまして
先程述べたえー五項目行きましてきて分析を行なった結果となっています
まず第一次成分つきましては
一二を明瞭
資料
病気を利用性あのーまー
声の質
に関係とは項目こちらのケースが非常に大きい
で結果になってます
と第二成分つきましては発話速度ポーズなど話のテンポ流れ
こういう風に関係する
項目のケースが非常に考え
という結果なっておりまして
その一成分分析の結果なんですけれども
えー講師の特殊拍に対して分析を行なった
ってことで
こちら見ていきたいんですけれども
えー横軸第一次性の公園
せえ縦軸が
話の流れ展望に関するまー
えー
軸なんですけれども
例えばこうツリーを見ていただきますと
まこちらはえーえ
こういうことの差が一応あるんですけど
まこうし気が大体言えましょうかこの質問文全部をもいいんじゃないか
木枠をしなっておりまして
三でした方しいー
とこちらの
まこちら
腰が実際にまとまりを残し四は左下
今止まるって明らかになっておりまして
はこれ全然見ますと行為語
講義ごとの違いというのあまり見られるんですけどやはりこうし
よって大きく
その学生が感じている音響的な
評価点が大きく変わっております
でこれによって
並行しによって例えばこの一つ利用性が悪いんじゃないか
えー
腰がやはりお話の展望
えー少し入れ話が
長過ぎるとかま置かない
で喋ってる腰まそういう色々
教えて特徴が現われかと思うんですけれどもえそういう改善点はどこにあるのかということを模索
探していきたいと考えております
はい以上につきまして
えー上下私の発表終わりなんですけどもえーこちらの
言語を分析まとめここの解析は
えーテストにあの発表さしていただきます
えー
えー
えー
んー
えー
えーということで残りの後半部分言語分析等を求め方もあ内容そういう発表いたし
まー
という二言語情報の分析ということで
言語情報の一つである嫌わに着目いたしました
でまー分析内容と
といたしましてまず一つ目にフィラーとも
二匹があのーはず
ペットに選んでいます
で次が七十
えーっとそれぞれ時あったりかしらとやっぱり影響の調査を行ないました
えーこの分析を用い関係と
ということでまず左側は
のような五段階評価にあるアンケート
や興味が七十二の評価
というのアンケートを
こちらの順位付けというのは
それをそれぞれの分析に対して
そいで使う
音声を準備して
それを取ってきていい幾つかの音声を聞かして一つ下を
行なってもらいました
えーその項目として私も指摘をさ鳥が一が参加する一で行ないました
えーえ条件
ということで
こちらは
分析表が多くて
の
印象を二分
という方で被験者に書いてもらいました
そこでまずフィラーと者に関する分析ということで
学生前面に一軒家による
教科で実験を行ないました
実験文字と音声はまず伝音性
て畳その原音声の一等を全ての語に置き換えた音声
この二つでえー実験行ないました
です
その結果が原音声をこ評価音三にでは気が退化したと共に圧倒的です
のこの一二乗をから
飲んであげよう開け旅行が聞き手にとって良く一階にはこうある
ということができたと思います
えー
全て平の数に関する分析ということで
まず開かずの調査を行ないました
えー調査ではじこう自分の講義音声を用いて五段階評価にはえーと
で被験者は受講者であり凄いなと四十名程度で
そして
調査結果を元いた映画な数を実験例を行ないました
でこの実験を用いた三つの音声はまず一つ目に顔を含まない音声では〇は〇パーセント
怪我を少し篭もって
六．五パーセントでこちらは調査結果をプレッシャー割合です
精密に気が多く持つえーこちら一二パーセントです
んでまーこちら訳なのだろうと避けたい
でえーあのーなどが的な使用されているか
スイスの内容で
行ないました
動物も内容からこう情報三．五以上
ポストの
発話された形態素数の大怪我の割合
が六．五から七．二パーセント
お割合でえー声とか集中する結果となります
について
平の数を
実験結果です
でこちらぐらいは
実験の用いた音声が
おー被験した人と人付いたん七十からサインそれから盛り上げ人生の中を示します
その時はスターに関しては
もう一が最も多いの〇パーセント二十五パーセント
さほど物もありませんがこの二つの合成の際のバレエも多いです
で一方六十五パーセントというのは一割をもっと使いくださいが
五パーセント半分
割合が半分ぐらいということでま六．五
音声が一番を評価ではないかと思われます
提示頭スターに関してはこう的〇一二割を最も良くて六パーセントの音声
だと言えます
付いて気が付いに関する分析ということで
石の数ですといたしまして文法を文中に分けました
えまず
怪我の一のよう実験
行ない全てその予備実験結果を対策がうちの
実験を行ないました
父が二つの実験ということで
検査学生五名
て評価は前提と
文章家ですよ会いました
で実験を用いた音声はまず
そうすね文法に辺りを表わすこちら文法で文節のえー割合で怪我を作ります
で二つあり分析辺りがあの音声多分当時文中九という割合
えー
その結果
文という過程がある音声が行為語かでした
えしかしえこの二のおせいも現象があー検証キリストはあまり良いこと相手をモーラ数毎日終わりという結果でした
そこでこの結果を考慮さ実験一ということでえー
予備実験を用いた二つのえー
に加えまして
文頭坂が多いという文法七二四の割合で洋服で音声を追加いたしまして
同じような
全然やる実験を行ないます
こちらが結果です
でまず一二に関しては一歯が最も良い
後は文法なら二四ということで
この
んでえーと七五四の一
大本を聞き易いという結果でした
えー理解し易さに関しても
うちのあれが最も多いのは文法なら二四の割合です
ということでえーこの文法な文章が最も理解し易い
結果はこういう
で先生が変わったに関する分析ということで
長さを生成いたしまして長いもの短いものに
分けました
でこちら書き起こし文で情報洋服が付かないか
そこでえー
話しいたしますと
これまで怪我の長さによる実験
行ないました
で続いて
そのよう実験結果を取り酒がどんな形の実験行ないました
んでま敵が表わされる事件
ということで
検査学生五名
で評価は一型と
以上ですで行ないました
まーそう為に
あ実験を用いた音声のま二つ目にえー伝音性
二つ目に方言音声のフィラーを全て長い距離を控えた音声
また三つ目に
原音声だけがされて短い嫌いな方をえこの三つで実験を行ないました
でその結果
原音声が最も声とか
後まー全て長い短い置き換えだけが
あのー音声はどちらも三つ終わり結果でした
でそこで全てのある一を関連付けた実験というものを行ないました
本実験をセット音声はもっと頭原音声
二つ目に
文法眺め分析二日目という音声
で三つ目原文とを見て食べるんすかねこの三つで
実験を行ないました
えー
その結果こちらです
まず私がスターでは
ま一が最もおー
一名前が最も表現をして
ですが文法のレベルで見る為思った程おー変わらない結果と言えます
そこでえー
文法で外部者がま六名Ａだけが二十歳のあれが極端に多くて一も少ないということでこの組み合わせだけが悪い結果が遅い
理解し易さ
え感染をま原音声が必要も
ま例を最も多いですが
多分こう眺め文
一短いもまさほど変わらずまた関西のあれ多いですけど
とこちらの
またその文法中なんです眺め
こちらに書いてあります道が少なく実は
二つの正常に極端に多い
という結果で
何か知ら生活の文法短めるじゃな訳
航空やつだけが悪いという結果でした
でそこでこれはどうかずっと一長さの
実験から最低条件ということで
んーまーうちらの数に関しては五．五パーセント程度
またフィラーの一次関数の文法をおー縁が七回四程度
理論長さに関しては
名前短めに関係のないことを
文法身近別に背中の組み合わせには
ということは言えると思います
そこでこの先どういう現象を実験手ごたえを得ました
えー実験では三
三講演を用いました
でそのまー〇
分析でえー用いた音声とまた別の三つの講演音声を整備いたしましてでその日音声を全て
最適時直して
生成いたしました
え本実験では被験者は各二十名です
各二十名ずつで
んー評価は典型と
印象形成を行ないました
でその結果
修正の音声を声とか
動作人数はま消えたり頭と共に
参考Ｆのポータル六十名ですえっと三四十名ずつぐらい
で
ま三逃げたりは修正音声が行為語が
という
結果を
結果でした
まそこで
以上関係が多く使うとで経験取っていより話すことのある
ということが見えたと思います
でまとめといたしましてまず音響分析の方では
音響情報と
学生の評価の間要素が関係があることが分かりました
でまたコストという特徴があり改善すべき点は異なります
言語情報
に関してはまー元の二十日の朝においてえ被験よ良い影響を与え型の差が取り出すことができました
えまた一等を適切に使うことによりますと
話し方になるということが確認できました
言って今後の課題といたしましてまず音響分析法では
データーの信頼度の確認
と後アルバイト調査
言語情報に関してはえーフィラーに関する二のどの要素の分析
またフィラー以外の
言語情報の分析
そしてえーフィラーとその他のあそのー言語情報との関係
以上が挙げられます
発表以上です
まとめました
#############################


#############################
# query = え講義の一つとあー更新の話し方がの関係性を研究したもので特に声の一後えーあのーの明瞭性の関係を説明しているものが知りたい
# rank = 2
# slide = 07-14_fix.match_word.jout.txt
# value = -3.10728745934565
#############################
えーつ声の高さ
えーっとスペクトルは多分外国人と言って表現を残し
いうタイトルでえー
はえー
んー
えー
えー
えっとまずですねあのー本研究の内容について進めする前に
入るなりましたスペクトルクラスタリングいう
えー
ものについてま簡単に説明したいま文書のあの
出るとん時間も一度説明しますけども
えー言葉の説明ってことで最初
娘し
えー
あースペクトルクラスタリングっていうのはまこのスペクトルですけれども
えーいわゆるえー
て比べまして部分がえー固有値分解
という意味ではスペクトル
ということですで
えーんーまー実際には対象データー間類似度行列に対してえー固有ベクトルを用いて
クラスタリングをするという手法なんですが
えー元々はそれぞれ四の最小カット問題というもので
えーま適応されたもんでして
えーまかなり
えー取り扱いが容易である簡潔な
えーんます
完結編
ということから
え近年えーこういった
す文書分類であるとかえー画像認識という毎日ね形と色々な分野で用いられています
でえーま関連仕事しましては
えー
ま線形のま一でした成分分析ってあるとか
二つがえーま同じ考えでえー民族を
いったものとまー
ほぼ等価なものであるということが報告されている
でまた
えー生まれてしまって
これですね
でもまー関連性があるってことでえー馬琴に注目を二ん
えー
えー元につきましては後程えー
また
娘じ
えまず研究背景ですけれども
えーま企業とですねま今日の発表と
まー
んーなぜか来るとまー一つとかと思うんですけども
えー我々研究してま行ってもそこに製造検索システム
いうものをま作ろうということで
現在関してこう
で
えーま人手で行なわ大変え索引を付けたいんだけれども一例を
数量化の困難であることから
ま音声認識率自動的に二四つということでまー多くの研究比較で
えー行なわれてると思うんですけれども
まー
これだけに
えー
二万二千の対象としているということから
そのニュース記事と全く同じものがゲーム上にまー話者ＢＣＤ中のものが要集にもあるということで
えー二つに削除ウェブから生成して
えーっとにくいと書いてるもの構築するいうことでえーまこの青年行ってきます
でえー
で実際にあのー関連研究としてこういうゲーム上のテキスト利用するというもの
ま研究は数を行なってましてま先程の研究もありましたしま昨日の
五分でまとめますけども
えー
まこのようなものが関連研究としてあります
でえー実はあのー昨年度の強くえーですねえー
音声言語シンポジウムのいいますけども一昨年えー
ま同様のですねえー矛盾えニュース記事を対象としてから検索式を用いるという
えー発表水があるんですけれども
えーま基本的にあーの同じようなあのー
えー
で
えー
このあのセッションでもえーっと
立川
えー
訳だったもんですけども
えーま劇団テキスト利用する場合にはえー
ま大きく二つのパターンが
んーであるということでまー予めえこういったテキスト集めてほしいという風に指定する場合とえー
まず
認識結果直接集めてきたりという場合とが
いうことで
えー我々のえー後はえーこのこちらの方と同じ
んーとです
ねで考えて長いお勧めしますけども
えー最初にえーニュース音声のえー範囲を言語モデル認識します
で
でえー認識結果が索引語を抽出してえ索引語を選び出すえー
えー六畳か生地を
えー関連した二十．二以上はえー検索し収集してきてえー
それを用いて元モデルを更新するえー
で
この処理がえーとま音声認識
最初の音声認識の時点では
えーま誤認識と含まれてるんですけどもうまく類似記事を集めてくることができれば
えーまー
交通の認識ができるえー誤認識を少なくなってことで
でそれをまた繰り返しなんかすることでえー
精度が癌でないということでえーっとこの
あーこれについては昨年のですねえー聴覚
これで
発表したんですけれども
えこういうやり方を
という
で
ま結論としましてはま
正直に運動をえー
うまく行く時はもう
でまー当たり前の結果はですねえーうまく行くとつまり
えー認識がうまく集められて言語モデルの中
いい付ければ
えーどんどん更新
分かりませ分かるんだけども
もしくはレベルにえー音です
え以上から四十一記事がまノイズがあった位置がトピックの地であったりすると悪くなっゆまー
当然の結果になっていく
でえー
えーと問題点としてそれにまーお話しましたけども
そのというじょ適切なものをただ連れられているのか
いうことしてから
えーまー
ま適切で各重要な量の文書収集できているか
いう二つの問題が
えー問題です
点として考え
で
えー
ま先程もお話しましたけども
えー誤認識がどう違うトピックを拾ってしまう可能性があります
まーそのそのー
えーそのニューストピックそのニュースの内容はですねえー
例えばあの町議会形でよく男女ニュースで報道されてるものと非常にたくさんの記事が存在する訳ですし
えー
七十なり分けて二できるんですが
で一時的なニュースであったりもしくはまローカルな記事だったりする入学すると
えーまー
想像の類似した木自体が見つからないという問題が
なります
でえー本研究では
何まこの問題を解決する為に
えー
友情となってきた
えー
文章の中から
適切な文章先のおー選択してそれを用いて
えー言語モデルを作ろう
えー
でそれからえー二点目としては
えー
えー昨年度のえーえー発表では
風にそのおー予め切り出しておいて
えーま全体にえー検索全体の認識結果が検索をすること行ったんですが実際にはそのニュースの中では
えー他の回答インタビューと中に含まれていたりってから
社会県であったりとか
えーもしくは背景雑音だったりとかで
発話ごとにえー
海の認識精度が異なるということが
えーありますので
えー発話単位の処理をする
いうことを考えます
で実際に行なわ楽しむ非常に明瞭な
二十なりますので
えー
検索とか
非常に認識精度なんですけども
まこちら生まれたその旅であるとか
えー記者会見音のものと全く認識実験今日とか後まー
そういう問題
では
相手からえーとですねんー
これまであのまた続けまし手法ではえーニュース記事であるということから
に回答限定せずにサイトから記事を詰めてくれることを行なっていたんですけども
えー
まー
その場合
まローカルな記事やっぱりえー一次元二者ってずっと十分な共通語化できないということでま今回は二三入札への対処して検索を行なって
んー
で
ここで基本的な考え方なんですが
ま繰り返しになりますけども
えー明瞭な発音でえーま発声されたアナウンサーの音声
まそういう
発話区間であれば
認識精度もなかなか一
でずそういう認識結果から抜き出した索引語を用いた場合には
えー
ま関連した後類似した
大量の文書収集することができる
まこういう前提でやっていたんですけども
で実際には
誤認識多く組まれていることから
実際その誤認識が含まれているような
えー認識結果から索引語を抽出して検索しますと
まー微妙に異なるとＢだとかもしたまた関係猫であるとかまばらばらとですね色々な文章がしゅ抽出されてしまうんじゃないか
いうことで
で
えー
あーまこういうえー想定から
集めてきた記事をクラスタリングすることで
えーそのー
分布状況部分のえ上映会を調べて
えー
最も多く集まっている
えー
いうものを用いたというのがあー基本的な考え多分
んー
でえーそのクラスタリングにま最新御説明しましたスペクトルえースペクトルクラスタリングを利用するんですけれども
えー
二十一文書に対してえー各文書間の類似度をま三十計算します
で
えーこの時に
えー
基本的にはそのー
ま単語ベクトル空間上での類似度計算するんですけども
えーま非常に
益々ね
で下降次元の空間なってしまっいうことから
んー
まー
そのまま
通常のクラスタリングを行ないますとま計算量の問題であるとかま精度の問題等で
えーま若干
えー
クラスタリングます
ま望ましい重られないということで
えー今回このスペクトルクラスタリングを用いるとします
で
えーま特徴としましてえーこういったあー単語ベクトル空間でのえーま特色化数の低次元化を行なうこと
そいから
えー特徴空間流れており環境構造と書いてますけども
一近いものは
保険は何っていう
えー
えー提示喧嘩特色化を提示喧嘩した的に
えー
文章が文章として二言語学近くにいけないが特にという
形でえー距離が共存したままでえーこの事件なしかできますので
えーま非常にこういった文章
二クラス二とＶ形
いうことでえー今回構築するクラスを用い
えー
でま簡単に原理を説明しますとま最初にお話しましたえさえあの子供大学の最小化と問題として
いう提案されていたものですけれども
下手でもこういったグラフが
存在していてまどこで
えー分割するとえー最も
えー最初の異なるいうことを考え
いう問題
で
でこの仮にえー
各ノードとお
えー
まそれがえー
繋がってるかどうかいうことでえー
大勢か二日ぐらい前に言った重みをま設定してて
で
更に
えー二つのクラスの二つのおー逆に分割するという場合には
えー考えますと
もしあの
上の方のえーグラフであーグラフに含まれてるのはえー生き甲斐を一と四
えーＢの方逆の方ではマイナス一とするというように
気が四百ということをしますと
別のえーこの対象をかと問題はえーこういった式をえー最小化する問題としてえしかし二で
まこれは簡単ですねの弟ノードと
形を取ってえーその間繋がってんのというでまー
えー全部足してしまった時にえー最初何々ということなんですが
でこれをま展開していきますとまいわゆるこういった二十形式という形に置き換えることができまして
えー
で更にこれを
んー
えーところがですねえーこれが生成計画問題なりますのでまー
えーっとま父が難しいということで
えー連続値に緩和することになって
えー
この式からえー
ことをし加えることができます
で
原点ですねこの形に
変換しえー変形した時点で
えー
ま今えー固有値問題という風に置き換えることができますので
えーこれのえー固有ベクトル高いと
いうことになっ
でえーと先程のえーこちらのえーと書くんですけども
えーんー
まこれは最初講演者〇．という性質があることが分かってで〇での要するに固有ベクトルが全部一もしくはマイナス一対の直流成分なる訳なんですが
ま経験ての頃医学全体を表わして一分割でプラセンタ表わしているのもいうことで
えーま一般的な語に関連この固有値に対応したという距離を自分
なります
で
えーんー
で更にえーっと先程グラフの分割の問題だったんですけどもま一般のクラスタリングに応用する場合には
えーっとまー学の接続関係を表わした頭が主というものを
の中の類似度まー
文書クラスタリングのまだ文章間の類似度ですけどもに置き換えることでえー
そういうの問題
とことでえークラスタリングを行なうことができます
で本研究ではえー
ま簡単な為にえー第二こういうですね二番目の講演賃貸でしたこういう風だけを用いてま近似的なクラスに行なうとします
え更に
えー
ま元々の
元々のえー
このクラスタリング額の最初核問題っていうのが
要するにこの
一番
縦のグラフの間でま一番生徒が少ないと思っ小さいところっていうの求める問題になっていますので
えー
クラスタリングを行なう時の境界口語としてはえー疑似的類似度の総和が小さい体の境界で候補として
えーまクラスタリング行って孤独まこの後えーっと
んで
んー
えー時代の
スペクトルクラスタリングどういうことができるかということなんですが
でこちらがですねえーと縦横
がえー
文書集合なんですけれども
えー
まこういうようなあ文書がんー九十三つとして
えー
勝手にですねこの観点はえ暗い方がま似ているということを表わしています
で大学でも当然自分年ですねまーうまくなんですけども
こういったものを先程の式でえースペクトルクラスタリングを行ないます
まして
えー
得られた値にこういう風にもちょっと気にしますとえこのようにですねえー
非常に
まギャップが存在するようなこういった結果が
大体
という
でこの想定した結果に基づいて元々の方の類似度行列を並べ替えてみますとこのように
えーま奇麗ですねえー
似てる文が似ているところに対角線上に集まるような形でえクラスタリングされ
いうこと
でえー
えー
結局この前ですねえーと元々三つのトピックを混合してえまーだんだん辞めたんですけども
えー
クラスタリング境界点としてはまこういったとこですねこの集まった集合のこことここという形で求めたいので
えー
二点においおけるえ
えー
二以上の総和
いうものを求めた時に
え最も小さくなるというのが
教会っていうことになり
えー
んー
でで以上のようなえー方法を用います
でんー
実際にメルから収集した記事に対して
えー
クラスタリング行って
えー実験を行ないます
で
ね二次元一としては
んー
えー二やつですね用いてますで汎用言語モデルは今回は
えー新聞記事から学習した文一文単語バイグラム
モデルを用いて
で
えー
先程の
処理の流れでえーですね
と決定ニュースと経験的おー言語モデル言語的行なうという風にお話してたんですけども
今回のえー
実験では
九十五記事から作成したバイグラムモデルに対してえー汎用言語モデルの語彙を追加する
いう形で
まーニュースと低いよう言語モデル
ま同化してるん〇
ん作ってまそれ実験行ないます
で音響モデルはえー九十二月机の分布ですけども
評価尺度として
音声認識単語正解率と
えー索引語の方となる名詞のみを対象とした再現率適合
んでえー評価を行ないます
んー
でえー実験で用いた二つトピックなんですが
えーと今回ですね用いたのはえこのようだと
はい
で
えー
まこれ縦軸を用いたまこれあのー
わりと最近のものを用いるという文字だけがあるんですけれども
で一つはあのこの理由の一つとしてはえこれまでにですねえーまー
幾つかのトピックで
千実験行なっていて
えーま音楽家をま聞くことが分かっている
いうことで
えー
ま比較的
一時的かつまローカルな
まあまりこう話題になってないような気し
いうのでこう四つの基準にそれがあのー
でえーま平均
各肉の平均を当時からまー三分ということ
で
この中のえー平均発話文数は
大体六文型ということで
各発話
形には言えずまー三十八単語
平均三．三六単語
えー含まれているんですが
ま中には小さなものや大きなものまゆ
でえー索引語をこう
発話内の平均を削減法としては
んー待ってるし
いうことになりますえー
でえーっとー×です載せてますけれども
えー
今回の実験では
えーっとー結婚後に
予めトピックが気に分けられているものとして各トピックごとに実験行なっ
でそれからこの発話切り出しに関しては
えー
え発話切り出しに関しては二つですね
まＪｕｌｉｕｓを用い方と同様の処理でえー
えーまあ接続をし程度で
えー
言って
自動的には
ここと
でえーっと性が索引語母語に関しては喧嘩したら
えー一般名詞二三四五分
でまずはや言語モデルに
用いてえ各発話をえー認識した結果をえー
御覧いただきたいと思います
でえーっとピンク一から四までありましてえーまそれぞれ大体六二十分と入ってですけれども
えーん御覧のえーとですね
緑が
単語正解率で真ん中の赤いのがえー
適合率でえー黄色い方がんー再現率になります
で御覧いただいて分かる
んー他の体系と思いますが
え例えばこれですねえー
非常に
発話によっては非常に精度が高いものが
いうこと
で
ただえーっと逆にですねこのように
まつまりいーえー発話によっては
殆どえー
認識されてないもの
いうものもあると
えっとー予稿ですね背景な雑音で学習者は上がっていってるんところ
なんですけども
えー認識
世界一はあーＡます
四十五十パーセントですけども
空から名詞はもう殆ど間違い
でえー最後のこの六
えーと決定の六番目の文に関しては
えーこれはですねえーふアナウンサーの
発話が終わった後で
んー
社会気になってまーからこういううー
んよく見ながらお話
いうこと
えー
でえーと実際の例を御覧いただきますけどもま正解文の中ができました名詞がこういうものなんですけども認識結果としては
父の発達とか影響ぴったりの数というのも変わってるんですけどもえー誤認識でえー
全く関係名そのものが詰まったりもできる
えこのような
これを用いて検索しまうと当然ま関係ないようなトピックも集まってくるということ
でえー先程の
スペクトルえークラスタリングを用いたクラスに結果なんですけども
えー実はこういうな
んんー
えっと上の文ですねそう金融低下が一形で行なった後類似度行列になっ
でえーっとー
ん波形に対して累積類似度を求めて
えークラスター
あのー歳の
教会高校出しているんですが
毎回この一例が下の方にできるものではクラスター教会の九
で
えー
ってクラスタリングを行なった結果あートピック一に対しては
えーまー
ま関数は大体同じようなとこに集まっていてま最大のクラスターを形成している
で
えーサイン音というように
えー
若干違う基づいてえートピックを集めてしまってきます
違うと離れどこにあるという
でえーと結果三四に関してもんーまーほぼ同様なんですけれどもえこのように
認識率が低かったものをそこにを弾き方れるようになって
えーっと
こちらもしますけどもで最終的に
えー認識結果Ａを見ますと
えーこれは結果なりましたえトピック一二三四とありまして
太陽言語モデルと
えー正確に言うとえ今回提案手法
の結果が分かっ
でえー
収集したり全部で集めたま広くなっ
えー
まー
でえーっと
ま若いところで今回提案した手法でえーまか改善が
えーとまー
ほぼ同じが改善が見られ
いうことが
はい以上まとめですけれども
えーま今回はあー
えー
彼女の類似文書の中に一結局のモデル構築するという際に
できたらクラスタリングを用いて
よりえ明示したあ文書集合の形をする手法を提案します
でえクラスタリング結果から
信頼性の低い音声認識話そこは使わないという
えー方法取ります
ま今後の課題としたら分
んー
#############################


#############################
# query = 話し言葉コーパスにフィラーをその導入することでえーその言語モデルを作った時に音声にきシステムの性能はどのように変わるのかえー結果がどうなるのかっていうのが知りたいです
# rank = 1
# slide = 07-12_fix.match_word.jout.txt
# value = -4.34400839794846
#############################
でここでございます
えーっと．二五各大学のえー特徴と申します
えっと本日は
えフィラー予測モデルに基づくフィラーが好き言語モデル
の構築という題目で発表させた
えー
えーと一番最初の背景なんですけれどもまーあのー嫌いに参加して出してみ字のことはできはないかもしれませんけれどもま
話し言葉に対する処理あのこれまであのーびっくり定常音
えと読み上げに対するま守備がまたその後も困ると行って活動の方がま話し言葉に対する処理ってのは主流になっていくでしょうってのは
えっとまー皆さんの相手喧嘩の一致するとこれはその
で
ところがですねその話し言葉を対象といたし理由を実現しようと思いますと
そのまー書き言葉と違いましては非常に上がったようなそのフィラーですとか言い直して使いより三まそういったようなまーあの
え文法的にあんまり正しくないまーそうでないあのーまー
そういうえーっと色々なさまざまな
えーと現象が発生しまして
でそういう現象の為にまそのえっと音声認識が非常に苦労するところであるというのはまー
んこのまタイトル皆さんの喧嘩にするところだと思い
でえっとーおそれですねあのー現在の音声認識システムいうのは
まーあのー統計的なえっとーモデルに基づくものが主流になってますから
でそういうその対応なえと話し言葉に対する現状取り扱う場合であっても
やはり
その大量な話し言葉の現象さまざま色々なものを全て取り扱っているような大規模なコーパスというのも四
仮に存在するのであればまー話で非常に簡単で
ペットそういうそのえっとーコーパスからまーあのー
話し言葉のような現象に
えっとー対応したえーっと言語モデルのまー作ってやって
でその言語モデルに基づいて
えー
音声認識というの行っていれば良いと思われるんですけれども
え現実にはそういうことはありませんでして
例えば一九九ＩＰＡ最大のその日本語話すことの方はそのでしてもう
持ってきましても
えーと講演音声す二千七百見て
ちょうど二五百二十三件で合計百七十五語一万語と
でそれがしまして例えばしあのーこれまでえーとー疲れて新聞記事で見ますと
まこのぐらいだ監督四十三つありまして
で最近ではもう上はから収集することができますからまー
この差というのはえっとー
開くことは気もする言語町でまロボットはかなり難しいと
でそれは深いどこに大きな原因があるかって言いますと
まこちらの日本語話し言葉コーパスの方は
えっとーおー非常に
日本語話すこと五千円あその話し言葉コーパスの構築というのはま非常にこうこうそのせいであるというところが問題なくて
でえっとそういうような背景でま対象とする為のコーパスを十分に得られない
まそういう状況でどうしていきましょうがあることがえー混合研究課題なってると
で
それでですねえーっとーという訳でまー本研究の目的なんですけども
まー太陽の日ごとのコーパスから
その話し言葉言語モデルはえーっと構築できればいいんじゃないかということを研究して
で
ただですねえっとー現段階ではまーもう少しここまでは言ってませんで
えー
体あの書き言葉コーパスの代わりにですねえー不正確な話し言葉コーパステーマに注目してる
えところは一体どういうものかと言いますと
えーとビデオとかこうへの結果形で作成されている
であのー
え成果のフィラーなどは話し言葉特有の現象までは書き起こされてないけれども
でその公園の内容は十分に書き起こされているような
そういったようなええーコーパスを想定して
んでってまそういう風その程度のコーパスであってもえー正確な話し言葉コーパスに比べれば
えー十分にえーと撮影コストが低くて
えーのんびりとこう色んなまーあのーかなりたくさんあの作成されておりますから多分それは言えると思うんですけども
それであのコーパスから
話し言葉言語モデルを作ることができとまー一十分に有用であろうと
でえーっとそういう訳でえーっとー本研究では
そういうえ不正確な話し言葉コーパスから
でフィラー予測モデルに基づいて
フィラーに対応した言語モデルを作りましょうということをおー試みを報告させ方
えっとまーあの関連研究ま非常にえーままずあのー
これまで存在するんですけども
えーそれともうどうして例えばえっとー一番典型的な例としては
えっとーおー何皿によるえーと第一語の日本語話し言葉データーベース文字が講演音声認識という研究では
で例えば
で話し言葉言語モデルに対して
え対象為の言言語モデルをえーと混合して
でそれ対象駄目に適用することやっと
テーマがえっと赤河原らによるえーっと二千五年前統計的機械翻訳の国に基づく言語モデルは話し言葉スタイルの変換という風研究では
えーと書き言葉から話し言葉への変換規則というもの
その統計的な機械を翻訳モデルとして表現しまして
でそういうえっとー各他のモデルを
えー
後もう一つのえー
ボイスの内容に対する
話し言葉と
書き言葉の両方のえっとーコーパスをえーと用意しまして
でその両方のコーパスから英語の翻訳モデルを学習し
で
そしてそのほ翻訳本を使ってえー書き言葉言語モデルを変換して考え話し言葉を言語へ変換するということであると
でまこういったようの取り込みがあるんですけども
えと我々の提案手法などちょっとえーっと方法が違いまして
えーどういうことやるかと言いますと
うまくえーＰがま正確に書き起こされた話し言葉コーパスと
一部屋あ応募は
手続き等の話し言葉のについ何でじゃ不正確に書き起こされてる一二六と記録もそういうあのコーパス
この二つのコーパス両親
でそしてえーフィラーが正確に書き起こされた話し言葉コーパスの方を使いまして
えーフィラー予測モデル
どう我々が見るものをえー
学習します
で
このフィラー予測モデルというのはえーと我々のページの表ではえーＰがあの
そういう箇所を決定する
フィラーそういうモデルと
その
せされた方に置かずに書いてどういうフィラーを生徒のニュースのよろしいかということを選択する
フィラー選択モデルという二つに文化として定式化して
でこのようにしてえ日が正確に書き起こされた話し言葉コーパスから
部屋と後モデルの学習しも
で
そしてそうしましてもう一つ四つのてましたこちらの
えー話す言葉に対するえー現象は正確には書き起こされていない
二二六はそう記録というような形の
えーく正確な話し言葉コーパスに対しまして
このプラントモデルを使ってフィラーの挿入すること行ない
でこうしますとえーこの
えー対象とするドメインのえフィラー付きのコーパスをいることができ
でこうしておきまして面が付きのコーパスから
えーまー通常の言語モデルを構築する方法をま適当にまトライグラム何でも構わないんですけどもそれでもあって
えー言語モデルを得るとでこれでえっとこのようなことやりますと
えー
本来話し言葉に対応していなかった
温泉正確な元のコーパスから
えーと結果フィラーに対応するモデルを作ることができると
これがえー我々のえーっと提案する手法になります
でそうしますでえーっとおーそれでえーっとじゃ実際のおーなりますかってことでえーっと日は予測モデルは
えーっとその
糖尿箇所を推定するモデルからえーとこれは仙台市で語彙を推定するモデルのえー二つに分割して定式化しており
で最初の方は条件付き確率はえー四Ｒと呼ばれるもので学習しまして
本の方はえーと普通の悪条件付き確率で表現しており
でえーそうですねえーと六つがこういうモデルの方は九二回検討しますかと言いますと
例えばえー例外としてえーこの場面を見ると．三〇六．三七文を考えていただきたいと
でこの場面を見るという点で丁寧語に対しましてえフィラーを導入しましてえーこの場面をでえー見ると絶対に風に
えー
えフィラーを購入しますそういうするという風れるのかな
でこれに対しまして
えーこの
最初に与えられた文
のこの部分をま手が〇．一分解します
で
その形態素列に対しまして
このフィラーの挿入されるかその
そこであのこの女子高に
この後に対しては
そこにフィラーが購入されるというラベル
このラベル五五つ半あのー
アプローチも
それ以外の形態素に対しましては
えーとここにフィラーの方にありませんからえここでえーとフィラーが挿入されないという字は四ということで食べる方あのー付与してま
でこうという風にしてえっとフィラーの方にありますそこでには得られる画像を与えるような形いーそれ以外に溢れラベルを与えてるような形で
えフィラーの方にお活動をえーぶんあの各形態素のえーラベルへの分類問題だって言ったような形で形式化し
へこんえ分類問題を解くというモデルをえ知られ方を使って学習すると
そういうようなえーっと流れになると
でえーまー水とかにつきましてはまーあの最近のえーと大自然言語処理もいる音声認識がま非常に
あその研究例があります
けれども
でそのーえーっと識別モデル
でこれでこの識別モデル使いますとえーま非常に
で一七十成績ができるということが特徴ですまこれは今回あのー
んえーとすいませんとその柔軟なえーとー素性設計ができまして
せっかくえーとまわりと少なめのえーとデーターにあの少なめの学習データーに対してマイクを良い
性能が得られることが知られてる
でそれでま今回の研究に適しているでしょう
いう風にして知られ方とか
でまーえーと一応ねその
形式とした効用が始まりますあのいわゆる普通のえーっとあの
ですあのエクスポネンシャルなあのー
表現形のあの典型的な形なと
で者としましてえっとこの四八個でえーとまー学習する
でじゃどういうえーと実験のあの構成しましたかということを説明し
えーと先程のえーっと我々の提案手法
遠いと殆どずっと司会者なんですけれども
学習コーパスとしてはえーと正解えっと先程で言いますと
正確な話し言葉コーパスに当たる部分ですけれども
えーこちらとしましてはえー日本語話し言葉コーパスから二千百五十二講演をえ文法気がして使いました
でもう度数疑似旅行へのえ当たる部分なんですけどもでこちらの方は本当にいいのここ五六を使えばまー今本当は一番都合がいいんですけれどもするとあのー
まだあのーん
えーデーターとかの関係難しかったもんですから
えー話し言葉コーパスから
えっと五百講演取り出しまして
そこから
えっとフィラーを取り込んで
でケーキが私のコーパスを作りました
これでえと先程の提案手法で言いますと生地のところこの部分は
こういう風に少なく八月のコーパスでもねえー少しだなとしていタイトル
でそうしまして
でこちらの学習コーパスから水があるうでえーっと実はそういうモデルを作ると
でこのフィラーそういうモデルをフィラー話のコーパスから
えーっとプラスの開発コーパスを作ると
別フィラー月の開発コーパスは言語モデルを作り
でこの言語モデルの性能というのはえー日本語話し言葉コーパスがやはり解けました五十講演のテストセットを使ってえーパープレキシティーを計算して
えーっと評価すると
そういうあのこう水な
でそれにですねえーっとーおーんどういう官能評価してみたんですけれども
まず
えーっとすあすいませんあの
えー
マイナスａのこのここの開発
コーパスの時に
えーＰが置いてえーこれのほいでもう一フィラーの方になりました
ですから
えーっとここのところでえとどのぐらいフィラーが
正確に
再現されたかってのは重要なとこだけ
んで
えっとー
その再現のどのぐらいで
勢力再現されたかというのは
で目標としては
この話し言葉コーパス元々フィラーを除去する前のコーパスある
このコーパスはあのまー
缶詰め正解データーはずですから
このコーパスを使って
言語モデルを作りまして
その言語モデルを作って得られる性能というのは我々の目標値ということになると
でんーそうしましても自分とこの表を見てい高いんですけれども
えーこの一番下の行
に書いたものがですね
でその
えー開発コーパスえっと
ＣＳＪのんえっとー後えーと五百公園から
えー
フィラーを全く除去せずにえートライグラムを作成した場合の性能で
でその場合えーテストセット単語列が七十六．七五なりましたこれがえ我々の研究の目標値になっ
でそれに関しまして
その開発コーパスから一旦
フィラーを取り除きます
ぼっ
その上でやはり除いた上で
フィラーがあ勝てば十分の一辺で怪我が発生するようでしたらそれ十分の一の確率でランダムに気が放映します
でそうしたえーコーパスを作ってやりまして
でそのコーパスから作った言語モデルってのはえ八十六．二ページですが生徒は別なりまして
こちらはベースラインになり
別としましてじゃえっとー我々が止まってますかって言いますと
えー提案手法その位置はですね暫くで
カップ
直前に形態素と思い形態素小売り店が形態素素性としてえーと予測モデルは他の方に面であのモデルを学習しますとえー最後の五七十七．三〇型が得られました
つまりこれはどういうこともあるかと言いますと
えベースライン
後ランダムにコンテキストを考えずにえーっとフィラーを購入した場合に比べますと
結構よろしいと
で各
えーその開発方向性発声される一番有意与えないと結構使いと
ということでですねえっと我々の提案手法はまーかなりえーっといい感じでえーそのフィラーを再現することができるよって異なる
でもう一つその音声認識っていうから考えますと
えっとー方もその問題にやらなければ決まってないかもしれませんので
でえーっとその
後ろの
単語の形態素というの行動しなくても
スポーツなかった場合どうなるかということが興味あるところを見ますけれども
そちらをちょっと見てみますとえ七十九．四という形になりまして
んで
でこれはえー文法全国から
そこの契約を見た方がとー男性の多いんですけれどもまーあのそれなりにえっとを
そのえーとベースラインに比べるとま結構古の持ってえー再現することができると
という訳ではこの表ではそのー我々の提案手法というのは
ベースラインに比べると結構いい性能が静的四の生活を目標条件が結構使いあ文ということが主張できると
でもう一つですねえーっとーお
えー
て学校にモデルの個性を比較なんですけれども
えーすまずえーっと
えー
えー
と
素性としましてえ先程の二形態素数で使ってたんですけれどもえー気が説明使って摩擦音ドメインに依存した形態素に使ってしまっていますからそのドメインに依存しない形態素のどの方も多いんじゃなあのドメインに依存する形態素使わない方がいいんじゃないかということをえ検討しました
で通しますと
えーと七十七．五ということになりまして
えーこれはえーっとそのドメインに依存するものも含めて全ての形態素使ったバイグラムや何らかをしてますけども
そのベースラインに比べると結構いいよということになっ
で後そのえっとー学習コーパスその二人フィラー予測もフィラーはそういうモデルをえ学習する学習コーパスの分量がえーと両方とか二個あなたどれぐらいいいかということをちょっと検討しました
でそれでえーっとおーだんだんを少なくていたんですけども二百公演ぐらいまではまー殆どえーっとーテストセットパープレキシティーは生活ません
でえーそれから千二百からずっと下がってきますとどんどんどんどんとのこのテストの歴史がえーと悪くなってきますので
最適なそういうモデルを学習する為ま二百公演が少なく必要れる好みで
でえーともう一つえーとー講義音声データーベースに対してえーとテストセット単語列どれぐらいなりますかということ評価しましたけれども
この場合もやはりえっとー目標値に結構近い値というのを体験することができると
いう風なことになっており
でえっとこういう風な形で取り敢えずえっとフィラーえー挿入モデルの方がえーっとをうまく僕よることが示せたと思いま
で次にえっとフィラーの語彙えーとーそういう言い方する数が決定されたとどのフィラーは挿入するかということをえーっとお花の推定するモデル二です名詞
でこちらの方は実はあの非常に簡単でして何えーとちょっと前に
えーとこういうあの情報はられた時に
フィラーがどのぐらいなるかということをえーどう考えるというまー条件付きのえーと確率でえっと表現しており
でそうしましてでま色々のえっとーお
やってみたんですけども
で後そのフィラーの導入フィラーがいいかって言うとおーその直前ポーズがあったりとかその口の形的丸四とセット二に色々さまざまにえーっと
素朴な仮説というのがあると思うんですけども持続が不十分でしてやっぱりえっと直前の形態素ですとか
それでもま考えた方はえー生の声を知ることがあって学生で
でただえっとーおー
Ｋだと思う疲れてしまいますと
そのドメインにえーと依存してしまいますので
でそのドメインに依存しない
であのー素性を使ってるなと思われますかと言いますと
その名の自然と体を使いましてもまーそれなりにはちゃんとえっとーお推定できるということが分かり
で後えーそのーバイグラムとトライグラムでは比較してありますとやはりそのまトライグラムを使った方よろしくでですねえーとまーそのー
んちょっとその日が安定なてあのーそこでなされてそのー
そこすそこそこでのものができるまでの五七十個から五取り上げとトライグラムを使った方はよくき
で通しまして
えっとーおーまそういったような条件付き確率でのその学習セットからえーっとー
えー
学習するそのフィラーこういうあのフィラー合わせて
水が選択モデルを作るということであります
でそれでこのフィラーがそのモデルを統合しましてえーと言語モデルを作るという実験ありました
でそれで今度はですねえーっとおー
目標値に対しまして
四通りのえー実験を行ないました
我々の提案手法のえーと一番
えー提案したのこれです
つまり
風なそういうモデルといたし歩くを使ってコンテキストを使い
でかつうーえっとフィラーこの選択の方もえーやはりそのそこであの二例八歳な形そのコンテキストを使い
でこうしますと
えーっとー手創作パープレキシティーは八十六．五ということで
でこれはあー開発コーパスなんかに十分使って
まずベースラインよりはかなりあのベースラインから五回転している
という訳でえーっとーそのー
フランス等にも出ると日が選択モデルをえー統合した場合であってもやはりフィラーはそれなりに再現できるということが示すとこの
んで
それに対しましたこのところちょっと見比べてだったんですけども例えば両方共にえ二グラム使うつまり全然分からコンテスト付かないでまベースラインで
でえーっとここの
えっとＢはどう使うかと言いますと
フィラーそういうモデルはコンテキストを使って
フィラーは選択モデルの方コンテキストを使ったり使わなかったりという風にパラメーター間
でそうしますと
がえー一つの例ですがえーっとここで
日本と性との
で
それに対しましてえーフィラー語彙選択モデルの方はコンテキストその使いまして
四ｒプラスこういうモデルの方コンテキストを使わないという風に変えますと
えーテストセットパープレキシティーはえーっと七ポイント程えー差がある
という風に比べますと
えークラス高二のモデルの方が
えーっとテストセットパープレキシティーが有効であろうというところがえーと見て
でえー以上をまとめた二が来ますとえー本発表ではこの二で囲ま話し言葉コーパスからえー話し言葉言語モデルを構築する方法として映画予測モデルを用いの方法を提案しました
てＣＳＪの対象とする実験にありましてえー実際の話し言葉に近い言語モデルを構築できることを示しま
でえーっと今後の課題としてはまーと存じ前の二十九個使った実験ですが他ドメインのえーコーパスを使った実験とかセットごとえっとー検討していきたいともっと
え発表は以上に
#############################


#############################
# query = 話し言葉コーパスにフィラーをその導入することでえーその言語モデルを作った時に音声にきシステムの性能はどのように変わるのかえー結果がどうなるのかっていうのが知りたいです
# rank = 2
# slide = 08-01_fix.match_word.jout.txt
# value = -4.44805227051486
#############################
えではライフモデルを用いた話し言葉のえー
言語モデルのこの選手より評価と題しまして
九八二す各大学のおー他言語は発表させていただきます
えまず本研究の背景から御説明いたします
えー講義音声の自動要約やニュース音声などの音声のテントの利用といったように
え話し言葉音声の人でしに対する重要な近年高まってきています
えこうした音声のいいんですね実は音声認識は重要となり
そしてえーこういった話し言葉の音声認識には
話し言葉の言語モデルが必要となってきます
二十一こうした話し言葉言語モデルの構成なっては幾つかの問題があります
まずえー話し言葉にはえーこのようにえー一文見直すといった
えーと上のさまざまな現象がお開発しますので
ところを正確に書き起こしたコーパスがまず必要となります
えまた話し言葉と一対ましても
えーっとーやはりえーニュースなるといったように
そのドメインや発話スタイルは非常に的に分かります
違ってその認識対象と同じドメイン発話スタイルのコーパスを用意する必要があります
えしかしそれはとても
文コーパスが実際に適用できるかどうかそういうのを考えていますとえーまず今いる書き言葉コーパスとしてはえーこのようにえー新聞記事等を多分こうまあるコーパスといったように
えーさまざまな語彙について
えー非常に十分な量のえーデーターが利用できるのが現状です
しかし
これらはあくまで書き言葉コーパスであり
えー何々の付いた
話し言葉特有の現象は含まれてきません
えーこれに対しえーこのような現象をえー含んだ家から外のコーパス
としては例えば都内最大のものでえー日本語話すとまコーパス
というものがあり
えーこちらはえー学会講演や六講演など
このえー自分なりを含んでいます
えしかしこのように十分な量の
えー話すとどうもそれが利用できると人というのは非常に海外というのがえー現状であります
んー
これは話し言葉特有の現象即ちフィラーや言い直しを正確に書き方作業というのが非常にこうコースな為です
えそこで我々は
えー二十六八えーと記録といった文正確な話し言葉コーパスえっとえもう一の方をいたします
えーこれが例えばえーと海外六が挙げられます
その他に回六まーえー現在まで二十七月に気をこえー自分が蓄積があり
えーまた
フィラーや言い直しなどは省略されていますがその他の部分に対してはえー正確な話し言葉コーパスに非常に近いものとなっておりえーしたって
えー
またえーこういった国会へ入るかなとえー双極などは
えー比較的えーようにえー二つ程はできる為
えこのようなこと頭に来たやり直しをえー復元することができればえ非常に重要であると考えます
えまた日本語話し言葉コーパスを分析した結果
えー二さまざまな発話というのでその中でも
えー特にフィラーの出現率がえー極めて高いということは分かっています
原子挙げまして今回我々は
えー活動は父いの現象の中でも特に嫌いに注目したいと思います
以上踏まえましてえ不正確な話とまコーパス即ち自動クラスを記録理解しえフィラーの復元を行なうことで
話し言葉言語モデルの構築を用意する即ち依頼をしたモデルを用いた八月言語モデルの構築法を今回我々は提案いたします
え本研究の関連研究としましてはえーまずえー私が等による言語モデルと発音辞書の統計的に話し言葉変換
が挙げられます
えー秋からのこの手法では同定実験かもう根本的元のモデルと発音でしょう
話し言葉の世代へと変化することができます
えしかしこの赤の方法では変化モデルの学習の為に
えー
捉えるコーパスを必要とします
これはえー同一の内容に対して
えー結局えー書き言葉と等価とはそうでそれで
えー作成したもの
えまた
えー本研究と
えー
近いってアプローチとしてえーし七八年によるえーランダムな気がそれに基づく方法が挙げられます
えーこれはえー行ってるうちに基づいてえーフィラーを挿入するものであり運転手と五六番八と釣りですがえフィラーそうになってえーコンテキストは一切殺しておりません
これに対し我々のえー手法では
えーコンテキストを考慮した全ての音色的だと二を行ないます
えーこれについてはえーこれから詳しくえーと疎開娘いたします
えー本手法の
いいのかなではこのようになっております
テーマ
えーフィラーが正確に書き起こされたコーパスこれを
えー学習コーパスまして
えフィラー予測モデルの学習に使用します
えこうしてえー学習された第二モデルを用いて
えー先程の公開回路図のようなえー自動クラスを記録
に対するえー
であのこれを行ないます
御指摘が学園が行なわれるコーパスを開発コーパスをえいうことですね
並行して駅が付きのコーパスはえー獲得できればえそっから八月の言語モデルを構築することは
え非常に容易であると言えます
えーここでこの開発コーパスえっとえ認識対象はえーこのドメインで
ある必要はありますが
えこの学習コーパスに関してはえー開発コーパスや認識対象とえー必ずもえードメインが一致している必要はありません
があって家を正確に書き起こしたとパスであれば
えー開発を頭に最初この犬とかって意見を
下手するとま個性
利用することができます
えー続いてえーその怪我の元にえー用いるフィラーはその前についてえー御説明いたします
え今回はこのようにえーと前後二つ前の形態素モーラに基づき
フィラーの挿入数を推定するって後にモデルと
えー突然そこまでの形態素に基づきフィラーの語彙を推定するであ選択モデルの二つに分けてえーモデル化を行ないます
ではまず
えフィラーの挿入数を推定する偉そうにモデル
についてえ二つ目といたします
えー今回我々はえーっと後あそれもＬを
このようにえー形態素列に対しえーそこにフィラーが挿入される場合にはえー比べておそうでない場合にはモーラ目を要するというえーラベリング問題としてえー定式化を行ないます
と言いまして
えこの例ではえーこの断面を見るとという人達のこの何年頃その後には国
えーフィラーが
でそれされるということでえーここに比べではえー付与されて
えこれはまー別ラベリング問題に対して
えーと決意確率は
え知られ方を適用します
この調べというのは自然言語処理や×を今ですと言って分野で一応ただ住んでおります識別モデル
皆と言いまして
えーこのように表わされる条件で一つ一を最大化するように学習を
行ないます
その寿司屋で考察な人が問題に適用することにより
えーま大人にあるんんであ最適と皆したえー
食べるってすると共に
えーとトラブルがえ付与される確率がよくあります
でそこでえー我々は今回
えこの
えーラベルを付与確率に基づいてえー何の
不良を行ないます
次にえフィラーの語彙を推定する気が選択モデル
についてですが
その日が選択モデルを構築列にありまして
えー我々はまず日本語話すとまコーパスに出現するってあの分析を行ないました
その結果このようにえー知らない部分が上位五種類でどうもこれグループで
えーカバーできることが分かりました
単位ましてえフィラーの語彙をえ推定するというのは一文とであると考え
また
フィラーの選択に有効なコンテキストを
を調査する為に
予測に用いるコンテキストをえー変更さ頭の上でえフィラー部分の
テント日予定が先かはこちらになっています
えこのようにえコンテストまこれしないえ自然がえーもっと丸く
それに対するえー今回採用しました
世代その
トライグラム
によるものはえ最もえー良い性能が得られています
えーもう少し
ともかくえ見ていますと
まずえー×アンド推移を比較しますとこのように形態素のま色んなこともよく
えーそっから形態素の表層系の情報を取っ
っていうことした場合延々とＰがえー〇から詳しい
またえー同様にえー品詞やモーラの情報を
えー音空いた場合にえー
落とすえー情報として検定でエントロピーは増大していきます
えー特に形態素の表層ってや
えーモーラ即ちえー形態素の発音に
えある
情報が
提案した時に特にえーエントロピーが大きく分けるかから
えーこのような情報はえ特に重要であるとえー言えます
またえーバイグラムとトライグラムをしたシステム夏とえーこのように一貫してトライグラムがうまい題名にも推定って言うと
えー言えます
一以上のような調査を加えましてえ今回我々はプラセンタその例として
形態素のトライグラムを使用しました
えこのプラセンタと群とえ先程説明しましただそうにモデルを用いてえ実際にピアノ方言をこの手順なこちらになっております
えまずえ以上でランダムな確率変数部を導入し
えーこれでえーこの確率変数と
えじゃそれまではいわゆるえーであの
えーくる確率
をえー
学生
えー形態素から携帯すると共にであのー
そりを行ないます
続いてやはり一様では七十五ヘルツを導入しまして
えーこの覚醒すると
えー各じゃ語彙の
んえー選択される確率訳なモデルからなる確率を下に
えーとそれされたえフィラーの語彙の選択の決定を行ないます
このような手法によってえー
であのこれを行ないえー開きの言語モデルを獲得するというのがえー我々の提案手法になります
えーこのような
提案手法を
今回は
えー実際の海外旅行を対象とした
えー実験でもって評価を行ないました
え具体的な
このようにえー一月の色がする為の学習コーパスをしては
えーＣＳＪにどの発話コーパスの六講演前な猫一講演
を用い
えー開発とパスをしては実際のえっと海外六千八十三講演文を用いました
えー講演学習コーパスに用いたもう二十六講演とえー文構成用いた公開採録
に対して
えー森公園が静止対象を用いてもう一つをえーそれぞれのえー未知語率を求めていますと
えーこのように両者は未知語率は
えー非常に
えー五十行ったのとなりました
違いましてえーこの学習と×での森公園とかそうパスであるえっと海外六はえー非常にドメインの異なっているコーパスやる
ということができます
そして
このようなえ×の異なるコーパスを使った場合でも
え我々は．一ではえー適切に直すと二することが
できます
え実際に直そうでした例をえこちらに
示します
このように
えー実際の公開回路に対し
えー音声を担当してない人で
記録した公開体力があってこちらになります
これに対し
提案手法でえーグラフにした方が体力がえーこちらにあります
でこのようにえー適切な位置に適切な語彙の家は復元
そんでできてると
家は
その日が挿入を
平成五でもって評価した結果はえーこちらになります
えこのように
えー
コンテキストを一切これ繋いに選んで持ってきが向こうに行った場合と比べ
えー今回採用したＣやべく
やえー父がそのトライグラムでもって何とに行った場合の方が
えー認識精度はえー正規化したえー精度忘れていることが分かるかと思います
このように断層においてコンテキストえこれは非常に重要であると言えます
んー
次に
えフィラーの種類を区別した場合即ちえー先程増やそう二群のみの評価でしたが
プラセンタ頭まで変えた場合のえー精度がこちらになります
またなどにもえー推定って言いますと
えー
先程と同様にやはりこのテストをこれ繋いであげるにもえコンテストこれ親しいや例二を用いた方が
えー精度は
連れていることが分かります
また
そうようにじゃ選択モデルについても
えーと前に形態素コンテストとして
えーこうした場合とかでえーコンテキスト殺し合い
南の方ではえー精度は元います
与えましてえやはりフィラーの選択においてもコンテキストを考慮するということはえ重要であると言えます
なおえーこれあの精度はえー一見非常に低い精度であるかのようにえー見えますが
ここで注意していた高いのが
えー嫌わ画一的な現象であるということ
違いましてえー音声を百パーセントにすることは
え本手法の目標ではございません
例えばえー参考としてえーっと文の言語モデルによる単語列と一分九十七パーセントとなっております
次に
えー本提案手法によって構築した開けの言語モデルを実際の認識実験によって評価した場合
の結果について報告たいと思います
え気染めたとしては
えー二千七年に
知る人で開かれた四県の海
からえー五分ずつを抽出し二十分分のえそれさを作成しました
声
音声データーは集金の弁別のビデオがχから推定したんで
またあ正解テキストは
えー
その音声を担当しながら人手で書き起こしました
えデコーダーとしては地下投資をしまた音響モデルをしては
えＣＳＪに苦労している名詞一でえーＦＦＴえ二の方を使用しました
えーこれはＣＳＪの学会講演
および六講演から学習した
トライホンであり
えー性別独立モデルと行なっております
えーこのような条件の下で
えベースラインの言語モデルと提案法に基づく言語モデルとえーとそれぞれ四四
線を比較しました
えーベースライン原言語としてはえー丸四ですに付属している言語モデル生成モデル
そして
えー開発を二つの全国大会六から完全に学習した
えーＡＴＲの
そしてえー対訳コーパス
とえーＣＳＪの森公園の言語コーパスから学習したＡＴＲプラス一つのえーを用意しました
で特にこちらの国ではえリアルとは水でスピーカーモデルはえーこの場合にえー従来よくこちらでした
そういうあると思います
このようなベースライン言語モデルに対して
提案法に基づく言語モデルとして
えまず情報の漏れ
え一六それしたコーパスから学習したモデル
そしてえーそれにＣＳＪの森公園もえ混合した
えー規則六を二つＳＰＬモデルを用意しベースライン元のモデルとえー比較を行ないました
えまずえー各言語モデルをえーパープレキシティーで評価し比較した結果が
えこちらになっております
上の方でえー生成モデルに関してはえーと自分は品詞体系を採用していることから
えー緑てた中で最ものえー比較
今は行ないません
なおえーまだ花粉のでの語彙サイズはいずれも約二万語となっております
えー学園やモデル
からえー見ますと
えーケーキ屋モデルは
えー僕がえっと海がいるから三十二項としたモデルである為
えフィラーは全く含んでおりません
対話してえ水をいつも非常に高くなっており
えーまたえータクシーは八十七．二
えーまた癒さこれはえー未知語を考慮した確率ｐ即ち構成が苦しいですがえ二七百三十三．一をえ非常に大きな値となっております
これに対しえー声
ＣＳＪの森公園も混合したえー音であるクラス会ですですモデルでは
えー森公園の言語によってえフィラーを含むモデルとなったことからえ未知語率は大きく削減されています
えー確率については
英語となっていますがえー未知語を殺さ構成楽しんついてはえー大きく改善がされています
私本提案手法によって
え構築されたプロこのモデルは
えこれを更に何がある
結果となっています
えー森公園がえー含まない事柄に通りその削減され
また他の歴史
えーっと成果としていあまり大きく改善されています
なおえーこれに対しえー木構造のえ三歳えー六講演を混合したと行動ですでその上については
えーま言い方への混合した言葉へ帰って未知語率がえー若干とか四
えーパープレキシティーや固定化と四においてはえー改善しています
え以上のパープレキシティーによる評価結果です
これに対し
えー実際の認識実験における認識精度を比較した文はこちらのえー国はとても
えー左側の青いなはテキストデーター全体に関する単語認識精度
でありましてえー三層の会話はえー
二つ例のみ
に関する単語に性をおえ示しています
えまずベースラインの言語モデル
から見ていますとえーまず
えー認識対象と思いの不一致しない中で既にモデルについては
えーガイドラインの中からテストデーター全体についてはあまり良い性能が得られていませんがしかし
えフィラーを含むであることから
知らする前に関してはある程度の性能が言われています
一方で
で他に採録が五つでした平面やモデルに関しては
ドメイン名に対する認識対象と一致していることからえいてそういうテストデーター全体に関してはある程度の性能が
得られています
一方でえフィラーには採用していないことからじゃそれに関しては
えー低いって音をあっております
えこれらに対し
えー
他五回六にえ六個用法もしたえ年八クラスＳＰＳＳモデル
では
えードメイン間に体操とほぼ一致しえー例えば五講演の混合した方へ家に対応したモデルとなっていることから
えーテストデーター全体
および第四件のみ
の以前においてもえーある程度の性能が得られています
しかし
提案手法によって構築された後ロボットのベルはえーこの両方においてえーこの辺にあるやってきて頭をえーとなっています
例えばえー例えば現代に関するえー二文字
精度ではえー
で二十パーセントのえー誤り削減が得られました
また知ら弦変換しても非常に大きなえー改善が見られます
えここまでは先程示しましたえーパープレキシティーとえほぼえー一致した傾向が見られますが
えーここでえーと子供にえー六五四混合した
えーと行動クラスえストレスモデルを見ていますと
えーっととどまるとかで
えーわずかに店はとしています
これはえー模擬講演の言語によって帰ってえー未知語率がえーと買ってしまったことなどはえ原因として考えます
え以上は家の処理を区別しなかった場合のえー結果ですが八種類を区別した場合でも
えー同様の傾向が見られえ提案手法が
ですれていることがあります
ま取ります
正確な話し言葉コーパス
え以上であ講演録からえー話すとは言語モデルを構築する方法として
ライフモデルを用いる方法を提案しました
これはあたしあれに基づくいやそういうモデルとえートライグラムに基づく家選択モデルの二つのモデルから構成されています
えー実際の公開温泉地のタスクにおいてこの試合をしたモデルを用いたえー提案手法
用いた頃
えー従来法よりも高い音先生の持たせることができました
特に従来よく用いられるコーパスの混合による
えー方法と比べ誤り率が二十パーセント削減されました
今後の課題としては第二モデルの確率値を認識のデコーディングで直接用いる方法の検討即ち
えーピザを開発コーパスに挿入する手間を掛けない
方法についてえー検討していたいと考えています
え以上で発表終わります
受けました
#############################


#############################
# query = 構成ドキュメントと六えーとにかく検索したい時にえー音声のちょうど去年とーで得られた情報からそれでの生徒を徹底騒音データーも検索する際に資料をする手法をがあるんですけどそれてフレームって言ったからフルテキストを選択してフレームインデックスエ来る時どのようにしてそのウェブテキストからはインデックスもう選択するという川作成する間の方法を示したスライドはえー衰退です
# rank = 1
# slide = 09-06_fix.match_word.jout.txt
# value = -3.73652017686726
#############################
あー肺ではえー
検索対象の類似性の高いえーページを利用した音声だけで政策の検討を
について
えー山梨大学工学部コンピューター部屋工学化することが発表さしていただきます
で発表では普通の
まずえー研究の目的と背景
そしてえー研究概要を説明しましてえー例を利用した音声ドキュメントを検索の概要
えーその
ある手法を用いましてえー評価実験
んー行ないますその後えーまとめと課題
えー
まー今後の課題について説明いたします
でまずこのからえー一
研究の目的と背景
えーそれと
研究の概要について説明いたします
えまず研究の目的と背景にあります
え目的としましてはえー音声のえーと検索精度というものを解析法
と考えます
でここでえー音声学など検索というものなんですが
はえー近年のえー記録媒体教え方という風に
で大量の音声や映像というものを保存がおりました
でこの
えーこの大量の保存されているえー音声
からえー効率を検索すると
ってものが必要になります
でこう
こちらの検索をどのようにして行なっているかということなんですが
まず考えるのはえ人手によるインデキシングというものがあります
って人手によるインデキシングというものはえー
対象とするデーターが多くなれば多くなる程えーことが終わってしまいます
えーですので一般的には音声認識ある事情インデキシング
というものが行なわれています
えですがこの手法ですと
え音声認識率が悪いとえー制約検索できない
という問題があります
ではこちらをどのように世界で一日
ということなんですが
でまず第一に考えるのがえー音声認識の改善というのがあります
え音声認識を改善しますと
えー
インデックス時代の一つは良くなります
えしかしいーは何かん的な認識を行なうことは難しいということを
でまた
未知語や認識誤りを回避できないという問題があります
えーですので
本研究では
え音声認識誤りに頑健な検索方法としまして
えー検索対象音声とおんなじ内容のえーページを利用しようと考えました
でこのえー
本手法用いることによってえー検索精度を改善しましたので
その手法について説明いたします
まず研究概要になります
えーページを利用した音声をけれど検索
といたしまして
えー提示しての為の
え検索への検討をということを行ないました
でこちらはえー単語Ｎグラムの手法まだ
えー
ペルー日本語Ｎグラムというものを使用しました
で次にえー三ページの妥当性判定ということを行ないました
えこちらは
えー収集した上で力
であります後えー
でページもう全然の選択を行ないは
え検索精度良くなるんではないか
っていうことを考えました
で次にえー検索結果
の
方法の検討ということを行ないました
でこちらはえー抽出をえーページをどのようにして検索システムに組み込んでいか
ということを考えました
で次に
誰でも利用した音声におけるえーと検索の概要について説明しています
まずこちらが
一般的に行なわれている政策になります
えまず
検索対象の音声
というものを構成意識いたします
でその日
えーそそこで得られた音声認識結果からキーワードを抽出し
ってインデックスを作ります
えこのインデックスをここではえー認識でセットします
そしてえー混雑したいのにえー認識インデックス
とえーユーザーの検索要求である
で我々について検索したい
というようなえーテキスト形式の
いう規模
付けます
えーこちらのえー
ユーザーの検索要求と
えー認識です後
えー検索エンジンでえー比べ
で
できた結果を得ます
でこの時にえーっと音声認識結果は中に
未知語や後認識単語というものが発生してしまいます
ってですので
検索エンジンにはユーザーの検索要求にえー未知語や誤認識単語っていうものが含まれていた場合
えーっとなく検索
することができません
ですえー提案手法としまして
で
音声認識結果から
キーワードを抽出しえ検索用のクエリーというものを構成します
でそのえーっと構成した
増え検索用クエリーを用いて
二ページというものを収集します
でこの時えーページの妥当性判定ということを行ない
えー関するえー提示文というものを作成します
下手なからキーワード抽出
というものがないＸを作成します
でこのインデックスをここでは有名です
と言います
でこのようインデックスを用いることによって未知語や誤認識単語を二のと考えました
んー
この二種類のインデックスに
対して
それぞれ検索エンジンもう
使用します
でこの二つの
検索エンジンに対し
ユーザーの検索要求
母音それぞれ
二四つの
でそうすることにより
えーそれぞれの検索エンジンから
えー
検索結果ってものが得られます
でその得られた検索結果を
統合することより
最終的な検索結果を得ます
えあついにこう流れをえこの処理の流れだから
え音声認識結果から
でＣはあのー
放置してみて体験
えーで検索用クエリーの構成を行ない
えページの収集を行なう
までの流れを説明します
でまずえ検索よく旅行生になります
え要因では損失
というものは収集したメッセージの内容で変化いたし
えーですので
えー検索対象音声というものが文のあの話題で
分喋っていいかっていうことを特定するとかって思います
ですので
えー検索よく言っては重要になります
えーですがえ今回
の研究では
えー
えページを使用することの有効性を
節程二十でも
書きましたので
え簡単な話題な絞り込みの方法としまして単語の連結ということを行ないました
でこちらがえー単語の弁別の方法になります
えまず音声ドキュメントの音声認識結果
んがえー一万円します
して示しますこちらの
よりやっていたとします
でこの中からえーキーワードを抽出し
検査クエリーを構成した時に例えばこちらの
データーを
というものを検索例として用いた場合
えーデーターだけですとどのデーターに対しての検索要求があるか
というものか分かりません
えーですので
広い範囲の
えー提示を集めてしまいます
でただここでえーベンチが続く限り単語を連結しました
えー単語の連結を行なうことによりデーターという単語に学習というものが付加されます
で再学習データーという単位でえーメールを検索しますと
そのえー話題が絞り込みことを
ま話題の絞り込みを行なうことができます
えですがえー
名詞扱いに単語を連結してしまいますと
あーこちらに示すように
学習データー数縦軸というような
え二では．五のような単語でもまーできてしまいます
ですのでここで
えー日本語Ｎグラム
というものを使用しました
えこの英語日本語えであるということはえ文が作成しました
普通のページに含まれている
単語Ｎグラム
というものを登録してある
データーベースのようなものです
でそこに登録してある単語がどうかということを
えー
比べることによって
こちらの学習データー数
えーとーえ縦軸
というように
えーパンを分類することができます
でこれらの手法を用いて
えー単語の連結を
行ない
えー
名詞一というものまた撮影したえー単語Ｎグラムの出現頻度
えー上位語単語のえー検索駅
として採用しました
んー
え次にえーページの収集の方法なんですが
え先程の方法でえー作成しました上で検索用食
というものがえー例えば大切に
テーマ三四に五の一つであった場合
ところでですとＡが一番出現頻度が高くなるんですが
えーこの五つの検索用クエリー
というのは
えー組み合わせを
作成します
でこの組み合わせだから
最初はえー全部を用いてこの検索を行ないえーページ
というものを収集します
でここでえー
収集したえーページっていうのが目標
二十代目標係数に達しなかった場合
で次の組み合わせでえー
えー
検索を行ない
元々ヨ
あー先程の係数ｐで
収集しました上ベースに追加してきます
んこの処理もえー繰り返し行ない
模型をえー収集するえページあの表現されたするまで収集を行ないます
月に二えーん
音声認識結果を
またえー
収集した上ページから
それぞれのインデックスを作成する方法
についてえー説明します
えーまずえーページの妥当性判定
えーあります
んー
え音声ドキュメントのえー認識結果というものは
でこちらなります
んこちらを元に収集した上ページっていうのは
こちらになります
現在ですとえー学校の
こちらですとえーＡＢＣＤ
にえ二
え六個の
あ六県のウェブページを収集したと
します
でこの
六件の
でえー
それぞれのページのえー類似度計算を行ないます
基本的えー発話えー尺度を
使用し
それぞれの思いはえドキュメント内の出現頻度
用いてえー類似度の計算を行ないます
そして得られた類似度っていうものが
えー
こちらのようになります
でこの中からえー閾値以上の
古い町
になったものを
平面図をして採用します
でこの例ですと一五パーセント以上類似した文
になります
またえー閾値八の上ページがない場合
をえこれこれで言いますと二十パーセント以上となった場合ですが
でその時はえー認識結果を
二ページの代わりに対応いたします
え次にえーインデックスを作成になります
認識
がこのようにえー
でこの中には
平和な予測係数に空気が単語というものが含まれています
えこちらで例ですと
このもというのもまたは四時
まーついては単語になります
でこれはあの
単語を
あれだけ子音
話題を特定する単語文
でえーインデックスを構成しました
では次に
それぞれの検索エンジンから
得られた
検索結果を統合する
について説明をいたします
で検索結果の方方法としまして
えーユーザーの検索要求中に含まれている
え未知語の割合で統合を行ないます
え統合式は
三こちらの
式になります
えこちらえー構文というものは
えーユーザーの検索要求に含まれている
見積もり
んで
ではえーこちらの
政治やるっていう本を聞いた日っていうのは
でそれぞれのインデックスで
で検索しました
結果の検索スコア
になります
でここでえー後まー
三つを使用することによって
未知語率が
多く含まれていれば
えーページに夜
え検索結果を
んー語をえより強く反映させようと考えました
でこれが
えー検索結果の方方法の例になります
えまずえーユーザーの検索要求というものが
こちらの話者認識の学習データーのサイズが小さい
推定ようなテキストを入力やった場合
えこちらを
えー認識時に用いて認識でしょう
とー
えー見受けられまして
んー未知語というものを
んあー思います
でこの場合ですと
この
認識というものと
データーっていうのがえー未知語であった場合
でこの
検索要求の未知語率ってものは四十パーセント
となります
でこの四十パーセントを先程の
地域に代入しまして
で認識インデックスで求めた検索スコアを
庭でえー僕も
でまた
いうインデックスの為だけだ活動を
言わでえ四
というものを
発表させます
それにはそこのドキュメントえー
というものになります
認識に出曲求めた訳で
のえー〇．九を掛けまして
いうインデックスで求めた
初めての
入れて三人で手を掛けます
そしてえーとぼけ
彼はその両方の値を足して
えこちらの結果になります
こちらえーん
うーインデックスを持ってることよってこのドキュメントに
というような
えー認識率ではえー検索違ったドキュメントっていうものが
で
最終的な統合結果
縁は
で検索されるということになります
では次にえー評価実験につい意外と思う
まずえー検索対象音声の教員と
には
えＣＳＪを対象にしましたテストコレクション
獣
使用しました
でこちらはえー千七百にのドキュメント
えまた
えーユーザー検索用機は三十九個
でその中に未知語複文ユーザーの検索要求は一一方なります
え検索対話一講演も
後ドキュメント
としました
できるだ
えこちらのＣＳＪを対象データーテストコレクション
言わば
て予め認識
結果というものとされていましたが
てその認識結果の中には
発音し結果は
まえーとー
未知語を
三つってものが
って言うかまー誰に
で今回は未知語を
であえー五十単語っていうものを
にえー改善されたかどうかということを調べる為に作業
入り未知語をあそうですして認識
二を行ないました
二つの条件がこちらになります
で言語モデル
はえー
学会講演の書き起こしデーターからも実は
二十七キロのトライグラムモデルにあります
えー音響モデル三はえＣＳＪから作成したトライホン
二三十八次元
星をしました
で音声認識システムにはえー二八つの音声四．一を
えこれは手法
を用いてえー
音声認識を行なったところ
え単語正解率は七十六．一パーセント
普段えーす
正解精度がえー七十一．六パーセント
設けました
で次にえーページの収集方法になります
えページを収集には約検索えー二二八五というものを使用し
一時のえー月五十点程度
フレーム影響を生成しました
背景ざ
えー二には
え反映用例村連想型三二十一日
というものを使用しん
でそこに含まれています一つの方法
というものを使用して
で検索出しました
え次にえー
評価尺度に
関しましては
で保管中にえ平均精度
というのを用いて
えー検索結果の音声二千件
でえー評価を行ないました
で実験結果をこちらになります
まずえー
えー検索要求文の構成をおー
の
えー対象検索
程度になります
へこちらはえー画像検索要求全体
ですね三十九の
ユーザーの検索要求に対しての
結果になります
んー
普通の
認識Ｘのみ
んで
計算を行なった時の精度になります
でこちらがいい
並列
語を収集する時の
クエリーの構成法の
時にえー
いう日本語Ｎグラムというものを使用しましたが
えそれにより
あのー
連結
たかどうかっていうことになります
ナシというものはえーでも日本語えの募集をしていない場合
でありっていうのは
テレビ日本語えである募集をし
して
えページを収集しました
でこちら総合はえーっと
提案手法による
精度になります
え提案手法を知ることによって
どちらも
えー検索精度を
解決することが
できました
でまた
という日本語Ｎグラム
もう使用することにより
四十間でありますが
検索精度が良くなる傾向が見られます
え次に
話をえーえ未知語を含むユーザーの
検索要求
みたいと
に着目して
検索精度を求めてみました
えこちらは一
二のえーユーザーの検索要求になります
二こちらも同様にえー提案手法をすることにより
えー検索精度というもの改善されました
でまー
えーえ基本概念であるというものを使用することに
まこちらも若干ですが良くなる結構
胸が見られました
んえー
二ページの妥当性判定により検索精度
になります
でこちらはえーユーザーのけだけを聞い全体に対しての精度になります
えこちら横軸の
〇．一
一五というような
えー政治は
テレビを選択すると
する時の類似度になります
ですねこの〇っていうものは
集めた上で一応全部使用した文を
ただこの
一というものは
えーベイズの妥当性判定死類似度を計算するんですが
でその一パーセント以上になったている以上
んでえー例文二十を作成した時
の精度になります
二個
え括弧で囲まれている政治ってものは
言えるインデックスが付加されているドキュメント数
になります
でこの結果を見ますと
えー
んー
平静時の妥当性判定を行なうことによって
で検索精度がえ触ってしまいました
はい
次にえーみ
同じ条件で
水を含んユーザーの検索要求でして
行ったところ
矛盾は結構
が見られました
でこの
あのー
結果あの考察なんですが
でまず
ページを収集する時に今回はえー簡単なあー手法
で
えー検索用クエリーを構成しえーページを示し
したこと
でまた
いう指導を計算する時に
がん二単語の出現頻度
よる重み付けで類似度を計算したことから
不要な六ページというものが集まってしまった
ことを考えられ
では最後にえーまとめと今後の課題について説明します
えまた私まして遊園地を利用した音声ドキュメントを検索
に関してえーページを利用することで検索精度の改善を行なうことができました
で特に二十五九ユーザーの検索要求いたしは大きな改善が見られたと
思います
月にえー検索要求の構成法に関してですが
でこう専門の違いにより検索精度
の改善が
可能であると
と
分かりました
えまたえー五ページの妥当性判定に関しなんですが
でこれは最後
検討する必要があると考えます
ですが
でえージョン落ちることで
検索精度を歳で二十五パーセント
肌未知語を含むユーザーの検索要求に対しては検索精度を
二．五パーセント改善することができたので
えページを利用することを
の有効性バスですのではないかと考えます
え今後の課題ですが
え検索精度
向上の為に
テレビでまた一か月に一二個
と考えています
え例えば
で現在
二検索用クエリーの構成方法
中では
え単語連結したものまた言説を行なっ三段階で使った者というものを
えー同じ割合で
使用してるんですが
えー単語を連結した単語Ｎグラムの方がより話題を特定していますのでそちらの単語有声収集をしを
と考えています
でまた
えページの妥当性判定の
方法の体系ということを考えています
以上で発表終わります
述べました
#############################


#############################
# query = 構成ドキュメントと六えーとにかく検索したい時にえー音声のちょうど去年とーで得られた情報からそれでの生徒を徹底騒音データーも検索する際に資料をする手法をがあるんですけどそれてフレームって言ったからフルテキストを選択してフレームインデックスエ来る時どのようにしてそのウェブテキストからはインデックスもう選択するという川作成する間の方法を示したスライドはえー衰退です
# rank = 2
# slide = 07-13_fix.match_word.jout.txt
# value = -3.77659243748502
#############################
えーそれでは京都大学の根本が表記の題目で発表させていただきます
でまず最初に研究の背景についてえー説明します
定期健康にはそのデジタルアーカイブかと取り組みが活発になっており
でそういった中でえ要約テキストやインデックスにより人に利便性を向上することが望まれておりますが
って人手によるこれらの作成は非常にこう子育てを今
でそこでえー音声認識技術の活用によるえーこれらの
半自動化にえー
検討されており半自動化が検討されております
えーそこで本研究ではえー購入音声の認識に取り組んでおります
で本研究で対象とする購入音声の特徴と課題について説明します
えまず本研究ではスライドを持ってる購入を想定します
でここでスライドで申しますのはまこういったパワーポイントの使用のことです
えー
スライド対を用いたさまざまな項目の説明がこういった行為が行なわれるのですが
えーここではあって
スライドにえ専門的な内容が多く含まれる為
抵抗に全体としてえー最適な話題が存在します
え更にえー表示づらいのに関連する発話内容がたくさん現われたり
えースライド前の重要度スコアが反復が起こったりすることから
で局所的な話題の偏りが存在します
えこういったことから
共通の言語モデルのによる認識はＦ０となります
で具体的にどういったことが起こるかと言いますとえー話題に特有な表現の予測能力が低くなってしまう
で更にえ専門用語が未知語になり易い
といった問題が生じます
えそこで本研究ではえーこうに面移動を手掛かりとしてえ言語モデルの適用を行ないます
えこれまでにもこういう音声に対する言語モデルの適用の試みは数多く行なわれております
え代表的なものを御紹介しますとえ関連テキストを利用した方法としてまこういったものが存在するのですが
えーこれらは
影響関数がこうに音声の書き起こしといったテキストデーターを使用しております
ですがすえーこういったテキストデーターがえー電子化されていてかつ利用可能な係数というのは
テーマ限定的であります
でこういったことに対してえースライドするようを用いたえー言語モデルの適応の手法も提案されております
え具体的にはえーつらい顔のＮグラムの他による手法
が提案されているのですが例えばこれは断片的な絆知人となるえーこう二スライドではえー効果が奇麗に出てきたなと今
んー
えまた話者するモデルを用いたえースライド全体のテキストを使用してえ適応を行なってあるという手法も提案されているのですが
でこれはえー行為全体の話題に対する適応のみが行なわれております
でそこで本研究では
効率ライトの特徴を考慮した手法を検討します
えー
で具体的にはえー効率ライブにおいては
キーワードを中心とスター断片的な絆が中心であるといったこと
え更に二系列に沿ってこうに内容が記述されているこういった特徴声を使っ適応を行ない
えそれではえー本研究で行なうスライド映像を利用した適用の概要について説明します
えまず最初に
えー
でえーつらいこう二スライドで使用された面間の全てを用いてえー言えるえー性能持っていることでえー具体的な話題対する適応を行ないます
えー更にえー
学校にスライドからえー一つずつえー検索えー四一つ一えー空を用いてえー検索を行ない
くえー通常されたテキストを用いてえー適用言語モデルを構築する
といった手順で
えーこれまた一的な話題へ対する適応を行ないます
えー更にえー話題の局所的な課題をいへの適用としてま適応としましては
えー
各スライドのテキスト情報を用いてえーその面以外に
えー時間的に対応する発話に対してえーじゃすモデルを持っていることで
え局所的な適応を行ないます
えまたえーこの言えるえー前による大域的な適用
それとえー気圧モデルを用いた局所的な適応えこの二つのえー組み合わせることにより
えーえ帯域的な適用さ局所的な適用映画痩せることを行ない
んー
えそれではまずえー言える性を持っていた最適な適用についてえー説明します
でここでは
えー
五につらいあの単語頻度情報を用いたって言える衛生を用いたえー単語確率の推定
更にえースペインが
といった二つの手順でえ適応を行ないます
えこれまでのＰＬ衛星を用いた研究はえーさまざまなものが行なわれておりますがえーこういった枠組みに基づいております
でここではえー
単語確率をえー部分空間への際に基づきえこちらの好きでモデル化します
えここでえーこの潜在変数の時
というのはえー話題に対応するもの
え突然
え家なアルゴリズムによりえーこちらの日なバブルって言っＰのＴＤを付いてきます
えーコーパスからこれを推定することにより
えー人手によりえー話題を事前に定める必要がないといった特徴が今
え更にえー適応用文章おーまー持ってきてえーそれに対する潜在変数の生起確率の推定
を通じましてえー単語の生起確率を推定することから
で適応用文章の中に出現しない単語の確率の推定可能となり
でそしてえ本研究ではえー次のようにしてつらいと像を用いてえー単語確率の推定を行ないます
えここではえースライド全体をえー先程申しました適応用の文書として
えー単語確率の推定を行ないます
えこういった推定を行なうことで
でまず単語頻度のみに基づきえーこの確率が推定されます
えーその為えーこう二スライドなどでよく現われるえー一番あのキーワードの羅列などからえー確率を推定できま
えー
え更にえーコーパスから学習した潜在変数の生起確率を通じてえ最終的にえー単語の生起確率を推定することから
えーつらいの中に現われない単語の確率も推定されます
えこういった特徴があることからえー総数の間にられた単語によるえー断片的な記述が中心であるえーこうつらいと思っている場合に言える衛星が有効であると言えます
でそしてえーこのようにして求められたえー単語確率を用いてえー家からマスキングを行ないますえこちらの好きならされるのですが
でこれはえートライグラム確率全てに対してえー先程の推定行なうまーえー計算量が膨大なる為えーこういった計算を行なうことにして今
えまたはえー
スライドには主に話題に関連する傷が中心ですのでえー話題の三への適用を行なう為に
えー話題の人の語彙を限定してえーこちらのスペイン語を行ないます
でこのようにしてえー言える衛生による影響が行なわれまして次にえーテキストを用いたえー最適な適応について説明し
えこちらではえーまず
あ失礼しました
まず最初にえーこれの抽出とえーテキストの生成そしてえーそのテキストの収集道具の選択という二段階な手順でえー適応言語モデルの構築を行ないます
でまず最初にえーかつらいとからえー検索色を生成します
でここではえーＴ会とＩＤＦ値除いた名詞をえー各スライドを元にえー選択します
えそしてえーこれは検索をいたしましてえ検索エンジンをもついてえーれるテキストの生成を行ないます
えこの際えーまずえー十分な数のえーテキストを用意したいのでえー
マーカーと移動するとえー
ごみが増えてしまうのでえー二つの町にはえーくえー一つ当たりえー五百件
と定めました
えー
でそして次にえー集められたテキストにはまー
類ＩＴをえーま相手の長さより短い文や
えアルファベットがえー殆ど全て言わない言語モデルの学生にあって汚いと思われる文がまれるので
えーこれらは付いてしまう
えっとですが
えそしてえーベースライン言語モデルに対して
えーパープレキシティーを計算しえー猿がスキー場したまた文をえ学習用のテキストを
として選択します
でそして最後にえーベースライン言語モデル
のえーこの
適応用にえー集めたえテキストの今後行って
でえー適用え言語モデルをこう
え以上の手順で
テレビで傷を用いた言語モデルの方もえー適応が行なわれます
え次にえーじゃそのモデルを用いたえー局所的な話題への適用について説明します
でここではえー
じゃすモデルの枠組みでえーこう二つられたデーターを使用することで
で最終的な音声に
結果を得る
そういった手順になる
でまず最初にえー提案するモデルについて説明します
でじゃすモデルというのはえー直前に現われた単語は再び現われ易いという仮定に基づき
えー各
各単語の直前の単語履歴をえーチャンスとして記憶する
といったモデルになっております
えー突然
えー単語確率をえーこちらのようにえー
履歴の中でのえー単語頻度に基づいてえー推定します
えこの単語履歴はえー最初に自動音声認識を行ないますでえその結果を用いてえー得られ
え次にえーこの二話者モデルにえースライドを情報を利用します
でここではえー自発モデルとえー同様でしてえースライド中の単語はあー現われ易い
という仮定に基づきまして
で先程の式の影響するのを元にえーある発話に対応スライドをえー
スライド中の単語頻度を用いてえーパルスライトの下での単語の生起確率を推定します
て更にですねえー先程のテンスモデルで用いた単語履歴とえースライドを併用する
でこうしてえー総合の中での振動トータルしましてえそれを操作ではある
といったで前によりえーこちらの確率の推定が行なえます
えーこう捨てられたえー単語確率のいずれかをえーベースライン言語モデルのえートライグラム確率とえー
線形補間することによるえー適応単語のえー言語モデル確率が推定されます
でこうして得られたトライグラム確率を用いましてえ最初に行った音声認識結果のえーベスト仮説のリスコアリングを行ないます
で構成財政的なえー適用ものを低認識結果が得られま
でまた
でえー先程ベースライン言語モデルを用いて最初の音声認識を行なうと言いましたけれど
えここでえー最初に説明したえー言える衛生による適応言語モデルを用いた
えー音声認識部を組み込むことにより
え大域的な話題Ａに対する適応度をえーこの局所的な話題
えー
対する適用をえー組み合わせることができます
えそしてえーこれらの機構に対してえー評価実験を行ないました
で対象としたデーターはえー二千四年二千五年にえー京都大学学術情報メディア全体で行なわれた
音声認識音声対話字ずつこう社会におけるえー一二回目の音声となっております
え更にもう一種類のデーターとしてえー京都大学で行なわれたえー通常の後に三回分の音声を用いました
でこれらは全て時間はほぼ全て九十分となっておりますでえー五つの重複は五名のみ
でそしてえー全ての五人においてえー使用された効率ライトと
そのＴがえ時間情報が利用可能となっております
え音声認識は映画の強い検定を行ないました
でデコーダーはＪｕｌｉｕｓ三．五．二を用いましてえ音声モデルはえＣＳＪの学会講演からえー話者適応学習を行なったえー状態共有トライホンＨＭＭモデル
に対してＭＬＬＲ教師なし話者適応を行なったものを使用しました
えー〇づらいん言語モデルはえーＣＳＪの学会も二講演からえー学習したので
で語彙サイズはえー五万語のトライグラムえ言語モデル
でまたえー先程御説明したそうにおけるえーパラメーターはえー一二のように設定しました
えまず入れる前によるえー部分空間の学習ですが
でこれは
えー話題をカバーする為にえーベースライン言語モデルの学習に用いたえー結果赤い講演のえーテキストを使用しました
え潜在変数の数はえーテストセットパープレキシティーが最小となった時の値であるえ百と定めますが
またえーできるとの生成にはえー検索エンジンツバキを用いますが
えー
更にえー国の選択の際にえー用いるＴＦＩＤＦ値の計算ですが
でＴ会としてはえー彼スライドにおけるえー単語頻度
でＩＤＦはえー二つ前のえー学会主に講演の一講演を一文章と見なすか値を使用しました
えそしてえーＮグラムの頻度の今後はえー重み歩いて五つとしますが
で更にえー局所的なクラスモデルにより適応の際のパラメーターですが
でこれはえーこう全体音声に対するえークロスバリデーションにおい決定しまして
えーじゃその長さがえー六十え線形補間の重みはえー気圧の方もあるえー一五
えベースラインモデルの重みがえー〇．九としました
で更にえー適応を行なう際にはえー単語辞書にはえこう二スライド中の未登録語をえー追加しておりました
えまず最初にえーベースライン言語モデルを用いた場合の音声認識結果を示します
でこのようにえー講習会で七十五．六パーセントえー大学を二でござい発展六十パーセント
都営号仙台の方がえー認識精度がえーま大まかに高くなるといった結果が得られます
えこれは
でまー幾つかの要因が考えられるのですがえー
重要なこととしては講習会はまー学会講演に従って一回生の発話スタイルである
でそれに対して大学のこうのというなま教室で学生を相手に行なわれるものなので
で一分くだけたスタイルである
といったことがあります
でまたえー先程えー未登録語単語辞書に追加した場合はえーまーその改善はえー×となりますが
えこの実験ではえーこの三道路が追加された単語辞書を用いてえーすモデルの適応を行ないました
でえー次にえー冷静によるえー具体的な研究を行なった場合の結果を示します
えースライドを用いたところえー改善が得られたのですが
でえー認識結果を用いた一度の三ＬＳＩを用いた場合でこちらの値ですね
でこちらに比べてえー
番号に精度のせえー改善は三割結果となりますが
えこれは認識結果にはつらいのに困らない情報も含まれる為
で七ですがえー
ただえーつらい共付ける場合えー合成音二は一の間で行ないば良いので後続なそれがあの都内
でまだ一単語としてえー
認識結果をえーベースラインのモデルの学習テキスト二言語して
えー
認識を行なった場合をえー上回る結果となりました
え次にえーテキストの生成によるえー適応を行なった結果について説明します
でここではえー
やはりえー単語に精度の改善が見られましたが
でこう社会ではえー一パーセント酒
の改善に止まったのですがえー大学を二ではえーま二パーセント
今日の改善となりまして
部屋の改良になさそう舌を出ました
えこれはこう一回の話題はまー音声認識関係のものが多いのでえ話題がある程度カバーされているのに対して
声帯学校には全く関係のない話題なので
で話題関連のえテキストの収集によりえーこういった
ベースラインのコーパスでカバーされていない話題がえー適切に音になるかと考える
別にえー気圧モデルを用いた場合の
結果について説明します
でこのようにえー
通常のジャズモデル用いた場合えースライドを用いた場合
更にえー
つらい時や調整をした場合
でそれぞれにおいてえー話題の局所的な形に対する
適切な適用が行なわれて
え認識精度が改善されました
でその際表示されているつらいどん底があって急に有効であったと考えられま
で更にえー具体的な適用と局所的な適用の組み合わせを行なった結果を示します
えこちらがその値ですでえーこれはえー二衛生えーじゃすモデルそれぞれ単独で用いた場合の結果となっております
えこのようにえー具体的な適用といっ局所的な適用の組み合わせによりえーほぼ客観的な効果が得られました
えまたえー各
五年ごとのえー単語認識精度を見てみますと
え例えばえこちらの方にではえー例文の説明などの影響によりえーＰＬ衛生の交換はえ非常に小さくなると言うか悪くなっております
え更にえーれるテキストの生成の手法に注目してみますと
えこれらでは
えー
二つ精度の向上がえー低くなっておりますでえーこのようなテキストの青春が起こってしまった
ということが要因として考えられます
でまこのようにえー全体としてこう人内容やスライド後です形式によってえー適応の効果はえーばらつきが大きいという傾向が見られました
え第学校に対してはえーこのようになっております
猫面でのえーこの二つの語にはまず次の文記述が多い為にえー言える衛生による適応の効果はやや小さくなるといった傾向が見られますが
えまたえーこちらの方にではえーテキストを生成によるえー大幅な改善が見られました
でこれは英語の方にはまー画像それに関連する話題がえー話題のページなどで
えー
テキストの収集がえー高価で現在大スターと考えられま
え更にえー話題語の二つ精度による評価を行ないました
えここではえーこれらの語をえー話題ごと定めまして
でこれらは高二の内容理解の為必要でありえー認識結果表だとそれが正解要約をする影響が大きいと考えられます
えこちらはえー再現率適合率による評価を行ないました
えー交通書い音声に対する結果をこちらに示します
で言えるえーせえー年齢えこちらの値って言っなってきをですねそれに対して局所的な適用他にえーその二つを組み合わせた場合
についてえーすっえーを示しますてるとえこのようにえー失礼えー
八．〇．八五から出て二十八
といったようなえー改善が見られました
え大幅にえー再現率が上がっていることが分かります
えまた大学校についてもえー同様な結果を示します
でこちらも同様にえー再現率がえー大幅に
とそうしておりますで
芸術としてえー〇．七から〇七八分の改善が見られました
でこのようにえー
先程えー御
えー先程のえー手法によるえー適応はえー話題の何精度の改善に燃えおいしく固定しました
えそしてえー特に話題もあの認識率でえー特にええ再現率においてえー大きな改善が見られました
で以上まとめますと本研究ではえー後に音声に対する面の情報を用いた言語モデルの適応行ないました
で具体的にはえー具体的な適応とは局所的な適用を行ないそれを組み合わせますと
えーそしてえー
実際の声による評価を行なったところえーこういった改善が得られますが
え以上で発表を終わります
#############################


#############################
# query = 時面と中の大きく影響え強調発話の検出にあのーちょうど去年そちらの強調発話の原子数をえーどのようなアルゴリズムを使って実装しました
# rank = 1
# slide = 13-04_fix.match_word.jout.txt
# value = -2.70062779390233
#############################
んーそれではえーっと部分というペットと思っ
えーっとベクトルを特徴とする距離尺度を用いた音声検索を検出手法の検討見てて
え静岡大学大学院山本の木は
発表さしていただきます
本研究概要ですがえー我々はえー
そこはえー音声部分途中で発話されている箇所を特定する
えー音声検索を検出えー閾値
えーこれについてけんえー研究をしていますこの中に対して最も単純なアプローチとしてえー第五一音声認識システムによってえー
音声部分と思うと一か所
それに対してテキストレベルでのマッチングを行なうというものがあります
そしてこれにはえー高認識は未知語といったような問題がある為
せっかくの検出が困難という問題がある
うー七時の関連研究としましてはインデキシングをではえー検索アルゴリズムの改良といったことを行ないえー検索処理の高速に重点を置いたプロセスってまたはえー距離尺度の九二八九自動評価法の工夫などによる
検索性能の向上にえ自分でもう一日中
もう聞く訳でこの二つのプロ違うられています
なおこちらもえーサブベースのアプローチが主流となっています
えっと我々はえーこちらのえー検索性能の向上にえー主に一．五と当日を今回は発表者の
このサブのレベルのマッチングに基づく典型的なアプローチを紹介しますと
まずえー音声認識結果が検索をサーバーと列に変換しそしてえー
連続ＤＰマッチングによりえスポッティングを行ないます
これはサーバーとか六時五．四
後は特別の一つ目自動評価を一つの一部の問題にとして定式化するって思う
本研究ではそのー二音列に対する不連続ＧＰマッチング手法ですから
するとします
んー
我々の研究目的ですがえー音響的自動を考慮した
えー距離尺度の導入といったことを目的とします
えー先行研究ではその場と体の音響的類似度に基づく
二尺度やえー音素別特徴にも作る距離尺度のが提案されています
えー本研究ではサブワードとはえー二音の状態三図一でも作ってる尺度で
えー
以上滞在の分布間距離を特徴量とした新たな距離尺度えーこれを提案します
まずベースラインとしてい事実の概要をですね
んー
まず最初に音声とそれとおーす音声認識デコーダーはそうする
その後どうですの認識結果と
えー
単語ベースの認識結果を
優れ検索用データー別に蓄積します
なおこの際単語ベースの認識結果をＳＡＴと系列に変換して
えーデーターベースに
都会とします
えー
そして検索語は二十六された中検索語側音系列に変換し
その検索語が
志望であった場合は単語えーベースの認識結果
いうサポート系列
とーえー
持っキングを行ないそして未知語であった場合は
えー認識から三郎ベースの認識結果
とーえースポッティングを行ない
そしてえー
という結果を出力します
えこの際のサポートをレベルのもの新聞に基づく検索語のホテルですが
まずえー砂漠化の特徴量を提示し
主として連続ＤＰマッチングによるホテルを行ないます
えー
この海の側をどう体の特殊距離ですが
えー
まずＡさん程体の音響モデル
のえー一年の状態間の分布距離を
えー分布間距離えーこのような状態他のえー状態化の分布頭を一つ一一え実験マッチングを行なったと
って行ないえー砂漠化の特徴それを提示します
えーそして
でえー提示したいとくるこれをえー続いてるとしてもっとしえー連続ＤＰマッチング御承知の
えー
この際の文頭一つはえー一
ＨＭＭのえー出力分布間の分布間距離をえー三十するのですが
えー一般的にえー出力分布はえーこの別にえー幾つかのこの五成分からなるえー混合ガウス分布
になっていることがえー一般的です
えー混合ガウス分布間の分布間距離のえー
算出方法を色々提案されていますが
えーここでは
んーの混合数変化の二つですよ
をえーそれぞれ計算しその中の際一最小値を
で分布間てるとしてえー利用します
えー
えー
提案するアプローチとしましてえー
その後レベルの場合
って凄くではえー音響的なえー一つ一の関心を持ち
がえー音響モデル
んーとー
モデルを推定精度で三つある程度問題に対して
で我々はえー連続ＤＰマッチングにうえー抽出したえー方法区間をそこを取ると
えー状態単位の
えー系列に変換する
て状態レベルの詳細のスコア付けを行なう
えー更にえー分布間距離を元にして拡張した分布間距離ベクトルというものをえーもう一つ一でそれもこう作るっていう尺度を導入します
従来法と提案手法を比較してみますと
従来法をえサーバーとレベルのマッチングですのでえー計算量はですねですだから一個程度のその
それに対してえー提案手法は
えーサブ音レベル音を大切にえー起こしますので
えー詳細な服を付けをが二つの言葉で言いますがえー計算量が多いという問題があります
そこでえー計算量を抑えつつ精度も高いスコアを付け行ないたい
ということで
一発目でえーまずえ従来手法による方法絞り込み
そして日本常で
えー状態全てのえーマッチング行ないえー
こうリスコアリングを行なうという
一つの手法を適用します
二度提案するえー日本すえー七二システムのこういうお気に入ります
んまず一発目はえーですがシステムと同様になっておりえー
検索語の差分を取るとえそして検索対象のデーターベースの中のそのボール別の
連続ＤＰマッチングを行ないそして高校を出力します
一個の際には
えー砂漠化が付いてると一つ前に
えー
計算しておきえー検索時の
えー
計算量削減するということを行なっています
一つ目ですがこれはえーボールのおー提案法による詳細な付く訳です
一モデルえー検索語の
とーえー
えーそしてえー一一と二名で得られたこう区間
えーそれぞれの
のえサーバーを取ってるえー対応するＨＭＭ状態てると
えー
状態系列の指示のマッチングを行ない
そして
後はえー
えー
一月の
そしてえーもう一つ分布関する数によるえースコア計算を行ない
もう一つの不幸を
えー三つ下
そして二つの不幸って結合し最終的な面とそれのスコアとしえ
えっとその結果を元にえーけん結果をするかと
えー計算量の削減を行ない
えーこの提案手法のえー詳細な付く訳ですが
持つえー
一つ
二つのえーすことを行ない
一つ目は分布間距離をすると一え状態ですのでいいマッチング
でこれこれによってえー評価タイムって気持ちもえー一一一二個を算出することで
元はえーこちらでえー
状態系列の長さをえーん
この二の誤差に正規化する必要がないのですがえーその際えー
このＧ気持ちによってアラインメントを行なうことができます
んえー同時にえー
状態系列の
って政治家もこの言葉では
そしてもう一つ目のえーそこである分布間来る時に基づくです強くて
では
こちらのアラインメント結果
このえー文化をすると
えー
母音列をそれぞれえ算出しその二つの
えー系列から一類似のスコアえー
を単位とします
その際のえーこちらのえー
ものがえー
一具体的には後程説明しますがこれは分布間プリテストとなっておりこのように状態系列に沿ってえー並べたもの
止まっています
ではその分布間距離ベクトルとはないかと言いますと
言ってます先程を提示し多分被るっていうのはＨＭＭのある状態に対して一と一の定義を直接評価をしていました
それに対して分布間距離ベクトルは
である状態とでその間えー具体的には前音節ってん状態の
その距離
これをえー
この
間の距離を
四要素としたえーとベクトルの通りえこれにより特徴を想定しています
んー二
これこの目的はえー構造的な特徴の一音によってエージェントと精度を走行中の変動の要因に対す対する
えー観点性
あのー
で目的としています
んー
このえーっと一とかを取り
ベクトル
んー用いてえースコア付けをこの間にはえー我々はえー三つの式を
でそこを算出式を提示しました
まず一つ目は
えースコアって言いＭという項目数っていうものです
これはえー分頭内のえー言語それぞれえー三四つ四
そして二系列でその中の最大値を取る
それをスコアとするものです
んー
このおーう
式のえー目的としますとえー一つ重要性を強調する
ということが挙げられます
すると他の二つのえースコアのえー知識ベースだっ
もう一つ目
後はえー
えー
ん各ベクトル間で
えー普通の論を取るそしてえー時系列をてるしてするって音楽
つまりえー一九移動距離をするそしてそれをえー分析していく
というものです
えー
えーそしてもう一つはえー
同様にえー分布間で取るかっていうものの本に
そして二系列でおで分析していくって思う
っていう
以上のえー三つのうちいずれかで
えーんー使ってて
でフレームと過ごすことを行ない
えー一つ目の
とても際に利用します
えーっと先程えー一応大体のＧＰマッチングによるえースコアをもう三されそしてえー分割数に基づく
後はもう生産されると言いましたが
えーこの二つのこうえーっと爪の
で最終的な行動としてえー二つの不幸を結合して最終的なあースコアとして用います
概念としましては
えー
えー状態系列
の間はもうえー一回頭を考慮したえＧＰの後によるえースコア
そしてえー
ある状態とその他のえーっと具体えー多くの状態系列
えー多くの状態
んえーっと情報を持った
えー分布頭
ベクトルによるえー
後
えー
んー
一がこちらとなりえーそれぞれの不幸立ち直ってえー日本爪の最終的な今年の
えー
んー
のえー実験条件に入ります
検索対象ですがえー日本語話し言葉コーパス
えーし一つ前のこう講演データーを用います
音声認識結果はえー調べるネットワークんの反映された単語ですと文節列の二種類のリファレンスに結果を
一ベストを用います
この認識結果のえー性能はえーこのようになってます
なおえー我々はえー
んー既知語の
うーん既知語も検査語に対してはえー単語列のえー
認識結果を用いえー未知語の
っていう検査語の場合には音節ですの
認識結果を用います
続いてえー検索語ですがえー伝えるな多くの複合タスクの方もあるんで用いられたっぷり五十語を用います
んそして分布間距離のえー三つの際に利用し
するえー音響モデルは
八十コーパスのえーこの公園の得点講演データー
こう適応しそしてリファレンス認識結果を求める際のモデル学習と
この二条件で学習し作成しました
二つ上に一からえーその認識ではえートライホンのＨＭＭを
え用いていましたがえー我々はえー音節
平成六
を用います
えー
詳しい資料はこちらの方になっており
えー三十二混合のえー
三十
発電
一のえーＨＭＭで音節ＨＭＭを用います
評価指標ですがえーリコールプリシジョン
えうちえ
結構生成してえーリコールが
えー
ってこうプリシジョン曲線
そしてのえーこれらの
評価指標を用います
主にこのＦ値を
もう目にしてえー評価行ってきます
ではまず一ぐらいのおー
もう一か月
えー従来法えここでいうえ従来方法はえー
提案手法の本こそ年の三つまで連続的にマッチ
文のえー結果となって
これは音節レベルのちょっと表象しても
それに対して提案手法はえー分割手法を用いており
状態での食料理をし
そして分布間ベクトルを用いた貢献行なって
んー
えこちらを見ていただけると分かりますがえー
提案手法はえー
従来法に比べてえー
ポケット改善していることが分かります
そしてえー×手法を用いた音の有効性としてえー
検索時間
をえー比較してみますと
えー
一発目の三と別にどうすれ
まで含めた
減って四手法でこれを比較してみますとえー五分かあの検索時間
でえー
ですがえー検索精度がえーこれだけ大きく向上しておりますので
えー我々のえーとす手法加え一有効にえー行なわれたということが分かりました
えー
二
ここではえー分布間距離ベクトル
でうを用いたすとても歳はえー
終わっている自由になってる項目数を使用してました
えー
え先程えー
この
この検査音は三つの式をえー提示しました
そこでえーこの三つの式の
えー
とーそれぞれで
比較をしては
えー提示した式があー
定義したスコアをえーこの三つです
まず一つ目はえー四分以上性を強調した後
そして二つ目はえーゆっくりと定義を用いた
えー
用いて分析したこう
そして
もう一つうー三つ目が得る言語
文節一個
えーこの三つです
一つ前においてもえベースライン
えー上位性能を示してる言葉を彼は
そしてそれぞれで見てみるとえー
後はＤ次元のえー部分も口においてえー最も用例Ｆ値を示しました
このこところへ分布変わってると思っ一タスクをずっとこのおー実はえー一つ重要性を強調したものを
自宅木したもの方が
えー最も良い性能を示すということが分かりました
続いてえースコア結合文の一生を調べます
一つ目の二項ではえーと
状態単位のじ今自分より求めたスコアと
分布間距離ベクトルをえー用いて
算出した後
この二つをえー結合重み
掛けて
そして足し合わせたもの最終的に五つ目の
こうそしてもう一点は
えー
そこでこの
重みを
いう変化ファースト歳の
えーＦ値の影響をえー見て
まずえー
四五えー提案手法の
自分中央のえー含めたえーこっちも他をが
歳の
評価結果とえー一つなのみたいな
って思ううーどちらか文書
法を用いた場合えーつまり
一重みが〇もしくは一えーこちらのポイントにおいてもえー
従来法の一発目の別のものでえー提案法の方が一一点お示してる言葉を
っていうんここらも
えー
従来法えーつまりえー
んー
サブワード体のマッチングを行なう方法よりも
えー
提案手法であるえー
状態単位のマッチングをこの他えー視点はいいということが分かります
えー
あーそしてえ既知語をえーっとー未知語をそれぞれえー重みの影響を見てみますと
自分の身はあまりえー重みに影響がある影響はえーないということが分かりました
そして三自分を見てみますと重みを変化させることで
んー
検索の性能を上げることができました
このことからえー
状態単位後一気持ちのスコアと母に含むグループを用いたでスコアこの二つを利用することが有効である
といったことが分かりました
続いてえー分布間距離を算出する際のＨＭＭの出力分布の混合数次元数を変えた時の影響をみたいな
まず三十六時えーっとー三十八二を見てみますと
えー実験を書いたことによってもではあまり表は
声をよ
でえー今日はないっていうことが起こりました
って本当はえー混合数
交通ルールで見てみますとで本来はえー音声認識
えー結果のえー認識精度
とーえーこういった対応
隠して
えー考察して見るのが
あのかもしれませんが今回はそのデーターが
えー
むしろことはできなかったのでです
えーあくまでえー推測でしかないですがえー
えー一．一混合のあのー一Ｍを用いたえー認識はえー
その他の
っていう混合するえー
一認識性能をえー劣ると思われますが
閉店してえ今回のえー検索に用いた場合テスト
することさを少なく
打ち込ん五においても
えー有効であるということが言えます
ではえーまとめに入ります
って我々はえー実はどう単位のマッチングに基づくえーステージの為の
恋人をサポートですから
うー自動評価のえー改善手法を提案しましたここでは音響モデルのえー状態レベルの一っていうの全部
行ないえそして分布間距離ベクトルを特徴量とした
えー状態間距離尺度の導入を行ないました
そして音節でえーと状態レベルのえっとする手法に乗って
えー計算量の動向の特性を行ないました
今後の課題ですがえー今回は思い計算量の削減といったことあまり考えずにやっていましたので
えー今後はえー高速なんで新手法を工夫をすることによる
えー計算量の削減を取りたいと思います
えー
元建設この閾値の自動推定も挙げられます
後ここには記していないですがえー複数の認識結果を
えー利用したえー
計画っつうのも今後の課題として
行なっていたいと思います
以上で
発表終わります
#############################


#############################
# query = 時面と中の大きく影響え強調発話の検出にあのーちょうど去年そちらの強調発話の原子数をえーどのようなアルゴリズムを使って実装しました
# rank = 2
# slide = 11-10_fix.match_word.jout.txt
# value = -2.80764712681705
#############################
えーそれではえー画像の曲線先生基づく音声中の検索件数というのはどういう風いたという題目で
えー入力でえうー第二世紀は発表させていただきます
えー聞けないっていうのですがもうつ先程あえー発表された
病院は二つ多くの頭子音のはいである
少し発話え続いておりますが
後はもうえー
構文あえー検査を禁止する
はえー音声認識率数により音声をテキスト化する方法はえー自分もそのーおーえー用いています
でこの方法はえー問題点として
音声認識誤りがあるとえーまー三十分
テキスト型の検出だけでは難しい
という意見が
あまりあります
えー先行緊急の
えー一つうー
んー先行研究のベースはしえー
画像中の非線形性
基づくえ点数を検出っていうのはありまして
さてえー
さてえー検索語
ある語に音声認識結果を置き
各方式ってにえー音節間のてるようなことで
その重要文だと思う見ると
このような画像が現われ
結合は現われる一二曲線が現われるので
音声中の検索現実問題をえー雑音喫煙率問題に迎えることができます
しかしこの手法二の問題がありまして
えーこのようなうちの誤りに対してはこの問題にはならないのですが
んえー削除誤りえー八挿入誤りがあると問題になってっつうぐらい泳い
あるとこのように進ん船が途中でえ途切れてしまうので
直線鉄は非常に難しいという
ことになってしまいます
それは〇の場合は音節がえー
えー連れてしまいます
そこでえー提案手法のベースは
んえー調整検出だけではする誤りや
すえー挿入誤りは対応できないので
え直前検出を行なう場合に
画像に対してフィルタリングを行なうことで
えー先誤りや挿入誤りに対応している方思います
えーまずこの直線上するデーター
っていうものですが
これはえーすであまり家そうにあえー
で後対応する為のものです
音圧の
ま色合いの
がその中で
最も黒い三つの活動の平均をおー中心がそのー
方に置き換えます
これをすると
声
しえー検出自体中世の部分
があるのですが
デザインを掛けることによってえー
えー
え直線バック六現われる音
えーこれえ直線が緊張して使われます
私まーこのようなところに
想像図二の二音が現われる雌は
まーそのようなえー
雑音が
ま二つの起点となる言える
ことはあります
後えー雑音
後はえー誤認識しその言葉あるいは
そこで
雑音中で事例データーというものを書いてます
まずえー先程のような雑音
前の
雑音をを重視するものです
この図の
回路の範囲の数がそのー中間一応
おー中心のそののによっ買えるもので
で
コンピューターを直線九十三等を掛ける前に行ないます
そうすることによって
これでえーまー
少ない
えー
そのー
少女時代部分だけが
強調されて
えーその部分が付く
なることで
えー
貢献する
で
えーここにあります
えー実際の直線検出法について説明します
がそのー例えばえーと総数を
気そういっで
旅行の
何か総数をえー九
します
でこの音節間の距離を
試合中六と
えー
んー
直線状も各
何かその
五の合計値を
連接種類としてち事例時は
そっち事例を
えー
えー
縦の
えー
検査語長のす
夏は
で
持った第四
えー平均累積値よりえ見て
と思っています
えー
これをえー閾値
あり方
に掛けて後は未満なら
で
えー検索を終わるとして
それ以外から結合は
バイトをします
で
えー
薬があるをえー
検索システムのアルゴリズムですが入力としてえー係数は
入っていた時に
音声認識結果の一発話文をす
えー検索行動は
組み合わせて
それがどうを作成します
その部分に対して
そして検出を行ない
えー接合なければ
雑音推定値データーと喫煙という結果を掛けた上で
もう一度えー
直線幻想を行ないます
えー
自然が
あるいは
これをする集合の方はえー
これをえー
全発話文
繰り返して
そのー
えー
方でえーし
今回用いたサブワード大会のえー
音節音節音は面しているのですがすえー
この音節頭を求める為に
です感じ量を求めます
まー
さて大きさを感じるようを二例ですと二十四名のですが
えー音節を
支援と思いに分割し
それぞれの
スポーツ界データー対二で割った値をまー
を続けているとするのですが
一え数ではえー考察関係で
ＣＢはえー
もう疲れてるに
なります
でこのＣはす
支援に語っており
二四五母音になります
まーやえーのそのー
えー
一音素からなる
えー実は
それと後えー
を同じ音声として扱います
でそれを求める為の
を支えてるのもそういうえーことですが
ホテル尺度として
各
音素ＨＭＭの私割合という
利用を用います
えーこれで今回用いたのはまー
まこういうえー今回用いたＨＭＭは
中高校モノホンの男性用の音響モデルを用いました
うん
えー
この式があー考察できるのですが
二番という通話ともかく
音素のえー特徴ベクトルのえー五人で
えー四分も悪くも通話えー
計算機をもう三四五に当たります
えー
この三時
んーこう
用いいるのですが
政治家はしないと思うしいうことはできないんで
えー
後
後用いいうことで正規化します
でこの式
〇一そのーデーターっていう値をし
えー
この正規化をする際の
小説での係数
で今回は
二．七おー
っていう値を用いました
で
実際の実験なんですが
今回はえー
ステージ用テストコレクション
を用いて
えー
えー検索対象として
ＣＳＪのおーえーペットのな一の方へ九
四十時間の
音声認識結果
を用いました
これはえー
単語トライグラム
そうですがえー用いたものを用いました
検査語は
そのー講演の
この講演をあの自分を五十検索行動
えーっと既知語五十検索語を用いました
えー
未知語を実験なんですが先程説明した
直線件数も
えー
閾値α
一の値を
えーこのように
〇から八十もえー
んえーとコストは
結果をおーしています
えー
直線上昇
により
えー
戦場助詞の言葉に比べえーす
ま全体に再現率えー向上してるのですが
えー
えー
で
適合率は
えー
小さな市に比べると
えー
生活しているということを分かっています
えー
雑音適応
をすることによって
ほぼ同等をえー一つえー上昇しするしただけの結果とほぼ同等の
失敗に二つを得られたあー得られ
かつえー
四五六というのを
で最後に終わってきました
えーこちら自分を評価結果の比較んですが
えー未知語をえー
二十一ドル
あのー
えー音声
認識誤りであり幸いモダリティーを
えー検出したあー完全一というえー結果がこれで分かるんですが分かんないし
材料を取ると
未知語は殆ど再現率は得られない
結果を終わっています
えー
従来法の一つはえー二
の結果とおー
このショートセンテンス
えー朝鮮検出法
のおー比較すると
採用人数
まほぼ同等でＸ
適合率はえー
向上しております
これは連続ＤＰの一つえー僕は
えー
編集行けるのは〇一
の検索用になのに対して
直線上にそのー
給食後は
えー〇から百五十語の音節数〇っていうことを
がによる効果だと
考えております
えー
次に
ま直線でそのフィルターなし
とー
今回提案した直線状子音プラスうー雑音推定した結果のＳは
あのー
朝四歳にする
ま高齢者ですが
えー
考え後
それで自立を比べるともうどうこうはですが
喫煙所でしょうというでした与えられると低下した結果と思っています
えーんそこで
んー
利用率の低下を調査しました
んえー児童は滞在して
そうですね傾向を調査すると
検索音声す短いで最後に
誤検出が多いことが起こりました
検索を町に悪いえーことが閾値を用いて実験を
ええ思いました
えー具体的には
検索音声よって
三つのグループ二分割しました
録音一つ三万
そのー
六音節以上二音節にまー
後音節以上
それぞれ
ここら閾値を用いました
えー
こちらはえー検索音声
子供結果をベースは
こう左母の実家はえー閾値を
固定した
後は言いまして
えー右側の結果は
して位置を変更して
で口が最も高い値を夫は
えー
式えー中では最も
ある私ちょっと確か五分
え七頭の場合だと
おー六本ずつでもあのー実家を
あのー
使用率
があー低い
でえー音素数はえーなっており
えー
閾値変更はして位置を変更すると
えー
四十八五えーっとある文数は
まーえー
再現するか
非常に低い結果と場所の
まー六音節以上二十二音節三四はま閾値もう殆ど変わらない
というのもあるんですがほぼ同等を持つ一方という
私音節以上に関しては
これは
最近ＡＩＤＳが
向上しました
でえー子音の結果を
見たところ
再現率は
ほぼ同等で
四十八率は向上しました
それはあー一言も
えー評語で言ったのですが
既知語の場合は
考えし
えー実は
場合でも
えー
えー課題と大体一日
と適合率を得られて
まず
連続ＤＰをおー
た場合えー
えー
えして利用
用いてる中でも
重要視した場合えー適合率が著しく伝わってしまうもんで
まー
考えると
後まーくえー間に一地域は一二は最も高い値にあるという
で月様は
えこの結果を載せました
えー
えーただし
の場合と
えーと
終戦余剰
発音する
のえー結果
送られるとまー未知語の
私と比べるとし
改善率は用いたようですが
さいえー実は
相当で
適合率は向上する
しました
えーまとめです
今回
えーどのえ直線で二つに基づくえーえその検査
性能向上させる為に
二そういうフィルターのしん
水を行ないました
えー
まー実験結果なんですが未知語セットに関しては
すフィルター処理により際にえ実は
向上しましたが
適合率は
といたしました
そこで
え検索音声
によって行なわ閾値を用い一ここで
歳リゾートそれともう一つ的効率をえーえ二三から
〇．八に向上させることができました
え七五セットに
関しては
まー
未知語と同じ手法を用いいうことです
えー未知語程ではないのですが歳二つ多いという強く適合率の例二十三から
〇．八の二
向上して
する言葉が出てきました
今後の課題といたしましては
えー短い
て最後に
感じで
まー未知語大きくはあまり落ちて分かったので
えー
短い結合に関してはえこの手法を組み合わせ一つの
考えようかと思っております
以上で発表をおります
#############################


#############################
# query = 位置情報を使ったえー教師協調発話のケースそので非常音とリコールはどのぐらいの値になりましたと
# rank = 1
# slide = 10-13_fix.match_word.jout.txt
# value = -3.70341188859116
#############################
はいそれでは複数音声認識システムに基づいた音声中の検索を検出方法の検討と
えー一つ一テストコレクションで三評価という目的山梨大学のなそれが発表させていただきます
えまず本研究の背景と目的ですがまー×先生の方からも言われたようにＡＢＣＤの重要というものがあります
んー
でそれに対して幾つか問題点がありましてそれにです方法がま色んな方面から
えー検討されています
で本研究では
えー複数の温泉にシステムを利用して
まーこの形式いーの性能を改善させていこう
という風に
えー
な
形でえ研究を進めております
え本研究のえ次のタスクについて簡単に説明します
え本研究ではえーとまー
音声データーに対してえ複数の音声認識システムによって音声認識を行ないます
えその結果に基づいて
まー携帯の違う
異なる
インデックスを二種類構築しておきます
でこれらのインデックスに対しましてえーと検索語をテキストベースで
与えられます
でまそれぞれの携帯にがえーとそれぞれのインデックスの形態にありました
形式でえ検索を行ない結果として強くする
まこういった感じのタスクになっておりますんー
んー
んー
はいで今回報告させていただくよう点について説明します
それでまず本研究では複数の音声認識システムを利用しております
で実際にこの認識シス二えーと複数使うことがどれだけ
効果的であるかそれを
まー音声認識率で
評価したところ高い認識性能が得られたうん
んー
でま得られましたんでえーっとこれらを使って検索用のインデックスをんといったものが良いかというのを検討しました
でこれらのインデックスかなんまーどういった方法でんー検索すればいいかってことを検討し
えー実際に
ＣＳＪのテストコレクション似て
京成の語彙を評価しました
で結果から見てみます
後二三四五六んに対して大変有効であることが確認されました
ま有効であると言いましても
イコールにおいてま評価になります
ま特にコンピューターネットワークを利用したインデックスエにおいて
まリコール八十パーセントん
これは未知語に対して八十パーセント気分なりますが
これだけの性能が得られましたんー
でまずえー複数の音声認識システムの
概要について説明します
て本研究ではえーっとデコーダーにＪｕｌｉｕｓを利用して
えー各モデルを変えることによって複数の音声認識システムを用意しました
で本研究では言語モデルを五種類え音響モデルは二種類
って組み合わせによって
芸術通りの音声認識システムを用意しました
でえー言語モデルの説明をしますが
え一番多いのかな感じ単位の単語単位
んー仮名漢字単語単位のトライグラムモデル
これは一般的な音声認識で疲れてるような
えー言語モデルになります
で続きまして平仮名の単語単位のトライグラムモデル
これはえー意味的いただいたように全ての単語というものが
えー平仮名で表記されたん
言語モデルになります
んで過ぎまして平仮名文字単位のあのーんまー平仮名文字単位の
えーっとトライグラムモデルです
まこれはんー
本当九例に示したりお二十一文字単位でえー構築された言語モデルになります
二
で次が
えー平仮名二文字単位のトライグラムモデルを
これが
まうえと何が違うかと言いますと
そのー単語単位一よりも短く万一文字文字単位よりは長いという
こういった形の言語モデルになっていますん
っすね最後にこの学習なしといったモデル四しましてこれはＪｕｌｉｕｓを利用して
えー疑似的に連続音素音節認識を行なっ為に用意したものですえー
で音響モデルには
えモーラ
第二のモデルと後それのタイプのモデルこの二種類を用意しております
でこれらのモデルなんですが全て
えシステム幸以外の公園から学習を行なっています
で実際にえーと音声認識性能がどの程度改善されたか
ということを示しますん
えーっとー
えー音声認識対象のおー
三
調査対象の音声ですがＣＳＪのこの講演音声によって
調査を行ないました
えちなみにこの単語んーこの音声に対する単語レベルの認識率が
えコレクトで七十六．六八パーセント明Ｃが七十一．九三パーセントというするのなってます
でこれに対しましてえー複数の音声認識モデルの結果音節レベルで評価しました
んで
えー音節に比率がこちらに示すようなっております
んで一番左からえーっとま一種類
音声認識システムに要しましたんでその間ワンベスト出力で最も良いものを
で青いものがんえーっとその二種類の権利とし六で
最も良いもの
えー
であ多いねでその為白いものですが
これが一種類のワンベストの出力を組み合わせた時のえー認識率になってます
んでえー印象に残るものですがこれ一種類の点ですし力を組み合わせたもの
になってます
でまーえーとーん認識結果が増えるに従ってえーリコールは改善されてまた手順は
したがっていくっていうような傾向が見えましたが
えっと同じこうす認識結果の構想ですね
こういうとテンベストと
一二種類の音ですとまこれ両方共一個の
出力をんーによって評価行なうんですが
それを比較しますとリコールだと大体こうパーセント以上んの
差が出てくると
えー
っていう言葉にありました
まーこれからんーこの結果から言いますと音節の生活が向上しましたので
す何の気はどの
見つけられる可能性というものが高くなります
ただしこちら二十二えーとあ嫌いじゃ何を示しておりますように大量の挿入誤りが発生しております
その為えー多くの湧き出し誤り検出が発生する可能性というのが
出てきます
えー
んで
で次続きましてえーっと音ですＣＤをもうインデックスを構築しました
え本研究ではこのインデックスが六種類用意してあります
でえー構築したインデックスはこちらに示すようになっていきますが
えっとーんまー
このインデックスというものが
サブインデックスというものから構成されております
ええー検索インデックスというのなんですがこれを単一の認識結果からあえーっと生成されます
で
えっとまー警察に音というものは
んーまー異なるインデックスという形態になっておりまして
えー
えーとんー
評価ですがえーでそれんーえっとそのこれらのインデックスからの評価ですが
次いずれかのサブインデックスで検索を検出された場合にえまー
評価を行なう
えーとこと
一そのインデックスの中でまーそのインデックスって幾つかあるんですが
は寒いんで複数
んー
の
二か所元に二つのサブインデックスで同じいー場所を建設驚いか所という形で評価を行ないます
んでまー
それぞれが特にえサブインデックスなんですがこちらに示すような
形になってますんえー
んー
それで多分インデックスのコースでえー
こう説明します
でこのワード形式えーっと本というものですが
後えーっと現地でというものですが
これはえー認識結果をその用いたインデックスになっております
えそれぞれの形態ですがはどうも二列レベル
えー資料は音節レベルのインデックスなっておりますん
んで検診ｎとえＣのんーですがこれは
えーっとそれぞれ二十個の音節へえー認識結果を根底じょネットワーク化したものになります
でこれメーンの違いですがえーっと
でんＣＭの方は
次にえーとん
点ですと後強く単一の認識システムのテンベスト出力を
それでこういうじょネットワーク化した者
まそれが認識システムの数だけある
水の中に対してっていうのは
えー
えと
ん一種類の認識システムのワンベスト出力を
五ページのネットワーク化したものって形になります
ってま高齢者ネットワークとえ子音のイメージですか
ま一般的なこういう点ですがネットワークのような形にこういった形になってます
でこの拍に入っている情報ですが今回は音節と
えーっとその音節を認識された
んえー音声認識のシステムの種類って思わ格納されております
えー
で決していいものを構築例を示しますとんー
えこれは音声データーはコサインθという音声を入力してあるんですが
えーと一種類の音声認識システムで認識させその出力を
えもうＤＰマッチング利用したマルチプロアラインメントを取った結果
まここのテーブルに示すような形になります
でこの得られたてるからんー
この一つの列を得たとして登録していく
で最終的なえーっと検索用のインデックスが構築されると
こういったイメージなります
っていうえーっとー天津ぬの方の購入じょネットワークですが
ここの認識の分布認識されたシステムの部分というものが
三十二番ですとかラテンですまでえーんという形になります
えー
えーって続きましてこれは
インデックスを用意しましたので
これらからのえー検索方法もう
何と言ってもないかんーちょうど
えー検討しました
てまずいようが検査語ですが一般的に用いられるってが一番最初にこの一が出るのが完全一致というものになります
またえーっとーこれをワードスポッティングと同じような形になるんですがえーっとんん
ファンのレベルでは単純な文字でしてえーここのコサインというもの見つけてくる
えーと音節レベルのインデックス彼は音声スケール指標間完全身に付けてくる
次にと終わったらば
えーっとんー初め方から見ていって残さ
時ケンネル全員でいい
んで寝る前一分というこういう経路を見つけて
えーっと検索を行なっん
といった方向になります
ですが完全一ですとやはりえーと探索の限界というものが存在しますこれはこの九十ネットワークの例なのですが
実際にここと言う人という
えー音節ケースが存在するんですかここに
それ全員がなくんー
まーうまく検索が行なえないといったパターンが存在しますと
うんえーとー単純なえーっと認識結果においてもここに特に我々が存在して検査を行ないないといったパターンは当たります
でこれらに対しましてえー本研究では
キーワードの音節ケースでのミスマッチを許容する
といった方法を取ります
で
え実際どういったミスマッチにどういうおえーっと音のレベルのミスマッチを共有するかと言いますと
音節という音に対して一つだけ二つとし訳です
といった方法を取りましたんー
でここにいるミスマッチですがえこの挿入誤り以外にも時間八月の約誤りに対応しております
んでえーまー
認識誤りに対応することによってえーと一二つを一つえー
時代は
一良くなるのですが
大量の湧き出し誤りが発生してしまいます
ってゲストに対しまして
抑制をする人があります
で今回はえーっとんーこの九十二つは考慮した韻律ＳＤｎに対しましてこの
フィルターをを構築しそれをん
えーとそれによって検索を行なってみました
で
パラメーター
えっと湧き出し誤りよく西洋のえー
パラメーターとしましてはえＣの探索パラメーターと利用しましたんー
で
このパラメーターですが
全ての段差経路における認識したシステムの数というものと
パスを認識したシステムの数による信頼度というものを
えーっとこれ以外のデーターから学習しまして学習と言うか調査しまして
設定をし
えーコンピューターを構築しました
え実際に構築したけれどですが
一持た先画像の
えーっと清潔市内の掃除を平均というものが既知語の場合は〇気にするか
二．三四五年
の場合に破れて人を以下というものを調査
設定しました
また
えー全ての探索経路において認識したシステムの一つの場合は
でえーっとんーでえーっとー
の族といった
えーこれを担当に
三度で設定した
フィルタリングになってます
でこのパラメーターですが
えー調査データーが講義音声だっ
から調査しましてせてしております
で実際にえ推理の戦後おー比較してみましたその条件を示しますが
えーっとーんんー一
ま最小も
音声データーは終止形のこの講演をしてこれは木は全然大手の使われたデーターと同じになります
んで県先程セットのをえーどういうものになります
んで内訳ですが
えー未知検索語が二十八種類で
音声中には八十九か所
で記事検索語が五十種類で七百六十九か所となっております
でえっとーこのテストコレクション設計時には本来この未知検索をわもう一種類だったんですが
えーとー言語モデルが変更になった
入ってそこれ子音設計する他の言語モデルが変更になりましたので
えー
んー
まこのテストコレクション一に既知語が
派生するなってしまいました
でそこから完全なる未知語を抜き出したところ二十八九月になっておりますのでこれを用いて評価を行なっております
え評価尺度としましてはリコールとプリシジョン後Ｆ値
またえーっとにその法で評価尺度で地域の評価尺度として利用されております
敵ＷＶというものを用いました
で本研究では特に五分五えーと道検索語と
イコール人
よって評価を行なっ
えーを検索時間についてはあんまり考えたとかは行って
えー検索時間に対しました評価を行なっておりません
で検索用のインデックスと検索方法の組み合わせですが
え表に示すような形になっております
えー
えー
んー
一え実際にこの点知る音節レベルのインデックスからえー三四十五検索した場合の結果がこちらに示すようになっております
でリコールがんーこのような形になっておりまして
え完全まーんー
二つえー完全一致でもえ
え誤りを見達を共有する場合においても
そのインデックスの数が増えれば増える程
つまりこれは増えていくその傾向が見られました
一んで変動完全一致による検索ですと
一つもリコール以外のプリシジョン訳地域Ｗ部において同じような結構
二分インデックスの数が増えれば増える程検索性能も良くなるそういった傾向が見られました
結果あえーと四分の一
後四音節に対していただきミスマッチを
いう必要な場合ですと
え二値が高くなるんですけどそれ以外の性能があまり良くないんー
サブ韻律の数は増える程
まちょっと悪くなってくるといった傾向が見られましたん
んーに続きましコンピューターネットワーク形式のインデックスから検索した場合になります
．んでえーとリコールの比較ですがこちらに示すような形になりまして
一番左側えーとーん
本研究では一種類こんえーじょネットワーク要してますので
その一種類の中で最も良いもの
でその一首全部使った場合
んでえーっと本研究提案してきているＳＥＭ
その結果になります
テーマ
この天津だとえ七人の
破壊してかにちょっとイコール
変わってないのですが
えーミスマッチを許容することによってだいぶ差が出るようになってきました
まこのことから複数の異なる
携帯の認識システム特に痩せることでえー木構造を棒に改善するということが示されるかと思います
えー
ただえーとーリコール以外のおー評価んー尺度で見てみますと
ちょっと一二年のま悪い部分があるかなと
えー
またえーっとミスマッチ分けをする場合ととーそれがもっと顕著に出てきてしまっている
いうことがありません
んでえー結局未知語に対象といった倫理太いかということですが
ま完全一致におけるんー検索ですとあのーそのインデックスの大して変わらない
んー
そのインデックス今使わえーっと単純な音声認識結果から構築したインデックス
本節レベルのインデックスと
パソコンいうじょネットワーク化したものまたえ心理では
私変わらないん
ですか
えーと誤り
認識合間に対応することで
ま一犬というものはこれだけに考慮が他のに比べて上がっている
とこのことからもう
ま複数の
認識辞書の結果を組み合わせるっていうのが
にこれ改善には
効果がある
父が示されます
で他の性能に関し道もいみますとやはり
んー
ま一犬というものはちょっと悪いかなという観点があります
えこれは大量の湧き出し誤り件数が汗している為
っていうことになってます
んで閾値五に対しての結果があのちょっとグラフが多くて申し訳ないんでそこのような形になってます
でリコールに関し見ますと一個のこういうじょネットワーク考慮したインデックスというものが
一番
よくなっております
ただやはり
湧き出し誤りを履いてるあのーん
為に
えー出て支援の方はんあまりよく寝ていた結果が
ありました
縁高例題を考慮しますとま単純な
えー音節レベルでのインデックスが効果的なのではないか
という結果が選びましたんー
でえーま道分だ修正の有効ということがあー
示されましたので
フィルターを適用した結果
ってものをこちらに示します
でまー見ていただくと分かるんですがフィルターの効果というのは殆どなかった
という結果になっております
んー
でこの原因としましてはこのフィルターに設定したでえーとパラメーターというのが
えＣＳＪのこの講演音声んじゃＣＳＪの音声のではない講義音声から設定した者と
その為
だと考えられて考えられます
えでまー実験結果をまとめますと
まこちらリコールにおけるんまとめなんですが
えー
まー
未知語に対してはこねるネットワークをそのー二インデックスが効果的ま特にえ四の四個
で閾値五後はえ音節認識結果ですのインデックスが有効かと言う
ありましたんー
ですがいずれにしてもえーっと大量の湧き出し誤りが発生しているのでこれを抑制する必要があります
言ってまとめさせていただきますと
え今回はえー整理タスクにおいて複数の音声認識システムを利用するんことのメリット手が有効かどうかということを調査しました
傾向が六種類のインデックスによって知りの性能比較しまして
んー
あー結果から見ますと聞見し検索語にかかわらず複数の音声認識システム要するということは
え成人有効であることが示されました
で今後の課題としましては
あのー
今回は単純な検索用のインデックスを用意しています
しかもでえーと処理時間やメモリー使用量といった思い最高量としていません
そのでも統計折々検索用のインデックスを構築するん市場があります
ところ不要な部分の調査であったり
まー性能改善の為にＪｕｌｉｕｓのコンピューターネットワークの出力を統合する
後は
精神の点ベースを構築してリコールざるに上げるそういった方法が考え
あのーそういった方法を今現在検討しています
で更に
えーっとこれらのインデックスからの湧き出しを抑制する
パラメーターんー
というものを調査していき
えーっと検索方法自体も改善していく必要があります
まこれはもう
ですとえーと
えー検索パラメーターを利用してす無音えー実は決定木といったもの
木の
柄をと考えています
さ更にえーっとんー
検索語に対しまして
え異なるインデックスを使用した方が
ですいーの性能が上がるということなので雨結合に対して
えーインデックスを検出の方法をどれが良いかということを判断する必要があります
でそれを判定する方法を検討していく必要が
あれっ
かと思いますえー
以上ですからそんな町
#############################


#############################
# query = 位置情報を使ったえー教師協調発話のケースそので非常音とリコールはどのぐらいの値になりましたと
# rank = 2
# slide = 13-02_fix.match_word.jout.txt
# value = -3.7875250837366
#############################
一えーそれでは音声中の検索を検出の為の音素遷移ネットワークのエントロピー先頭のＰ分析についてえ山梨大学大学院のプレーヤーが発表します
すえー本研究ではえー七八為のインデックスであるえー音素データーの値でえ九つのえー複雑さに着目しえそのエントロピーの分析を行ないましたでその結果とえーその日による検索どう改善の試みについてえー本日は述べます
えー
えまず初めに研究の背景です
えー近年えー記録媒体の進歩やえーネットワークにからの実より
で大量の音声や映像が保存利用可能となってきています
えーそれに伴いえーこれらのデーターからえー二のキーワードを含む発話ヤシの検索を
えー効率良く行ないたいという要求が高まってきました
えー音声認識結果をえ音声中の計算をベースのえー一般的な手法はえー音声チケットを利用した本がありますが
えー検索語がえー認識時間は後
えー未知語である場合や
えー認識性能が百五場合にはえー検出精度が低下してしまいます
えーすこの背景からえー音声中の検索を形成している性能の向上が必要となります
えー精度向上の為にえー我々は
えー音素遷移ネットワークＰＴＡの用いたえー七昭和提案してきました
えーこれはえー複数の音声認識するの実力を利用してえーネットワーク型のえーベースを構築し
えーＧＰを用いたえー音素単位での検索表一行なうものです
えーまたえーＴ２を構築する際に得られる情報を利用した
えー個別抑制したりする手法も提案してきました
えー更に
えーえー
音素数の三身近少ない検索語のえ国立を抑制する為に
えー検査語の音素それに基づいたえー探索パラメーターの調整を行ないました
えーこれによりえー高い検索精度を実現することができました
すえー今回はえー我々が提案したインデックスのえーＰＴＭのえーください着目し
えーそのエントロピーを分析しました
えーその分析結果をえー検索エンジンにえー適切に導入することで
えー合計数を抑制しえ更なる検索精度の向上目立つことは
で本研究の目的となります
えー今回の発表における報告予定です
えーまずえー前回のワークショップのおさらいとなりますが
えー一例を用いたえー国立抑制したりスキー手法について述べます
えー次に
えーＰＴＡのエントロピーを分析し
えーその分析結果を用いたえー合計得点手法について述べます
で最後にえー本手法はえーテストコレクションにより
で評価を行なっ
だことを述べます
えーこの図はえー本研究に四ページのタスクとなります
えーまずえーインデックスを構築する為にえー音声データーを
えー複数の音声認識システムに入力し
えーその出力をえー
えーです適用インデックスがＰＴＭで変換します
え次にえー計算表一を行なう為に
えー検索語をえー音素単位を検索語に変換し
で先程構築したＰＴＡからえー検索表一行なうことで
決していい結果が得られます
え今回はえーこのＰＴＡの
えーください着目してエントロピーを分析しました
え次にえー複数の音声認識システムの利用方法について
え本研究ではえー形態の異なるえーこの五種類の言語モデルと
えー二種類の音響モデルの組み合わせにより
えー二種類の音声認識実験を構築して今
えー言語モデルの内訳ですが
えーＷ３Ｃは
えー
形態素単位のトライグラムであり
えー仮名漢字交じりで構成されています
えＷにうちはえーＷ３Ｃ４えー全て平仮名で構成したものとなっています
でＣＢはえー文字単位のえー
父トライグラムでありえー全て平仮名で構成されています
えービールはえー五十境界のえートライグラムであり
音系列は全てにもそちらで構成されています
えー父はえー全てのモーラの出現確率が等しくなっており
えー疑似的にえー連続音素音節認識を実現しています
え音響モデルはえー音節百二十四力があるシラブルモデルと
えー音素四十三四からなるえートライホンモデルを使用しています
えー各モデルはえＣＳＪの強語彙外からえー学習を行なっています
えまたデコーダーにはえー事例暑い日上位四て言って三を使用しています
えーここ予備実験としてえー複数の音声認識システムの
えー音声認識率を調べました
えー実験対象の音声はえー四つ中の子は講演音声です
えー実験結果より
えー単一の
えー音声認識システムのえテンベスト出力をえー
組み合わせた結果よりも
えー複数あ二種類の音声認識システムのえーワンベスト出力を行なった結果の方が
えー音節正解率が高いとなることが分かりました
えーつまり
え単一の音声認識システムの出力より
ベクトルの音声認識システムの出力を組み合わせた方が
えー二のキーワード見つけられる可能性が高くなると言えます
んーんえーしかし
えー正解精度を見ると分かる通り
で大量の挿入誤りが発生していい為
えー多くの湧き出し誤りが発生する可能性が高くなっています
えー次にデーターが対立のえー構築方法についてです
えーまずえー例えば例ですがえーっと音声データーコサインという発話したデーターを
え複数の音声認識システムに入力すると
でその認識結果が得られます
でその次にこの認識結果をえー音素
音素列に変換し
えアラインメントを取ります
で最後にこのアラインメントが取られた
えーとこの列のえー悪として登録することで
ネットワークあ対立が構築されます
えーと若いＸの特徴として
並列い有意する後膜が存在します
平成五はえー能動とバスの検索ができる為
七十何幅広い検索が可能となります
で次にえーより洋裁を検索エンジンについてです
え本研究ではえー二三マッチにおける距離尺度に
えー編集距離を用いています
って編集距離はえー一の場合はえー遷移コストを〇
誤りの場合はえー置換脱落挿入にかかわらずえー全て一としたものです
えーこの図はえーＰＴＡからえ検索をコサインをえー定位し
数〇となっています
えーこの例ではえーコサインの形容え数はえー
ＰＴＡの枠中に含まれている為え一として採用していきますが
で次の枠にはえーっと〇が含まれていない為
えーここはルール遷移を使用してえー喉音はして検索を続けます
えー
えー最終的にえー
と薬がえーこのえー正解が含まれている為
で本研究ではえー水のコストを
えー一設定しているので
えーいインデックスとえー検索語の距離はえー〇．三となります
で最終的にこの距離は
んえー設定した閾値我々は検索語が提示されたと判断します
え次に貢献強くてえーパラメーターについてです
えー合計属性パラメーターはえーＰＣＡを構築する際に得られる情報をえー利用したものであり
て今回は二種類を用意しました
えー一つ目は五チームですえーボーリングはえ同じ音を認識していた音声認識システムの数を表わしており
えー多くの二二システムでえー認識されていることでそのその信頼度が高くなる可能性があります
えー二つ目はえー三つです
えー約一はえー二音化に存在する拍の数を表わしており
えー拍の数が少なくなる程えーそのノード間の認識結果の
え信頼度が高くなる可能性があります
えー合計属性パラメーターはえー二種類別の
で距離計算に
えー合計えパラメーターを加味することで適用されます
えー傍線部とえー後一共にえー一の場合の先行するにえー関することで
ま一致した音素がどの程度信頼できるかということはえー管理された用語を検索エンジンとなります
えー例えばえーコーチングのえー値がえーこのような通じなかったとすると
えー
左のノードあーこれ英語とかではえー
信頼度が低い為
えーコースとは違う設計され
ゼミのモデルの音ではえー信頼度が高い為えコストが低く設定されます
約一に関しても同様で
えー左のノードではえー八数が多い為えコストが高く設定され
えー三四では悪は少ない為えーコストが低く設定されます
でここでえー現状で二重性のえー評価する為の実験を行ないました
えー実験条件です
えー検索対象の音声データーには
えＣＳＪの子は講演音声を
えー検索語にはえーこの声を未知語テストセットとえーされないのです多くの情報も卵テストセットを用いました
えーこちらのテストセットはえー場合に応じてえー未知語と既知語に分割しています
って評価尺度にはえーリコールプリシジョン被ってるしまこう用いました
えー実験結果です
でまずはリコールプリシジョンカーブです
えー小学校四未知語テスト千
投資をした場合えー
編集処理のみの場合ではえーこのような顔となっていますが
えー合計属性でまーデーターを導入することでえー大幅に検索性能が向上してることが分かります
えー特にえーコーディングをえーアコーディング曰くいと組み合わせることによって
えー同じ有効類似した者はえープリシジョンが二十パーセント以上
改善してることが分かります
え次にえーされない方も何テストセットです
でこちらのえー二種類のみの場合はえーこのような結果となっていますが
えー合計属性パラメーターを導入することでえー改善し
えー検索性能が改善していること分かります
えしかし
でえー
でこれが七十パーセント前後ではえー編集距離が三の場合の方が
えー検索精度が高くなってしまっています
で次にえー舌をまーこの値についてです
えー後は講演音声テストセットはえーうちまー二共に
えー国え属性パラメーターを導入することでえー検索精度が大幅に改善しています
提示法をえー歳の方もま等のテストセットでは
テーマは改善していいもののえーピッチはえーボーリング単体以外の三ではえー検索精度は低下している
という結果となってしまいました
えーこれはえー一部の検査語において
えー
合計属性パラメーターの効果が薄く
えー
こくえー湧き出し誤りを四つ嫌だった為だと考えています
え以上のことから
英語専攻継続性パラメーターを導入することでえー検索精度が向上することは分かりました
えーまたえー以前より閾値を細かくすることにより
えーボディー部単体の方が検索精度が高くなっていることは分かりました
えー次にえーＰＴＡのエントロピー分析についてです
でまたエントロピーを算出方法です
え本研究ではえーピッチの二のノードからエントロピーをえーコーディングエントロピーとして
えー
その日本語が存在する音素の数とえー事後確率により算出しています
えー事後確率はえーその音素認識させるでしたえ音声認識システムの方に基づいて三つ行なっています
で算出方法はえーこのような式で
行なっています
えーついにえーピッチえーっと五．〇と料理をしてえＰＴＭ全体のエントロピーＰＴＡとのＰを求めます
えこちらはえこのような式でえー単一行なっています
えーなおえーとそのＰＴＡではえー音声と発話文の音声認識結果より構築を行なっています
えーこの図はえーＰＴＡのもしたものであり
えーこれらの政治はえーその音素認識していた音声認識システムの数を表わしています
でこの例では
えー五十メートルＰはえー各このような値となっており
で最終的に利用ＡとＢはこのように算出できます
えー最後に
えーあるって錯誤が生まれる日の日のエントロピーをえー
求める意識がこれつこちらとなります
えー先程の三次元のえーこの四角で囲まれた区間をえー検出空間とすると
えー本一メートル二はえーこの間の三の
値を使用しえーＰＴＡのえーと四三する為
で先程とは異なる値となっています
えーそれが分析の結果です
えまずはえー各テストセットに含まれるえ検索語は存在するかのＡとＢを集計した結果です
でその結果こちらの表となります
えー赤い四角で囲まれたえー未知語の検索音を
えー緑の四角で囲まれたえー既知語の検査語では
えー必要な検索語が生まれる官の方はえーとゆいうことが分かります
えーこれはえー未知語はこうれる可能ではえー単語認識が可能である為
え音声認識システム考えが大きく
で八月の多い
ＢＧＭが構築され易いあっためだと考えています
えーそれに対してえー既知語は囲まれる区間では
えー単語認識が可能である為
えー音声認識システムがあまりいい例が小さく
ペア数の少ないＰＴＭが構築され易いと言えます
えー以上のことからえーまー情報量の観点から相手を的手法はテニスが容易であると言えます
えーそこでえー今回はえー未知語の計算量は囲まれる区間のエントロピーはえー高くなるという事実を踏まえ
えーエントロピーの閾値を設定しました
んえーこれはえー七二五三はえー閾値と連動する形であり
えーとローリーの閾値よりも
えー提示する単語エントロピーが付い使った場合には
でその結果を国立と見なしえー格するようにしました
えーこれによりえー考慮ホールでの吐き出し誤りを抑制し
しえー検索精度が改善できないかえ調査を行ないました
えーこの図は
えー
横軸にエントロピーええ縦軸にえ水変数コストをを取った場合の
えー検出結果
正解率と英語系列の一えー一部の
分布を示したものです
えーこの一直線がえー今回設定しタイトルの閾値で
えーこちらは
えー本研究で検索エンジンのえー最大の点数
構想である〇．九の時に
えー一最もえーＡとＢの高い正解率の最大値である値になるように設定しています
えー
えこの図のＡＢ
古い音声より上のえー部分のえー
部分出会ったえー結果はえー四百行ないます
で図を見ると分かる通りえー正解率を
で幾つかえー棄却してしまう為
えリコールが低下することが予想されますが
でそれに見合ううー訳五えー五．五はえー抑制できれば
えー検索精度が改善できます
えーそれがえーと閾値の導入結果です
えー
えこちらがえービザが生徒のＢはえー先程示したえ従来の結果であり
えー水エントロピーはえー今回のエントロピー四つの導入結果となっています
えー声を未知語テストセットではえー最大値となる
提示音は
えー正解率を記録してしまっている為
え若干精度は低下してしまっていますが
えーリコールが六十五パーセントから八十パーセントにかけてはえーエントロピーによる国立の抑制により
え検索性能が改善していました
えー続いてえー伝える困らテストセットでは
えー今回はえーっと未知語の検索母音の三えーとＰの
閾値を設定しましたが
えー全体的にえーリコールが低下してしまう結果となりました
えー次にえーその二あー一度えー僕海外スピーチの合計数についてです
えーこちらもえー
えー正解率を手付けてしまった為
えー父が若干低下していますが
て最大五記事の合計数を見てみると
えーエントロピーの閾値を導入することでえー従来の
ものよりもえー十分近くに貢献し
数を減らすことができました
で以上のことからえー正解率が記憶される為えー最大名詞が若干低下してしまうことは分かりました
えーまたえーこうイコール一の国立をえ大幅に抑制することができましたが
えー最大の歴史のある閾値成人ではえー効果が薄いことがありました
で更にえー未知語であっても
でその日の低いものが存在することがありました
えー単純なえーとＢによるえー二十一ではえー効果をすること分かったので
えー
これ更に分析を食べる為えー最良な一次性の二の
えーとＰを示したえー調べました
でその結果がこちらとなります
でえー頭のあ表のえー正解がリストはえーその
最大の一なる閾値でえー
された
で正解を含む発話のことであり
えー合計実はえーその閾値で
提示された者の
えー正解であったものの発話では発話であり
え二．一つは
えーその閾値では提言されなかった
発話のあ正解発話のことです
えー表を見て分かる通りえー正解で一つ
えー五．五
提出の一にエントロピーが違う流れていることが分かります
えーまたはえー正解率のエントロピーが低いことから
えー
検索を含む発話では
えー音声認識システムあの家が小さい場合には
えー検査語の検出が容易であると言えます
えー一方えーす検出のえーっとＰが高いことから
えー音声認識システムを考え揺れが大きい場合には
えー検出閾値をえー固定すると
えー検査語の検出が困難であることも言えます
えー
んーこの場合えー閾値を言えることでえーケースが可能となりますか
え同時に合計数が増加してしまいます
えー以上のことからえー未知語企業に限らずえー国立を抑制しようとすると
エントロピーが低い発話者が駅一できないことになってしまいます
えーそこでえーと
検索精度を改善する為のえーアプローチの一つとして
まエントロピーが高い発話に対する音声認識上の対策は必要であると考えています
えーまたえー五．五よりも
でえーと四つの発話の方がエントロピーが高いことから
えー合計された発話ではえー検索語と類似している音素列が
えー音声に複数の音声認識して認識されている可能性があります
えーこちらは
えー
感じな音素系列マッチングであるＧＰでは
えーこうペースかどうかの判断が難しい為
えー何らかの対策が必要であると言います
え終わりにえーまとめとしてえーピッチを用いた
えー合計強い訳です抑制した一時についてので
えー合計属性パラメーターを導入することでえー検索精度が向上することが示されました
テーマ化ＨＭＭエントロピーを分析し
でそのエントロピーのえー閾値を用いた後えー属性手法について述べました
えーこちらはえー氷これでは合計相対両方ハワイ抑制することができましたが
え歳でしたらＳＤ法そして一では
で効果が薄いことが分かりました
えー今後の課題として
えー今回のようなえー単純なエントロピーによる足切りではえー効果をすること分かった為
えーより厳密な音響マッチングの導入をこうするなど
を検討しています
えーまたえ音響尤度をパラメーターとえーと六Ｐの関係の調査を行ない
えー更なる検索精度の改善を目指したいと思います
え以上で発表終わります
#############################


#############################
# query = 音声ドキュメント検索とか砂糖をその未知語を一つ認識用の辞書に登録されている間をいうのがやっぱり問題なってくると思うんですけどそれに対する対策とかが借りてる論文があったら教えてください
# rank = 1
# slide = 11-01_fix.match_word.jout.txt
# value = -3.24461443103035
#############################
えーっとこのおータイトルで発表するんですが実際あの予定だったのがたりというのは
一人のお店にえー出てしまったので私があります
えー先週ですかねこうもの会話と二重したえー大きさっつうんだと行っ
終戦というのは
ん待ち合わせというのられますのは先生だったんです
知っ彼はどうも他の間にですねまー三つの音主にやってたんですが一つはまークラスのモデル
あの一般のですね
それようやっていてもう一つはトピック依存言語モデル
やっています
で最後にいーこの点はですね未知語の言語モデル
を考えをえーん
あーやっぱりその最後にえーっていったあー
内容紹介
私も
んでまーあー言語モデルというのはあー
ですねま音声認識いーまー使う訳ですがあーその中で元の立体図うーがまー大体何とか六万とか
やる訳ですがどうしても
あー辞書に登録されてない
単語があればですね
そういうのは統計であると呼んでたんですがあーそれが音声認識率に影響すると
もう一つはあー登録されていないから絶対に
その単語認識されないという問題と
もう一つはまそれがこういう形ですねんー
んー
もう
六えーというのはま指示語であればにえーまたもう二
六音がえーえー明示されてしまう
まそう選んでえー登録されていられたのは認識されないという問題と
もう一つはあー周辺の単語にも影響を及ぼすというもですね
モデルのモデルを使っていました本当に通常を使ってえー
編集していましたら
そのーこの単語だけでなくてその週にあの誤り
もうの影響を及ぼすと
経験的に言えば未知語率が
まー例えば五パーセントあればその一．五倍ぐらいの誤りやえちょっと身近なできるんですね
だからあーお婆ちゃんと未知語があれば中でも走るとこれはもう未知語の影響で
んー四五なんで
まーそういうな
まそういうなので一応減らそうというのをね僕用例数を増やすということなる訳ですが
二十便利さも例えば新しいいーいー単語というのどんどん出てきます
全て統合することが出てね
いうことで
ま以上の面悪い人は使った顔ということは重要な問題
いうことでそれをどうするかと話
どうやっては
で特にいーあのー条件することがあー内容がえ警察ですね
んーそういうのは
非常重視とかそういうのもそうなるとおー固有名詞とか
その考え重要である新しいいー単語ですね
そういうのが結構重要になってくるから
その前に一個になっているというので
ただ未知語を真剣に考える必要まー
いうことになる
でそれでですね
まう今までは動作例という言い方を普通はですね言語モデル作る時いーえー純音は一つのコーラス
単語のクラスと
願いしてえモデル作ると
そういうことでえーこの三一本もおーですね
えーえ単語の履歴として使って
えーんーまー
何を予測するとあまり僕らのやり方を予測するとかまそういうことなのですが
ま基本的にはまー一語は一つプラス
えーやっていたんですが
ましかし一つのクラスで扱うような問題があるであろうとね容易に分かると思うんですね
えーとそれを二万というのはあー個人のえーまー初めでして
んーこう木っていうですからこういうのはまーこう普通関係の単語であるとしたらこれを一つの
コーラスとおー発話がちょっとやっぱり問題など
いうことで
そういう形でえー四方向ではですね
えーまーこの未知語もですね
フォーカスがあってま意味的にえー分類したいということ
でそれでえーここで使ってる方はまー
そういう量を使ってですねこの新しい単語という国が
多分三つの有効性がガイドさんを見つけて
その人も八ぐらいえークラスタリングしてあった単語のクラスに丸付けると
まそれは大きな流れでやろうとして
でどんな問題があるかということ道が扱う時にですね
で一つはあーまー
のテストコーパスというのはまー認識する対象ですからあのこれが分かってないですね
をこうずっと同じ認識していかないという形が
その為に
二十五点の音が身に付けるかという問題はですねまそれが研究もある訳ですね
例えばうーのテストデーターを結構認識してえーまー例えば七割八割維持できたとしたら
それでトピックをま推定できて
そのトイレ関係するようなあのー
そうですねえーえーえー
リストと言うかその余暇探していってですね
それで一部分のおーいう動きが見られなかっパターンを登録してると
いうのが一般的ですね
未知語の見つけ形のテストデーターに対してき一番目付け方は
それらが一般的でそれでまー辞書には登録できるということにある
んなれるかなと思うんですけども
我々問題するのは未知語登録したとしてもまー自動的にどうするか
あるいはユーザーがあーえ行なった後二語であると思ったとすると
いうようなことで何かの方で登録できると
道もですね
でその前提の下でえその言語モデルをどうするかと
いうことをやろうとして
んでそれでまー未知語の元の扱い方の問題としては統計悪いえあまりいー魚を増やすとまー一万語にするとか二十万を一とかまそれの中ありますね
それをお湯をあの冷凍されると
いうことも勿論
んー現実的だと思うんですがまこれはまー
えーえんまーメールとかそういう言葉まそういう場面もあるかもしれないけども
そして二十五避けられない
文の私たので
そういう問題
もう想定してこれは
それな目でえー未知語の言語モデルをどうするかと
んーとまークラス言語モデルを使うか
差分をどうモデルでえーそういうな一部をですね
えーサポートしえすえー耳にするということもあると思うんですが
まーここであっですのはプラス言語モデルをどうするか
いうような
判定の考え
んーやって
汚いをおーおーそのー
でまクラスでももううーの紹介なんですが
まーあーまトレーニングデーターからあー実験等に対してはあーワード別のＮグラムを作ると
いうことですね
でその辺ボキャブラリーをおー七の方でクラスタリングしておいて
もあればなクラスター二のクラスにクラスタリングしてですけれども
そういうまー一個からえ関数のクラスに対して
えー新しいいー未知語に対してですねどういうデーターを使いながら
クラス数をおー推定すると
えーよほど
でその
未知語のクラスに対してえ×ですえーグラムを使う
まこういう形で併用してやろうということです
んでプラス一文モデルは普通はこういう風なモデルなるとまず一つ通り
単語の利益いーうー現在の
パンを推定するという確率ですね
それはまー暮らすうー
えー
んのおーカテゴリーで
えーえ推定クラスを推定してるコーパスから
あのー
本質
えー用語です
で未知語の場合は
この音ですね確率はちょっと分からないというので
あーこの研究ではですね一応六七八
英語を仮定してまずあるクラス数音が
ま彼はですねその頃は既に
いうよう歌もまーもし後百側としたら
その間は五百万が一の確率で生じると
いう一様分布を仮定しています
方向が分かるで入れちゃうかもしないですけど
ま現在はそういうな名詞句は
大手
えー
んでえー先程言いで二三を八ぐらいである単語は一つのクラスター
三月
することもできます
ま一応これを一つの
クラス言語モデルと
んー
考えたんですねまーいい状況がが格がま一つの頃
という
んで後もう親に対してはある意味でいい対応をまプラスに割り付け
いうことですでさっき言ったこの確率は
えー一様分布でえー
んー
んでそれでですねあのー以前のような例をクラスタリング数しておく訳ですが
んまー一番まーよく使われるようなターム同定データーマトリックスとかバイグラム当たり
こちら現在のあのーこれまー
一つ前の単語と概要これはマトリックスで表現し
えー四ですね
でこれでいいという文に対してはこういうような要素は
ちょっとイメージですけどこのえー行列の要素は
んーま求められっていうとしてで後あのー子供なのに対しこれは新しいデーターの方も帰ってきて
辞書には登録してるけれども
あのーこれをどうするかというえーっとーまー上二うーデーターからですね
まーこのあのー推論
んー
ちょっと理由ですまー
えー
ま親データーからこういう成分を持っててきてですねでこのまーそれ作ってこの後もう体のベクトルを一枚目えーいいるような
えー
言語で習ったあのー見つける
いうことですでこれもまた要するにも体も見つかればまそのクラス
交際をするま兄弟が取りながら
んー
あのー貰うような結構何で
えーまーいいと思いますけれどもそれで三十一例なあーことであるというボキャブラリー乗ったもの
古い自動計算すると
まそこで
まーファンクションをあううーのはどうみたいのをですねまーどこにモデルは単語おーはちょっと考慮しないというので
あるいはといううー
んー
メジャーで重み付けしています
そういう中で占められてよ
変数七年の八文全てに対してえー一度も
もう
あー求めてその中で一番大きい
対応する言うとやっぱり
パンを見つけてそのクラス
交際をし
私の方で
でこれはまー例なんですがあー
それでえーま後四五一名です
一に対してえー応援うーうーデーターサーチ
えー
え先程のマトリックスをつく
えー
普通の融合型や回答のおー類似度を計算し
まーこういう風な
そういうのではない二万単語とかあるんです
でその最大値に対応する
クラス四歳です
まーそそういうことですね
でまた二つとしてはかもという面止まってる側のま二つを使ってですがまー実験的にはバイグラムうちの一ということなったで
できたのですが
えーま概要なんですが
あーここでちょっと実験これ入れ境界推定方法二はまー
え対象テストデーターとそれうーデーターをおーそれぞれじゃになるんあのコーパス使いました
で千四十七年から八十九
のデーターがちょっと上ですが見え方それであの評価データーとして
えー正確に使われてるうーデーター
それらをしています
で僕らが最大に需要は
えーします
まこれはま基本的な模型をしたいですね
んでそうするとテストセットにあった程競馬での週いいいな六千四百
こうですね
後えー学習
テストデーターにはですね
んでえーっと例のデーターに対しては
んー
二十四．貰ったんすかね
あのー
ことでは二十九八五治らないやつが
百六十てもらったと
けれども
このテストデーターに対してまテストデーターコーパスにおいて
えーえ違います
二個からやって自分のデーター
えー
でこういうなので例えばうん
それでまーというのは
あーどういうな対応するうー単語一回かというあのーまー
利益を批判ですが
もうこれあのーうー固有名詞
えー一つの
私えーまー一年の一掛かってきてんですけど
奇麗には
なってないんですけどままー
一年はん一〇に近いような集まってきて
んーとーけあえーほ
一年一試合
単語のえー
んでここで問題はですね評価したり
トレーニングデーターの中ことでわりと
二テストデーターをどうやら
トレーニングデーターあーん
の二十三つだと思って私をしてもですねトレーニングデーターでも貧乏であったと思うやられ
なりましてテストデーターに対しても
冒頭であるというので
でまーここでえー対象としてのおー六年と書いてあるんですね
それがまーデーターあーに出てくる
ですけども
えー単語として登録していない後僕がこういうまー
これをまーまず最初にんー最初ちょっと
あのー
それの実験結果
うーそれでですね
本当はですねこのあの将来どうするかというえーですけれども将来テストデーターにいー
母音語彙数はどの程度
一度まー一度おー
坂というような
とかま色んな問題ができる訳ですが
我々の仮定としてはからのあー非常に多いとですね
この〇二保険が二十九四であればお父から〇とは
二三パーセントであるとしたら
テストデーターにおいても子供って文の例が二三パーセントであろうと
いうようなえーどうもえー
うーてやろうとしています
頭の事例がちょっと違ってくるんですね
このテンプレートと後はまーある程度推定しないというのもですね月から
まーテストデーターがある面トレーニングデーターであろうが
本当語形の例と同じであるっていうをするとまそんなあー考え
で
教科としては音声二二つとまこれ一えーよく出会うんですが
この確率で毎週もんで
あの構成では文章を使わないとですね平等な比較はできない
例えばえーボキャブラリーを二十キロでしょうそれが六十キロにするかというので
バブル時に変わってきます
あそれいいというホテルが主を使うとそんな問題を構成されます
まどういうことかと言うとですね
例えば後歴史というのは
まー子供にあるのに対しては一様に分布すると
ペルーの出演してると言うかですね
それであのーまー無事警察
そういう
そういう何らでえー評価して
それで先程言ったあートレーニングデーターとテストデーターがあれば
それでえーこれがまー今日のあー感があー補正パープレキシティーえー固有値があー
通常のパープレキシティー
でこれが僕らサイズの登録
二の数ですね
んでえー我々は基本的な一九八
通る二万語を登録してですが
最初でトレーニングデーターは全部でえー一六万も
一年していたんですねまーボキャブラリー
最終を
フランスとですね
パンフレットをおー音声学者同じ値なんですが
ま心でかなり差が出ています
ま二十九本ていう発話は結構んー
まこれがあーまずんー
あのーまー
トライグラムであれば私がどうなるかと言うとですね
でこれをですねクラスでこのモデルを使ってて話者クラス言語モデル
んで二十キロ音楽の家をらサイズで
後は部分からサイズをこうを登録しているという
年二十キロを登録すれば
全部で四の単語になりますけどね一万単語にボキャブラリーで
登録されて人間のトライグラム止まってるんですが
後二万単語を登録してえークラスでのモデルを
うーをおー作ってですね
それでまーこれし計算すると
大体四十ま話していいと言うかそして私四十からあのー
でベースラインの
あのー
方あーいあのー一二四六時集合であるから
んー
かなり
その
えー
まそれでこれをどういうことかと言ったらこう二年間
後あの登録して後もう一八万単語は全部一様分布であると
その一つはプラスえー仮定したやつですね
でこちらは
ん二万単語登録して未知語を
そのクラスに対しては
えークラス百からずっと翻訳クラスでま三人でした
食事があまりなくなっ使うと
んですあー
認識実験Ａや
テーマ
でこれは
ちょっとあのーもうそれであーのーんん
世界で使われてるうー評価データーは比較的なんで
二型のデコーダーでも九十五パーセントぐらいは
単語認識ですが
でそれでちょっと違いとか優しい過ぎると言うか評価でねもうちょっと難しいように
必ずえー自分は一部一部をこのようにえー
テストセットを作っていやああ
あータスクでえー
評価してですがベースラインであると
えーえーこちらの二百五十グラムですが
二十九モーラ登録すると百四十七．五ちょっと
言うんですけれども
ここえー理由があったかどうか二年目ですが未知語だけの後歴史を計算すると
ベースラインでは
バブル期が三百四十五まー尺度の値ですけども
んでえーコーラス言語モデル使うと二百万ぐらい
いいだろう
ま三百四十万から二百万
八ページの三は
んでえー明治二十九Ａが項なんですが僕が貰ったと言えばにですね男性後とあ前に
まーあのー
共有できます
こうぼけが理由をまー六万語の単語まで二
力ってなんですけれども
であると最小んあって話者七十二．七であった七十九．四一
ま言われながら
えー
二四八ぐらいのサイズをクラスというのは
んーまー
認識率の向上方法なんですが
まそれによるしても
の時は〇の問題は解決的なんーでということで我々だけにやってですが
んでそれで本当こうなりまして
あーのー
別までまー一クラスの言語モデル
けれども未知語に対してそれがこういうようなあー
誤り率に対して
百二十九二八九月になると我々がえーっと
で後ですね
でもう一つ高くなかったんですが
ああいうのが来なさいとこれが一二四月五日二十一型二十五えー
三十気にするとですねえーボキャブラリー
その数一の方だと文書というようになりましたけど
これは一個一一パーセント
〇．四パーセントぐらいを行なう訳です
さっき言ったあー
三十九本と
三十成功例二十九プラス一九八二三四八ぐらいとしてあったのは誤り率が
二十三．四ですね
二十三．八に対してフランスでももう一つカテゴリー三．八パーセントですから
単語をどんどんあの登録して
えー色んなもので
あのー
モデルを作るのと
おー単語と数分でえクラスのモデルを一度ですとえー
であっても認識率が
それをどうかを考えておりられた
いうようなあー
まー一応
んー現在までの
ですから
これをえー
#############################


#############################
# query = 音声ドキュメント検索とか砂糖をその未知語を一つ認識用の辞書に登録されている間をいうのがやっぱり問題なってくると思うんですけどそれに対する対策とかが借りてる論文があったら教えてください
# rank = 2
# slide = 09-06_fix.match_word.jout.txt
# value = -3.24997878544021
#############################
あー肺ではえー
検索対象の類似性の高いえーページを利用した音声だけで政策の検討を
について
えー山梨大学工学部コンピューター部屋工学化することが発表さしていただきます
で発表では普通の
まずえー研究の目的と背景
そしてえー研究概要を説明しましてえー例を利用した音声ドキュメントを検索の概要
えーその
ある手法を用いましてえー評価実験
んー行ないますその後えーまとめと課題
えー
まー今後の課題について説明いたします
でまずこのからえー一
研究の目的と背景
えーそれと
研究の概要について説明いたします
えまず研究の目的と背景にあります
え目的としましてはえー音声のえーと検索精度というものを解析法
と考えます
でここでえー音声学など検索というものなんですが
はえー近年のえー記録媒体教え方という風に
で大量の音声や映像というものを保存がおりました
でこの
えーこの大量の保存されているえー音声
からえー効率を検索すると
ってものが必要になります
でこう
こちらの検索をどのようにして行なっているかということなんですが
まず考えるのはえ人手によるインデキシングというものがあります
って人手によるインデキシングというものはえー
対象とするデーターが多くなれば多くなる程えーことが終わってしまいます
えーですので一般的には音声認識ある事情インデキシング
というものが行なわれています
えですがこの手法ですと
え音声認識率が悪いとえー制約検索できない
という問題があります
ではこちらをどのように世界で一日
ということなんですが
でまず第一に考えるのがえー音声認識の改善というのがあります
え音声認識を改善しますと
えー
インデックス時代の一つは良くなります
えしかしいーは何かん的な認識を行なうことは難しいということを
でまた
未知語や認識誤りを回避できないという問題があります
えーですので
本研究では
え音声認識誤りに頑健な検索方法としまして
えー検索対象音声とおんなじ内容のえーページを利用しようと考えました
でこのえー
本手法用いることによってえー検索精度を改善しましたので
その手法について説明いたします
まず研究概要になります
えーページを利用した音声をけれど検索
といたしまして
えー提示しての為の
え検索への検討をということを行ないました
でこちらはえー単語Ｎグラムの手法まだ
えー
ペルー日本語Ｎグラムというものを使用しました
で次にえー三ページの妥当性判定ということを行ないました
えこちらは
えー収集した上で力
であります後えー
でページもう全然の選択を行ないは
え検索精度良くなるんではないか
っていうことを考えました
で次にえー検索結果
の
方法の検討ということを行ないました
でこちらはえー抽出をえーページをどのようにして検索システムに組み込んでいか
ということを考えました
で次に
誰でも利用した音声におけるえーと検索の概要について説明しています
まずこちらが
一般的に行なわれている政策になります
えまず
検索対象の音声
というものを構成意識いたします
でその日
えーそそこで得られた音声認識結果からキーワードを抽出し
ってインデックスを作ります
えこのインデックスをここではえー認識でセットします
そしてえー混雑したいのにえー認識インデックス
とえーユーザーの検索要求である
で我々について検索したい
というようなえーテキスト形式の
いう規模
付けます
えーこちらのえー
ユーザーの検索要求と
えー認識です後
えー検索エンジンでえー比べ
で
できた結果を得ます
でこの時にえーっと音声認識結果は中に
未知語や後認識単語というものが発生してしまいます
ってですので
検索エンジンにはユーザーの検索要求にえー未知語や誤認識単語っていうものが含まれていた場合
えーっとなく検索
することができません
ですえー提案手法としまして
で
音声認識結果から
キーワードを抽出しえ検索用のクエリーというものを構成します
でそのえーっと構成した
増え検索用クエリーを用いて
二ページというものを収集します
でこの時えーページの妥当性判定ということを行ない
えー関するえー提示文というものを作成します
下手なからキーワード抽出
というものがないＸを作成します
でこのインデックスをここでは有名です
と言います
でこのようインデックスを用いることによって未知語や誤認識単語を二のと考えました
んー
この二種類のインデックスに
対して
それぞれ検索エンジンもう
使用します
でこの二つの
検索エンジンに対し
ユーザーの検索要求
母音それぞれ
二四つの
でそうすることにより
えーそれぞれの検索エンジンから
えー
検索結果ってものが得られます
でその得られた検索結果を
統合することより
最終的な検索結果を得ます
えあついにこう流れをえこの処理の流れだから
え音声認識結果から
でＣはあのー
放置してみて体験
えーで検索用クエリーの構成を行ない
えページの収集を行なう
までの流れを説明します
でまずえ検索よく旅行生になります
え要因では損失
というものは収集したメッセージの内容で変化いたし
えーですので
えー検索対象音声というものが文のあの話題で
分喋っていいかっていうことを特定するとかって思います
ですので
えー検索よく言っては重要になります
えーですがえ今回
の研究では
えー
えページを使用することの有効性を
節程二十でも
書きましたので
え簡単な話題な絞り込みの方法としまして単語の連結ということを行ないました
でこちらがえー単語の弁別の方法になります
えまず音声ドキュメントの音声認識結果
んがえー一万円します
して示しますこちらの
よりやっていたとします
でこの中からえーキーワードを抽出し
検査クエリーを構成した時に例えばこちらの
データーを
というものを検索例として用いた場合
えーデーターだけですとどのデーターに対しての検索要求があるか
というものか分かりません
えーですので
広い範囲の
えー提示を集めてしまいます
でただここでえーベンチが続く限り単語を連結しました
えー単語の連結を行なうことによりデーターという単語に学習というものが付加されます
で再学習データーという単位でえーメールを検索しますと
そのえー話題が絞り込みことを
ま話題の絞り込みを行なうことができます
えですがえー
名詞扱いに単語を連結してしまいますと
あーこちらに示すように
学習データー数縦軸というような
え二では．五のような単語でもまーできてしまいます
ですのでここで
えー日本語Ｎグラム
というものを使用しました
えこの英語日本語えであるということはえ文が作成しました
普通のページに含まれている
単語Ｎグラム
というものを登録してある
データーベースのようなものです
でそこに登録してある単語がどうかということを
えー
比べることによって
こちらの学習データー数
えーとーえ縦軸
というように
えーパンを分類することができます
でこれらの手法を用いて
えー単語の連結を
行ない
えー
名詞一というものまた撮影したえー単語Ｎグラムの出現頻度
えー上位語単語のえー検索駅
として採用しました
んー
え次にえーページの収集の方法なんですが
え先程の方法でえー作成しました上で検索用食
というものがえー例えば大切に
テーマ三四に五の一つであった場合
ところでですとＡが一番出現頻度が高くなるんですが
えーこの五つの検索用クエリー
というのは
えー組み合わせを
作成します
でこの組み合わせだから
最初はえー全部を用いてこの検索を行ないえーページ
というものを収集します
でここでえー
収集したえーページっていうのが目標
二十代目標係数に達しなかった場合
で次の組み合わせでえー
えー
検索を行ない
元々ヨ
あー先程の係数ｐで
収集しました上ベースに追加してきます
んこの処理もえー繰り返し行ない
模型をえー収集するえページあの表現されたするまで収集を行ないます
月に二えーん
音声認識結果を
またえー
収集した上ページから
それぞれのインデックスを作成する方法
についてえー説明します
えーまずえーページの妥当性判定
えーあります
んー
え音声ドキュメントのえー認識結果というものは
でこちらなります
んこちらを元に収集した上ページっていうのは
こちらになります
現在ですとえー学校の
こちらですとえーＡＢＣＤ
にえ二
え六個の
あ六県のウェブページを収集したと
します
でこの
六件の
でえー
それぞれのページのえー類似度計算を行ないます
基本的えー発話えー尺度を
使用し
それぞれの思いはえドキュメント内の出現頻度
用いてえー類似度の計算を行ないます
そして得られた類似度っていうものが
えー
こちらのようになります
でこの中からえー閾値以上の
古い町
になったものを
平面図をして採用します
でこの例ですと一五パーセント以上類似した文
になります
またえー閾値八の上ページがない場合
をえこれこれで言いますと二十パーセント以上となった場合ですが
でその時はえー認識結果を
二ページの代わりに対応いたします
え次にえーインデックスを作成になります
認識
がこのようにえー
でこの中には
平和な予測係数に空気が単語というものが含まれています
えこちらで例ですと
このもというのもまたは四時
まーついては単語になります
でこれはあの
単語を
あれだけ子音
話題を特定する単語文
でえーインデックスを構成しました
では次に
それぞれの検索エンジンから
得られた
検索結果を統合する
について説明をいたします
で検索結果の方方法としまして
えーユーザーの検索要求中に含まれている
え未知語の割合で統合を行ないます
え統合式は
三こちらの
式になります
えこちらえー構文というものは
えーユーザーの検索要求に含まれている
見積もり
んで
ではえーこちらの
政治やるっていう本を聞いた日っていうのは
でそれぞれのインデックスで
で検索しました
結果の検索スコア
になります
でここでえー後まー
三つを使用することによって
未知語率が
多く含まれていれば
えーページに夜
え検索結果を
んー語をえより強く反映させようと考えました
でこれが
えー検索結果の方方法の例になります
えまずえーユーザーの検索要求というものが
こちらの話者認識の学習データーのサイズが小さい
推定ようなテキストを入力やった場合
えこちらを
えー認識時に用いて認識でしょう
とー
えー見受けられまして
んー未知語というものを
んあー思います
でこの場合ですと
この
認識というものと
データーっていうのがえー未知語であった場合
でこの
検索要求の未知語率ってものは四十パーセント
となります
でこの四十パーセントを先程の
地域に代入しまして
で認識インデックスで求めた検索スコアを
庭でえー僕も
でまた
いうインデックスの為だけだ活動を
言わでえ四
というものを
発表させます
それにはそこのドキュメントえー
というものになります
認識に出曲求めた訳で
のえー〇．九を掛けまして
いうインデックスで求めた
初めての
入れて三人で手を掛けます
そしてえーとぼけ
彼はその両方の値を足して
えこちらの結果になります
こちらえーん
うーインデックスを持ってることよってこのドキュメントに
というような
えー認識率ではえー検索違ったドキュメントっていうものが
で
最終的な統合結果
縁は
で検索されるということになります
では次にえー評価実験につい意外と思う
まずえー検索対象音声の教員と
には
えＣＳＪを対象にしましたテストコレクション
獣
使用しました
でこちらはえー千七百にのドキュメント
えまた
えーユーザー検索用機は三十九個
でその中に未知語複文ユーザーの検索要求は一一方なります
え検索対話一講演も
後ドキュメント
としました
できるだ
えこちらのＣＳＪを対象データーテストコレクション
言わば
て予め認識
結果というものとされていましたが
てその認識結果の中には
発音し結果は
まえーとー
未知語を
三つってものが
って言うかまー誰に
で今回は未知語を
であえー五十単語っていうものを
にえー改善されたかどうかということを調べる為に作業
入り未知語をあそうですして認識
二を行ないました
二つの条件がこちらになります
で言語モデル
はえー
学会講演の書き起こしデーターからも実は
二十七キロのトライグラムモデルにあります
えー音響モデル三はえＣＳＪから作成したトライホン
二三十八次元
星をしました
で音声認識システムにはえー二八つの音声四．一を
えこれは手法
を用いてえー
音声認識を行なったところ
え単語正解率は七十六．一パーセント
普段えーす
正解精度がえー七十一．六パーセント
設けました
で次にえーページの収集方法になります
えページを収集には約検索えー二二八五というものを使用し
一時のえー月五十点程度
フレーム影響を生成しました
背景ざ
えー二には
え反映用例村連想型三二十一日
というものを使用しん
でそこに含まれています一つの方法
というものを使用して
で検索出しました
え次にえー
評価尺度に
関しましては
で保管中にえ平均精度
というのを用いて
えー検索結果の音声二千件
でえー評価を行ないました
で実験結果をこちらになります
まずえー
えー検索要求文の構成をおー
の
えー対象検索
程度になります
へこちらはえー画像検索要求全体
ですね三十九の
ユーザーの検索要求に対しての
結果になります
んー
普通の
認識Ｘのみ
んで
計算を行なった時の精度になります
でこちらがいい
並列
語を収集する時の
クエリーの構成法の
時にえー
いう日本語Ｎグラムというものを使用しましたが
えそれにより
あのー
連結
たかどうかっていうことになります
ナシというものはえーでも日本語えの募集をしていない場合
でありっていうのは
テレビ日本語えである募集をし
して
えページを収集しました
でこちら総合はえーっと
提案手法による
精度になります
え提案手法を知ることによって
どちらも
えー検索精度を
解決することが
できました
でまた
という日本語Ｎグラム
もう使用することにより
四十間でありますが
検索精度が良くなる傾向が見られます
え次に
話をえーえ未知語を含むユーザーの
検索要求
みたいと
に着目して
検索精度を求めてみました
えこちらは一
二のえーユーザーの検索要求になります
二こちらも同様にえー提案手法をすることにより
えー検索精度というもの改善されました
でまー
えーえ基本概念であるというものを使用することに
まこちらも若干ですが良くなる結構
胸が見られました
んえー
二ページの妥当性判定により検索精度
になります
でこちらはえーユーザーのけだけを聞い全体に対しての精度になります
えこちら横軸の
〇．一
一五というような
えー政治は
テレビを選択すると
する時の類似度になります
ですねこの〇っていうものは
集めた上で一応全部使用した文を
ただこの
一というものは
えーベイズの妥当性判定死類似度を計算するんですが
でその一パーセント以上になったている以上
んでえー例文二十を作成した時
の精度になります
二個
え括弧で囲まれている政治ってものは
言えるインデックスが付加されているドキュメント数
になります
でこの結果を見ますと
えー
んー
平静時の妥当性判定を行なうことによって
で検索精度がえ触ってしまいました
はい
次にえーみ
同じ条件で
水を含んユーザーの検索要求でして
行ったところ
矛盾は結構
が見られました
でこの
あのー
結果あの考察なんですが
でまず
ページを収集する時に今回はえー簡単なあー手法
で
えー検索用クエリーを構成しえーページを示し
したこと
でまた
いう指導を計算する時に
がん二単語の出現頻度
よる重み付けで類似度を計算したことから
不要な六ページというものが集まってしまった
ことを考えられ
では最後にえーまとめと今後の課題について説明します
えまた私まして遊園地を利用した音声ドキュメントを検索
に関してえーページを利用することで検索精度の改善を行なうことができました
で特に二十五九ユーザーの検索要求いたしは大きな改善が見られたと
思います
月にえー検索要求の構成法に関してですが
でこう専門の違いにより検索精度
の改善が
可能であると
と
分かりました
えまたえー五ページの妥当性判定に関しなんですが
でこれは最後
検討する必要があると考えます
ですが
でえージョン落ちることで
検索精度を歳で二十五パーセント
肌未知語を含むユーザーの検索要求に対しては検索精度を
二．五パーセント改善することができたので
えページを利用することを
の有効性バスですのではないかと考えます
え今後の課題ですが
え検索精度
向上の為に
テレビでまた一か月に一二個
と考えています
え例えば
で現在
二検索用クエリーの構成方法
中では
え単語連結したものまた言説を行なっ三段階で使った者というものを
えー同じ割合で
使用してるんですが
えー単語を連結した単語Ｎグラムの方がより話題を特定していますのでそちらの単語有声収集をしを
と考えています
でまた
えページの妥当性判定の
方法の体系ということを考えています
以上で発表終わります
述べました
#############################


#############################
# query = んえーっとと音声認識と合わしたと場合のまーえー二場合だとそのテキストをあの話し言葉をそのままなるんですけどそれ一日ま書き言葉の文とはまー書き言葉のものもまデビューから取ってきたりとかま論文のものだったとかそういったものます書き言葉になり付けをするとはだいぶ私形式が違うと言うかそのままではあんまりしないということが音声まそれをうまく分ける仕事あると思うんですけど父の書き言葉と話し言葉をうまく分類と言うかそれを区別する方法についての説明が四第一えーとーもうどういった特徴量使ってるとかはまーといった手法を使ってるとかそういうことをですね
# rank = 1
# slide = 11-03_fix.match_word.jout.txt
# value = -4.42707180201695
#############################
はい
であ東北大学のまずはえー
本日は上データーを用いた話し言葉調言語モデルの作成というタイトルで発表さしていただきは
えーまず初めに
えー日本語話すコーパスによりえー日本語話し言葉音声認識鮫がまず仮定したってことはみんな
実は三つてる通りなんですが
ま特に
言語モデルの面からえーと四時から四つがものが非常に協力であれっていうことがこう全体的に知られてると思いまー
えしかしながら問題点として
ＣＳＪ全体の異なり語彙数はあ六万個一程度ということで
さまざまな話題の話し言葉音声に挙げたようできないといった問題がある
またこのお話い全然ない訳テキストデーター量を形態素という訳ななかったなっていうな形容ってことで
ま頑健なＮグラム確率を推定する為にやってないよう割合二十一だと言えば
えーよって参考と言うかな為にあのー
元学習データー量が必要となるのですがこれ以上音声データーを人手書き起こすってのがあ非現実的だなって今
でそこで従来一般的に行なわれが四つとしては
新聞七の書き言葉データーとの混合により言語モデルを評価関数でできることが行なわれます
で話し言葉データーに加えてえー一年中の言葉データーを使い話し言葉の為の言語モデルを強化する
でこの
書き言葉データーのみではまー
認識性能認識性の低い
ノイズが
まー
こちらに恋がたくさん
ん入ってんので語彙合併えーさまざまな話題内容的に異なることによって
えー認識性能が上がるといったことが起こります
えしかしながらこの書き言葉のデーターを加えると書き言葉スタイルのＮグラム確率劣化動作の上昇してしまう為
話し言葉対話音声に大体二世の低下してしまう
といった問題起こります
部屋従来どうしてこのような方法を行なっていったあー程度
話し言葉への音声認識に生きた学習データー点も何か手に入らないと考えられていたら
て一方でえー我々は
メル以上の話し言葉でいや
論理要するえーっと利用するアプローチというものを今回私も
えー
えーレベル以上の言語資源の葉を手にする為に
音声認識の為の言語モデルの学習に背景というようたということが
え先行点
一から知られています
えーま人間
文章スタイルを考慮したで言語モデルにでもかなりえー例えば音声対話におけるえーユーザーの検索要求にえっと発話した言語モデルの作成であったり
え文末第九の文の形式である文章を利用した
疑問文と違った言語モデルながら作成例が多くなり
でこのように
でえー音声対話であったりえーこの質問でやはりさまざまな
あれすれのデーター食べる上には存在する
でそこで我々はゲーム上の話し言葉のデーターをうまく利用すれば大規模な話し言葉用言語モデルを作成できるのではないかと考えは
でそこで本研究では
え以上の話し言葉データーを利用した対象が話し言葉用言語モデルの作成ということを目指します
えとまたもう別でえー
のデーターのみから話し言葉用言語モデルを作成っていうことはまだてるかどうかを検証した研究ではありません
そこで我々はストーンに水を組み合わせて
ペルーから話し言葉データーを体験を二十一つで言語モデルを構築するといったことを行ないます
そして目標としては
ペルージャの面からＣＳＪ付ける言語モデルＡと同等の人数制の問題
話し言葉用言語モデルを作成する
まだす
ＣＳＪではその疲れが別に言語モデルを作る
買って四次以上の話し言葉用言語モデルを作成するっていったことを目指します
じゃその上でえー今回やる枠組みとしては
えーまだプロセスでは話し言葉の
景気があっというものを作ります
その為に縁から
で別に認め文節でえー次のような流れを適応していけば
まずベルからダウンロードした結果に対してフィルタリングを行ないます
えぴったりとあ言語モデルの学習に重要な部分のみを抽出で
つまり電車で便のみを今回はルールベースで抽出します
で次に
えフィルタリングを行なったデーターに対して
これ話し言葉なのでき言葉なんだっていうことを考えます
で最終的に話し言葉データーのみを使いたいのでそこでで
で二番目の分類といったことを行ないます
テレビや話し言葉と書き言葉のデーターが存在せんので
今回はないいる人をこう
分類木を構築して分類を行ないます
で最後に
話し言葉
と判断された後に大体すえー言語現象の補完を行ないます
えーこれは話し言葉特有な言語現象ようなあくまで今回扱って言われている以上の文書なので
本当に
でえーと音声を書き起こしたようなデーターに入るようなものは
入っていないっていったことで
今回はなぜ日はあまり実現しない
といった問題がなぜこれを日は父にいー
行ないます
えーまあー米の文章を
っていうのは基本的に表わす言葉なんで
でえーっと元の位置っていうものは実際に人間が食べる
場合ですとどうも音の一一は必ずしも一致しないで
ちょうど方というの行ないます
でこれによって疑似的にですがあー話し言葉のデーターを構築してきます
で
このようにしか出て音声を書き起こしたお店で
話し言葉データーを準備することができます
であのー
部分部分の日
について説明していきます
えー
えまず聞いたりですが
固定れた統計量組み合わせて聞いたりんどうかな
後は二つ目え性能を行なっていた方法を適用します
えまず固定いたしてはまー
基本的な方法としてえ百点に整理をするような部分
また
で上にはＨＴＭＬであって
ではえーいＵＲＬなどが書いてるのである為八ページ記号のお五ページのあのて
全くえー二年前を
対象としてので一ような長さ
金まで色んな形がある以上方
考えます
また統計例としては
平均年齢層はえー
二チャンネルなんかではまー二チャンネル四などがあればて
そういうものをまー言語モデルの学生には使えないので
それを予め一般的な単語をトライグラムを準備しておくことで
単語パープレキシティー基準でえー
っていう形を行ないます
でそうするとこのこれはあー東北大学への人ピアノページ
この
ＨＴＭＬタグを取ってきたものなんですが
でこれをフィルタリングを行なうとこういうこのような部分まあー
えー
ま後はこの括弧の中で言う
もう
奇麗にするように設定します
でこれによって言語モデルの学習に言うような文章で文のみを充実化を行ない
えー次に
というやり方がな何て何だか話し言葉データーの抽出を行ないます
で今回はないので分類器によりスタイル分類を行なうことで
で話し言葉データーを話します
その為にまで
話し言葉大量書き言葉書いてそれぞれにグラム言語モデルを利用します
で今回は予め書き言葉のデーターと話し言葉のデーターがあることを仮定して
それぞれから二グラム
母音がステージで
である
フィルタリング後の例で言えばが
どちらのモデルから生成素敵だなってことをこのように
書き言葉のモデルから生成
ある事情が提示さが類似性
などを求め
最終的にこのような好きなものを
第例と判断します
で今回この家に比べには
大分類が目的なので名詞弟僕は金してえー助詞や助動詞などを重点的にしています
まー
スムージングが何一つの生成確率も利用するといったことを行なって
でこれによりナイーブベイズを用いて話し言葉と言うのであの実は全自動で分類するといったことが可能になり
で最後に言語現象の効果はないまー
えこれはあー周波時代という二十二課題をかなり八百屋です
ちょうど喉頭ニューモデルを適応します
でえ後にえモデルＡは二つのモデルからなっていて
えー文章中のある一に水が挿入される確率えー
本モデル易い更にそこの文字そこに
フィラー購入するならこの日は購入され向かっていった条件付き確率
としてモデル化します
ま多少本当にモデルは文節エラー率にショートポーズが挿入されるかどうか
という訳語をモデル化します
で今回我々はまートライグラムえーでそういうモデルをモデル化します
えーっとずっとまー
普通の文書に対して
次二つのモデルを適用すると
このように挿入することができ例えば一番上文章だと
かなりならえーとちょうどいいか忘れます年齢といったように
まー
高齢は音声を書き起こしたような定義が
には
このように
話し言葉の特徴を持つようなま本来あれば書き言葉書き言葉ではべき乗のページを
でえー音声を書き起こした訳ではないですが疑似的に話し言葉データーを達成することが可能となり
部屋このような枠組みを利用して〇から文章
話し言葉データーを集めて実験を行ないます
えまずその他
相手に
どのような
で結果を相手にする訳ですが
まー編
いいリソースが出て全体データーを今のような方法で行なえればいいのですがこれはまー一技術的なので今回
まー
ま大体千網羅的にサンプリング率
えＡからサンプリングしたあー合計八えー戦後百ゆ
千五百万いＵＲＬの的な
妨害想定してそれからデーターを先程まで説明した流れを適用することで
っていう記事話し言葉データーを作成していてまー
でその為に先程までえー
フィルタリングを経る
の面でえーまたナイフ一つえーデーターも出て
才能がショートポーズえ
えー嫌い外ＰＯＣの挿入モデル
その説明してきたんですがそれでそれぞれを仮説が明瞭おーデーターとしては今回ＣＳＪ二千五百三〇六講演話し言葉の為に
えー毎日分にね年五枚上でえー使う書き言葉の為に利用します
で前にはえー体制的に生地話し言葉データーを作成し
このでいながら
音声認識用言語モデルを作成
また
元々の四時でから学習者モデル
文を学習しこれらを比べていけば
で三番目のおテニス実験ではレコーダーはＪｕｌｉｕｓで音響モデルは四二五から水さトライホンモデル
で
テストデーターとして
でえーこちらの二千五百三〇公演を含まない四十一講演を用い
えー山で
今回作成したデーター量がどのっていうのは
ようなのかということを説明します
えーここであり八ページのまー格好で後おー統計学ふえー
道を示してあります
で各事例が多くていた私
家が残っているとすると何か
でまこの二次会というものはえー四え制約に前後百五円学生に書かもので
こちらのデーターうはまー約七百万と一般的に調べてみようと変わりません
でこれに対してえー今回
えー約千五百万いう悪い例のデーターあーそれを
できればいいのかな
二度最終的に
五十四境界と言えますＣＳＪに比べると
第一講座が大きいデーター
えー映画が手元にある出来事が分かると思います
この手元にえーんこの手元においてこの五十億円
形態素のデーターを内部でいいです
分類器で分類すると
んえーこちら
こちらなかなか聞くことばかりを判断されたものこちらの方が話し言葉という判断されたもので
えー話し言葉と書き言葉の比は約一たいなないぐらいで今回判断
んでえー自動で判断されました
で更にこの話し言葉増えた中で単位解析が挿入ショートポーズを挿入などを行なうと最終的に
逆六億てないと
のデーターが強く
って言いました
でえーこれは事前のデーター量
割り当て七百万えーこちらは逆六億しないと
なのでえーまＣＳＪの約八十前の話し言葉データー今回は疑似的に集めました
で
次に今詰めた例が
付けたデーターから定型のモデルを達成し認識性能を評価していては
えまず最初に
えーボイス動いたりえーっぽいって
今回やえー四番の娘以外でで言語モデルを作成し比較を行ないました
えー縦軸えーまーあの世界性で
まずこのす緑色のＣＳＪの部分が
まこちらは
で認識ドメインでそれがあの学習データーも同じドメインでありかつえー音声を人手で忠実に書き起こしたデーターを使ってが付いて
まこの場合
六十二四五パーセント程度でした
で
これが一個の丸一丸二丸三回であのあんまりじ読まないので一えー分類器
などの話し言葉二のデーター
この形は更に日学校に行った後の本を
もの
でこの最後の
丸三は更にショートポーズ導入を行なった場合えー
でこれを見るとまー
えー
言語現象の他により認識性能が改善し約六十円
六十．二パーセント程度
テーマ二十一二えーお婆六十二四五パーセントまでまだ二パーセントぐらい差があるのですが
更にこの一二三
後
まー単純に足し合わせて
それで補間し文ですけれど
最大でえー約六十五．〇四パーセント
その
ま四事例とい約一パーセントぐらいの差ですが
ペルージャのみで実現に匹敵するモデルを作成できるといったことが分かると思います
部屋
今のモデルを使ってえーこの語彙サイズを変化さして認識性能を見ていました
え先程早い四万語い
んー
データー果物もお四つえー文読ま語彙を使っていたのですが
祭りでは大体五六万
後一程度が限界であって後出してありますのがま四じゅまー
あー四万語一にして
生活程度の内容まー後まー後えま二十万三十万と
えーえーデーター量はいっぱいあるのでその分語彙サイズも大きくすることができ
でこれを見るとまー
語彙サイズを増やすことで認識性の問題でして毎日一万個一型
ぐらいであ六十二年三
八パーセントとまー
殆どＣＳＪ返さない
書いてないということをどの部分ができているってことが分かると思います
まあーデーター量がいっぱいあり未知語率の解析ん〇．〇パーセントまで改善が可能です
これに別々涙一つは話し言葉用言語モデルを作成歴史以前のみの場合と同等の二世のえーすることができるってことが分かりました
えまた今回作成した言語モデルの考察として各四例が手に出現したぐらいであのソースＡというものを見ていました
でこちらが付いえ二次会
の
はあートライグラムうー学生がん出てきたトライグラムの種類えー
えー
明治時代約三百万ぐらいなんですが
ま今回作成されるでは更に
その辺
で約一億円とか言ってい二億とか
多い
家庭のトライグラムを実際に観測できていました
で実際にえ課題Ａというのは二十一場合
えＣＳでよりこちらが二十一倍で
また
でトライグラムうーの数は四十倍ぐらいということで
えー
全然
生徒が生徒に
えートライグラムをまだまだ観測できる
えつまり頑健なＮグラム確率を推定する為に一つ前の日にはまだまーデーター量が不足して入れてくださってると思います
えー最後にこのモデルを混合した場合の認識性能というものを見ていました
え今回ＣＳＪの皆モデルと別々の三のモデルを作る際のえーこれら混合します
えー混合手法は要ら監督を用いて
チーズ出掛けたモデル後的にデーター量が小さいので四つでもう一倍にしてベルを一
にして
混合しています
でこちらが結果となっていて
この緑は先程まなどはえー説明したＣＳＪで
こちらが
四十何個か四万語い述べ
で
でこれ私はえーとこのような認識性能になり
娘以外ではないんですがこれらをアジアっていうことで
えー
性能が改善しているとは
いうことが分かります
え今回話題の依存性は完全に食べてるので
完全に学習データーがどう対して話し言葉のスタイルがより学習できることによってえー改善したと言えまー
ま娘以外で親と更に改善しています
えー一般的な知見として四つ言えば話し言葉あの体系的には十分なデーター量を今まで考えられていたのですが
今回このような結果から
話し言葉アークはまだまだあー評価することができでそれによってＣＳＪの実の言語モデルから更に二の改善が可能であるといったことが分かりました
えー山と今
えー本
こうでは出る以上の話し言葉データーを利用した内容な話し言葉用言語モデルの作成を検討しました
電話回線レベル文章による体系の七二二話し言葉データーを作成し
え最終的にＣＳＪの約八十代の話し言葉データー欧米から六しました
でそしてこれあのデーターを使ってないけど話し言葉用言語モデルを作成し
えー例から獲得した話し言葉データーのみでＣＳＪに匹敵するえー認識性能を達成することが分かりました
学べるからあ即した話し言葉データーとＣＧ絵を組み合わせることで
ＣＳＪの三よりも高い認識性能を達成しました
でこれらの力話し言葉音声認識の更なる高精度化に後えー劇場の話し言葉データーの内容は有効であることを示しました
以上です
#############################


#############################
# query = んえーっとと音声認識と合わしたと場合のまーえー二場合だとそのテキストをあの話し言葉をそのままなるんですけどそれ一日ま書き言葉の文とはまー書き言葉のものもまデビューから取ってきたりとかま論文のものだったとかそういったものます書き言葉になり付けをするとはだいぶ私形式が違うと言うかそのままではあんまりしないということが音声まそれをうまく分ける仕事あると思うんですけど父の書き言葉と話し言葉をうまく分類と言うかそれを区別する方法についての説明が四第一えーとーもうどういった特徴量使ってるとかはまーといった手法を使ってるとかそういうことをですね
# rank = 2
# slide = 07-15_fix.match_word.jout.txt
# value = -4.46056365809822
#############################
でそれではえー表記のタイトルで発表さしていただきます発表者はえーとーぐらい学校学研究科の山な音ですよろしくお願いし
まず初めに研究背景ですが
えー
話し言葉音声のえー自動書き起こしを大語彙連続音声認識もしまして
で海に六八
二六などを自動的に作成するという研究が
え広く行なわれています
そしてえー話し言葉の音声認識が難しい理由として
えー内容その場で考えながら話してるという特徴がある為に
成分なまとまりのないものになり易い嫌いな理由三四の女とか現われる
といったことがえー
通常のえーこれまで用いられていた方では認識が難しくなると
はい難しくなるというえー理由になっ
でこっちへ制限モデルについてえーまずえー説明いたします系列え言語モデルというのは
えー話題四モデル化するという目的で
で壊されたものでして
えー
特定の話題他した単語出現確率を複数混合モデルという形態を取っています
えー
言語モデルの内部にえー
潜在面と呼ばれる
特定の話題や話し方の特徴にＮグラムのモデル
例えばえー政治スポーツ経済の部分を
えー話題であるとか
あるいは方言の話し方で話している場合英語で話している場合といった
話し方の特徴のＮグラムのモデルの
二．五分持っていますそして
表わしたい話題やえーハムスターの特徴に対して
それらの複数のモデルの最適な混合比を推定して混合することで
で目的の
若いではえー話し方の特徴を持った言語モデルを得るというので
でこの系列で言語モデルを話し言葉
のえー式に適応した場合の問題について説明いたします
まず話し言葉のコーパスというのはえー
ＣＳＪなどが代表的ですがえー広い話題性を持ってるものではありませんので
でそれだけを使ってもえー
話題性を十分明日系列を作ることはえー難しいと考えられます
逆にえー広い話題性を持ってるコーパスとして新聞記事などがあるのですが
こちら書き言葉で書かれてますのでその町をすることはできません
えそしてえーこれを解決する為の先行研究として二千三年八月日に行なわれた方法に
音系列Ａを二つ
用いまして話題の家をですえーモデルと
えー話者性のＰＬ
一えー千モデルという二つのモデルを使う方法が提案されています
えその研究ではえー
認識対象成人関するところ番組の
音声書き起こしという風に設定しまして
話題の言える性を他の改良から
えーそしてまた精度言える性を
ＣＳＪ過程中だったコーパスから学習する方法が取られている
でこの方法でえー問題はある程度入ってたのですがまーあのこの問題点として
えーこの話題の日予選
でもこの学習データーの
文て話が可能性だとは残ってしまうまた
えー
話者性が言える性の方にはえーその適用対象とまー講演の話題性が残ってしまうであると考え
また話題性と話者性のえーっと発話有声音モデル重み付け混合しますのでそちらにどれだけ強く適応するかというのが
これと関係になってしまうという問題
でそこで本研究ではえー提案手法としてえーこういう分割ＰＬ制という違った方法で普通の許すモデルを使う方法
提案しています
でこれは
でモデルの行為四分という考え方をしてまして
えー話題によって出現頻度が変化する声
プロは対応と呼んでいます
でそれから文献によって出現頻度が変化する語
ま話し方や分解能ですねそれを文傾向そして
この二つの影響どちらも県内紅葉汎用思っという風に呼んでこの三つのクラスにえーこういう分割するという
方法を取っています
えー
そしてえーそれぞれ別々にＰＬ性の学習取ってき行なって今
でそうすることで
でまずえー先程の先行研究と同じように同じ学習データーやっコーパスの中にはない
話題え文献他者を適応が容易である
またえー
えー
言語モデルの合意を三つに分割であこれ一つにまとめるという処理をしますので
えー話
最もえー話し方の特徴と話題の特徴
こちらにどれだけ適用するとこれどう関係にならないです六という特徴がある
でじゃ具体的なうえー言語モデルを生成方法を説明します
音系列え言語モデルは学習データーとして空間とは第八文献を接続し地元の
単語出現頻度のデーターから最尤推定を行ない
でそしてえー
本研究で用いてる方法ではまずこの学習データーを
えー話題の
えー話題に関連する母音のみの出現頻度
え文献を
後でえと大量の推定によってそれぞれの行為
クラスだけません本当に
学習データーを分類しますそして
えー若い時えーすえモデルを話者性の家ですので
でそして三四五のモデルこちらはえー
特徴いけないという前提に考えてますので適応を行なわない為にえ二グラムのモデルを生成して
都内に別々にえーモデルの学習を行ない
でそしてえー生成したあ三つのモデルをえーまず話題の並列モデルと
文献二重性モデルをそれぞれ
え目的の
表わしたい特徴が単語対五人とでえー適応を行ないます
そしてえー三つのモデルをそれぞれの行為クラスの
制限確率それぞれの語彙クラスの二分の確率で現われるかという
そこでえー重み付けをして普通の言語モデルに基づくえー取って
ちなみにここにクラスの出現確率というのはえー適応に用いた単語数で変化のデータートライグラム言語モデルを元にして
えーとある文脈の下でえー次に
この三つの声クラスターそれぞれどれだけの確率で現われるかというのを
え設計するクラス出現確率を推定モデルというもので
求めて
て式の上であこのような形になっていまして
で先程説明しました話題の一え専門データーはえーこの
えーう
え文系ＰＬってモデルのこの部分そしてえー範囲をこの
モデルがえー
この記事の方となっていましてそれぞれの
言語モデルの確率を
えー
あー文脈列とえー直前にいたもの後ろに
それぞれのクラスター現われる確率で重み付けしてえー混合数で計算をして
でですが実際にはこの三つのモデルの
えー語彙が完全に分かれてますので
えーこの
例えばＷＹＩ目的田んぼが
えーと話題語であった場合はこの話題語の並列モデルだけ確率を持っていって他の二つの確率が〇には
という状態で
三つのモデルと劣化を選択的に使っている状態
で次にえーその前の文型を履い用語の分割基準について説明をいたします
で基本的には高いものを持っている品詞分類九十二種類を
この話題文献範囲の方もえーそれがに分類するという方法で作っています
えまず
最初にえー
このえー九十二種類の分類を一の判断で
それがに分類するという方法で
二ページにこのような分割基準を考えることができます
話題語はえー一般名詞は固有名詞など
文献はえー情報を指示代名詞フィラー間投詞など
でソースｉに主に私はえー
文頭文末記号学という
ような考え方でえー基準を作ってことができます
別の人の判断で作った記述文がやはり間違いを含んでいる可能性もありますし
えー山も掛かるということでこれを
えー統計的な方法で生成できないかということを
考えました
えー品詞分類ごとにえーその品詞分類側帯に対してどれだけ関係性があるか
文献に対してどれだけ関係と思っているかということを統計的に測って
でそれに基づいて
えー分割の基準を決めるということを検討して今
でその為の
方法として整理情報量に基づいたあー語彙分割基準の生成ということ
で本研究で行なっています
で頭情報量というのはえー二つの確率分布の間で
えー科学大和説を二つありましてその
えー
月の値を足し合わせここで二つの確率分布の間をこちらから見ても
取り出すとし距離尺度行なうようにしたものです
四百五名の形になって
でこのテレビ情報量を
もうえーっとこのこことここで求めたと言いますと
ある決まった品詞あ一つは品詞分類の上での
えーっとその記事
ある決まっ多分今日もえー生地の上でのそのクラスの
単語出現確率の分布
一方もう一つにえー学習データー全体で見た場合のその
別クラスのおー
えー確率の分布というこの二つの分布の間がどれだけ
距離が一八分の一で情報量で計算
つまりえー
晴れて四分類の上で
でこのように全体の平均の分布となっているであるえ二グラムの確率分布と
しまった話題や文献の特徴を受けている
五つの記事の上での確率分布これがどれだけ違うというのを
計算していること
でこれは基本的な特徴量としましてえーまず
えー
若い構文敬語と
三四五
でこの二つ
三種類にえー分離する方法を考えます
で先程の距離をえー一グラムを構成して全ての記事について
えーします申しますと
えー
後
その品詞分類の範囲を後であった場合というのは
えー話題の特徴文献の特徴を持ってないつまりこのような生地の上でも
えー出現パターンは変化しないまずそういうことで
このように
えーこの図で言うとこのばつ印とがえーやめて
まず一つの記事がえー同じような位置にある距離が近い分布をしているということが考えられます
逆にえー話題にこうやっ分布英語であった場合はそれぞれの記事のモデル固有の特徴で出現パターンは変化しますので
距離が遠くなっている
ということが考えられますつまり
えその平均値が
高かったものは若い子が不一語である
提示耳が低いものがハイ四五になってるだろうと考えることができます
えそしてえー同じような方法でえーと話題語と文献を分離することを行ないことができます
で今度は事前に文献のこともあると分かっている二種類のコーパスを考えます例えば
えー書き言葉の新聞記事と
話し言葉のＣＳＪでえーあります
えーそしてえー例として
話し言葉のえ二グラムでの確率分布を
書き言葉の上での一つの記事の確率分布話し言葉の確率という風に
えー
この二つの距離を測ること
考えますと
えー同じ
文献を持っているものはえー文献のクラスであるとですが
多分Ｋ語では
えー
同じような
文献の特徴を持ってますので出現パターンも似ているつまり距離が近くなるだろうと
考えられます
一方
書き言葉と話し言葉というように違った文型を持っていた場合は
でこの距離は遠くなる
と考えられます
でそしてまた英語であった場合はこの同じ二つの距離は掛かったらどうなるかとか
言いますと
こちらは体制が一しない限り単語の出現パターンを変化するだろうと考えられますので
えー
この二つの距離がどちらも多くなると考えられますつまり
同じ種類のコーパスに対する距離と違う種類のコーパスに対する距離で
距離の傾向が異なってくるものが文献をじゃないかと考え
全体まとめますとえーこのような
ことが考えられまして
えー話し言葉の
えっと
書き言葉の生地
書き言葉のＮグラムと話し言葉のＮグラムで
えー四つの確率分布を考えることができますが
でその間である四つの
距離が
これも大きくなるものが話題こう
それも小さくなるものは汎用そして
えー話し言葉の記事をえー話すことも年話し言葉工学部というに違ったもので掛かった場合で傾向が異なるものが分敬語であると
ということでえー
えー
計算のし方としましてはえー
この四つの距離尺度のえーその逆数を取りますつまりえー距離がどれだけ小さい方範囲を御覧さを表わしていると
でそしてえー違う記事で測った
夏の距離の差分の事情は
えーつまりこの図で言うとこの話し言葉の指導話し言葉と書き言葉の処理の差分を計算しまして
でそれが大きければ大きい程文献クラスターが高い
のようにして何を貰った文献コーラス部尺度を定義して
えー実際にえー
各品詞分類について
え実験を行なっていました
でその結果が
こちらになっていましてえーグラフの横軸が三四五月二十二語が文系コーラスたいなって
そしてえー
この赤いで一つ一つがあさせるので自分で九十種類の
えーと二一つに対応してます
具体的にどのような
分類であっがえー現われていたと言います泊まったような差が非常に高かったものが
女性の連帯が
何々のももですね
それから六十四などが非常に高い値を示しました
えーそして文献は差が高かったものが
えー二の一二五乗法性とか後何々の四五にえー
でそれからえーピアノとも高い値を示しました
そして二つ共低い
値となる傾向だったのが名詞のさえー接続や
固有名詞などえー話題性を強く
反映してると思われるものは
でこちらの体も小さくなるという傾向でした
でそこで
えーこの配慮を網羅さ文系コーラスの閾値を
このグラフの
の音を聞いておりませんですま閾値を設定しまして
えーグラフの上で
二十されているもの
はい用語のクラス
左上に出るもの文敬語のクラス左下を若い方のクラスター
このように考えてこい分割の基準を生成いたしました
その結果得られるのがえーこちらの表です
えー最初に示しましたその判断で暫定的に決めたものに非常に近い
えーものが得られています
えー多少変化したものもありますでこのことが斜めになっているものが
その判断の基準からえー分割される
クラス係ったものですが
えー若い方に接頭辞や接尾語が
分類されたこと
でそれから文献をにえーっと音声は全て文系行ったことなどで若干の違いは
えー生まれて
家では以上説明しましたこういう分割形成言語モデルの評価実験の説明付けます
えー
言語モデルの語彙サイズはえー三万語彙のもの生成しましたデーター中データーに用いたのは
で話題性をカバーするコーパスをして毎日新聞の二千えーっと話者性をカバーするものとしてＣＳＪの学術声も聞こえ
会話を使って
でそしてえー
ほい分割系列Ａのえー三つのモデルそれぞれの
ボイス形態素数は御覧のようになってますが三これは
えー情報量基準で
えー
これ羊を決定した場合の
えー
条件となって
そして評価尺度にはテストセットパープレキシティーを用いまして
えーテストセットには
ＣＳＪの模擬講演の中にある現在から過去数年前です雑誌などで扱われた人
というものをえー百五十二個えー用いて
でそしてえートライグラム従来の日えー千モデル
そしてえーこの分割生成の種類えこれは
最初に示した一の判断で基準を生成した場合と
情報量基準で分割基準を決めた場合二種類でえーこの八つのモデルについて
学校行ないました
実験結果です
で左から順にトライグラム従来のＰえーせ
ほい分割平成でえー基準は人の判断で決めたそして情報量基準で決めたもの
このような結果になりまして
えー情報量基準でこういう分割を決めた者が最も
良い結果を示しました
従来のＰＬ性と比べますと四．五六パーセント
パープレキシティーの改善が得られて
で次にえーこの言表を認識実験に適用した場合のえー実験について説明いたします
えー
を言語モデルをＪｕｌｉｕｓに直接使用するといます
えー難しかったのでえーまずは
でベストリスコアリングによる認識実験を行ないました
えー認識エンジンとしてはＪｕｌｉｕｓを用いまして音響モデルにはＣＳＪの底の
確実も結構いてありモデルを使っています
そしてえートライグラム言語モデルを使ってま高い認識を行ないまして
えー五百別そのー
認識結果高校生六させますそれを
でこういう分割基準線の
言語スコアでえー
一五人をするという方法を取っています
体のリスコアリングの際にはえーこの
えー言語モデルの効果が強く現われるように
言語重みと挿入えー内容通常のＪｕｌｉｕｓのデフォルトの間に場合に大きめに設定してあります
認識対象としたのはえー
先程の
パープレキシティーの評価に使ったテストセットから一個の講演を選択して使って
実験結果ですがえーこのようになりました
えーそれぞれ一本もテストセットの
えー物理量がトライグラム
のかいえー認識結果の時点でのワンでその
認識精度そして青がリスコアリングを行なった後の
えー認識精度行って
そして順番にそれぞれのテストセットのてこのテストセットそれぞれの結果となってまして一番いいか平均値です
ま結果としてはえー
六十四．四五パーセントがリスコアリングを行なって六十四．八五パーセント
えー改善したのが〇えー三三パーセントということで
ま殆どえー結果としては変化が得られないというものになってしまいました
えーテストセットごとに見ていきますと
えー要因もので〇．七パーセント程度
改善
せまして逆に悪化してしまうものもの
ものもありましてそちらではえー
で七パーセント
何かすると
まそのような結果になってまして
全体を平均するとあまり変化がなかったという結果です
でなぜこのようなえーあまりであった結果が得られなかったというところなんですが
えーまず
この
五百ですとこのリスコアリングというこうもう頭があまり適切ではなかったのではないかと考えています
財はこの五百別分布の子が五グラム
政府で選ばれてますので
えーその
えー一文よりも
より分ぐらいで見て認識精度の高いものが
二日五百以内なければならない訳ですが
えー実際に
えー
認識精度が仮説はあテストセットを見ますと
この一文より良い文というのが二回ない
という
傾向が見られました
でまたそれ以外にも
この右側のグラフというのは
えー横軸に
えー
テストセットの正解文
を使ってえー海認識に用いたトライグラム言語モデルのパープレキシティーを計算下を通っておりまして
縦軸には各テストセットのリスコアリング前後での認識精度の変化を取ったのですがこのように
元々えーパープレキシティーが高かったものが書かせしまっていて
良かったものについては改善が得られてるという傾向が見られました
でこのことからもえーこの仮に二つの
トライグラムにえーリスコアリングの結果まで
国際されてしまっていたのではないかという
えーことを考えていますその為えー認識の適用方法に直す必要があるのではないかと
現在考えていましてえー
文内のリスコアリングではなくてえー単語グラフの上でリスコアリングを行なうという本やあるいは
気凄いのではなくてえー文脈適応したえ一重性をバイグラムやトライグラムに変換して
知らずに直接与えて
小するといった方法が必要なのではないかと
いう風に考えて
でまとめます
で本研究では話し言葉認識の為にえー話題と文献の特徴それぞれ
えー独立して適用できる言語モデルってものをえー研究しております
方法としてもい分割と言える性言語モデルというものを提案してして
紅葉は大部分て後半用語のす二月に
分
でそうすることでそれぞれ独立な適用が可能になるというものをえー提案しています
またその語彙の分割基準の生成方法に
えー統計的な特徴に基づいてえー文献コーラス範囲を網羅さというものを
数値化して求めましてそれに基づいた基準を作ること行って
必死でその結果えーパープレキシティーの評価では従来のものと比べ四．五六パーセント
パープレキシティーの削減効果がありました
またえー五百ベストリスコアリングで認識に適応した場合
えー〇．〇三三パーセント認識精度を書いておりました
で今後の課題としてはえこの認識への適用方法があって適切であったと考えるのでそれについて検討したいと考えて
以上です
#############################


#############################
# query = えーととー自動要約とかそういった研究も進められているようなんですけれどももうえーとま音声認識とかした場合と特にんまーま話し言葉んま話いったあ内容に関係こう祭られたとまー書き起こしてもまーどこは重要なむものかとかそういう言った言葉つまりよく分かんなくてまー重要な部分だけをまー抽出したりということでも重要文というものをこう本て判定するのかまー凄い一四分こと人もは凄い予測をしたりしてもそれ要約をするんじゃない人気があると思うんですけどもそういった重要文後えーとま海付ける時にまー特徴量と言うかも見るとあると思うんですけども何ことが今日量をどんなますけど付けをすると思うんですけども時に特徴量のニュースかって言うかとま手法をどういう風にやってるのかいうことはちょっと具体的に入ってやるところがもう小さいとえー
# rank = 1
# slide = 09-18_fix.match_word.jout.txt
# value = -4.11146245572061
#############################
まーそしてえ人手による重要文抽出実験
次に重要でそこに基づく要約
そして最後にまとめと課題となっております
この二番の後でよる重要文抽出実験と三番の需要予測に基づく自動や
二の二つの話題について発表いたします
でまず背景ですが近年第四四記憶装置が広く普及し
んーそれに伴い大量のデーターが容易にまた
パスタ用に伝達蓄積されるなりました
生かしながら蓄積データー増大伴いましてえ必要とするデーターが瞬時に
取り出すことは困難となっております
その為データー検索や自動要約などの技術が必要となっています
その為に本研究では重要文抽出による自動薬を行ないます
私自動要約手法の開発が評価におきまして
それによる重要文抽出結果が必要となります
ここでえー日本語話し言葉コーパスＣＳＪではあ三名の被験者による
要約再現基づいた重要文セット働いています
安い
それによって中された重要文は被験者間で必ずしも
高い一致度を示すと分かりません
そこで安定したというような結果が必要となります
そこで本研究では多人数による重要文抽出実験を行なうことによって安定したよって言ったらえらいことをいたします
また
そのー
一つ実験よって得られた重要文
の被験者かとまたその実験者グループでしてそのグループ化
うちの評価を行ないます
次に重要でそこに基づく字要約を行ないます
これには例文の一つでし
そしてその文の重要度昨年一情報利用することを考えます
それではまず人手による重要文抽出実験について
八説明いたします
本研究でＣＳＪは日本語話し言葉コーパスのデーターを用いましてこれは学会講演と森公園が九十パーセントで構成されています
本研究で用いましたら模擬講演の方でこれ一般話者による日常的話題についての二分程度の声使っておりまして
百七十七公園に重要文抽出結果が取っています
これは三名の被験者によって行なわれ二パーセントと五十パーセントの要約結果の程度
私
排気量の様子はえー重要文抽出したした結果がえー被験者間で高い寄与を示す分かりません
そこで
何ずによる重要にです
抽出実験を行ないまして
安定したえ人手によるには結果を出します
その注意した結果のえー重要文一の評価の方を行ないます
これはえー被験者が
とまたその実験者を
二つのグループに分けてえグループとそのグループ化
で評価を行ないます
また
大人数による重要文抽出実験を行なうことやりまして
はい
定量的な文重要度を算出しそれによって自動訳の
評価を行なうことができます
それは重要文抽出実験に使用した音声データーについて説明いたします
え今回使用した音声データー二つありましてＣＳＪ
あの二十模擬講演
そしてえー情報論
テレビの頃テレビのニュース解説番組良いでしてそれを二十個えー行ないました
この二の航路のデーターを用いた理由としまして
えＣＳＪは模擬講演ということで
えーこれはえー本当に伝えたい情報話せるかどうかに疑問があるということで
二心データーと比較をしたい
ということで二の頃用いました
この情報論
もうテレビニュース解説番組は
えーニュース解説委員にあるという問題化するＺの番組
あの内容となっています
ではその重要文抽出実験行った被験者ですがこれは二十名
んでえー要約率は約一パーセントで抽出一で挙げました
それは採用手順について説明いたします
まずえー講演音声を二乗値をすしてもらい
最後音声を聞いてもらいテキストから重要付加を二日で推定しましていただきます
そしてその抽出した区間が発話に含まれるはその発話を重要分類です
この発話っていうのは二百ミリセカンド以上のポーズで区切られた空間でありこれはＣＳＪでもその
方式でえーデーターの保存されています
では実際にその実験に用いたツールの説明をいたします
でこちらがえ左が一に発話番号
発話時間
発話内容となっております
猫型と判定したものがあるんですけども
え重要度をは
被験者が判断した場合にここを取らすることよって
でも二型と判定いたします
またあー方法の感覚なところをダブルクリックすることよってえ重要文の取り検証することもできます
これお母全ての発話に対して行ってことに四三重要文抽出
の資料とします
またこの後にログファイルを見ることによって
えどれぐらいの要約
率を達成したかということが通じることもできます
では次にえーグループ間で評価を行なう為に以下の作業を行ないました
メンバーは二十ならないようにえー一グループ二のグループを二作成いたします
次に各グループえ三人の被験者の結果を用いて文ごとに一を考察します
その重要度はえ一グループの被験者数
え例文の
重要文として駐車被験者数で三つつあれ
この文ごとにえ算出した重要を
後は上位約一割を重要文として二世達は
でまーそのー
評価
んでを
評価の為の評価尺度としまし二つ利用いたしました
まず一つ目が重要文指導Ａというものを使用いたします
まずそれぞれのＬに対しまして二グループを尺度をえ作成します
今度経営は一から一
そして次にえー各二グループ間の重要文指導を求め百これは平均を算出します
解き
一分一度えーは以下の式で
三つあります
こうできてＳははグループ一で決定され重要数
で次がグループ二で決定された重要文数
でそあのー二十一二が四グループに共通する重要子育ては
公的えーＸバーを用い正解
とするデーターと皆するならばえはは適用り
体には再現率
例はＦ値と同じモデルとなっています
三つ目の評価尺度としましてκ値を採用しました
あ町は二つのデーターの間で六で一致する割合を除いた
一致度を示す指標であり百データー二つの至っては
まこちらこちらがこの式によっ計算されます
ＰＡは実際上データー間で一致した割合を
ＰＴは行く前にえー音声データー解析する割合を表わします
ではえーまず重要文一声による評価の方御説明いたします
量グラフ共グループ人数
で四グラフの横軸がグループにずえー
であり縦軸が重要文一度えー
です
下りがＣＳＪのの結果第二三四五ですねその結果あありましてえーまずこの
発見のイコール一
この時は被験者間によるえー評価なんですけども
それよりもえー一日二二二乗
グループ化あの父の重要度一の方が高いことが
隔離されます
また
グループに頭ｎが増加するにつれてどんどん重要もう一度も増加してることが分かります
今回えーニュースから
この時ニュース解説のこちらデーターよりもＣＳＪのデーターの方がえ重要文中度が高いことが
特にされます
これはえー被験者に聞いたところえーＣＳＪは一般話者による日常的話題に
ついて話しＬへ
対しましてえーニュース解説は
提示問題を一二の番組まとめ挙げたものである為に
えー重要でないと判断する箇所はえー
少なかった為と考えれます
次にえーκ値による評価です
形より心の中でも
このＮイコール一の被験者から×も
えーカイ二乗のグループ間の力の方が一
形がえー一な形でこう風にされます
またえー
形がこう〇．二帰ってよ×家であり適用されてるかモデルということでえーこれは安定した
重要文抽出結果が得られたということですねまー
では次の話題としまして一予測に基づくう条約について説明いたします
んー
まず音声自動約えー事例について説明します
えー計算機による虫は声の意味理解が容易ではありません
その為に中央値ですね暫くやって非常訳行っ研究な記録行なわれており
本研究でもそれを採用いたします
まず音声から韻律分析を行ない
韻律情報を生成し韻律特徴量を算出します
また
音声から音声認識を行ないまして
言語情報抽出し言語特徴量を
たってしまっ
これは文ごとに
一ついたしまして
ん重要度を
部分発話のことですけども文集を算出します
この文重度三四八とえ
ここから上位一割
をあ重要文として抽出しゅ要約テキストの過程とします
ではあー先程の文の重要度を算出うのところのえー
算出方法なんですけども
えーっと口の組み合わせ
え重回帰分析を行ない
行なうことを採用します
この重回帰分析によって予測された値
あの上位約一割を重要文として話します
倉敷の説明ですが
この場合事例というのがうち二十代の
文一予測値
でこちらのＸ掲示で
がえー一発話文の抽出した
えーＫ番目の特徴量
でこちらが回帰係数でありえーこのα系がえーこの各
抽出した特徴ように掛かる重みとなっています
で
っていうのが組み合わせる特徴腰痛
私当てることによってえ予測
それ重要度が算出されます
では実際にえー一予測の為にえー特徴よ
かつて読書につい説明します
まずえ言語特徴量をこれはあーＣＦはＩＤＦに基づいたあ重要となっていて
次に発話時間長
そしてえー韻律特徴量を
この四つありましての
音素時間長
基本周波数ポーズこのそれぞれこの種
ガラス熱はこの高さに感情取られています
本研究では言語特徴量ですとしたペーストしえそれに発話時間長や
体に測定を加えることによって精度の改善を持っ
しまっ
ではえー言語特徴と発話時間長について説明します
言語特徴量を
あっとしましてえー形態法を用いました
テーマＩＤＦはこの式によってえー算出され
多分これ苦しいとして
一講演で出現した単語の回数
立てないとこれクエンシーとして
一講演データーをが出現した発話数
ボールドキュメントブレークえー四として一講演の点発話数
そしてえー発話構成する
各単語のＴＦＩＤＦ
あのおその発話の特徴量として用います
次にえ発話時間長ですがこれは一発話時間長をそのものを
その発話の特徴量として用いました
では次に韻律特徴用法は一で説明いたします
そのー
え自然にまー数をえーと発話した場合にえー絶対的なまーあの
値に差があることから
でえー各音素間で
正規化をこの式を行ないました
んで
この後の特徴としてえー以下の四つを算出しました
戦後で発話九九七五発話で聞いてくれて
そしてえ最大値
最小値幅を算出し
この最大値というのはえー括弧その発話内で構成される放送を
のその音素のえーっと新たな一番ていう形のもの
をえーその発話の特徴とします
最小値はあ最大値を逆でえーその発話内で一番あーの値の小さかった
えー
値をえー発話発話の特徴と周波まーはえー最大生きていくうち最小値をそのー
特徴とします
次に放送時間長ですがこれもおーまー同様にえー音素間でえ推定を行ないまして
一つ特徴量もえーパワー同様に前後に発話含む発話減って
から対象とする平均を引いたもの
また最大値
最小値のはを算出いたしました
次に基本周波数ですが
これはえーっとお
男女間や個人でえーこの立たされ下がるということでこの式によって正規化を行ないまして
えー生成した特徴量は
場合放送時間長同様にえー前後に発話含む発話平気で出てき最大値最小値幅を算出しました
最後に一特徴用の特徴としましてえ構造時間長
これはもうもう一巻の
えー長さことでありましてえーっと発話が発話の間に挟まれるポーズ時間長はありまして
そのポーズの長さを前の発話の特徴量とする
の方図一
えー後ろの発話の特徴とするのポーズに
としました
それでは
で特徴う組み合わせ方ですが
でこのリングってのは言語特徴ようで
えー例の発話時間長下ろすってのが韻律特徴抑圧
で
この
えー言語の特徴のみでえーまず
重要度を予測したものが四〇
次の
え言語特徴量と発話時間長で即した者はえー四は
んで言語特徴よと発話時間長と韻律特徴よ
んでえ予測した者が四つとなっています
この括弧内の数字はえー組み合わせる特徴数の数を表わしています
次に
この音声認識っていうのはえー実際システムでえー字要約を行なう場合にえー発話内容を音声認識で決定する人があります
その
音声認識に基づいてえー算出された特徴量を例九
そして次にえー
ＣＳＪにはえー人手によって
先程それだけではありますのでそちらの方からもそちらに基づいて
採取された
特徴量が半島
九六種類の手法によって
対しました
とか実験ですがえ今回使用したデーターはえー
一一よる重要文抽出実験で一を
もう一つは多分私Ｓで四十六声を使用します
動画としまして交差検定等を
クロスバリデーション用二度体を行ないます
二十講演九十九効用学習データーとして用いまして
残り一講演を評価データー
でも
評価します
えとこれを繰り返している
それぞれの公園や
対して起きることによりえその平均を算出します
で要約率は二パーセント三十パーセントで行ないました
で次にえー
え評価尺度ですが
で今回は１．四一一
文中で重要文抽出実験結果が
答えましてＳ１が一で決定された重要文数
普通にがあ自動決定された重要文数
鉄はまたすええ常になり両方に共通する重要文す
で今回この五番の一例に決定された重要文をすを正解
データーとして見なすことができますので
二番が
適用率
体にはえ再現率
ってがＦ１と見なせます
ではえ評価結果ですが
えー
こちらの
ここの図がえー要約率二パーセント
こっちの図がえー百三十パーセントです
横軸ですがこち
このおここは音声認識意味が一でこちらを知らせる
で
えー嫌いか一年四〇一一大人に変わっています
縦軸は重要文一度
で未知となっています
でこの時
この要約率二十パーセントの時よりも
三十パーセント酒の方が重要文中度が高くなってる音北にされます
また
約三十パーセントの
Ｃ２のえー舌下の方は除きまして
えーん言語特徴と発話時間長が組み合わせるよりも韻律特徴量を加えることによって精度が向上することは不にされます
また人手による
基づくよりもえー音声認識も続いた特徴よくあることにあった父の精度の向上幅も大きいと言えます
ではえー
先程の結果を公演ごとに見ていきますと
これを
以上グラフ共横軸が講演番号一回二十
で縦軸があ先程と同じでうち
でこちらの選手旅行
こちら図なってるかと
この三図を見ますと
えー講演ごとにえー
二つ特徴を加えることによるえ改善するばらつきがあることは確認されます
次にえ評価結果要約率三十パーセントの方ですが
後三十パーセントの方も法によって精度の改善法ばらつきがあることは確認されます
この要約率二パーセント三十パーセントの方両方二
合わせましておよそ七十五パーセントの講演において
言語情報言語特徴の時よりも言語特徴ように発話時間ちょっと
韻律特徴洋服は一型の方が重要文中度が高くなりました
ではまとめと今後の課題ですがえ重要文抽出実験結果の一致度を分析比較いたしました
有権者間で
重要文一度はえー使ったのですがグループ間ではえー試合一文一度は得られ
ページ条約の開発え評価に
んえー信頼できるデーターである方は確認されました
またニュース解説よりＣＳＪ文字声の方が高い児童が得られました
んー
次にえー二つ情報を用いた需要予測を行ないました
電子情報を加えることによりえー音素七十五パーセントの公園で精度が向上し
言語を特徴ようにえー韻律情報を加えること
による
っていう要請という訳に対する重要性が確認されました
また人手ラベリングよりも自動ラベリングにも続いたあー重要予測の方があるんです情報を加えたことによる精度の方で幅が大きいと言えます
では今後の課題といたしましてえ重要文抽出に有効な特徴量と語ら文一文を予測手法の検討を行ないます
また
次にえー先程の講演ごとのグラフを見て学校
えー一二つ特徴を加えることによる
えー重要文指導の
改善
というバスであるということで
えーそれは
各講演によって要約い有効な特徴量が違うのではないかということで公園
そのグループ化を思い出してきます
以上です
がございました
#############################


#############################
# query = えーととー自動要約とかそういった研究も進められているようなんですけれどももうえーとま音声認識とかした場合と特にんまーま話し言葉んま話いったあ内容に関係こう祭られたとまー書き起こしてもまーどこは重要なむものかとかそういう言った言葉つまりよく分かんなくてまー重要な部分だけをまー抽出したりということでも重要文というものをこう本て判定するのかまー凄い一四分こと人もは凄い予測をしたりしてもそれ要約をするんじゃない人気があると思うんですけどもそういった重要文後えーとま海付ける時にまー特徴量と言うかも見るとあると思うんですけども何ことが今日量をどんなますけど付けをすると思うんですけども時に特徴量のニュースかって言うかとま手法をどういう風にやってるのかいうことはちょっと具体的に入ってやるところがもう小さいとえー
# rank = 2
# slide = 07-03_fix.match_word.jout.txt
# value = -4.41425946412985
#############################
でそれはえー表現を題目で発表させていただきます
えーまず本研究の
えー
んー
でまず本研究の背景についてえー御説明いたします
まずえー近年のネットワークのえーよ第四四回伴いましてえー四つなこういう話といったこう人ビデオを
で配信しえー学習者がえー
白人自宅で
で一周できるようなシステムには人のシステムはえー研究初めてえー
えーただしえー
す日本人ビデオをそのまた一つだけではえー学習者にとって
まーより良い使い易い状態であるということは
いけないと思います
えではどういうものが必要かと言いますと
えー
必要かということを考えたえー
まず考えられるのはえー書き起こしのテキストのえっと
えつまりこれは話し言葉をえー書き言葉変換して
また文の国えー
得点二にえまーそういう処理が必要であると考えます
またえー高二の要約
予約でしたテキスト
あるいは音声
要約音声のえっとー
またえーキーはどうやっ一つの選択によるえー
本においてはえの
なん何な私です
そしてえー利用者すインターフェースこういうものが必要である
いう風に考えてえー
で例えばこちらはえー
質のいい自分で全然できるソフトウェアのえー
けれども
えー
左上の方にえー収録うーしてるゆ収録した後においては
の映像が現われます
そしてえー一会社の方にはえー
材料をあのタイトルなあー一番として表示
誰も
えーっと
そしてえーこちらですねこちらがその時このビデオの
実験で表示されています太陽の豆が
表示される
でこれをえー
今はその中で使って言うんですけれども
使用して言えばえー後程
これを二からえー再生して学習することに
えーそしてえー
でえーっとー
この先程のいえーデーターをちょっと改良して
ではらの研究一でえー作成していうのは
えー音声認識を行動に利用した教材のえー
教材ということで
まこちらの画面は先程と変わらないんですけども
こちらにま要約
えー先でのちょうどたちますけども自動要約による結果を用いて
えー要約率を自由になって後はそっ
いうのは再生速度ですけどもそれをコントロールしてえー再生できる
いう機能を設けました
またえーこちらについはあのーキーワードからのインデキシング
つまりこのキーワード一つクリックするとえーその言わばあーなされている部分をえー利用者させることができ
昨日も
受けました
でこちらが先程とま言っても同じスタイルの画面の
けれども
話者にもついはー
えー三四のえー岩がなされている一Ｎちゃんの機能を
受けて
そしてこちらの方に要約文の位置が
が表示されて
今現在二十歳付い
えーはえー早い適用されると
いう機能を
得ました
えーでまこういう教材を
く〇という目標があるんですけれども
ま高校で必要となる要素技術として
まず方に音声の構成同じようにし構成な自動認識がまず
ように
えー
まずえー
まずえー最初のトピックとしてえー
構成同じように
の為に何か
何を調査する必要があるか
いうことで
まずはえー収録装置デコーダー音響モデル
が違うこと違うとどのようにえー収録
えーした音声の認識精度が異なってくるか
というその影響の調査を行ないました
またえー
場所装置幾つかあまりえー三種類を
えー
帰っえー三種類で
記録したんですけれども
つまりうーことに開きがありますのでそれを正規化するにはどうしたら良いということでケプストラムの正規化法を書き
試してえー結果を比較しました
またえー
えーとー研究室で開発してえーコンテキスト依存せず
音響モデルと
いうものを使いまして
二十一からなる構成おかお分かりましたその結果について報告し
えまずえー収録装置でこれは音響モデルの比較について
ん私まー
えー
んでま先程上先生からも発表がえー
御紹介いただいたんですけれども
とー大学にはえー三種類のせいで収録装置で
講義を録音しています
まずえー素性としてえー指向性の販売こういう先生だっていう
でえーとー整備いたしましてえー
優先の決まり
これもなったニュース
でえーとすＣとしてマイナス一枚可能性を
えー無線であそこに飛ばしましてえーそこでえー食べえー圧縮を掛けて
どんな部屋主人はえーまー
二十年前データーの
えー
実えーソフトウェアでえー食べＭ３に圧縮される為
このように
んー
えー
でえーこのおーソースＡＢＣについてですけれども
また
えーシステム一二三
を用意しましてえー
デコーダー音響モデル
について比較を行ない
二十一．六一と二を比較することで
デコーダーの比較を行ないました
二つ三つとしてはえーこう何あ本研究成果されているそうです
システムににはえーＪｕｌｉｕｓ三．五
塩
で
こちら音響モデルの条件としてはシステム五人共同じ
えー百三十三音節モデル
言語モデルとしてはえーＣＳＪの二千四年のワンから学習した
一万七千語彙のえー
言語モデルを使用して
システム三としては
私一二と三を比較することで
えーこちらの二つですけれども
音節
百三十八三音節モデルとトライホンモデル
この二つの音響モデルを比較することができま
えー特徴量を
ボタン特徴量としてはえー
ま音声は一キロヘルツでサンプリングしておりましてそれを一に自然の
ってＭＦＣＣで対面してきてたあをに基づく
でえー音響モデルはえー混合数三十二
で音節数
モデルでは
状態で三から五え環境分散比を
この条件は殆どこの
えー
音が収録した後に音声
についてえー
ほ紹介しますけども現在前にえー六話者一一本
主に情報工学分野情報工学の方について収録しました
ポストの中から今回テストセットとしてえー認識の為に利用した方には
えこのようにえー四旅行に行っていますでそれぞれどこには前半後半
で表記はえー一番上の方になの前半が一の一後半の一のこのように表
で今
で話者は三人で
えー
でえー今日とに
それからえ音韻特徴について少し述べますとこう二つには
でパープレキシティーがえー体でこのようになってんですがこの後半になると少し
増大して今
でこれは話者はえー
他に後ちょっと疲れてくるのか
と思うんですけども他の発音なま木やえーそういうものが多くなってパープレキシティーが増え
という予想は
歳の
またえーこう日本に関してはえーパープレキシティーが
全体的に若干高めにありますが
はえーパターン認識の分野でえー
言語Ａには接辞を用いてえー二つのパターン認識の分野が入っている為に少しその面から外れて
え未知法律もちょっと高めになっている為ではないかと推測され
でえーこのおーこれあのこう二音声に対して認識実験を行ないましたその結果一らしいんですけどもこちらですね
えまずデコーダーの比較としてシステム一二を比較しました
えー
全体的に殆ど差がないんですけれども
まーえーっとー
えー
自然道が
えー
認識率でえー認識精度データーが持っているもう人が
もう一ということでま全体的にはシステム一が高い
いうことが分かりました
また音響モデルの比較についてですけれども
これもこうによってえーい別に差があるんですけれども
全体的に見ると大体トライホンシステムさんの方が優れているということをまー
また収録装置の比較ですけれども
えーこちらにえー
オレンジ色のまーあのー×
で三というものはえー優先のピンマイク
紫色のがえー無線の
まえーすマイナス一枚
いうことになって
えほぼ全ての本人において
ここと言うか全ての高二において
でハンドマイクの認識率が
あー二つよりも
あーのっていう
一番高いということが
分かりました
ですれた後において一番低いのは無線
のおー今や二でだ件目はちょっとした音声である
いうことが
他に
んー
また話者ごとに認識性能にさんが出るのか
という観点から
見ますと
えー
今回
テストした
音声の中ではえ話者Ａ型の認識率が一番全体的に
高いという結論になりました
でここで問題点ですがえー話者八四四つを展開によってだいぶ
三分ということが分かりました
でこれはえ実用上不便で大変有名な
いうことで
でこれをえー正規化する方法としてえー今回はえーケプストラムの正規化
学習正規化法
でえー
各種的方法
えー
かなり
結果を確認しました
えー
えまずえ今回えー実験者正規化手法として平均の正規化ＣＭＮと分散の正規化
だヒストグラムの形を合わせてえー一つの分析括弧の三種類を行ないました
後でえー
支援面と四名についてなんですけれどもこの平均と分散をどの空間で求めるかということが
問題になっ
まず一発話本を
えー講演各話者えーというのは
今回は一本一二話者
と考えていますのでえーやっていますが
まず一発話文と音の特徴ですけれども短い発話に対してで私があーすい
低精度が低下することが
考えます
ただリアルタイム性が高いのでえまー
んー
音声を入力してその認識結果ほしいと
いう場合には非常に有効な手法
でえー一方公演ごとではえー区間が長いのでより正確な推定が可能ではないかと思われます
あこれではえー全体の入力回るまリアルタイム処理が
え処理ができないに当たりませんがないという
欠点があります
また話者の色は二十的な変動にはついつい
ただしえー
都会の日本海の方に音声はえー収録しておいて
後でまとめて認識すると
えー施設
文のえー
えーそれの目的ならば公演ごとにすることで性能向上があるのではないかと考えます
えー
でこの実行単位に関する
調査にはついに先行研究がありまして
えーＮＴＴさえ×です研究者の方は下がって
がえー
でこれではえーこの研究では八種類の二．五
打ち合わせ案内の星様一状態一話者五．八つのましたで比較検討を行なっていました
結果としてはえー
分散政治家は
が有効でえー話者ごとの体の効果的であるという
がでした
えー今回はえー
到達ぐらいの係数次にして下の方がこれをおーに音声でえー
えー
えーまず
えー
平均と分散についてはいる
の観点でえー実験を行ないましたが最後に一グラム正規化について御説明しますが
えーこれは適用対象話者のえー
累積分布し字関数の逆関数を使ってヒストグラムを
パーセント
方法で
でこれにより平均分散のみなさい
確率分布の形状させることが
できます
えーここへえー基準話者をどう決めたかという問題ですけども今回は先生のテストセット
まつまり学習データーに含まれない
えー
歌はえー講演のうちその中の一人を選択しています
つまりえー音響モデルの
学習データーをえーテストセット音に音声のデーターも全てこの人に
のえー
五グラム合わせて
実験を行なって
ただ
えーそして学習データーとしてはＣＳＪ二千四年の間の
えー男性話者二分の一四声特徴量は先程と異なりまして三十八次元を用いました
音響モデルは百二十六音節モデル
デコーダーはえーとー経験したスポーツの
バイグラムによる認識で
学校内の
でこちらがその結果になりますが
ま一字ん音のえーＣＭＮをです単位としますと
え話者もっと
洗面熱ＰＫという機能で赤い
えー
おーでえー話者あ社会言語話者ごと青い棒が
上手な本なんですけれども
全体的にえー話者下でやった方が
認識率が若干
向上すると
最大１．九七パーセント向上するということが
分かりました
新しい分散が四分円をつく用いた場合は
でなぜかえ平均の
正規化よりも悪い結果となってしまいました
この原因はまだちょっとよく分かっていないのですが件中にはこのようにえー
えーそしてヒストグラムの正規化も行なったのですが
んーこちらもえー
ベースラインであるえー一は三音のＣＭＮよりも
全体的にはいい結果となってマスコミによってはえー向上しているでも
ありますけれども全体的には
笑って
いう結果によってしまい
えここでまとめますとえー一月の楽しめる場所無声音では
話者元の生命の方はあー良かっ
ということがありました
私故にはえー一字音の支援面よりも悪くなってしまいました
まヒストグラムの政治家はえー方によっては効果がありましたけれども
平均的には一発話文との支援面よりも
悪い結果と後ま
えー次にえーコンテキスト依存音素ＨＭＭ
によるスコアリングというタイトルでえーちょっと御報告した
でこれはえー
四状態四校の音響モデル
なんですけれども
えー
コンテキスト依存というのはえー直前の音節を考慮して
学習して
えー撥音とえー文法のあのー
えー
ショートコースとして一つの文
×えー百一音節で千九百二十八このモデルを
作成しました
んー
そしてえー
これをこのモデルをえー発話本を
後えー面を用いた
えーコンテキスト既存の格ですと
先程出した実験結果
ですけれども
それに対するリストにスコアとして使用してえー表の効果があるかということを調査しました
えこちらがその結果ですけれどもま全体的に結果は良くなって
実際には二．０７パーセントぐらい向上しました
んでえーコンテキスト依存せず音響モデルは精度向上に有効である
一九八
えーって
結論ですが
場所元のＣＭＮはわずかながらんー考えました
あ推定分散を使うと予め
でえーっと一グラムの性格をこうによった方があります
でえーコンテキスト依存節の音が性の向上に
まずあのーあらゆるこうでありましたいうこと
え次にえー要約とをえー資料四分に重要文抽出要約を
自動インデキシングトピックに分割について
報告いたし
まず要約ですけどもえー．一四分の一つの形で行ないました
これによりえー
予め音声を分析にいー
えーっと認識結果と音声データーが重要箇所これはこの文が重要であるということを
判断し
その音声を提示しま
そうすることによって認識誤りによるに
えー利用者の解釈を顕現することが
えー
重要文の抽出方法としてはえーこのような特徴を持っていました
韻律情報と表層的言語情報
ありますけれども韻律情報としては
え〇の平均の高いパワーの平均の高い文なのはえー
表層的言語情報としては
一般的によく広く用いられている家やまたはスタイルの情報二四のおー
そこに
で使用された世界の中の音一三を含む文
まそういった情報二
分
また予め
これは明らかに重要でないと
判断すれ
ちょっと特徴として
えー〇パワーの平均が低い発話時間長の短い
などをしまして
そしてこれらの特徴を組み合わせて部分の騒音を使わだし
そのスコアを相手から
えー重要であるという
え四十八分の一の二含めて
また
この要約の評価方法ですけれども
えー
検索ね
えいずれもこの高二の方目に明るい
えー指揮者の方達に六名による
えー重要単語中の後まー
そしてその六二十三人称が重要と判断した文を正解としま
そしてえーこのシステムの目標値はえー各被験者とその被験者の付いた
つまりえー個二十三人が重要であると判断した文一文との一致度
を目標として
評価尺度としてはえー活発に
から二三分の一秒前の一致を考慮しえー調整した指標です
そしてえー一二年
これはえーリファレンスに含まれてねあのーまーシステムのえー一二
そのかえーと前方という尺度でえー評価して
ただ
でこちらが結果ですけれども
え御
えー要約あ今日今日参考に四について行ないました
えー
こちらに各特徴
でえー格好いいあれねっていうのは人手による書き起こしで
で表層的言語情報抽出したあーもの
括弧Ａスターというのは自動認識で表層的言語情報を
示したもので
いや例はえー左右の理想
っていうことで
えーどのくらい触れるかっていうことを調査する目的で行ないました
えー
六結果としてこちらに
えーそれぞれの要素を組み合わせた
組み合わせ実験を行なっているのですが
この実験においては高認識によるえー各意見は
二つある時やめることも変わらないので
ま経験は原因されるということがある
またこう二三四に付いた目標値に非常に近い
七十五によって性能に若干ばらつきがだいぶんばらつきがあるということは別
えー
こちらはえー先程の後による評価あったんですけどもこちらが三例
よる評価で
えーこれはえーと×による評価と必ず実験しないということは分かりました
えーまたえーこの組み合わせ実験では人間による要約よりシステムが高いスコアを出してしまい
えー魚直感的に合わない値となって
え次にキーワードの五に神について説明します
えー今回セグメンテーションの実験を行なったんですよこちらは
思って結果で分かった訳八え省略いたし
人間深夜については
えー
文章のスライド大切な命の次はあの岩場かでね
与えましてその二十名の発話文との二を対応付けをしています
対応付けはえーいいマッチングで
行っ
またキーワードの選択の方法は心配にえ二
おー
また
私はまー一般的にマッチングを歌うんですけどもこうに音声で
その板の単語が並んでいた場合
えー
つらい気持ちはここのように関連付けてえー
疑い
でえー以上のしゅえー実験を行ないました
えー要約についてまとめますと
ま韻律表層的言語情報の曲の特徴組み合わせことで人間ていう要約とほぼ同等のκ値が
得られました
また認識誤りについては頑健であるということは分かりました
ある一本の値はやや大きめの為
これは評価方法として最適やっぱりあの
いうことが多い
で今後の課題としてはこのようなものがありますが
そんちょっとでも
で試作した教材文でも行ないたいと思いも
んー
えー
えー
えー
えー
えー
んー
えー
えー
んー
んー
えー
で
んー
んー
んー
すあのーんー
えー
んーでもえー
えー
えー
タイトルはえー先程最初に見せた
画面なんですが
えー
えー説明を張ってはえっと例で再生さして
見ますと
んー
えー
えー
まこのようにえービデオを再生されるんですけれどもえーえーあー
こちらの方に言われてあのえーんー
んーあーえっと
んー
えー母音のまー魚はあー
んー
えー
えー
んー
でえーそれではこちらに認識結果
八のえーんが表示されているんです
けれども
んー
んー
んー
んーんーんーえー
んー
えー
んー
えー
んー
えー
んー
二つの形でちょっとしてましてもできないですがえーこのような教材を取り敢えず三
みました
人が全部ん再生モードになっているんですけども
えー要約率をこのように加えることで
えーえ重要文だけ
要約の結果えしたがいましで重要文だけを再生することは
できます
んー
んえーえーていまして要約のあーのもう分かりづらいところにあるんですけれども
えー
二万文全般をが
えー二十四文一九八一発話日本ていうのが分かるかと思いますまそんなにあのー
歩いてもそのーま一つでもあるか
だという
でえーこちらはえー先程インデキシング説明だけしてしまったんですけども今のインデキシング
の機能でえー実現したんですが
え例えばここをクリックするとえー
その分がなされその単語があなされっていうところで
ちょっと
ああいう機能
えー
でこちらの方も同じく
んで
えー再生速度も
えー変えられる
んー
酒も理由の小説が
んーんー理由でも
えーえはというのは元にえー後で帰っ
で後あのー今はんー
日本の一〇〇なのですけれどもちょっと周りの人でまーあのー
本はええーんんまー
であまー
んーん
五のようなものの中でえーえ
んー
あー
んー
んーまーえーとまたあのーうまく操作できないですがこのようなものを作成しましたがっていうことでおうー母が問題
一日でちょうどえーと三名詞方ですが以上で発表終わりますよね低くなったかなと
んー
#############################


#############################
# query = 野球中継の構成要素について説明しているところを見せてください
# rank = 1
# slide = 07-17_fix.match_word.jout.txt
# value = -3.69096141139546
#############################
えー神戸大学の差これえーっと表記のタイトルで発表させていただきます
えまず研究の背景なんですけれどもえー近年まー地名やコンテンツがえー増大してきています
えその為人手でまー全てのマルチメディアのコンテンツを設定して
えー何を見るか決めるということが非常に難しくなってきていると
言えると思いま
でその為えー検索がま要約を行なう為のえー情報が必要となってきます
でこえー真面目で何件全てを無礼というのはえ少しまー難しいっているとおえー考えられますので
えーま代表としてまスポーツが扱い易くうーま二つも存在するということから
テーマスポーツ実況中継そしてま特にえ九十途中での構造についてまー構造化をえー行ないます
でここでえー音声認識を利用してえ特にえー後で標準型の音声認識を利用して
でまその認識結果を用いてえ構造化をなものとします
えーえシステムの概要なんですけれども
えー
このようにえーまラジオの
中継音声がえーあるものを
え音声認識しましてまその結果から
え構造化を行なうということになってます
で構造化の内容なんですけれどもでまーどうかどうかお前が一回のモデル一回の裏でえ息子がえーばＡの音ではなくて
いったようなまかんこの情報構造としてえ二をしていくということをえー目的のこの今
でここで特に重要度があるのがえーまー男の子のえー境目だったり
えーっとないかもどうもまー境目母音を観との境目もしくはそのバーがえー火を用いなどがえー一項のことをまー
でえー温泉式をえー用い上での問題点なんですけれども
でま当然この板橋区えー認識できればいいんですけれどもえーこのアルコールが
え例えばこうボールといったようにま高認識されてしまうといった問題があります
でここでえー音声から音響モデルえー
ポータル適用するものもしくは言語モデルを
えーきっちりマッチしたも使うということで
えー認識精度を改善するんですけれどもえー改善しても
えー大体六十五パーセントと
えーそれえーその程高い値とはならない
いう問題があります
えその為
えー音声認識性能をまー更に向上させるということや
えータスク持っ
すえーま野球中継というタスクの知識を持ってることによって
えー誤認識へ対応するといったことがえー必要となってきた
えー音楽を知識を用いてえー音質評価するというのは
えとどここでえーアルコールを溢れ今使ってるんですけれども
えー次の発音男でも三線という発話がありますので
えーまこうボールと水のバッターに代わるだろうという知識を用いれば
え次の端に変わった
変わってすぐにもう三四のおかしいといったようの判定ができると考えます
でえーこのようなえー点に注目して
えー従来えー行なってきて提案なんですけれども
えー野球のまー二十代の状況とえー単語をえー同時に推定すると
いうような音声認識をえー
提案してまいりました
えー同時に推定することによって音声認識の中に
えータスクの知識をえー持っていることがえーできるようになります
でまたその状況を推定いたしますので
えー状況と構造というものも対応を取るといいよって
で構造化もえー可能であると
いうことになって
えただしえーと先程の例のように
えー改善が得ない部分というのは
えー状況の変化に関連のある〇かそだけとありますので
えーま単語誤りの改善はえ一はこの三人限定されていると
えー一つはえー問題
かなり
でまたえーっとー
音声認識率をまー報道させる為のえー
提案します懸命いたしまして
えー話題の遷移を考慮した言語モデルというものを提案も行なっています
えーこれえーこれはえー全体的な単語誤り
崩壊え改善というものが得られるんですけれども
でえーま構造というものはえーま考え方にもえーま構造化はできるということになっ今
でそこでまー親の二つの手法のえーとま高校いたしまして
えーまー全体的な単語誤りを改善した上でえー
でまたその知識を用いて構造化を行なうと
って言ったえー提案を行ない
えまずえ従来の二つの手法についてえー解説えー説明さしていただきます
えまずえーこのえーとー京都単語を同時推移する
え音声認識についてえー動作してたと
えー
本手法ではえーま単語系列のＷとえま東京の系列をベースとしましてえ観測音声の系列方から
またと同時に推定するとえデーター形式を行ないます
でえーま通常であればえーここが
てこれがま比較をＷ体系ってこちら側のま一がないと
えーいうような式になるんですけれども
えここではえー音響モデルも言語モデルも
ま状況というものが関係してくるって思いながら
でえーこれを展開いたしますとちょっとえーここなるんですけども
でまーちょっと複雑なのでえー
ポーズでえー簡単に表わしたいと思います
でここでは
えーまた意志的に得られたえーま形式なんですけれども
えー単語がえーま前の単語に依存する
で更にはえーその状況に依存すると言ってたような
モデルになって今
えーま即ちえま状況に依存したバイグラムであると
えー言えると思いを
でここでえー状況の遷移確率というものもえー存在するんですけれども
えーま完全にまＨＭＭのように相当遷移確率が存在するだけという
言語でもまーいいいかと思ったんですけれどもまもう少し積極的に
まず音を推定するという意味で
えー
前のえーまー
認識結果ですね単語認識結果を用いて
えー次の状態を推定するというような
えー少ないモデルになっております
でこれによりまして
例えばストライクという単語があった場合にはえま水でそれ今度は増えるのかなといったような推定を行なうと
いう風になっております
でえーっとこのモデルでまどういうえー効果が得られるかというところなんですけれども
ま例えばここでま先程二十五えー先程の例なんですけれどもまある五六方
思うと
えー誤認識した場合
えー次の増大
後はえー次の状況はま次の祖母に変化すると
ま左右されたえーストライクカウントボールが本父がまー〇に戻るといったような推定が行なわれますもんますねまえー
推定が行なわれます
でここで
えーまー大阪三線というような場合なんですけれども
でここでま二つのえー
場合が考えられまして
でま関心とそのま認識されてしまうと
いうた場合には
えー次のえーっとラティスの状態の
ま遷移確率が
テーマ
それがあの〇んとこ時からえー三支援するという選択とま存在しませんので
ここ〇になるということで全体的な尤度は
え体系化する
でもしくはその頭子音ではなくてま誤認識なんですけれども安心と二つあると
えー
見た場合には
えーま言語尤度音響尤度共にま体が私ますので
えーま全然できない尤度差があると
えーとユーザー結果になると考えられます
でそこでえーまー
えーそもそもこの
終わる頃おーま方法ま一月にえーまーあることを認識していれば
全体的に誘導はまそのこと生活なっても済む
っていったあー結果が得られ
え利点としてはまえー以上のような
えータスクの知識を用いて
え誤認識を化することができるんですけれども
あ回復することができますまたえー
状況をえ推定するとこう備えていますので
てその木構造化
行なうことができるといった利点が挙げられます
えただしえー改善をすることのみに限定されるとえまたえーラベルをもう不要
行った上で学習を行なう必要があるといった欠点があります
で次にえー話題遷移を考慮した言語モデルなんですけれども
えーこちらはえーま野球中継を見た場合にも発話内容がある程度
固定されていて
えーまー
えー表現がえー
偏っていると
でそれから発話全部にもま一定の規則のようなものが
ありますので
でそのようなものをえ表現できれば
で認識精度を改善するのではないかという風に考えます
でそこでえー
えー話題のえークラスタリングを行ないえーそのクラスターごとにえー言語モデルをえー構築いたします
えそしてえークラス間の遷移確率を与えることによって
でまこの第一のような形でえー言語モデル
ま全体の言語モデルを表現しまして
えーこれによって認識精度は八回です
するのではないか
えー
いう
となって
でえーこれに関しましてえー従来手法としてえー中はえー生物によるえー
え生成Ｎグラムというものが提案されて今
えー生成何グラムでは
えー家まアルゴリズムを用いまして
えー
ま単語
おーテーマ一ののように正規化することによって
えー複数の言語モデルをこう
四でその言語モデル間の
えー遷移確率を与える
えっとモデルになって
二つ入れ方もえ生成Ｎグラムでは数件
田んぼをベースにえー
えー言語モデルを学習する為え学習するということなっていますけれども
で本研究では
えーもうそこ潜在的な話題を考慮した
えーモデル
をえー提案いたします
でえー潜在的なモデルを考慮したえまずえー先程から何度も出てきてると思うんですけれども
えＰＳ重過ぎまして
えー文章構成する洗剤と結構学習いたします
でその潜在えーまた訂正では
仙台トピックごとのえー単語Ｎがまー学生ですでまー
えーま例としましては例えばまーワールドカップの経済効果についてのブライダルサイトがあるというでは記事
えーんの
え潜在トピックを分割してはまサッカーがこのくらいの割合を占めて
でま経済あこのくらいの二分全てといったようなえー分析を行ないます
えー実際の英単語文章における単語出現確率は
えー潜在古くからの単語数に庭もする確率と
えー文書におけるえー潜在トピックもまー各えー出現確率のま線形結合で表わされる
で表わされます
えー
このえー形成を利用してえ文そのクラスタリングを行なっていて
えーまずえー学習コーパスがあーまこのようにまた的文章の中三年ですけれども
でこの文章に対してえー系列を行なうことにより
えー各音素における潜在トピック性と音からえーずっと紀元前のえーますえー
分布のえー
確率を
えー計算いたします
でそれがえーまーえー文書の数だけ存在する
といった風になって今
でここで
えーあ五番目の
えー文書におけるえーま特徴ベクトルというものを
でこの
えー
潜在トピックの
えーまずなくてこう含んでいる割合
のおーでえーそのまま
えー
特徴ベクトルとえーいたし
えーこれをえー文章
えー会いにおける
えー
特徴ベクトルＸＹといたしも
んでそこでえー
先程Ｘｉを用いまして
ＨＭＭを構築いたします
で一年はえー一人このＡから思ってえーまー
月一回の面とか一回の裏という単位で
で一つの系列としまして
えー学習を行ないます
えテストはまこの辺があるんですけれども
でまその結果ま普通のＨＭＭになりますので
えーこのえー状態の遷移確率と
えー状態からもえーこのＸにえー
ま紛争における
えー潜在トピックの
あえーと割合ですね
僕その仙台トピック文法のえー出力確率が偉い
えーつまりえーこの過渡状態から
えー各状態から
潜在トピックのまー
えーする確率と
えーその状態間の遷移確率と二つが挙げられ
いうことになり
でえーこの
えここからえー言語モデルにえー点が付いたんですけれども
でまずえー
最初にえーっとこう却って文章をえー攻めて分析した
えーものを
えーまー潜在トピックのえー実行をまこのように取りましてでそれをまベクトルで表現するとおもこのような
えベクトルはえー書きます
でこれを全てもえー場所についてえーま分析を行なう
の行なった結果
えー
似ている話題
によっても構成されている文書というのはま近くに集まってきて
えこのようにまクラスタリングが行なわれる
いうことなりますでここまでは先程のＨＭＭの話なんですけれども
えーここで
えーここからま言語モデル化古代について言語モデルをえー構築したいので
んえー今度は思いくさいとま分布になってるんですけれどもえーもう一つうー話題括弧の五月もう一つだけの言語モデルと
でいるというえ近似を行ないまして
えーこの下降第については平均の分布だけが存在して
ま平均
一階の分布はもう存在しないという風な人で行ってしまい
でこれによって
せっかく話題のクラスターからはえ一つだけの
え仙台で行く分布がする食べると
っていうようなえーモデルになります
でそこでえーまえー言語モデルもえこの二形式お酒なんですけれども
でもう少しえー簡単にえー説明いたしも
でここのえ差異というのはえーっと
トピックＨＭＭにおけるま状態ですえートピック別にあのーえっと文におけるえその各状態の遷移確率という本を
えーそのえ状態からの
えー単語出力確率というものが
えーえー
得られるとまー高校ではこれがえー欲しい訳なんですけれども
えー各状態におけるまバイグラムが欲しいというところにえーいうところなんですけれども
えー各状態における場合はまーえーっとーこれも先程えーできたと思うんですけれども
えーグラフにしていくと
えーいう手法によって
えー
計算生い立ち
二グラムミステリーにはえー通常のまバイグラムやっぱりトライグラムから
えー各状態における議論の出現確率とまーえー各状態を提示しないえー全てのえー状態におけるえー単語の出現確率をあの最近によって
えー得られ
でこのえー各状態における単語のえー人間であるというものを
えー先程の
えー過渡状態における潜在トピックを用いて
えこのように計算いたします
でこれはまー通常のえー形成の計算式とおえ全く同じで
鉄砲
それが形成ここはまー文章になってるんですけれども
えーこの
えー先程の話題のクラスターあー全てを
えー一つの発生する古代のクラスターを
とその星という風に考えまして
でそのー話題のクラスターからえー千でトピックは
であのー分布があると
えその話題のクラスターについてえー
ええー二グラムのえ出現確率を求める
いう風になっ
でこれによって
えー各状態において
えーバイグラムを超えててまー持っバイグラムを使っトライグラムを形成することがえー可能になり
えー
この手法の丸い点なんですけれども
えー多くの単語について認識あまり高い音するという利点
とーまーもえー音はラベルを付与がなくて自動的に
え学習ができると
えーいう点が挙げられます
えーただしえーま知識をえー
付与していない為にえー構造がはえー区間行って
え提案手法ではえー先程述べました二つの手法の統合を行ないます
えこの表しかえーとー後するんですけれどもこれもえーっと
ヘルツで簡単に説明ですが
でまずえーっと両方共一という記号を使ってたんですけれども
えー最初文状況の方はえーそのま五という記号を使いまして
で先程のトピックの方はえーまＫという希望に置き換えます
えー
えー状況の遷移確率がありかつえー状況からえー
ま話題の
えー古代の強い
次に実話題が出現すると
えまつまりはえーと東京ごとにえ先程のトピックＨＭＭが存在すると
いったようなモデルになっております
でえーとす各トピックＳＮからは
えー
単語がえま出力され
出されるんですけれどもこの単語はえーっとー
トピックリズムだけではなくて
えー状況のにもえーまーどうしようとするとえーっとモデルになると
えただし今このまんまモデル化してしまいますとえー状況ごとに書い膨大な数の
えー言語モデルを作らないといけないということになってしまいますので
えーもうえーっとー
トピック別メンバーの状況にあ依存せず
えーと設計者全体一つだけを作ると
えいう風に近似を行ない
えー
これによりましてえーまー全体の認識の手順としましては
えー通常のま音声認識において毎年テストの出力を行ない
えーそのＮベストに対してまーあえー話題ごとに
えー話題止まっていですねを用いましてえー話題語と二グラムミステリーの行なう
え更にえその結果に対してえーもう一度その状況に
かなり強く依存をした単語については
えーリスコアリングを行ない
え最終的な言語モデルを得る
えーいう風になっており
でえーっと実験なんですけれどもま通常の音声認識の結果と
えーそれからえー最初にえー説明いたしましたえー状況単語を同時に推定する音声に
でそれからえー先程説明しました
えー話題遷移を考慮したえーま言語モデルとまそれらを統合した
えー
手法についてえ実験を行ないました
で評価基準としてはえー単語正解精度
えーそれからまキーワード
水は六というのは
えーっとーこの
状況を推定する為にま用いられるようなえ単語
のえー二値を求めております
えそれからえー構造化が
えーどのくらい正しくできたかということでえー一つあのーほっていうことに反映しております
でえー文えー音響分析条件はえーこのようになってま
え音響モデルは生成では別に
えテストセットと同じ音素を用いてえー話者適応を行なっております
えー言語モデルはえー書き起こしえテキストからえ学習しております
えー未知語はえーまー
ないという風に仮定しております
えー音声データーはえー
約一時間半のえー×一と二型音声で
えー異なり単語数はえー大体三千単語という風になっており
でえーっとー仙台トピックするという本て会社の状態数なんですけれども
ええー色々まー実験した結果まこのような値をえー選択しており
え結果なんですけれども
えー通常の音声資料は大体ま際立って足が六十五パーセント程度
んえー得られております
えーそれからえーま状況
を状況方同時についてその語千四十八はもう単語全体であってあえー単語
生活面との向上しないんですけれども
まーキーワードえ二の方は少しでもそうする
でそれからえー大体七割ぐらいの精度で
えー構造を正しく推定できているという風になっております
でこれにえー話題の遷移を考慮した思いを加えることにありまして
えー
約ま〇．七パーセントの改善が得られており
えーそれからキーワードについてもえ改善がえタイトル
でこの二つの手法をえー統合することにありましてえま全体としてえー
この前制度も変わらないんですけれども
えーキーワードをえー二では更にえー少し改善がれまして
えー七十五．五パーセントで
という風になってます
えーキーワード
の正解精度の向上したことにありましてえー構造化もえー正解率も
えま少し違っている
いうような結果になっておりも
でえーとー話題モデルをえー用いた
えー効果なんですけども
えー
まずえー
従来ま通常の音声認識手法ですねこれは際にえどこの村が出ましたという風にまま使ってしまっていたんですけれども
えー話題モデルもそういうございまして恐らくを定型的な表現
がえー学習された結果だと思うんですけれども
皆さんよく心が出ますと
えータスクにすることができております
でまたえーこれはお外に定型的な表現
という部分を
だと思うんですけれども
その話題の遷移確率というものを与えることによる
えー効果も得られております
えー
とーそのー
認識えまー従来ですとまーたまにという風に間違ってしまっていた
そう一つ前の発話
で
ま一秒だけましたと
四十発話が得られてるんですけれども
まこう生まれましたと
いううー発音を次の発話であるということから
また村
という発話よりもえー
まから文の方がまーそうするということで
えー
新しく認識することができていました
えーまとめですけれども
えー受け付けの構造化を行ないましてま総合的に
えー統合することにありましてえー七十二で二十パーセントの各えー生活レートがえ構造化
できていました
えー従来んえー二つの手法をえー統合を行ない
えーっと以上で発表
んー
#############################


#############################
# query = 野球中継の構成要素について説明しているところを見せてください
# rank = 2
# slide = 08-20_fix.match_word.jout.txt
# value = -3.93288523980162
#############################
じゃお願いします
えー
とそれではえーと統計的手法に基づくえ講義音声書き起こし文章文境界推定ということで相手端からの歌を発表いたしも
まず初めにえーと既存自然言語処理の送ってもらっ文が認定されている文章ってものを対象としてから多いですと
またえーっと音声が書き起こされた文書部分の境界が明確ではない声場合がまーもう一つと
まー即ちまこの既存の研究でま提案された手法ってものを音声から希望された文章に直接適用することはこの歌を飼っています
んーそこで本研究の目的なんですけども本研究では話し言葉できるされた文章の文境界アーティストの目的とします
知ってそこで今回対象する文章はま大学の講義音声を否定人手で書き起こした文章を対象としています
また程度ちゃうようになります
えーっとこの際まこの文書にはとても苦労されてもらうん
んん同定が付与されていませんまたま他のポストテストではその一は
父は実は思っ音韻情報ってのリサイクルできません
あ書き起こした結果だけです
また本研究提案するというのを対象文書の母音や話者に依存しない手法最も提案します
既存のまーこれどういうことと言いますとその既存の形態素解析や係り受け解析などを用いてみますとこの状態が推定できるかって言ってもこうこう
などはえ文境界が判別できるかと後独立したと
えーとここでその話し言葉を対象とした文境界
おー検出
のま従来木について簡単ですです
まず英語を対象と人間と英語を対象とした研究するのかどうかありますがま
端的に英語っていうものは日本語で二つうまくえー特徴のある言語ではありませんので
ん係り受け解析などを必要となる
資料となります
またそもそも
事情がなかった人でもそのー文境界推定ってものは．二ということだという本が好きですねだの研究では立っている
これに対して日本語
であの文末にあるという特徴がありますので
んー
まー英語よりは制約
文境界推定ってのは．九二文境界の推定を行なうことができます
まー日本語第二に日本語を対象とした研究としましたまーこのような三の方が挙げられ
学ぶ
今回三分程度舌のテンプレートを持つテーブルとマッチングを用い方
んまた機械学習を持ち方
で最後はまとめ
まここで発表させておりましたもう一ではないか総数の接続詞を用いた方法
着いた我々も
まーこの日本語を対象と選挙もう少し詳しく見ていて
んテンプレートマッチングによるほ
んんですが実は非常に高い適合度最近です点を仮定して今
私当然ながらこうま人手によってテンプレートを作成する
コストってが非常に高く
またえーと今回
ものと他の研究ではＣ一二を対象にしてるんですが経験をこうＣＳＪの
のような公園や
講演なら文しか使えないするとされますそこでペット
で次に機械学習の手法ですと
的分析がえーと使ってますのでテーブルとマッチングと比較手法によっては比較的高いと考えますと
父がまたおないとテンプレートと同じように適応度ことの学習を行なった文章の母音やり方をすると考えられて
二異なってその手法なんですがこちらえーと係り受け解析を使っていますのでいう強い解析ん
正解ばかり大声で付与されたあ学習データー一なんですけども
この学習データーを船を単純ですが非常に
ん実はあります
まこれに対して
ま普通あえーっとメンバーで忘れていましたまー
人手によって与えたそうする特徴を用いてえーとこのこと外的に文末を推定する方なんですけども
あー製鉄方がありますと
生かしながらこれにしても適応度の方対象文書実現するその文頭に一二三分の後に出現する表現
卵と言いますと二残ってもう一で高いす終わります
で自分のこのこの対象文書の二呼ばれますので
まこれも少しコースを買ってしまいます
えー
で本研究の提案手法じゃどういうもどういうまー本研究ではまー同様の手法を提案します
今回その対象とする文書の三つを用いて
後形態素分割を行なった後に
モダリティー
まこのモダリティーっていうものは一文の命題に対する話し手の販売
えっと話し手の被験対する心的態度たもの男の人
二個のモダリティーがモダリティーを表わす表現というものが止まって集中するという日本語の特徴から
文境界を推定する手法となりますと
まこのそうなんですけども
何ではそれはこの学習データー人手によって与えるデーターってものを一切必要としな手法となっています
ここでちょっと日本語の問題について簡単に説明してきます日本語のモダリティーん
というま基本的多分末尾に集中する格要素文とそれに対応する
文頭に現われす原稿用紙に表わされます
基本的に各要素が衰退ではこう予測発言しません
で格要素ってのどういうものが出ます達がどういうものがあるかと言いますとこの
種類が挙げられますと
歯でやりますとこのだろうねと言ってもですね
この場合だろうっていうものは
でえーとこの場合は楽しみ半分持ってですね
ですねというま伝達態度についてのもえーっと
持った
こう点数をあの二世ですね実験などが
素晴らしいこちらが時間
んあのモーダルで最後ですでこう丁寧さをもっと一．五できます
行ない日本語では
千分の後ろの方にモダリティーロバスト限定のたいえーとー集中しますので
これを検出してあれば分まー文の
多分の境界とのか推定できるのであのたまたま．八個
で提案しその概要ですま簡単に言いますえまー大きく分けて後でま二つのえまー
歯の初めのステップでは形態素分割の行ないます
と今回
まそう学習で対戦用いませんのでその学習用データーが必要な傾向程度で形態素解析が可能なマージが提案しているマッチングエントロピーっていうものをベースにした手法になって
ってって多分が伴った後に
先程のモダリティーが集中するといっ
えー集中する場所を見つけま文境界推定を行なって違ってそこまでは
まず初めの形態素分割について簡単に説明します
三と言いますブランチのエントロピーというものですがこれ名付けていたり
これはどういうものをどうするかと言いますと的心ある用いある文字列Ｘに後続するその文字の多様性
を表わす指標となっています
ここの値大きければまさまざまな文字や後続する
この値は小さいと特定の文字しか今年は
ということを表わします
即ちプラスＮとＰが高い文字列というも負けてしまう可能性が高い
タイトル
で形態素分のほ手法っていうのを
あーする形態素音楽もえっとー
青のが弱くなってます
と分かりにくいので図を用いて説明します
んーと
あこうねすえーとここで示したのはそれぞれ
この辺がそれぞれ一の主といった問題集の二つ目とこれら手法の価値の時っていうのは一
と
提案ちょうど都内に分割成果と言いますと
えーとある文字の月五メートル一とそれに後続する一文字を加えたものの
もの
あー後続する一文字を加えた文字列行ってねと
をそれぞれ求めますと
でこのサイクルが低下したらまた
場合と後まー
後続する申し上げん出たということでま形態素続いてると判断します
そして次に
一系統の周波と周波数
手を比較した時に
ま周波数で
えっとー周波数の後によっても
えーと例えばこちら経験とか
えーっと
格助詞
あー嫌だっていったものや
まー
そしてパス解析まメンバーと道が続いといったさまざまな表現が
続くますできますので
これから二メートル級の上昇します
この三点目と三が上昇した点でそれ時は
でここまで気をニンジンだの手法と一緒なんですけども
えー
えー
で何そこではこの後
えー
神の持ち方ではずっとこのままえっと
次にえこの次の形態素
の認識に移るのですがで後です起こしとても焦って
えーっと更に
形態素境界決まった時点ではこの三月まで
次のえーと漢字音という計算し
まこの値がスキー場高かった更にここできるといったそれして今
まなぜこのような処理を加えたと言いますと
えーっと
感じの手法ではその一本の形態素
というものに手で決めてたもんだ形で
それに加えてえーっと日本語日本語ではえーっと今年と意見としてま基本的一文字で構成されますので
まそれはそれが問題だとえー今回
えー
でこうやっても超えています
でまた同様に
三ませんけど一．二述べていましてえー低下してるので切らないって
筆の本計算していって最終的にサンプルとサンプリングた時に
サンプリング音でえーとそうしますのでこう子供達え音治療法
何度も繰り返してくのが適当となります
でこのように分割した形態素
思っあー単位として
次にモダリティーが集中設けそしてそのまそう文境界としますと
文という文境界と
するのはえーっとー
番目のステップになり
で
先程言いましたけどもまーアイデアとしましては日本語では特に文末にモダリティーの格要素一九九四取っていたのは格要素を推定します
でこのまま行けるという方って後の地域の声機能語であのー昨日です
ま即ち一のお躊躇することは例えばでき文法側文末やろうを
好きな予測できますと
まここで簡単な仮定を置きましたそういう過程だと言えますとま内容より機能語のま水の高いだろうといった発表しますと
音声が付いてまして
えっともの
ペットの二つ言われていますまず最初に先程求めた形態素のモダリティーの格要素数といったものを計算しも
二十二つのモダリティーの発表酒を使って
あーの文末を推定しておといったことな
えーっとモダリティーの発表と言いますという及ぶしたものも別求めた箱のようになっています
とこちらまた音にくいので
んー図を用いて説明します
んー今ある形態素あー形態素列まー一応は雨が降らないだろうねっていったものとします
その場合
出掛けてたす元確率最もまこのようになりますと四つに
えーっと
格助詞あー音としや後の後ですね女性っての五つのコストの出現確率が高くなります
ここで問題になるのはこれあの一つの部分一二二者で選択したと高いので
そのこの何とおー最後メンバー
この本を最後に古典洋裁今後できればこのようにモダリティーの部分だけをたかったあーの各部分を
が格
なん
んーなるような指標を作ることができます
ここで提案手法では簡単にまこういうその
このとえー出現数の系列とも二系列データーを出して移動平均で平滑化を行ないます
まするとこのようになり
まこのようにすることで
んで一応ところモダリティーの部分ていうのは
高く
あー高い値が得られ
といった
えー
がえー高い値が挙げられます
このようにして求めたそのーん
とモダリティーの発表とラストというのを用いて
積分ところ
あーモデルをプラスを用いて文境界推定します
ま何やってるかと言いますとまあるもどこまでどうもパソコンて言ってそれが閾値以上だったか
んー
多分
それが閾値以上たそれを採用すると
で閾値以下だったら
ま閾値が二つを採用しないとおーなります
で更に
建物い
一番
で最後にその
文末の差っての局所最大端点ていうもの文境界と認定し
まこのようにしないと思うと二人なんで下でのバイトえーと最初のモダリティー語とするとＭＡＰ推定されてしまうのでこの水が入っています
んまこのような提案手法に対して今回ちょっと簡単な実験を行ないました
ままた実験は多くて二つの食べてます
で一つ目の実験てあの形態素音楽に関する実験です
とこちらはまー提案手法においてもてるけれど分割を行ないとかってのが一つと
本実験データーが大勢の再現率といったものがま六つの文章書いている達成できる再現する条件まー
んと分かります
えー
でこれを確認した後三
えっと文境界推定に関する実験を行ないます
あっ
今回対象文書について簡単一今回対象としたのは
えーっと情報工学部にあのこういう音声をするには人手によって書き起こした不足
ま講義内容とした音声言語処理で収録時間を六十七．八分
でまもう一つとした四万四千三百三とさも
ここで形態素分割実験のまー評価法について二つ評価法今回にするやり方
ま突然形態素境界と評価対象としたもので
んこととどういうものかと言いますとそのそれ対処の文書の四分の一に対して人手によって形態素境界を値が出たと
まー
提案手法によって得られた結果状態を比較すると単純比較する実験です
九歳人手で分割ってのＩＤＦ値体験しまして
二つ目っての文境界のみを対象と先程法とかですと
ま今回のしえーと最低こん本研究での目的っての一九文境界
推定ですのでこの文境界の的二万文境界が対訳
テニスできていれば
次のステップになっていてあー
次の徹底的にすできる訳ですので
ん
このような評価法であるとなっています
ま正解データーっていうのは最初の
対象文書四分の一に対して
ま三名により文強化された後その状態後二名以上
二分以上たった安定したものを正解です
でそれ
他元モデルとの比較です
えっと
上の方ではえーと性別第一両方出すのですがその方では際にですのみを達も
テーマ形態素分割
日本一種類の実験てまずまずパラメーターの変動を取って
何もまパラメーターが変動する実験と更にえー提案手法っていうの
適応の文書サイズ完全に依存しますので提案手法に勿論著作っていうもの
迷っても疲れ様の文字まで変化させてまその際の
というのを調べを調べようといった実験
その為と変動と素材のまー結果をうちのグラフのこのなっています
今青色図に示したのがま別の質のも手法ですで赤色できまして示したのがまー
今回提案いたし程
まわずかではありますが
納豆を今回提案さしこの悪くなっています
次いで二タイプの影響ですで
とこのようにまー
えーっと前形態素境界を対象評価対象とした場合ですだとまー
非常に低い再現率になってしまってるのですが
短文章は何を対するこうした場合ですと
んでえーと二十パーセント二十で文字以上使い方
もう七十五パーセント以上正答とするではあー対立を達成できるので
えまたえ手法ではないかと考えるです
ま今回の形態素分割実験に関してはま的二次のまそういう性能を
えそれ程したことに多少向上した方が確認できます
またませ文字以上を使用すれば
ま物をですね一応でないあー五つのステップでま十分使える
の
えーっと系列二．一ているのではないかと考え
続いてまー本研究の
ファミリーであるその形態素語が
文境界のケースに関する実験です
対象文書を実験した後ま先程の情報を強く分野の方に音声を人によって化しようとした文章を用いました
で実験としてはまー
んえーと携帯えーっと
パラメーターを変動またその店で仕事×です
その調べました
で評価の方法なんですが
ま先程のえーと結局形態素分割の時の
えっと文境界の三の情報と同じように三名の被験者に二．三名の被験者のうち
ま二三乗の文境界だと推定した者正解だとして
結果をねなりました
二を八の前期の回答面こちら提案した
えーと人手によって少数のデーターを与えるこの方法の結果で
高いものてんのかと
んー第一部を負けているものですがまーホームね
でつまり勝ってると言えますと
また更にはあのほえーとこのベースラインとしている表示する方法となって一部のどこ人手でデーターを与える必要がありますので
まそうよりも思ってので
まー醸造の結果が得られ得られたとじゃないかと．
とまた
んー
えーと被験者音の正答結果本が生まれました
えー
えー被験者ＡＢＣが三文を共に
えー
後安定被験者ＡＢＣ全員がえと文境界と推定した
部分を正解とした場合ですとまー第一発話で越えております
昔
またえー
定義しあー一被験者に二名の被験者に出てから
文境界推定した者
こう選択した場合ですと
んーまー
精度を行なった後六十五パーセントを達成することができました
まその結果の方はえーと一ですがえ特定ですのでまだまだ
あー行なわれてるものなんですが
絶対にその子を調べた結果今回
これらの要因がえー
問題は多分が分かりました
まどこストレスも多くて後五分のところをえーと主題を取り上げ際に母の代わりに動詞と上昇用いてる場所です
例えばこの周波数ですがえー
こういった部分でお水水というのがえー二つが起こっています
また
とこれあそれといったえっと第三えー七十代名詞が原因で精度が低下してることもありました
えっとこれは誰した出来事を出現頻度が高いとかいったね先程その形態素のモダリティーの各要素が差を求める際に
ん
二万語彙となってしまっていると
一度
下の二の一となってしまってることが挙げです
体を言ってた全て今回人手によって真面目しなければならないデーターベースへ用いずにまー前回の手法ま文頭に自然性を表現音であっという方法ってのはま精度を達成したと言えます
またあーですがまー
幾つか問題点があります
まず第一の問題点としてました的な買い物が必要であると
もうちょっと問題としてしてまそもそもま一応搭載率のものが改良には違うといった問題があります
最後に今後の課題です
まずえーと適合搭載率の向上を目指しますと
んー
ま今回
バッテリーえーと対象といつも認められ統計情報です
踏んだところなんですがまそれは多分恐らくうー
非常になりますので
ま既存の形態ん何か既存の解析を組み合わせ
ま提案手法
の対象文書とられる統計情報目にしつつも
んまー持っ使えるものも使ってえ方法を考えています
また今回
えーと対象文書
がかえー結構長い
文書必要となっていますと
えーと最低でも二十文字以上必要なんだせいもしてもえーっと時間で言うと
えー
一か月五十分程度の
四十分程度そのまー音声
から書き起こした文書が必要なんですけどもそれはまー後はと思いますので
それ少ない文書で文境界推定できるようにしようと考えています
また
まＣＳＪの適用しえー適応しそれのあの手法との比較実験をあのー考えています
以上で終わります
#############################


#############################
# query = えー分からん言葉があったんですけどあのーインデックス情報ってのを五十一二
# rank = 1
# slide = 08-22_fix.match_word.jout.txt
# value = -1.83249367995093
#############################
体講演音声自動要約の為の重要文抽出実験とその分析について
一年間大学の単位が発表します
ただ本研究の背景溜まってきですが近年第四八名にあの気に伴い
音声データーの
月への蓄積が四生かされています
七
席が容易化する中で兄弟データーの中から
千字は何を抜き出すパターン一は音声データーに対して非常に困難であると考えています
その為現在音声データーに対して情報検索や
自動要約何舌が求められています
本研究では講演
えーっと音声や
会議の収録音声に対して要約を自動的に作成すること
もう目的としています
男性まだのデーターで自動的に要約を作成する段階には至ってはなぜ本発表では
読点によるえーは文節実験とその分析結果について
なってしまう
えー
探検家でまずえー音声データーの要約って前を説明します
パーティーがあってで二つに
分かれます
まず音声認識をした後
テキストデーターに書き起こし音声
そのー言語情報
もう本当に
重要文を決定する手法と
もう一つは音声データーを利用性
声の高さ話せスピード
声の差などの韻律情報を元に
西洋文を生成して
手法でえー
体制的にはこの二つの手法を
を用いてそれを組み合わせて
より性の高いよ
要約を作成しようと考えています
現在は
非言語情報や
韻律情報なっ
に対してい行っ特徴を探している
状況です
幸せや音声データーは生成のデーターベース
先生前の中には
のデーターは訳でえーパーセントが学会講演と模擬講演
でされています
爽やかに
原形は
に付加されたでえー
いいですかあのデーターがありますが三あったり
重要文抽出結果というものが百七十七公園の中に出されていますえー
えー
その
では文節って方が三名の被験者が
二パーセントとも〇パーセントを目標に
各講演に対して要約を作成したものです
次に本研究では
特に千二十四文生成実験行ないました
今述べたように
既にＣＳＪには元々
三年でなぜ四文節結果が
あるのですが
学会文章に大先生の数八ではないかという
夏だけではなく定量的に評価しようと思ったんで
今回採用したをの人数を増やして
実験を行ないました
一強さのは
先程のあ
重要文抽出結果が
含まれてい百七十七公園の中の
二十五円を二十この模擬講演を利用しました
して三ギョーザは全七名でこちらは
えー一般の学生に一頼みました
って要約率二十パーセントを目標として
抽出日間は任意の区間としました
国の文化なので単語でも
ま一年長くてもいいということにしました
その結果
でじゃ前の平均要約率が
全七パーセント大体監督
表としていたも音が高くなってしまいました
せ公園や作業者によって要約率が異なることあっ
で分かりました
次に
んで八文性質点線は説明します
まずテキストを使わずに反省の実を聞いてもらい
吸う中で
ん聞いてもらって
大体の内容を反映してもらいます
で次にこのような二〇もついて
えー
重要だと思ったところ
選択してもらいます
あ平らになってるところが
選択されたところです
えーとして発話版の発話時間二ないよと
示されていますが発話はあのてんのは性別で決められてＩＰＡのことです
一月
三四保存されな
現在何パーセント絶滅
違って設立が
確認できます
何か
それを見て何だの
柿のすこともあったのです
次に
その抽出されたデーターはえー
んどれ程一致してるのかを調べる為に
葉っぱって思っていて性質が
一程度を算出しました
活発発達の
データーの間で見る前に一次性
わりあいあのこういった
一精度を示す指標ね
ってあんま好きで
まとめられます
ＰＡってのは絶対に二つのデーターで一致した割合
Ｐってのは
んが前に二つのデーター間で一致性割合を示しています
大学の×ら
形で系の二つのデーターのみであり
今回各講演に対してみてあーこのデーターがある為
全七人の作業者から二人を抜き出し全ての組み合わせにたくさん〇二割のκ値を求め
その平均を
それぞれの講演の発達としました
そして最近あの
生成され談話人と
いたのですが
今回発話ごとに比較を行ないました何で発話の中に使っても
西洋だと舌された部分があればその発話全体を
星を発話とえー
で
えーκ値を求めました
じゃなかったはずの
結果になります
活発は〇．二五から〇．４０の間でやってあなた言われており
〇．八一を変えることは
殆どないと考えられています
まずえー知らない方のから二に専門としていただきたいのですが
面を勝手に行った全七名による結果です
二十五年生全二十公園が〇．二一から〇．四ん〇がペアになってい
んーまず
使っているので
暗い方に専門としてい違った二つ合わせて前に元の特化されている
三年前のオリジナル結果なんですがこれは
一番体は〇．一日
一番高いもので〇．七四と非常にばらつきが出てきました
んこの原因として考えられるものが
大体
作業行なった時の抽出する
単位が違うということです
今回の実験では人でやってもらったんですがＣＳＪに含まれているものは
節単位でやったらません自然だとえで
決められた
変なのですが
節単位は発話単位に比べて一．七差が非常に長い為
が違う
説が一次性な活発な契機にあのありますが
二つ出てしまった非常に差がある
後でこのようなばらつきが出たと考えています
次に一．八文節結果が一致し易いつまり
先程の活発な
学会講演には
何か特徴があるのかっていうことで
学会講演の間ますとＦ０の分散を比較しました
えで皿が分散が高ければその公園は声
に抑揚があると言えます
で活発たＦ０の分散がまー星一例関係にあれば声の四大音で主には相関があると
テーマ
面がまー
とあＦ０の分散の相関です
まずえー二十五文全て気はしたものの相関値は〇．二五になりました
この一つの点が一つの
講演を表わしています
二十講演音声をするとあ〇．二四人とま理想感がないような感じがしたんですが
いただいて
活発な非常に低く
先程のペアとよりも低いところにあっ
で
えーですから分散が
かなり高い公園がありこの講演の内容実際に聞いてみたところ
上手で
何があっ二代
内容なのかっていうことはよく分からなくて作業者の人にも訪ねたんですが
前の文節が非常に身に飼った経験があったんで
その公演を除いたで一講演の相関を出してみました
すると
．三八から〇．二八二から〇．四七三に
まで上がりました
なのでＦ０の分散が大きいつまり
でやはりなあえ講演の方が重要文が一致し易いのでは
ないかと考えられます
次に
これまで
んで皿は一つの講演をまとめて考えてきましたがもう少し細かく見る為に
発話持たないで前の何かやった通りえ算出しました
資料一は一発話に対してその発話が見ないで〇の平均を待っているしもう
で
つまり一発話なんかに非常にたくさん入れて七体があるので
たら全て平均
せー一つにしたもので
千葉には一発話に対して
戦後確認発話を含むの発話内で〇
が適用のせる手法です
例えば発話番号五の一分前をま
発話番号三から七のＦ０の平均値を用いました
二十五文の中の一つの
テーマが卒業論文という講演の
Ｆ０の結果をこちらになります
手法一では
発話によってはＦ０は〇になってしまったり突然
高くなったりと
動きが激しい
ものが
いましたが
手法二では選好を考慮している為そのようななんですよも家や
〇になったりすることは
なくなり
滑らかなのになりました
クラスター性拡大してみても
そこまで
激しく五年
置いているということはなくなりました
次にえ専門人にある各発話のＦ０と
事例をどう比較しました
重要だとは
各
発話を抽出した人数で決定されます
あー出て斜めの作業者の前で眺め
全員が
で四分の大切自然な
西洋の場合五となり誰も
訂正していなければ〇となります
突然
その前八度の高かった上位一割の発話を本研究では制御文と
しました
三が先程と同じ卒業論文というテーマなＦ０男性用の
を表わしています
横軸は発話番号で縦軸がＦ０です
とこちらは
えーと各発話文
発話番号と西洋文末
ただ
全部の声に対して大体
三百二十相手があるのでこれではちょっと細かくて相関が分からないので
後男性
完璧って短い単位で×です
んえー
マスター
その結果面になります
まず材料はがはい比較的高かった発話含め二千発話内で〇と〇どんなグラフを比較しました
えーと第一つ訂正しなければならないのですが
論文集ではここが〇から始まっていまして本当は発話バンドってなされてい一から始まってるのね
と見せたんです
それが多分
グラフがずれていると
思いますがじゃ私ので先輩しまう
このグラフは比較的い言ったらば
高いところは西洋の向かって
で手では比較的低いところは〇度の低い為
でそれらの高いところを男性をどんどん高いのかと
身を持ったのですが
えっとー
簡単に分位数
面は
違う月の
ってですねえー音なのですが
面はＦ０が非常に高いところの重要度はかなり低くなってしまって
一単位にＦ０が高いから
西洋度も高いということは言えませんでした
面結果に相関を取ってみても
で皿の
千葉市内で〇でま相関てマイナス〇．〇型
町人でもマイナス〇．二四五と殆ど相関は
ありませんでした
これはえー発話のＦ０その一発話のみを見てきましたが
それであ相関はないので
こんなＦ０の変化ように着目して
調べました
一発話前のえで〇なたい
ただそのまずあの
〇を比較し
平成七値が大きくなった上位一割小さくなった一割
が大きくなった
〇．五あると
小さくなった〇．五内の合計値は一
これが西洋文とどのような関係にあるのかということが知られました
全七
せあ文の中でＦ０の変化や顔結果と発話の割合です
重要文とあ先程の
部屋に重要度が高かった上位五割の発話を示しています
その中でＦ０の変化用の機関と発話が
それ
まだ含まれているかというものをこの
後は示しています
で皿が大きくなったと言っては〇では政策なった二割で〇全くに変化したい世話になって今
で一枚一えものは
全くえー含まれてあー一〇パーセントもから
二十一パーセントと何もかなりばらつきがあったと
えーように思います
どこでも
訂正があるのですがデザイナーが得意に変化した発話の
平均の値は資料では
一．六となっているのですが本当は六．一本の計算はん違い
で大体
〇パーセントから二十パーセントとばらつきがあったのですが
平均的には
一選ば大きくなった発話には
発展全二十パーセント絶対何か
小さくなったツアーでは
八．七九パーセント全くに変化した発話六．五六パーセントと
それ程高い数字がいませんでした
常に
んで皿の変化量は比較的大きい発話の特徴を調べたところ
でや
えっとーなど
じゃまたは波の名詞を含まない発話が
多いことがありました
その為
今度は同じようなことを
名詞泡が発話のみを使用して行ないました
面の一発話前のＦ０の値と比較しました
そして大きくなったあの上位五割と小さくなった一違い
ぽつんとなった以上五〇．五ないと小さくなった醤油〇．五割の
光景一割八
で要はしました
その結果はお世話になります
こちらのＦ０全くに変化した発話の
平均はちょっと先程と同じ
一．六パーセントになっているのですが本当は一．五七パーセントなのでこちらも訂正お願いします
えー
面は先程の音声発話は利用したものに比べて
だからまー結果なった二つはＦ０は制作なども一つは特に変換した発話
体を比べても平均はま
二パーセントから三パーセント程講座をして
今
ただまだ〇パーセントのものもあれば二十パーセント講演の他のさまざま
ありましたが
世話が誰もやはり一応手を好みのもの
抜くと
重要文の中で出〇二年間量が大きかった発話
勝手に言われている割合が上昇することがありました
次にトラウマでは韻律情報に対してＦ０を見てきたのですが
骨テキスト情報言語情報として
いったような四つ原因の
な音声を文に関して
調べてみました
生成前に生かされているデーターを元にえー
名詞のみを抜き出して
それぞれの名詞の四つ原因度
調べました
だが千二十五円全てに対し分かったものというのは
非常にあのふまたを取ったものが〇という訳ではないのでそれは省きました
二点声の質原因度の高い上位一割八つえ四単語としました
そして各講演に対し先生四文の中んの
重要単語を含んでいるって思うんすよ面がグラフに示しました
前半高いものでは
重要文の中で重要を含んでいるものが
約八割
なものもあれば一番低いものでたくさん悪いという形になり
四二十五円全ての平均当たると
構成二．五六パーセントと
パワーメントはない比較的
やはり西洋文というのは体を単語
高頻度語っていうもの
含んでいるという形が確認できました
でまとめですが
今回一年にあれで八文節を勝手に行ったのですが
第一側出会いにはなるものの
それ程人の住んでも
たカップはならないっていうことが分かりました
また前のよ上のＦ０の分散大西洋文の一致し易さは
正解はあるものの外の関係でないことが確認できました
なっちゃったあーものであーなどのＦ０は
非常に変化し易い為
んで皿は変化が起きえ発話は必ず連れや文という訳では
ないかと
な確認できましたが
ななぜや
じゃ情報熱気
名詞あってま発話のみを利用した場合は
んで〇の変化例あのーや発話が
重要文である確率が
高くなることの確認できました
で今後の課題として
今回えーＦ０
と声の高さのみを見たのですが
次は八
面魚や前の大きさなど他の韻律情報と
性は男性四文の相関分析したいと考えています
映画
それを大本が自動的に決定する手法として決定木の利用などテントステートと
考えています
以上です
#############################


#############################
# query = えー分からん言葉があったんですけどあのーインデックス情報ってのを五十一二
# rank = 2
# slide = 11-01_fix.match_word.jout.txt
# value = -1.84342680342601
#############################
えーっとこのおータイトルで発表するんですが実際あの予定だったのがたりというのは
一人のお店にえー出てしまったので私があります
えー先週ですかねこうもの会話と二重したえー大きさっつうんだと行っ
終戦というのは
ん待ち合わせというのられますのは先生だったんです
知っ彼はどうも他の間にですねまー三つの音主にやってたんですが一つはまークラスのモデル
あの一般のですね
それようやっていてもう一つはトピック依存言語モデル
やっています
で最後にいーこの点はですね未知語の言語モデル
を考えをえーん
あーやっぱりその最後にえーっていったあー
内容紹介
私も
んでまーあー言語モデルというのはあー
ですねま音声認識いーまー使う訳ですがあーその中で元の立体図うーがまー大体何とか六万とか
やる訳ですがどうしても
あー辞書に登録されてない
単語があればですね
そういうのは統計であると呼んでたんですがあーそれが音声認識率に影響すると
もう一つはあー登録されていないから絶対に
その単語認識されないという問題と
もう一つはまそれがこういう形ですねんー
んー
もう
六えーというのはま指示語であればにえーまたもう二
六音がえーえー明示されてしまう
まそう選んでえー登録されていられたのは認識されないという問題と
もう一つはあー周辺の単語にも影響を及ぼすというもですね
モデルのモデルを使っていました本当に通常を使ってえー
編集していましたら
そのーこの単語だけでなくてその週にあの誤り
もうの影響を及ぼすと
経験的に言えば未知語率が
まー例えば五パーセントあればその一．五倍ぐらいの誤りやえちょっと身近なできるんですね
だからあーお婆ちゃんと未知語があれば中でも走るとこれはもう未知語の影響で
んー四五なんで
まーそういうな
まそういうなので一応減らそうというのをね僕用例数を増やすということなる訳ですが
二十便利さも例えば新しいいーいー単語というのどんどん出てきます
全て統合することが出てね
いうことで
ま以上の面悪い人は使った顔ということは重要な問題
いうことでそれをどうするかと話
どうやっては
で特にいーあのー条件することがあー内容がえ警察ですね
んーそういうのは
非常重視とかそういうのもそうなるとおー固有名詞とか
その考え重要である新しいいー単語ですね
そういうのが結構重要になってくるから
その前に一個になっているというので
ただ未知語を真剣に考える必要まー
いうことになる
でそれでですね
まう今までは動作例という言い方を普通はですね言語モデル作る時いーえー純音は一つのコーラス
単語のクラスと
願いしてえモデル作ると
そういうことでえーこの三一本もおーですね
えーえ単語の履歴として使って
えーんーまー
何を予測するとあまり僕らのやり方を予測するとかまそういうことなのですが
ま基本的にはまー一語は一つプラス
えーやっていたんですが
ましかし一つのクラスで扱うような問題があるであろうとね容易に分かると思うんですね
えーとそれを二万というのはあー個人のえーまー初めでして
んーこう木っていうですからこういうのはまーこう普通関係の単語であるとしたらこれを一つの
コーラスとおー発話がちょっとやっぱり問題など
いうことで
そういう形でえー四方向ではですね
えーまーこの未知語もですね
フォーカスがあってま意味的にえー分類したいということ
でそれでえーここで使ってる方はまー
そういう量を使ってですねこの新しい単語という国が
多分三つの有効性がガイドさんを見つけて
その人も八ぐらいえークラスタリングしてあった単語のクラスに丸付けると
まそれは大きな流れでやろうとして
でどんな問題があるかということ道が扱う時にですね
で一つはあーまー
のテストコーパスというのはまー認識する対象ですからあのこれが分かってないですね
をこうずっと同じ認識していかないという形が
その為に
二十五点の音が身に付けるかという問題はですねまそれが研究もある訳ですね
例えばうーのテストデーターを結構認識してえーまー例えば七割八割維持できたとしたら
それでトピックをま推定できて
そのトイレ関係するようなあのー
そうですねえーえーえー
リストと言うかその余暇探していってですね
それで一部分のおーいう動きが見られなかっパターンを登録してると
いうのが一般的ですね
未知語の見つけ形のテストデーターに対してき一番目付け方は
それらが一般的でそれでまー辞書には登録できるということにある
んなれるかなと思うんですけども
我々問題するのは未知語登録したとしてもまー自動的にどうするか
あるいはユーザーがあーえ行なった後二語であると思ったとすると
いうようなことで何かの方で登録できると
道もですね
でその前提の下でえその言語モデルをどうするかと
いうことをやろうとして
んでそれでまー未知語の元の扱い方の問題としては統計悪いえあまりいー魚を増やすとまー一万語にするとか二十万を一とかまそれの中ありますね
それをお湯をあの冷凍されると
いうことも勿論
んー現実的だと思うんですがまこれはまー
えーえんまーメールとかそういう言葉まそういう場面もあるかもしれないけども
そして二十五避けられない
文の私たので
そういう問題
もう想定してこれは
それな目でえー未知語の言語モデルをどうするかと
んーとまークラス言語モデルを使うか
差分をどうモデルでえーそういうな一部をですね
えーサポートしえすえー耳にするということもあると思うんですが
まーここであっですのはプラス言語モデルをどうするか
いうような
判定の考え
んーやって
汚いをおーおーそのー
でまクラスでももううーの紹介なんですが
まーあーまトレーニングデーターからあー実験等に対してはあーワード別のＮグラムを作ると
いうことですね
でその辺ボキャブラリーをおー七の方でクラスタリングしておいて
もあればなクラスター二のクラスにクラスタリングしてですけれども
そういうまー一個からえ関数のクラスに対して
えー新しいいー未知語に対してですねどういうデーターを使いながら
クラス数をおー推定すると
えーよほど
でその
未知語のクラスに対してえ×ですえーグラムを使う
まこういう形で併用してやろうということです
んでプラス一文モデルは普通はこういう風なモデルなるとまず一つ通り
単語の利益いーうー現在の
パンを推定するという確率ですね
それはまー暮らすうー
えー
んのおーカテゴリーで
えーえ推定クラスを推定してるコーパスから
あのー
本質
えー用語です
で未知語の場合は
この音ですね確率はちょっと分からないというので
あーこの研究ではですね一応六七八
英語を仮定してまずあるクラス数音が
ま彼はですねその頃は既に
いうよう歌もまーもし後百側としたら
その間は五百万が一の確率で生じると
いう一様分布を仮定しています
方向が分かるで入れちゃうかもしないですけど
ま現在はそういうな名詞句は
大手
えー
んでえー先程言いで二三を八ぐらいである単語は一つのクラスター
三月
することもできます
ま一応これを一つの
クラス言語モデルと
んー
考えたんですねまーいい状況がが格がま一つの頃
という
んで後もう親に対してはある意味でいい対応をまプラスに割り付け
いうことですでさっき言ったこの確率は
えー一様分布でえー
んー
んでそれでですねあのー以前のような例をクラスタリング数しておく訳ですが
んまー一番まーよく使われるようなターム同定データーマトリックスとかバイグラム当たり
こちら現在のあのーこれまー
一つ前の単語と概要これはマトリックスで表現し
えー四ですね
でこれでいいという文に対してはこういうような要素は
ちょっとイメージですけどこのえー行列の要素は
んーま求められっていうとしてで後あのー子供なのに対しこれは新しいデーターの方も帰ってきて
辞書には登録してるけれども
あのーこれをどうするかというえーっとーまー上二うーデーターからですね
まーこのあのー推論
んー
ちょっと理由ですまー
えー
ま親データーからこういう成分を持っててきてですねでこのまーそれ作ってこの後もう体のベクトルを一枚目えーいいるような
えー
言語で習ったあのー見つける
いうことですでこれもまた要するにも体も見つかればまそのクラス
交際をするま兄弟が取りながら
んー
あのー貰うような結構何で
えーまーいいと思いますけれどもそれで三十一例なあーことであるというボキャブラリー乗ったもの
古い自動計算すると
まそこで
まーファンクションをあううーのはどうみたいのをですねまーどこにモデルは単語おーはちょっと考慮しないというので
あるいはといううー
んー
メジャーで重み付けしています
そういう中で占められてよ
変数七年の八文全てに対してえー一度も
もう
あー求めてその中で一番大きい
対応する言うとやっぱり
パンを見つけてそのクラス
交際をし
私の方で
でこれはまー例なんですがあー
それでえーま後四五一名です
一に対してえー応援うーうーデーターサーチ
えー
え先程のマトリックスをつく
えー
普通の融合型や回答のおー類似度を計算し
まーこういう風な
そういうのではない二万単語とかあるんです
でその最大値に対応する
クラス四歳です
まーそそういうことですね
でまた二つとしてはかもという面止まってる側のま二つを使ってですがまー実験的にはバイグラムうちの一ということなったで
できたのですが
えーま概要なんですが
あーここでちょっと実験これ入れ境界推定方法二はまー
え対象テストデーターとそれうーデーターをおーそれぞれじゃになるんあのコーパス使いました
で千四十七年から八十九
のデーターがちょっと上ですが見え方それであの評価データーとして
えー正確に使われてるうーデーター
それらをしています
で僕らが最大に需要は
えーします
まこれはま基本的な模型をしたいですね
んでそうするとテストセットにあった程競馬での週いいいな六千四百
こうですね
後えー学習
テストデーターにはですね
んでえーっと例のデーターに対しては
んー
二十四．貰ったんすかね
あのー
ことでは二十九八五治らないやつが
百六十てもらったと
けれども
このテストデーターに対してまテストデーターコーパスにおいて
えーえ違います
二個からやって自分のデーター
えー
でこういうなので例えばうん
それでまーというのは
あーどういうな対応するうー単語一回かというあのーまー
利益を批判ですが
もうこれあのーうー固有名詞
えー一つの
私えーまー一年の一掛かってきてんですけど
奇麗には
なってないんですけどままー
一年はん一〇に近いような集まってきて
んーとーけあえーほ
一年一試合
単語のえー
んでここで問題はですね評価したり
トレーニングデーターの中ことでわりと
二テストデーターをどうやら
トレーニングデーターあーん
の二十三つだと思って私をしてもですねトレーニングデーターでも貧乏であったと思うやられ
なりましてテストデーターに対しても
冒頭であるというので
でまーここでえー対象としてのおー六年と書いてあるんですね
それがまーデーターあーに出てくる
ですけども
えー単語として登録していない後僕がこういうまー
これをまーまず最初にんー最初ちょっと
あのー
それの実験結果
うーそれでですね
本当はですねこのあの将来どうするかというえーですけれども将来テストデーターにいー
母音語彙数はどの程度
一度まー一度おー
坂というような
とかま色んな問題ができる訳ですが
我々の仮定としてはからのあー非常に多いとですね
この〇二保険が二十九四であればお父から〇とは
二三パーセントであるとしたら
テストデーターにおいても子供って文の例が二三パーセントであろうと
いうようなえーどうもえー
うーてやろうとしています
頭の事例がちょっと違ってくるんですね
このテンプレートと後はまーある程度推定しないというのもですね月から
まーテストデーターがある面トレーニングデーターであろうが
本当語形の例と同じであるっていうをするとまそんなあー考え
で
教科としては音声二二つとまこれ一えーよく出会うんですが
この確率で毎週もんで
あの構成では文章を使わないとですね平等な比較はできない
例えばえーボキャブラリーを二十キロでしょうそれが六十キロにするかというので
バブル時に変わってきます
あそれいいというホテルが主を使うとそんな問題を構成されます
まどういうことかと言うとですね
例えば後歴史というのは
まー子供にあるのに対しては一様に分布すると
ペルーの出演してると言うかですね
それであのーまー無事警察
そういう
そういう何らでえー評価して
それで先程言ったあートレーニングデーターとテストデーターがあれば
それでえーこれがまー今日のあー感があー補正パープレキシティーえー固有値があー
通常のパープレキシティー
でこれが僕らサイズの登録
二の数ですね
んでえー我々は基本的な一九八
通る二万語を登録してですが
最初でトレーニングデーターは全部でえー一六万も
一年していたんですねまーボキャブラリー
最終を
フランスとですね
パンフレットをおー音声学者同じ値なんですが
ま心でかなり差が出ています
ま二十九本ていう発話は結構んー
まこれがあーまずんー
あのーまー
トライグラムであれば私がどうなるかと言うとですね
でこれをですねクラスでこのモデルを使ってて話者クラス言語モデル
んで二十キロ音楽の家をらサイズで
後は部分からサイズをこうを登録しているという
年二十キロを登録すれば
全部で四の単語になりますけどね一万単語にボキャブラリーで
登録されて人間のトライグラム止まってるんですが
後二万単語を登録してえークラスでのモデルを
うーをおー作ってですね
それでまーこれし計算すると
大体四十ま話していいと言うかそして私四十からあのー
でベースラインの
あのー
方あーいあのー一二四六時集合であるから
んー
かなり
その
えー
まそれでこれをどういうことかと言ったらこう二年間
後あの登録して後もう一八万単語は全部一様分布であると
その一つはプラスえー仮定したやつですね
でこちらは
ん二万単語登録して未知語を
そのクラスに対しては
えークラス百からずっと翻訳クラスでま三人でした
食事があまりなくなっ使うと
んですあー
認識実験Ａや
テーマ
でこれは
ちょっとあのーもうそれであーのーんん
世界で使われてるうー評価データーは比較的なんで
二型のデコーダーでも九十五パーセントぐらいは
単語認識ですが
でそれでちょっと違いとか優しい過ぎると言うか評価でねもうちょっと難しいように
必ずえー自分は一部一部をこのようにえー
テストセットを作っていやああ
あータスクでえー
評価してですがベースラインであると
えーえーこちらの二百五十グラムですが
二十九モーラ登録すると百四十七．五ちょっと
言うんですけれども
ここえー理由があったかどうか二年目ですが未知語だけの後歴史を計算すると
ベースラインでは
バブル期が三百四十五まー尺度の値ですけども
んでえーコーラス言語モデル使うと二百万ぐらい
いいだろう
ま三百四十万から二百万
八ページの三は
んでえー明治二十九Ａが項なんですが僕が貰ったと言えばにですね男性後とあ前に
まーあのー
共有できます
こうぼけが理由をまー六万語の単語まで二
力ってなんですけれども
であると最小んあって話者七十二．七であった七十九．四一
ま言われながら
えー
二四八ぐらいのサイズをクラスというのは
んーまー
認識率の向上方法なんですが
まそれによるしても
の時は〇の問題は解決的なんーでということで我々だけにやってですが
んでそれで本当こうなりまして
あーのー
別までまー一クラスの言語モデル
けれども未知語に対してそれがこういうようなあー
誤り率に対して
百二十九二八九月になると我々がえーっと
で後ですね
でもう一つ高くなかったんですが
ああいうのが来なさいとこれが一二四月五日二十一型二十五えー
三十気にするとですねえーボキャブラリー
その数一の方だと文書というようになりましたけど
これは一個一一パーセント
〇．四パーセントぐらいを行なう訳です
さっき言ったあー
三十九本と
三十成功例二十九プラス一九八二三四八ぐらいとしてあったのは誤り率が
二十三．四ですね
二十三．八に対してフランスでももう一つカテゴリー三．八パーセントですから
単語をどんどんあの登録して
えー色んなもので
あのー
モデルを作るのと
おー単語と数分でえクラスのモデルを一度ですとえー
であっても認識率が
それをどうかを考えておりられた
いうようなあー
まー一応
んー現在までの
ですから
これをえー
#############################


#############################
# query = 三十四中継のもうロンドンだったと思うんだけどえー二月四者の興奮状態では必要なのかってのは都合がなかったんでまー詳しく説明しているうー文があったら五十一歳
# rank = 1
# slide = 07-21_fix.match_word.jout.txt
# value = -3.07514644120421
#############################
はいすいませを持たせました
しか構成のカメラと申します
えー自動子音分割を利用した
えー病気を第二世支援システムということでえーこれについて簡単に御説明さいたします
えーっと最近あのネットワーク上で利用できるビデオ教材がえー色々増えてきます
えビデオ教材をしますとおー御存じ内容的な考え方何々分かるっていうことで
えー要旨集を作っ四十二が七十まこれらに有効であろう
難しい
でえービデオ教材の種類や数はまだまだ少ない
ビデオ教材実際に作る為には結構手間後時間が掛かってしまうというのが問題で
でえー例えば
えー教室とをでえーこう木を録画しますと
えー
まー一般には
本音な流れになろうかと思い一万式で確認とあって
で導入それから話題性については第二つにまとめ
この中で必要なシーンの抽出もしくは
不要な資料三情報と行なえれば
ま最低限のコンテンツができ
しかしながらこの話題って言いますか子音の影響を書い一を決めるではなかなか大変な作業ってが時間が掛かっ
でそこでえー
でえー我々はあの六が遊び様子を楕円のおー話題ごとに自動分割することによって
えービデオ教材作成のテーマをえー少し経験してあげようまそういうシステムを構築するということを目的としてえー始めます
えー
えー本システムの方がようなんですがまずＡＢ八番から
えー音声情報をえ取り出しましてえーこの音声情報を元に
えー音声認識しまして
えーテキスト情報にします
えこのテキスト情報がなく対テキスト情報ですが
でこれを用いましてえー新
分割位置の推定を行ないまして
えー子音にはえーま
でえーこの子音の中でえー不要なものだけを削除するだけで基本的には
まー最低限のビデオ教材はできるだろう
でえーまず音声の収録環境なんですけどもまこのような今やってるような形で
えー接話型のマイクを使って
でそれをおーは嫌ですトランスミッターでえー
えーこう多分
産婦人送って
それをＢＢカメラで
収録する
まー
かなり安上がりな構成
でえーこのような構成でえーちょっと
でえー数年前に
予備実験を行なったところ
えー評価
最初はＩＰＡの
で評価文百文なんですけど
これを実際こう私の方で読み上げまして
やってみましたら
正解率が九十五パーセントぐらいあるのでまデーターベースとほぼ同等の
数字が出てましたのでまこの四十六日環境で大丈夫だろう
で次にえー他の実際の地形
を
取ったものをやってみました頃音声認識していましたところを
でやはりかなり苦しくて
えー五十パーセントぐらい
関係ない
ま単語正解率で
五十パーセントぐらいしかで
でえー言語モデルの方を
でえー新聞記事から
講演の方に理解から
えー六．五四パーセントぐらいとか
まそれでも何まだまだ苦しい
じゃそこで試しにっていうことで
で実際のその行った講演の書き起こしテキストを
で実際に読み上げます
読み上げて
えそれを収録して最後認識してみます
そうするとまー七十パーセントちょっとぐらいない
まこう何の為にやったかと言うとまどの辺頑張れば可能性があるのかなってことで少し目を付けた形だけでしてえこれから何がいるって訳じゃないんですがちょっと乱暴ですけど
でえーまこの三を見ますと一四年後ぐらいあるんで
泣くともうん木を
モデルＯ頑張ればこのがいるかもし
で残りは言語モデル
かもしれ
いうぐらいの気持ち
でこういう苦しいえーテキスト情報を元に
ええー新聞月一推定を行なう訳ですけども
えその方法二はま色々
で御提案されてますがえまず
えー基本的な方針としてこう子音が幾つかありまして
えーこう隣接してるシーン感が
えー
こう似ていれば
四つのえ子音
家にいなければ
えーここ妊娠境界があるだろう
いうような
でまーあのー
一般的な方法です
で
えーその各子音のえー
を表わすような指標っていうのを
で求める必要があるんですけどもまこの方法も色々御提案されてまして
で言えばＩＤＦ法を最も勿論方法それが言えるＩＤＦを考慮した相互情報量であるとかさまざまな会議場をもう一歩ことが色々ございますが
えーここではえー独立成分分析を用いた指標をえー用います
でえーどのようなものかとまーごく簡単に説明しますと
えー独立の成分分析を
用いる指標としてまず用意するのは
でえー各文は内容語の頻度分布まこういう
でこの頻度行列ごと文の関係をも
あーまず求めま
で
えー八一で
誇り成分分析を用いて
えーこのおー
えーこと文の関係をは回答文
話題と子の関係に分離することが
でこのは回答文の関係をえ指標をインデックスに使おう
まこれによりましてちょっとこのは回数は一に設定できるので自然を
簡単にコントロールできて
えー
まーあのー
最後に小さな手計算量とかにも理由
出しうまくグルーピングできれば制度ももしかしたらあるかもしれないというちょっと気持ちが
で
でまーだ隣接する子音考えてるかどうかを調べるんですがその為には一般的に用いられるコサイン夢を持ち
でえーこの四年な
えー
ま小さい程似ていないってことで子音境界であろう
でこの隣接する子音が心情が出た後ずらしまして全ての四件の
でそう和を求めて
この総和が最小になるようなこの四人の
で後
これを
でえー求める場合
まこれはどうで結果ここで求めることができるんで
でその中で実装いたし
でシステムの
えー構成ですけども
ＰＯＣ三つに分かれて
で
ただ一つでも今回
それからもう一つはこうプラン
それから
え音声認識を用いたから
で
そうするから部員は
でまポーズ情報だけを使ってとにかくこう気が終わって
作っ編集したいっていう場合時間がないっていう場合には有効
でえー音声認識を用いたクラブには
え大まかにま御説明させていただいた方法
まず
えーっとー
えスピーチぐらい高い音の音声認識
ソフトがあればどれでも結構なのでそれを使って音声認識します
で音声認識しましたら
その音声認識え情報をえ音声にです確率情報茶筌を用いて形態素解析しまして
でベストをえー一度あのどうし
どう自立語を抽出しましてその語の頻度分布を求めて
てその語の頻度分布から
えー話題と文の関係を愛して求めて
でそれを
えー
動的計画法で
心境が求めというような流れ
おこの辺でやっぱり
でえーこのえーシステムおよびえソースコードはこちらあの言われるの方で公開しておりますので
えーまーあまり
中身は恥ずかしいんで
えー
まー御覧いただければ歳
で実験を実行例なんですけども
えー実行しまして
えー
えーホテルだっ
えー音ビデオ情報をしてＡＢ力を開放していきますと
えー自動的に
え音声認識をしてでそれからこういうような羽目になり
で左側
えー自動的に新聞がされた子音
んでＡスターと一致度を継続時間ぐらいが表示され
あまりにテーブル良くないですけど
このＣを適当にこう選ぶとその活動がこちらの方で再生二度再生され
テーマいただければあるじゃない五で最も直して
基本的な決してやらだけで二十五は
いうことで
ですが極めて初心者でも非常に簡単に使えると
でどうしても途中で切りたいっていう場合に入っているかとボタンをちょっと使って面倒な操作を必要
ですから結合には非常に気がある
でえーこのえシステムって言いますが自動を
え分割二音の効果を確認する為に評価実験を行ない
被験者は一六名で
えー練習対象は広義の約三十分分を収録した
えービデオ
そう第五種類
まー五人の先生の授業を用います
でえー開始の状態としましては
で二等分割を行なった状態とを行なわない分割なしの状態
評価の順序も有無
話し合いでそれぞれ半分
こういう形で
で実験を行ない
でビデオ編集二の四二としましてえこれから事業を六月日ビデオ編集してもらいます
で復習する為に利用するビデオを作ってから
いう話で
えー
んで要らないと思った部分を削除していくまこの程度の情報ぐらいしかえっと二月にあって
が被験者は
でえーっとー
ま学生さん
でえーすそのん
しーした後にアンケート調査を行ないまして主観評価の結果なんですが
で自動分割アイデアとても
飼い易かったって人が六名
えーやや使い易かった六名
どちらも違いはないでしょう
で嫌々
えー使いにくい
とても使いにくい二名って感じで約七十五パーセントの人達がま使い易いと答えて
で残りの四名については
で結構操作にあまり慣れてない学生さん
のようで
ですがある程度
操作に
ええー慣れている人達はほぼかなりの確率で
で文化祭の方が編集し易いという風に答えたり
んで編集に掛かった時間なんですけど
でえー自動分割なしの場合は二千三平均して二千三十三秒
それに対し成分があるという場合は
千七百四十六秒いうことで
で三十分の授業なので千八百秒
ですが千八百三四五六多少
平均〇
食
でえー一時間で五分
じゃこんなに早く終わってまともに返事でしたのっていうことでえーちょっと不安になりますので
えーっとちょっと調査しています
でこちらがどう第二ですがＢイコール
えー最近
えこちらが
えーっとー
適合率
でえーこのブルーの
あるかこちらナイフ一ですがブルーのものはえ自動分割直後のもの
で千自動で行なった結果ですね
でえー編集直前の状態
まず再現率なんですが
で三十パーセントちょっと
ね
えーそれで
でえーっとおー
えー次に
自動分割歩いて
えーっとー
現地行った後の結果ですが
四十パーセントぐらい上がって私変わらないようにちょっと驚きます
んで
でえーこの
黄色のものがえ自動分割なしで編集した直後のものなんですが四十枚からちょうど中間ぐらいになっ
まこれから見るとおー
えー
自動音楽がありにした方が帰っていいぐらいがまー同程度以上にはなって
かな
でちょっと驚いたのは先程申しましたように
えーリコールの方で
あまり
えー大きくならない
一対一が判断しても機会が判断してもそうちょっと畑があるんだけども
この他が〇になれば
先の人ボタンを押すだけで勝手に前後あるということな
でこのサインの部分だけかとボタンをしてえーちょっと手間が掛かるということにですから目標としたこの三が〇音楽というのが目標に
一方でえー出てきもう一つの方はかなり回転します月に二度ボタンをして言わないの消していくとですね
まこの操作あまり
あこの世界があっても
でえー操作としてはそれ程〇音では
彼は少ない
ということでえー精度のまま
でちょっとその
ちょっとの
んでこの辺のちょっとの
え改善を
えーするまー一つの方法って言いますか
方法例としましてまた問題色々おーあると思いますが
ちょっと
試した
例としてえー二千一年に前は三等が提案されてるテキストベースのえーと一二を分割する手法として
えーまー統計的手法による新聞かつてのはっ提案されてるんでそれをちょっとこちらの授業音声と言いますか
に適用してみます
でこのＳって書いてあるのは
えー一もしかセグメントのなら
でＷって書いてあるのは
えー単語の七
でこの単語の並びの与えられた時に
でこのセグメントもしかし員の
でならび
を最大化するような心境を変えて言いますか
を求める問題という形で形式化されてで
えーこれを
ん実際に
とか
でえー
まー結果とした何か
こんなような
はプラス法みたいな形で近似されてるようですけど
これを実際使いまして
えー実験の結果としまして
ちょっと分かりにくいんですが
横軸は
えー一の分割数
えー
二の分割さにえーま上げることを当然ですが
再現率は上がって
こちらは子音の分割
対立ってのは
全体の文数文のどのぐらいまでは〇．一ですと全体の分布数が
で五百文だったら
でその十分の一の五十文拡大しているという感じな
で縦軸のこちらが
え再現率こちらが適合
え再現率の方が
で重要と言いますが先程申し上げたように
でまた適合率の方は一つだけです
けど
こちらがあるけど
発表語
いうことで
えーこちらの実践な回路の方が
えー
隣接する子音が
を比べた方おー
とこの点線の
青い
ものは統計的手法による
もので
でこのまー一歳
わずかですけど
てえー統計的手法による
方法の方がちょっと改善されているようなで
ま声の音を色々二つあって言えば
えー
いいんじゃないかな
いう風に
もっと
でえー以上をまとめますと
えービデオ教材
作成を支援する為に
でビデオ編集システムを開発し公開させていたら
で機能としては自動新聞が好きの
のみを持ってまして
で必要なシーンを選択するだけで教材作成があのー
でこれに竹にこだわったのは
でその談話機能についてはあー世の中にあのービデオを編集するソフトウェア山の上にありますので
そちらにお任せすればいいだろう
ですからその振動を分割するところだ結果にえーっと五月早くして後は
で色々自分の好きな人って扱って編集してもらえばいいんではないかという意味
それから約八なっ
え実験評価実験の結果約
七割七十五パーセントの被験者が
で自動詞ん分割を利用する方が使い易いと答えていて
えー編集時間も約一句一割以上削減でき
でえーまこちらの方で
崩壊して
と時間が英語なら
ってもう
えー
えー
えー
えー
そのー
えー
タイトル
えー
えー
のえ少し
えよねこちらの方では二十
そして
まうー考え方としているとおーいう概念を
持っている
えっと
システムに移動しまして
なシステムを起動しましてえそれから
えー
音声認識を
え行なわせてえー自動的に四分割を行なうとでまこちらのような感じで自動的に効率と言いますか親密にえー開始時刻とか後実はんー
んでえーとまその子音を選べばそこはすいませんはいんー
歳って言われていきます
えー映画とか
んでえー日本の中で要らないなどもあったのはあのーん
削除するだけで基本的には
編集が怖いの三五割
みんな後にある日
んそれは
後でお金を常にまーその中での機能と後
でえーこちらあのー月に一
そして
例えばここでえーやっぱり知りたいなと思ったらまー
ちょっと面倒打ち合わせ面倒なんですけど
えーここでは取ってやるとまーうー考え方としているとこういう概念を
目的は
まうー考え方としてるとおー言うか
ま基本的には困難な形で
で子音を選んでえー削除ボタンを使ってで練習が終わるといいなんで
えーっと
まこういうのを作っておりましてえーまーもうちょっと精度良くであれば
え本当に出るとボタン
だけで
ですのではない
正しいって注意点としてはちょっと先程もございましたら
あのー
まこの結果
娘にもありますように
でまーこの辺
の
一日を見ればま何とか
もうちょっとお皿に使い易くなるのかな
でこの辺の
えー人間でもただあのかなり心が低いっていうことから
でまー
差による
ばらつきと言うか
映画館なりをするのかなに関しては
一応
#############################


#############################
# query = 三十四中継のもうロンドンだったと思うんだけどえー二月四者の興奮状態では必要なのかってのは都合がなかったんでまー詳しく説明しているうー文があったら五十一歳
# rank = 2
# slide = 09-11_fix.match_word.jout.txt
# value = -3.09230367643907
#############################
えーではえー音響情報を用いた外国データーをクラスタリングというテーマで
で法政大学大学院の御発表いたします
でまず初めに
えーライフん語について説明をいたします
えーライフんますのはえーと
個人の生活や
えー体験も記録でまカメラやバイクＧＰＳ加速度方法のおーわざわざ
えー形で記録されます
を利用法としましてはえー
二四六八個に気を自動作成今日の体系というなどへの応用が期待されています
そこではない黒くなるんですがそのーデーターは説明する辞めていく為に
て多様化放題で
ま冗長というような特徴があります
えーっとまその為にま効率的な利用の為にはえー検索要約が必要となってきます
畑作り要約の為には
後インデキシングんー系まクラスタリングなどの処理が必要となってきます
えここではない部分の先行研究といたしましては
そのー生態取ったものがありましてえー
構成さ情報の御家族のじゅ
後
僕は言ってえーその時のウェブの情報をえー三ページケーキ屋でゆいう素敵だと
からまー画像検索キーを
抽出して
辺がメーターカメラの画像検索を行なうというような
システムが提案されています
えー
また外国空いてるというものを提案されておりましてまこれは携帯を
使用して
波形は計測した後位置情報夫婦の感じを行なっています
えまたえー第六画像をクラスタリングやセグメンテーションについての研究もえ過去四行なわれていまして
上の方に分かれている研究では
このく二．五二日のデーター二と三十四種類のラベルを付けまして
実験三四クラスタリングという時間的に近いデーターがおらです
クラスターに含まれ易くなる
クラスタリングを行なっていまして分水報道を改善する方法
ちょっと報告されています
また
知ら下の方の
研究ではあの一日千七百八十五枚を
それに属した画像からなるまえーっとおー
こうま二次元一にあるか
えしましたえー二時間以上
では一度電源が大きくなっているところでま一つの分割を行なっており弁当ごとのセグメンテーション方法を
行った上でまイベント事仕事の
その可能言えるとセグメンテーションを
行なうという方が
後はえーやったセグメンテーションが提案されています
でこのセグメンテーションをあのつまりある画像の
一メートル以上により
セグメント境界を求めることで行って
でまたえーと映像が契約音響情報を用いた研究もありまして
えー
シラブルの方に書いてありますのはえーまー記憶支援システムというので
えーと位置情報を音声認識の結果を
えートリガーＩＴというものです
はですが音声認識の会話ここのデーターに音声認識を掛けると
誤りを含む可能性が態度で
あー認識下顎の信頼度ものを設定することで
えユーザーのソースを矯正するというシステムが提案されて
えまたえー
音響情報を用いまして実験を自動作成をするという方法も提案されています
本研究ではえーユーザーの二を最小にする為に使用しているでは一二は
ホーム指向性マイクとＧＰＳのえー
軽く一二時間のデーターで重要かそのラベルを付けて
あるいは都心からレストラン事業といったあのー柱状況を比べて
えー
まこれはデーターをこのスペクトル情報を利用してセグメンテーションや
クラスタリングを行なっています
でまこのように
利用されているホーム教育論情報ですか
ま得られる情報にはま音声や音楽環境音のとか
あります
あのー音声からは
調べ
えー
で
あー会話の内容であるという話者情報が得られたり
の音楽
発表用の
えー
えー
はいユーザーがほぼ一定でその方っていうのは職場ということを一型ではまもしや状況が分かる
んー
でまた環境音からはそれ以外に行動っていうのは
測ると考えられまして
補正をこちらの
フランスこう
っていうことなんですけどももうそん時の方とはあのー人がやってると思います
試み色々な情報を含んでいる音響ライト六十を
情報ですが
は非常に
情緒不のこういう情報となっています
音声長はこういうえーてます上昇といいますのは
あのーお父のま含まれていない
とそうでは含まれていないというのはまー
特に
ざっと見たそうみたいな
食そうみたいなものだけしか含まれていないかショーや
ま含まれてるお父があのそれを聞いただけでは
んー何か分からない場所というのはまー
冗長性があると言えると思います
えー
これそこでえーま本研究ではまー冗長語を省きまクラスタリングを行ないました
でまたそのクラスタリングの時に使う特徴量について
子供の効果的かということについて調査をいたしました
えー
あー水泳まーマイクロホンそれぞれにおけるま一般的な問題点について説明いたします
えー
バイクがほ編集された映像はテレビ番組あのー映像とは異なって
詳しい人が一回と機械的にま安定したりとかっていう
効果がだいぶ
ま人やものはカメラの場合は行為易いということで
私の一階が不明瞭であることはあります
えまた音響情報では
販売からの距離より非常にこう思うようにばらつきがあったりするような問題があり
ここでのことを中心的には考えてまだえっとー
これ
えーえまたえークラスタリングを行なったりするけどもセグメントを単位の長さですか
えーと従来研究ではま五分程度の処理が行なわれている
姿まこれは識別をしたい環境は
二十億と言われてる長いもの
ということが前提にありましてはこの程度の
え分解能でま処理を行なうという
後になっているのですがま実際は識別をしたい
環境はまー長時間とか特徴時間八時間のものがありまして
ま用途によって異なってくると考えられます
んー
白の
えっと予測としましてはまー例えば四があ環境を
にはあるような場所は環境ようなある程度時間を
えーえーっとー
二十円と呼ば掃除がありん型の町時間のセグメント向いているのではないかと考えますが
あの音声や音楽環境音といった
そのー環境の中で三十クラスタリングを行ないたいという場合には
また時間のセグメントを使うのは一二を考えられます
まそこで本論文では短時間セグメントの場合を扱いました
あの固有短時間と言いますのはまそうしより構成内容を
話者や後
最低限話者が分かるという内容をまー
発表は
えー環境音がそのことはないか分かるというな形としてあの五八程度
僕がそれをセグメンテーションを行ないました
えーっとところこれをま基本の単位としましてま冗長部分ん全部やっクラスタリングを行なって一
えー次にえーデーター収録について説明いたします
えー収録経済は
いう場合のアルバイト
ＰＣＭの方に気が法華経るをある〇型とであのペット楽しＸという時代を
用いていは
んーずれてますけど
えーっとこの
二つをおー使いまして
七分ま四十時間を収録を行ないました
二十落ち
雇用区分はえーえー議論は〇九で人文化
でまたのおー
えーレコーダーで
記録をいたしました
残り二つを使いまして
えー消えてしまっているのですが
えーっとマイクロホンを収録期間ていうのはまだ一年にも分かることはそうされますので
そそれも一四十四が短い為に四の変化に対応できるようなあー処理を行なわなければあーえっと
考えたのであまり大量の方を使って主としました
えまたえー
母音を以下の本来
えー
とー耳に到着して使用するものですが
あーのそういう状態をまそう時間の収録は
はいユーザーの負担になると考えられるので
畑に
嫌いの私の方が気にして
収録をいたしました
この状態で日常生活音をまサンプリング周波数四十八九付ける
ヘルツ
考慮した人数が二十四人とは重要文という
このレコーダーによって違う一つ
使用した人数でえ記録を行ないました
えー
では×収録された面もそう思うは収録音声です例えば昭和の研究して教室が
えー
えー大学×ですとおーレンタルビデオテストマーケットで
えーとそこで収録された音というのは
ま先程の音声やパソコンを操作していると多分
文の音楽あのー
ゴルフ場だ車をその場記録されました
えー
心がまー幾どう影響情報から不要なセグメントのま冗長分野からセグメントを削除する
感じるするということを行ないました
誇りを
先程二つまーえーと不要なあー状況としたデーターですが
歩行者の何が含まれているあのー分からないというものは
あの非常に他の音声とは特別するの難しいので
で今回は
方法もおーセグメントについて勉強ございました
えー手法としましては三つの特徴量が閾値以下のセグメントをさてあー
方法で行ないました
えー
その三つ延ばし特徴量ですが
ねそれができたスペクトルの頭の方は
でもこれは
えー
資料八つの四日本はまースペクトル包絡いないんですが
のえスペクトル情報その楽器を持ってきた取ってきたスペクトル包絡というものですが
とこれのえーフレーム間の差分をそもそもで
とこれが文の場合ですと
千葉のように
非常にま差分が小さく思われます
んー
二もう一つの
特徴量としましてまそうあのーサブの最大値
ですねこれは瞬時に変化する音を検出するということで先程の
数法というような
音など
がまー誤っている
提示されないようにこちらの
少量を用いて
後それと後はされている
あちらの式ですが
えー予稿集の式とえとなっているのですが予稿集の式は間違いですので
白の方に訂正を思い出します
こちらの式はですねえー
繰り返しんん差分の方は
いうことで
えー詳しく差分を求めているようですがまレコーダーによって
相当の大きさが異なってしまっているので
それを正規化する為に
えー
後振幅のそのセグメント内の振幅
平均振幅によって
ま的化を行なっています
えー
んー
んー
えー
で次にえー
あのー
この前の項目の三つの特徴量を用いたのですがまそれの閾値の決定の為の
実験を行ないました
えー
四十一時間のデーターを全て
えー約五四点目と二分のところ
三枚百五十あのセグメントに分割されました
結構だからランダム二百セグメントをやり指導でえラベル付けを行ないました
その結果三十一セグメント不要なセグメントで
えー
後三十七生の四月二十セグメントはあのーセグメントでユーザーセグメントが
生まれることはないか分からないっていう船がセグメントでした
えーこれをする必要なセグメントは自分されてしまうのは実は少ないので
えー
不必要なものが提案されないように閾値を定めますと
あー結果実践とは設定できて永久セグメントはもうもうで一つセグメントはあそうだと
生まれるとか目をセグメントでした
で閾値の方なんですがえーこちら三十一グラムてまして方法が
え各特徴量
あのー
全てのセグメントを
分布になっています
で赤い方のえーばはえー不要なセグメント分布になっていて
は正規化スペクトル差分の
二十分平均の一つはそうでは
えー何か
えー正規化スペクトル差分の最大値では一酸化
政治家
振幅の平均では〇．一以下というような閾値を定めてなりました
えこの閾値を用いましてえー
別のランダムに選んだ百セグメントに対して不要なセグメントの軸実験を行ないました
でこっちはこちらセグメントもえー手動でえーラベル付けをしたところ
三十四点目と二四でそのうち一名セグメントはあのーセグメントで実習生名とは食われることはもう
二名のセグメントでした
でえーえー病気のえー
えー連接しましたえー
んでです方法
適応させましたところ
母セグメント場所されてその後六セグメントはまあのーセグメントで
えセグメントがその他
六四えーっとでした
とこの結果から
まある程度の有効性があるよと考えられます
えーこのようにしてえーま不要な
セグメントを取り除いたあの残りのセグメントに対して波形ビーズ法によるクラスタリングを行ないました
で今回は夏の特徴量を用いてクラスタリングを行ないました
えまず
二つの特徴量としての平均スペクトル包絡を
えー正規化平均スペクトル包絡うーことで
知らえー先程のまー多分
私と同じのですがまこれを
方ますの野菜は全てのスペクトル包絡をの平均して一つのものでした
えー正規化しては妹伝わっ正規化してないものと
そのー両方でクラスタリングを行ないました
でこのスペクトル包絡を用いることで分類した音同士のクラスタリングができると考えられます
でまた明日の場合ですとま正規化によって
えーまー録音機の違いによる影響受けたことができるのではないかと考えられます
えまた平均スペクトル包絡放送をそのーお和としまして特徴量の一つとして扱いました
えーえ残りの六つの特徴量は
んー
えー振幅差分の最大値と
後先程の例をえー用いた三つの特徴量です
とこれらは環境音や音声が含まれている場合に大きい値をその傾向があります
あー逆に端的に音声という場合にはちっさくなるのでま環境音と
環境音や音声とまそのー一九一二分類されると考えられます
えー
これらのまー閾値を用いまして四五のセグメントの授業を行なった
九十五えーっとークラスタリングを行ないました
パーセントにはえー
まちょっとましょうとそう含まれて大きなベルが付けられています
えー
てクラスタリングの結果ですがこちらの
表四になりましたこちらはえー適合で書いてあるのですがまーしたり
その対応するえ場所が書いてあり
えー
んー
正規化をしてはえ特徴量を用いた場合にはえーの後期の違いによる影響が強くてしまいましてあまり
でクラスタリングはできませんでした
これはま世紀から音料理関係のない特徴量を使用することで
あの解決できる問題と思われます
えー
日本一の正規化した特徴量ではまスペクトル
あの平均スペクトル包絡が
良好な
結果でした
そうですがえーこちらんー
こう見て本当にえー
工場というのは研究室のクラスターのですが
既にクラス数を読ん非常にした場合には
えこのように研究室の方は
同じ場所のクラスターがいつもできてしまうというは
えーっと利用がえーですおきました
えー
あのーしたがってまースペクトル包絡ではまー特徴量そしてま不十分であるので
他の特徴量を持っているかま他のものを組み合わせて使うということを扱う
評価と思います
えー
このえー音響情報について
僕が上に
着目してクラスタリングを行なった場合の結果こちらになります
え対応する
組まれていることはこちらのようになります
とこちら見て分かる通り
他スペインがあのー結構全くできていないという形になっています
ましたがってその
生徒の兵器やあのこちらはこう変化なんですが
まー結果はまー
えー音響情報まそれにあまり
ていないのではないかと思われます
えー
また今回スペクトル包絡なのですが
そのー
えー四千九十六
定型文を使って
含めた
えスペクトルを始めてまで
えー特徴
初めてにして
あのー
だったのですが
えー
そうすると今回はいかない可能性があるということが考えられます
えー
私がここに九っていったあー研究ででした音の識別をしていたのですがまその時は
自分ってでも
えーそれなりに識別ができていたのですが
それ風呂には含まれてる音は
かなりたったえーま色々含まれている為
えー
おー一やっぱ可能性があります
えこの結果をま従来研究の
との比較を
えー行ないました
えーっとでえまー比較したのは二．七
二の比較を行ないました
え文献ならでは
トラベルを使わない学会の二六ラベルを用いてまたの一を用いて二五クラスターには一
そこのセグメント長は一分で
はその一五クラスターの中四クラスターでえ再現率精度共に七十パーセント以上
土置いて
他のクラスではもう片方が高いかま両方が低いという結果の一
入っを本論文の手法ではまクラス数多く出すと
この図はそのクラスター二できてしまうという傾向はあります
ことを検討して考えられますのはやはりセグメント長が短いということを言わないと思います
えー
これはですねえー
同じ場所大クラスター
あー同じはそもそもセグメントでも
方法があるというあークラスたり
で分けられてしまった場合にその方としてみると実はロボットが含まれているということが
ありました
ん伝わってまー
えー
まそれが悪いんだと考えられます
えしたがってその場所をクラスタリングはまある程度一二というぐらいのまあるてると時間をセグメントを見ているのではないかと
考えられます
えまた
えー
あーそのことによって
クラスターは普通に分かれてしまったということから考えますと
閉鎖時間のセグメントというのはあのー音響情報に関するクラスタリングでは有効かもしれませんが今回用いた特徴量ではあまり有効とは言えません
えー最後に
えー
これ話すとなるのですがまマイクを扱う上で非常に重要となってくる問題についてお話しします
ぐらいグローブはですねま常に
特に音声の音声画像を
では×え収録している為にもありがとう音声や映像は取れてしまうということはあります
えー
方でまー従来の研究でもプライバシーについてのことを
カバーや使われて適用されているのですが
えーまー
とーその例としまして高い要するをする場合に関する情報の収録は可能であるという風に言われています
ですが発言内容をそのー
結局は収録してはならない
いう風に
そう言われています
えー
ま今後はそういう
を行なう為にはま一つのフレーム内を御自由ように分割してランダムに理解というような手法は
提案されていてもこれを行なうと発話内容を一つスペクトル情報が残ってるという風に言われている
またその許可を得たユーズユーザーというこういった形からのその発話内容をお水は
は非常に精度の高い話者認識が必要であるとも言われています
えまた一般的に利用
一般的神様の為に解決すべき問題として
多分水道局が必要かということと
あー誰がデーターにアクセスの各を
片方適用方法や
あー社会的な規則についてもはっきりさしていかなければならないという風に述べられています
そこ四十
まあのープライバシーを面からもまたそのー
データーの数はえー
とーデーターの処理はえーとーやっぱり音声があったりしてはもう凄い音にえ表記があるのでま音響別のう情報の処理も非常に重要になってくるという風に考えています
えー
最後にえーほぼあの種を求めます
えー
この文ではえー
音響ライブ用データーをクラスタリングを行ないました
えー事前処理としてもうセグメント付けを行ない
二月の特徴量を用いて警備クラスタリングを行ないました
えーその結果まー正規化スペクトル包絡比較的良好な結果をいるのですが
僕らと数を増やすことで余計なクラスターができてしまうという
問題がありました
ま結果特徴量としては二自分ではないかと思われます
えまた
えー過去の研究比較
との比較からまそう時間のセグメントあまそのクラスタリングにもい言って
畑からセグメントは音響情報をクラスタリングにおいている
可能性があるという風に考えられます
でまた
今回のデーター収録は倍音マイクを用いてえーとなったのですが
あのー結構そのー優先のマイクを用いると邪魔になることはありますので
ファクターを減らすには物凄いこう使うべきではないかという風に思います
でまたタイトルは初期の発達収録されるのでま複数の講義はマイクを
用いて収録したデーターの処理を行なってここでは一と思います
その方の課題としましてはまクラスタリング手法特徴量やセグメント長
あのー
×ですそのクラスタリングのうちインデックスを付ける為の手法や
これは四の問題について
考えていかなければ
んーないと思っています
以上で発表終わります
#############################


#############################
# query = えっと後衰退んーだけどえーえーと叩きえー認識誤りについ体のえーそれを解決過程の複数またすー認識システムっていうのはどういったシステム化っていうのを後ずっと好きでテストを教えてくれまー教えてくれる
# rank = 1
# slide = 10-13_fix.match_word.jout.txt
# value = -2.57181812191844
#############################
はいそれでは複数音声認識システムに基づいた音声中の検索を検出方法の検討と
えー一つ一テストコレクションで三評価という目的山梨大学のなそれが発表させていただきます
えまず本研究の背景と目的ですがまー×先生の方からも言われたようにＡＢＣＤの重要というものがあります
んー
でそれに対して幾つか問題点がありましてそれにです方法がま色んな方面から
えー検討されています
で本研究では
えー複数の温泉にシステムを利用して
まーこの形式いーの性能を改善させていこう
という風に
えー
な
形でえ研究を進めております
え本研究のえ次のタスクについて簡単に説明します
え本研究ではえーとまー
音声データーに対してえ複数の音声認識システムによって音声認識を行ないます
えその結果に基づいて
まー携帯の違う
異なる
インデックスを二種類構築しておきます
でこれらのインデックスに対しましてえーと検索語をテキストベースで
与えられます
でまそれぞれの携帯にがえーとそれぞれのインデックスの形態にありました
形式でえ検索を行ない結果として強くする
まこういった感じのタスクになっておりますんー
んー
んー
はいで今回報告させていただくよう点について説明します
それでまず本研究では複数の音声認識システムを利用しております
で実際にこの認識シス二えーと複数使うことがどれだけ
効果的であるかそれを
まー音声認識率で
評価したところ高い認識性能が得られたうん
んー
でま得られましたんでえーっとこれらを使って検索用のインデックスをんといったものが良いかというのを検討しました
でこれらのインデックスかなんまーどういった方法でんー検索すればいいかってことを検討し
えー実際に
ＣＳＪのテストコレクション似て
京成の語彙を評価しました
で結果から見てみます
後二三四五六んに対して大変有効であることが確認されました
ま有効であると言いましても
イコールにおいてま評価になります
ま特にコンピューターネットワークを利用したインデックスエにおいて
まリコール八十パーセントん
これは未知語に対して八十パーセント気分なりますが
これだけの性能が得られましたんー
でまずえー複数の音声認識システムの
概要について説明します
て本研究ではえーっとデコーダーにＪｕｌｉｕｓを利用して
えー各モデルを変えることによって複数の音声認識システムを用意しました
で本研究では言語モデルを五種類え音響モデルは二種類
って組み合わせによって
芸術通りの音声認識システムを用意しました
でえー言語モデルの説明をしますが
え一番多いのかな感じ単位の単語単位
んー仮名漢字単語単位のトライグラムモデル
これは一般的な音声認識で疲れてるような
えー言語モデルになります
で続きまして平仮名の単語単位のトライグラムモデル
これはえー意味的いただいたように全ての単語というものが
えー平仮名で表記されたん
言語モデルになります
んで過ぎまして平仮名文字単位のあのーんまー平仮名文字単位の
えーっとトライグラムモデルです
まこれはんー
本当九例に示したりお二十一文字単位でえー構築された言語モデルになります
二
で次が
えー平仮名二文字単位のトライグラムモデルを
これが
まうえと何が違うかと言いますと
そのー単語単位一よりも短く万一文字文字単位よりは長いという
こういった形の言語モデルになっていますん
っすね最後にこの学習なしといったモデル四しましてこれはＪｕｌｉｕｓを利用して
えー疑似的に連続音素音節認識を行なっ為に用意したものですえー
で音響モデルには
えモーラ
第二のモデルと後それのタイプのモデルこの二種類を用意しております
でこれらのモデルなんですが全て
えシステム幸以外の公園から学習を行なっています
で実際にえーと音声認識性能がどの程度改善されたか
ということを示しますん
えーっとー
えー音声認識対象のおー
三
調査対象の音声ですがＣＳＪのこの講演音声によって
調査を行ないました
えちなみにこの単語んーこの音声に対する単語レベルの認識率が
えコレクトで七十六．六八パーセント明Ｃが七十一．九三パーセントというするのなってます
でこれに対しましてえー複数の音声認識モデルの結果音節レベルで評価しました
んで
えー音節に比率がこちらに示すようなっております
んで一番左からえーっとま一種類
音声認識システムに要しましたんでその間ワンベスト出力で最も良いものを
で青いものがんえーっとその二種類の権利とし六で
最も良いもの
えー
であ多いねでその為白いものですが
これが一種類のワンベストの出力を組み合わせた時のえー認識率になってます
んでえー印象に残るものですがこれ一種類の点ですし力を組み合わせたもの
になってます
でまーえーとーん認識結果が増えるに従ってえーリコールは改善されてまた手順は
したがっていくっていうような傾向が見えましたが
えっと同じこうす認識結果の構想ですね
こういうとテンベストと
一二種類の音ですとまこれ両方共一個の
出力をんーによって評価行なうんですが
それを比較しますとリコールだと大体こうパーセント以上んの
差が出てくると
えー
っていう言葉にありました
まーこれからんーこの結果から言いますと音節の生活が向上しましたので
す何の気はどの
見つけられる可能性というものが高くなります
ただしこちら二十二えーとあ嫌いじゃ何を示しておりますように大量の挿入誤りが発生しております
その為えー多くの湧き出し誤り検出が発生する可能性というのが
出てきます
えー
んで
で次続きましてえーっと音ですＣＤをもうインデックスを構築しました
え本研究ではこのインデックスが六種類用意してあります
でえー構築したインデックスはこちらに示すようになっていきますが
えっとーんまー
このインデックスというものが
サブインデックスというものから構成されております
ええー検索インデックスというのなんですがこれを単一の認識結果からあえーっと生成されます
で
えっとまー警察に音というものは
んーまー異なるインデックスという形態になっておりまして
えー
えーとんー
評価ですがえーでそれんーえっとそのこれらのインデックスからの評価ですが
次いずれかのサブインデックスで検索を検出された場合にえまー
評価を行なう
えーとこと
一そのインデックスの中でまーそのインデックスって幾つかあるんですが
は寒いんで複数
んー
の
二か所元に二つのサブインデックスで同じいー場所を建設驚いか所という形で評価を行ないます
んでまー
それぞれが特にえサブインデックスなんですがこちらに示すような
形になってますんえー
んー
それで多分インデックスのコースでえー
こう説明します
でこのワード形式えーっと本というものですが
後えーっと現地でというものですが
これはえー認識結果をその用いたインデックスになっております
えそれぞれの形態ですがはどうも二列レベル
えー資料は音節レベルのインデックスなっておりますん
んで検診ｎとえＣのんーですがこれは
えーっとそれぞれ二十個の音節へえー認識結果を根底じょネットワーク化したものになります
でこれメーンの違いですがえーっと
でんＣＭの方は
次にえーとん
点ですと後強く単一の認識システムのテンベスト出力を
それでこういうじょネットワーク化した者
まそれが認識システムの数だけある
水の中に対してっていうのは
えー
えと
ん一種類の認識システムのワンベスト出力を
五ページのネットワーク化したものって形になります
ってま高齢者ネットワークとえ子音のイメージですか
ま一般的なこういう点ですがネットワークのような形にこういった形になってます
でこの拍に入っている情報ですが今回は音節と
えーっとその音節を認識された
んえー音声認識のシステムの種類って思わ格納されております
えー
で決していいものを構築例を示しますとんー
えこれは音声データーはコサインθという音声を入力してあるんですが
えーと一種類の音声認識システムで認識させその出力を
えもうＤＰマッチング利用したマルチプロアラインメントを取った結果
まここのテーブルに示すような形になります
でこの得られたてるからんー
この一つの列を得たとして登録していく
で最終的なえーっと検索用のインデックスが構築されると
こういったイメージなります
っていうえーっとー天津ぬの方の購入じょネットワークですが
ここの認識の分布認識されたシステムの部分というものが
三十二番ですとかラテンですまでえーんという形になります
えー
えーって続きましてこれは
インデックスを用意しましたので
これらからのえー検索方法もう
何と言ってもないかんーちょうど
えー検討しました
てまずいようが検査語ですが一般的に用いられるってが一番最初にこの一が出るのが完全一致というものになります
またえーっとーこれをワードスポッティングと同じような形になるんですがえーっとんん
ファンのレベルでは単純な文字でしてえーここのコサインというもの見つけてくる
えーと音節レベルのインデックス彼は音声スケール指標間完全身に付けてくる
次にと終わったらば
えーっとんー初め方から見ていって残さ
時ケンネル全員でいい
んで寝る前一分というこういう経路を見つけて
えーっと検索を行なっん
といった方向になります
ですが完全一ですとやはりえーと探索の限界というものが存在しますこれはこの九十ネットワークの例なのですが
実際にここと言う人という
えー音節ケースが存在するんですかここに
それ全員がなくんー
まーうまく検索が行なえないといったパターンが存在しますと
うんえーとー単純なえーっと認識結果においてもここに特に我々が存在して検査を行ないないといったパターンは当たります
でこれらに対しましてえー本研究では
キーワードの音節ケースでのミスマッチを許容する
といった方法を取ります
で
え実際どういったミスマッチにどういうおえーっと音のレベルのミスマッチを共有するかと言いますと
音節という音に対して一つだけ二つとし訳です
といった方法を取りましたんー
でここにいるミスマッチですがえこの挿入誤り以外にも時間八月の約誤りに対応しております
んでえーまー
認識誤りに対応することによってえーと一二つを一つえー
時代は
一良くなるのですが
大量の湧き出し誤りが発生してしまいます
ってゲストに対しまして
抑制をする人があります
で今回はえーっとんーこの九十二つは考慮した韻律ＳＤｎに対しましてこの
フィルターをを構築しそれをん
えーとそれによって検索を行なってみました
で
パラメーター
えっと湧き出し誤りよく西洋のえー
パラメーターとしましてはえＣの探索パラメーターと利用しましたんー
で
このパラメーターですが
全ての段差経路における認識したシステムの数というものと
パスを認識したシステムの数による信頼度というものを
えーっとこれ以外のデーターから学習しまして学習と言うか調査しまして
設定をし
えーコンピューターを構築しました
え実際に構築したけれどですが
一持た先画像の
えーっと清潔市内の掃除を平均というものが既知語の場合は〇気にするか
二．三四五年
の場合に破れて人を以下というものを調査
設定しました
また
えー全ての探索経路において認識したシステムの一つの場合は
でえーっとんーでえーっとー
の族といった
えーこれを担当に
三度で設定した
フィルタリングになってます
でこのパラメーターですが
えー調査データーが講義音声だっ
から調査しましてせてしております
で実際にえ推理の戦後おー比較してみましたその条件を示しますが
えーっとーんんー一
ま最小も
音声データーは終止形のこの講演をしてこれは木は全然大手の使われたデーターと同じになります
んで県先程セットのをえーどういうものになります
んで内訳ですが
えー未知検索語が二十八種類で
音声中には八十九か所
で記事検索語が五十種類で七百六十九か所となっております
でえっとーこのテストコレクション設計時には本来この未知検索をわもう一種類だったんですが
えーとー言語モデルが変更になった
入ってそこれ子音設計する他の言語モデルが変更になりましたので
えー
んー
まこのテストコレクション一に既知語が
派生するなってしまいました
でそこから完全なる未知語を抜き出したところ二十八九月になっておりますのでこれを用いて評価を行なっております
え評価尺度としましてはリコールとプリシジョン後Ｆ値
またえーっとにその法で評価尺度で地域の評価尺度として利用されております
敵ＷＶというものを用いました
で本研究では特に五分五えーと道検索語と
イコール人
よって評価を行なっ
えーを検索時間についてはあんまり考えたとかは行って
えー検索時間に対しました評価を行なっておりません
で検索用のインデックスと検索方法の組み合わせですが
え表に示すような形になっております
えー
えー
んー
一え実際にこの点知る音節レベルのインデックスからえー三四十五検索した場合の結果がこちらに示すようになっております
でリコールがんーこのような形になっておりまして
え完全まーんー
二つえー完全一致でもえ
え誤りを見達を共有する場合においても
そのインデックスの数が増えれば増える程
つまりこれは増えていくその傾向が見られました
一んで変動完全一致による検索ですと
一つもリコール以外のプリシジョン訳地域Ｗ部において同じような結構
二分インデックスの数が増えれば増える程検索性能も良くなるそういった傾向が見られました
結果あえーと四分の一
後四音節に対していただきミスマッチを
いう必要な場合ですと
え二値が高くなるんですけどそれ以外の性能があまり良くないんー
サブ韻律の数は増える程
まちょっと悪くなってくるといった傾向が見られましたん
んーに続きましコンピューターネットワーク形式のインデックスから検索した場合になります
．んでえーとリコールの比較ですがこちらに示すような形になりまして
一番左側えーとーん
本研究では一種類こんえーじょネットワーク要してますので
その一種類の中で最も良いもの
でその一首全部使った場合
んでえーっと本研究提案してきているＳＥＭ
その結果になります
テーマ
この天津だとえ七人の
破壊してかにちょっとイコール
変わってないのですが
えーミスマッチを許容することによってだいぶ差が出るようになってきました
まこのことから複数の異なる
携帯の認識システム特に痩せることでえー木構造を棒に改善するということが示されるかと思います
えー
ただえーとーリコール以外のおー評価んー尺度で見てみますと
ちょっと一二年のま悪い部分があるかなと
えー
またえーっとミスマッチ分けをする場合ととーそれがもっと顕著に出てきてしまっている
いうことがありません
んでえー結局未知語に対象といった倫理太いかということですが
ま完全一致におけるんー検索ですとあのーそのインデックスの大して変わらない
んー
そのインデックス今使わえーっと単純な音声認識結果から構築したインデックス
本節レベルのインデックスと
パソコンいうじょネットワーク化したものまたえ心理では
私変わらないん
ですか
えーと誤り
認識合間に対応することで
ま一犬というものはこれだけに考慮が他のに比べて上がっている
とこのことからもう
ま複数の
認識辞書の結果を組み合わせるっていうのが
にこれ改善には
効果がある
父が示されます
で他の性能に関し道もいみますとやはり
んー
ま一犬というものはちょっと悪いかなという観点があります
えこれは大量の湧き出し誤り件数が汗している為
っていうことになってます
んで閾値五に対しての結果があのちょっとグラフが多くて申し訳ないんでそこのような形になってます
でリコールに関し見ますと一個のこういうじょネットワーク考慮したインデックスというものが
一番
よくなっております
ただやはり
湧き出し誤りを履いてるあのーん
為に
えー出て支援の方はんあまりよく寝ていた結果が
ありました
縁高例題を考慮しますとま単純な
えー音節レベルでのインデックスが効果的なのではないか
という結果が選びましたんー
でえーま道分だ修正の有効ということがあー
示されましたので
フィルターを適用した結果
ってものをこちらに示します
でまー見ていただくと分かるんですがフィルターの効果というのは殆どなかった
という結果になっております
んー
でこの原因としましてはこのフィルターに設定したでえーとパラメーターというのが
えＣＳＪのこの講演音声んじゃＣＳＪの音声のではない講義音声から設定した者と
その為
だと考えられて考えられます
えでまー実験結果をまとめますと
まこちらリコールにおけるんまとめなんですが
えー
まー
未知語に対してはこねるネットワークをそのー二インデックスが効果的ま特にえ四の四個
で閾値五後はえ音節認識結果ですのインデックスが有効かと言う
ありましたんー
ですがいずれにしてもえーっと大量の湧き出し誤りが発生しているのでこれを抑制する必要があります
言ってまとめさせていただきますと
え今回はえー整理タスクにおいて複数の音声認識システムを利用するんことのメリット手が有効かどうかということを調査しました
傾向が六種類のインデックスによって知りの性能比較しまして
んー
あー結果から見ますと聞見し検索語にかかわらず複数の音声認識システム要するということは
え成人有効であることが示されました
で今後の課題としましては
あのー
今回は単純な検索用のインデックスを用意しています
しかもでえーと処理時間やメモリー使用量といった思い最高量としていません
そのでも統計折々検索用のインデックスを構築するん市場があります
ところ不要な部分の調査であったり
まー性能改善の為にＪｕｌｉｕｓのコンピューターネットワークの出力を統合する
後は
精神の点ベースを構築してリコールざるに上げるそういった方法が考え
あのーそういった方法を今現在検討しています
で更に
えーっとこれらのインデックスからの湧き出しを抑制する
パラメーターんー
というものを調査していき
えーっと検索方法自体も改善していく必要があります
まこれはもう
ですとえーと
えー検索パラメーターを利用してす無音えー実は決定木といったもの
木の
柄をと考えています
さ更にえーっとんー
検索語に対しまして
え異なるインデックスを使用した方が
ですいーの性能が上がるということなので雨結合に対して
えーインデックスを検出の方法をどれが良いかということを判断する必要があります
でそれを判定する方法を検討していく必要が
あれっ
かと思いますえー
以上ですからそんな町
#############################


#############################
# query = えっと後衰退んーだけどえーえーと叩きえー認識誤りについ体のえーそれを解決過程の複数またすー認識システムっていうのはどういったシステム化っていうのを後ずっと好きでテストを教えてくれまー教えてくれる
# rank = 2
# slide = 12-10_fix.match_word.jout.txt
# value = -2.5857094711882
#############################
えーそれはえー複数音声にシステムを併用した
えーお父の作品にある
検索性能の改善と題しまして
えー定式近く大学の駅が未決定が発表さしていただきます
えー
えまず全体流れはえこのようになっています
えまーまずえー研究目的と背景ですが
えー
音声を含んだえーマルチメディアコンテンツの増加に伴い
でこれら功利的に検索する手段っていうのがえー望まれています
えしかしながら
えー
えーこういった音声を一つで書き起こすということにまーが非常にこう差があります
そこでえー音声認識システムを用いてえー自動的に書き起こす必要があります
しかしながらえー自動で書き起こした結果にはえー認識誤りが含まれていまして
で更に大語彙連続音声認識えーでえー認識した後には
えー辞書に登録されていない単語一語
がえー書き起こされないという問題があります
そしてえー更にその従来手法であるえー連続ｄＢえーではえー長時間の世界に対して処理時間に問題があると
いうのがえー金銭の問題としてあります
えーこれらを踏まえてえー目的として認識誤りや未知語を含んだえ長時間の音声ファイルに対してえー高速な検索手法のえー提案と評価
というのをえー挙げています
えー
そして
えー今回の発表ではえー特にえー挿入脱落この距離のえー緊密化とえー複数認識システム併用
でこれを用いたえー性能の改善にえー弱えー着目しています一
まずえー概要ですが
って英語音声データーから英単語を検索したいと言った時には
え一般的にはえーとこの音声データーをえー自動音声認識
でえーテキストに書き起こすと
でそれを
含めます
その際にえーっとだいぶ連続音声認識でえー認識しまうと
ふえーま
んー
ん辞書に含まれていない単語が認識たり強くされないという問題があります
えーそこでえーさまざまな研究でえー行ないできるのはえー単語単位の中でえーそれ小さいさまざま単位でえー認識をして一つに書き起こすといった方法が取られています
ふん本研究ではえー音節認識を用いてえーテキストに書き起こします
えこのようにえー
音節認識することでえー後子供に必要ができます
しかしながらえー認識誤りの問題がありましてえー置換誤りや
え脱落誤り
そういう誤りといったものがあっあいあります
一としてえー検索の従来法としましてはえーまず一般的なのがえー連続ＤＰにあるワードスポッティングが挙げられます
とこの他にもえー作品を用いたこの先されてはえー単語集合を用いたえー単語数といったものが挙げられています
本研究ではえー朝までの距離月のという
方法を提案しています
えーとステートにもえ人優しさをえーす
え話者照合について説明します
へ我々のえーシステム内容がえーこちらの図になっていまして
えまずえーユーザーからえー検索語がえー適当で与えられます
そしてえーこの検索語がえー未知語が既知語がえーのえー判定四大語彙連続音声認識の辞書を使って判定します
ってもしこれがえーっと未知語やった場合に
えー音節認識からえ予め作成したえーと五月の作品
こちらからえ音節単位で検索を行ないますえー
そしてえーもしえー既知語であった場合はえーそれに加えてだいぶ連続音声認識結果
えーを用いたえーと単語単位の検索
こちらを併用します
そしてえーＮの索引の構築の方向をえーここで説明しますえ本研究ではえこの犬なのＮをえー
三としましてえーとー音節のトライグラム
こうえー作品としてえー採用しています
船の索引がえー一つですとそのートライグラム
の映画でえー構成されていまして
各ポジションで
えーっと例も作っていきます
そしてえー作ったこれらを
えそれに相当しておくことでえー高速に検索が可能となります
そしてえーこの作品からのえー検索方法ですが
えーこのえー検索語がえー例えば
二二という検索別れ際に
えーこれをまずえー複数のおトライグラムに分割します
えー
そして
えーまーこの場合ですとえー二三というそれがま特に家という二本トライグラムに分割してこれをそれぞれえー作品から検索をします
そしてえーそのそれぞれ検索結果
からえー出現数連接を確認しましてえー言説が確認できたものをえー最終的にという風にしています
えーそしてえーと認識誤りに関しましてえー探索を行なっていまして
えー
我々はえーどっちかうんそういう活躍する前出して探索を行なっています
えまずえー使われただけではえー認識以下のえ複数の候補上位Ｎベストを用いて
トライグラムを作成してえ索引を構築することでえー対処しています
また
えーそう山高く
ではえー音節を一つ側さ三つ組み
はいそれでも作成して索引登録すると
いう方法で対処してます
そしてえ脱落誤りに関しましてはえー検索の際にえー
検索語が書かせてえー検索することで
えー探索を行なっています
えーそしてえーまー
これらのえー認識はま探索行なうことでえーぼけ画像化してしまうという問題があるんですが
これに関してはえーその認識誤り探索をどの程度行ったかという情報を
えー距離としてえ索引記録することで対処しています
え実際にえー例で説明しますとまず使いあまり高くはえーこの例ですと認識
こう頭にし結果のえー次ですあまり
をえー使ってえさまざまなパターンのトライグラムを構築していきます
てこのようにすることで
えー新しい音節があこのツリーですに含まれていた場合にえー力の人達できるといった方法になっています
でこの時の距離というのは
えーこの場合ですとからのえー距離で
えー×できるよう使ってえー定義しています
えー
そしてえっとー次にえー住んだ二百の作品という別の力価格のえー元さ手法としまして
先に説明したつかの大学ではえーと複数個に含まれている場合は安心できる
形態素が含まれてる場合を対処できるんですが
えーその検知できないというのが多く存在していまして
これを解決する為にえーと二音節でもマッチするようなえー包摂アスタリスクを何としてえー索引登録しておくという方法でやっています
えー
えーっと実際どういうものかと言うとえーこういったえーあってリスク
をえートライグラムにつき一つ何でして
えー
作品を作っていて水にを付けて登録し力という方法になっています
でえーこれはえー何の距離というのはまーえー先程の形で距離にえー比較えーっと比べましてえ比較的高いこと一九のえー採用しています
一個の音することでえ複数個に含まれない近いあまり御対処するができます
でえー次に凄いあまりことに関しましてはえー
そんな全くではえーっと
日英二次の作る際にえー一応テストバスはえー二つ文をえー作っておくと
いうことでえー
このバイクを飛ばした二つには言葉一つ二つに
これらをえー
タグに登録しておきます
んー
でこの時のえー距離は従来手法今までえー気がした手法ですとえーと〇か一えーそういうの結構人間社会で背中の日で表わしていましたが今回はこの距離を気に使わするということでえー後程詳しく説明いたします
んー
そしてえー脱落誤り
えーの対策に関しましてはえー検索語からえー
検索語の文節を
えー脱落させて
えー検索すると
いうことを行なっていまして
まえー検査語からオブザだけで二回検索するということいたとしています
で
てこの処理もえー今回えー従来手法では
二つあった二音節の方
をえー距離として
採用していましたが今回は厳密これをお見せしました
またえー挿入とえ脱落こちらの探索を組み合わせ方でえー四から六月にもなります
え例えばえーこの例ですとえー文えー
二二というえー単語が復元とえー各二つ書かれてしまった場合に
えーまずそう山高くて
えー一つはその一二をフーリエという一二を作ってお
そうします
でえー検索の際に脱落誤りが削減えー検査語から後活躍させた検索語フリーで検索することで
えー認知結果に
えーが含まれて置換誤りがあった場合でもえー一つが可能となっています
えー
そしてえっと本手法のえーＧＰとの類似点としましては
えーまず
その挿入と脱落のことというのを何設定することはできるという点が挙げられます
て逆に相違点としましてはえー聞いていることがあってその日日は検査語と認識以下のえー
音節別の二十九位を正確に警察ができるんですけど本手法はえこれをすぐはできないと
いうえー
違いがあります
んまた
経理ＢはＡの展開しているこの挿入誤りとお肉のＮ個
も脱落誤りでしていますが
本手法ではその二たり
ん〇一音節に
という風にここ来ています
え本手法の方が制限が厳しい為にこれは減少してしまうんですが私は向上すると
いう風に考えられます
でえっと今回提案する調査しましてえ距離に使うということで
従来手法では先程説明ストーリーにえ挿入脱落うーこれは距離はえー
えー
挿入の有無をえー脱落の音節の数
防衛として定義していましたで今回えー喧嘩するにあたって
え誤りとかって通常舌の前後のコンテキストのまたそれ距離を採用しました
典型例に挙げますとえークラスをにあまり高くの場合で
えー
この服もえー挿入誤りと
えー仮定して好きですがまトライグラム作る際の距離というのは
えーこの
そうやめたか警察俳優の音節で
えーこの場合と二と三のえー距離を計算しまして小さい方を対応すると
いう方法を取っています
それでえーと距離はえー先程〇か一日の日だったのものをえーこのようにえー変更しました
えー
ってまたはえー
今回はあその左えーつ挿入と仮定した音節のえ左コンテキスト母音群も考慮して
えーえ距離
を定義しました
後マイナスとＡとＢという
えー音節第一第コンテストがあるんすけど存在の
え母音部分にある
これもえー距離に考慮して
距離として考慮しました
そしてえーと複数人システムのえー四ということで
えー
本研究では店の検索性能が改善の為にえー二つのシステムを使って
えー各予稿つきましてそれぞれの検査結果を統合するといった方法を取っています
まずえーベースの認識実験中ばえー本研究で方がデコーダーに二つ二つ二つを
買って
え音響モデル音節モデルを使っています
そしてえー今回新たに併用するえー認知システムの方はえーデコーダーは二十五月を採用しまして音響モデルはトライホンモデルとなっています
あっそしてえーっとま
と二を複数認識実験用のえー流れなんですがえーまずえー
えー二つのえー
一認識かとえー近くにして書か
えーそれぞれえーＮグラム作品と単語の認知インデックスエ作為の
それ作っておきます
で
て
えー
んー予めえー二つえーとお酒を作っておきに
え検索を与えられ際に
えーこの索引がそれぞれ検索を行ないます
そしてえーこの二つのえー認識掛から作って検索結果とえー一つの検索結果
こちらのどちらかにえー
組まれていればんすすると
いうような方法でえー併用行ないました
でえー
え評価実験に入ります
で今回えー検索対処しましたのはえー日本語話し言葉言葉コーパスＣＳＪの行データー約四十時間を使っていて
えー検索語をにはえー音声雑音処理はグループの
これが継続長えーこちらドライバーを使いました
えー未知語既知語はそれぞれ五十種類となっています
えそして
えー
認識に用いたえーっとおー
条件としまして二つプロセスの方では音響モデルは左コンテキスト依存の音節モデル学習には九二に千五百二十個声を使って今
で言語モデルはえー音節のグラフの言語モデルでえー学習はえー本当モデルとどういう風になっています
八十四つの方法はえーこれは沿線でないんのえーワークショップで配布されましたえ認識がこちらを使っております
えー
まずＡプラスプラスプラスのえー認識システムのえーポーズにし結果はえーこのようになっていまして
えーと五月まで考慮するとあの九十五パーセントえー非常に高いグループになっています
てえーＪｕｌｉｕｓの方はえーこのような結果になっていましてえーＪｕｌｉｕｓの方はえーとー宣言全てのえーＮベスト使っている為え確率が低いのではえーこれとはえー八十三パーセントとなっています
そしてプレゼントもして用いてえー連続ＤＰはえー大雑把に
んでのえー連続ＤＰで
えー中には
音節ＨＭＭに基づく形で距離
ん使っています
低認識科目数候補を用いるということでえ今回はえー二つ結果の語ですと
一二つの個別と使いましたえー
父の定義はえーこのような式になっていてえー明日はえー
示している通りになっています
え実験内容はこのようになっています
えー
えまずえーっとー従来手法とえーベースラインのえー
んえーグラフをえここに示していますえー横軸にこれで勝手自覚したんだとなっていますでところが後まー従来手法でもえー
ベースラインよりもえー性能が良いというような結果がえーあります
えー
でえーとこの一の従来手法に対してえー距離の現実があって後で
んで挿入誤りの距離を現実化した際のえーグラフがこちらになっていますえーピーク値のえー最大値がえー従来法が〇．五六番なのに対してえー
二十八手法でえー村や形の距離を変化することによってえー約二パーセントのえー改善が得られます
でえーそして夏はかなり一方脱落誤りの方はえー
ってこちらが多い気になるんですが
え従来法よりもえー性能下がってしまうというような結果になっていますえーこちらの方ちょっとまで原因がよくあります
あれ
そしてえーっとーまそういうの距離の平均一日二際にえー母音の考慮えーした場合としない場合のえー三つの歳で一語こちらに示していまして
えー母音のこれはえー竹刀よりは母音を考慮した方が良いというような結果になっています
えー
でえーっと挿入句脱落えーこちらの図に
二のえー両方とも
喧嘩した場合のえーグラフが紫の線になっていてえー口で見るとえー
最も良いえーこのえーく比較して中では最も良いっていうな結果になっています
あってえー次に二二システム変容ということでえー
えーベースライン
えーまい従来法がえーこちらになっていますでこれに対して
えー
Ｊｕｌｉｕｓの個別の音節認識のえ個別の結果を併用したのが青い点が出ています
ところ挙げますとおえー従来法よりもえー二値型三パーセントの改善が二三パーセント程の改善が抱いていて二日ぐらいにでも
あえーをここに書いできるということが分かると思います
ましかしながらえー
で全然別やコンピューターネットワークこれらを使いますと
えーこう数が増えてしまう為かえー湧き出し誤りが映像化してえー精度が下がってしまうというような結果になっています
んん
そしてえーっと既知語の方
えーこちらの方はえー従来法にもえーベースラインと従来法がこちらのようになっていてこれそれぞれえー二つの醍醐認識が
えー
えーからえー作成さセンチインデックスを採用して
展示インデックスを使っな方法になっています
ってでこれに対してえー提案手法
えーにえー
通常質問一つの鉄の個別の規格化したのがお以前
それに加えてえーすＪｕｌｉｕｓの場合誤認識の結果こちらを足したものがあるのでやっていますで何えーっとー認識しても併用することでえー個別と
を併用するとでえーえ口で約二パーセントの改善が言われてますん仕方がないと第五日のえー結果を併用することを
でえー
まえ従来法よりは良くなっているんですけどまーん
この人最大値は〇一の餌が詰まってますがえーまほぼ同じ程度というような結果になっています
んー
でえー最後に検索時間のえー比較なんですが
えーまず
えー今までのえーＧＰマッチングとえー従来法の検索時間の比較がこちらになりまして
え従来法ですとえー
ピッチマッチングのえー
で約六百枚
えー事例えー従来法はえー一見てくれ
一九五〇．一見てくれんけど〇だ可能となっていますで
誰でも
ＢＢが気の毒なことというような結果になっています
んー
でえー今回えー提案したえ複数認識システム
んえー後はえー谷のえー含めた場合の
えー検査結果がこちらになっていましてんー
えー弾力がありことでえー検索時間はえーと
分か
行ってしまうんですけど
えーまたその二つにしてもうまく利用した場合でもえー日目でく程遅くなってしまうというな結果なっていますがえーこれのえーＧＰに比べて約五十代
のえー高速に検索することが可能となっていますえー
んで
言ってえーまとめにえーなります
え未知語検索ではえー世論
んー距離のえ均一化によるえー性能の改善が
であると
えー挿入母音脱落の距離をえーただ一句よりが
えー
でえー一度でえー下の方が得られました
んーまがあえー普通に自然の変位をえーこちらはえーま未知語既知語共にえー性能
オープンし結果のえこれその
利用することで性能が改善することを示しましたまー
えー
て検索時間に関しましてはえー紙を用いてえー数えシステムの併用行っても平均一えー一九八人一さんとお花非常にこうすぐに検査ができるということをしてしました以上で発表終わります
で構成されございました
#############################


#############################
# query = 増ええーえーとで行くとでいる人があー英語の翻訳家が日本語五の四月にえーその日本語の音声日本語の発話っていうのは五三と違った一人のっていうのだけど例えばどういうことを言っていいのかっていうのが普通みたいでんで
# rank = 1
# slide = 08-16_fix.match_word.jout.txt
# value = -2.33250158654909
#############################
あっあえー入国大学情報メディアが強く情報メディアがあのー母です
えー今回やはりあのー音声条件とまー入る検索の為の音声情報処理の検討について私の側と坂本発表さしていただきます
まず初めに平均でまー地名では本にえーバスの中でも音声ドキュメントは
えーんでとー当時えーネットワークを通してえー通じてえー配置され
えー文開花される傾向にあります
その検索にえー話し言葉の音声認識は必要かつ
重要なニュースを待っています
そこで本研究ではえー国際放送ニュースが台風について
えーっと焦点を当ててみました
でこれにはえー
重要単語などのえーインデキシングなどによるえー基本ベースのえーっと音声認識にはえーいいた全てのテキストする町ないんですが二ページ括弧二のノードに関しては言った全てをテキスト化する必要がある為に
えー音声認識の高精度が必要となってきます
でそこでえ複数の入力をすえーこれはえー二言語なんですけどまあー利用できるっていうことをに着目しえー機械翻訳モデルを用いながら当時一にする方法前半の竿提案さしていただきます
また
音声はネットワークを通じて配置良いきっかけ圧縮月
動かされる場合が多い為多いことに着目し
えー圧縮処理が音声認識に与える影響の調査について
怖さが本は発表さしていただきます
まずえ母言語の同時音声認識について発表します
国際放送ニュースはえーではえー丸三の音声は利用可能なケースが多くなっています
例えば多分の方そのー
つまり複数の異なる言語で同じ内容の発話されることが多いです
そこで
その二つの異なる言語の各チャンネルの音声の認識を情報を時代当時の実行すること
つまり二か国語を同時音声認識を今回提案さしていただきます
えーその枠組みについて説明します
えー国際放送ニュースなどではえー日本語の音声実音声として英語の音声と同一内容の英語の音声が付与されてることがあります
そのえーそれぞれえー音声認識を行ない
えー
翻訳モデルから
ええー英語と日本語の単位のスコアはえー算出し
えーリスコアリングを行なうことによってえー日本語の文字列
する節のそのす認識精度は改善させるというのがえーとにかくこの二音声認識の目的となっています
またのように英語の文字列をするその際も
えーそれぞれの音声認識を行ない日本語と英語の対応スコアを取ってえーその情報を何ことによってえものも一つの二六四
えー
認識精度を高めることを目的目標としています
そこで定式化について説明します
えー
ここでは日本語と英語の同時認識について説明します
えー
四六単語列はえー先程申した通りえー日本語と英語の面でもよろしいのですが
で今回は日本語のえー単語出力するのもえーと定式化します
その日本語音声認識について私は説明しますと
えー日本語の音声Ｘの英語の音声×が与えられた時にそれらを最もよく説明するのか日本語単語列体を求める問題としてしかします
まず
えー日本語の音声とＸというもの音声は五から
えー日本語のえー最大となる日本語の単語列で要するする為にまずこの式となります
次に
ピンＸとＹは事例によるえー最大化と二型である為に的なすることができこの式になります
次に
え全ての可能なえー表一つまりえーと八音声認識の各えー方法
ほいー検討を置き
で一応まー取ってこの式になります
またえーΣは関係ないところ外してこの式になります
次にえー先程の式から対数を取り重みを導入することによってこの式になり
フレーズそこを用いて
楽しく皆変形できます
重みのＫマイナスｂをα
古いお母もあ置いてえー整理する
最終的にはこの式があえー
採集されます
ここで
ただあー語彙部分を
えー日本語音声認識のスコアは
赤い部分を英語の音声認識息子は
八時期以来もう英語の音声認識のスコア配分を翻訳モデルのスコアとえー
することができます
ここで
えー日本語の音声と英語の音声を用意したえー日本語の音声認識のスコアと英語の音声認識のスコアと翻訳モデルのスコアを用いるとにおいて
えー日本語の音声認識が行なえることはこの式で一生できました
次に
えー予備実験を行ないました
入る解析や内容としましては翻訳モデルを用いた音声認識の文を正しく機能するかを調査しました
つまりえー
そもそもえーやり方としましては形態や英語テキストは間日本語の音声認識を行ないました
破裂音用いて説明します
で先程あって
ではえー日本語の音声と英語の音声の一内容の日本語の音声と英語の音声を用意しそれぞれ音声認識をして
えー親子モデルから与えられた翻訳スコアを使ってリスコアリングを行なうことにより日本語の文字とする二というのは
えーうまく説明したえー枠組みなってます
そこで
でえーそのえー音声と英語の音声認識のあのー
えー言語テキスト良いつまり対訳前のテキストでえ普段は今率が〇パーセントの対話例のテキスト二を用いて
えー日本語の音声と
えーっとー
あの音声
認識を行ない
えー日本語の文字列を出力するというのが呼び
い予備実験のえー枠組み若い方なってます
式はこのようになります
この式を用いてより詳しく説明さしていただきます
えー
先程の違ってこの場合日本語の音声認識はえー日本語の音声Ｘと英語のテキスト二が与えられた時にそれらを最もよく説明する日本語の文字列体を求めるプロセスになってます
ここで
えー
先程の式はえーこのような式になり
えー
この式でえー下の式で違うものは
えー
っていうものを音声認識のスコアというものが含まれてないことになります
つまり
えー予備実験ではえー
言語テキストいー一文を用いてる為えー日本語の音声認識のスコア完全に翻訳モデルスコア足し合わせ
その式によって
えーと日本語の音声認識ですがのみの場合
日本語文音声の認識でリファレンスモデル四のスコアを
足し合わせたものを比較することによってえー日本やっモデルスコアが用いを用いいることの有効性を
えー今回はえー予備実験で示すことができると考えました
また
えーテーマ二三式の原音声認識の方が方法二い料理の相手とし為え枠組みとしてはえー認知へ同時音声です
後えーっと同一であると考えました
ではえー評価実験について話します
評価データーにはえー二つ言いたい訳です九十四読み上げえー日本語話者四名から五十文取りました
次にえーと音声認識システムにはデコーダーはＪｕｌｉｕｓを
音響モデルには読み上げ音声から学習した文の方
方言をモデルには新聞記事から学習した
単語トライグラム
翻訳モデルにはＩＰＡモデルツリーを用いた
用いました
またその学習データーに歩いた記事対訳コーパスを使いました
では結果です
まず音声認識のスコアの翻訳モデルスコアの方法もみたいなもの効果について説明します
このえー式にそのえーあ翻訳モデルスコアのえーと重みγの値をえ社会
〇から一まで変えることによって
えー
このγの値がどれくらいならばえー認識率がより向上するのかというのを
で調査しました
横軸がγの値
縦軸が認識率の改善率の絶対値になります
その結果
えーγの値が例で五からあー〇〇〇〇一えー〇．四五程度で平均で認識率の向上が張りがあるということが分かりました
そこでこのγの値をれていようにえー
んえーと定めてえー次の
実験を行ないました
つまり
がもう〇．四四段階でえー翻訳モデルを用いた音声認識というものを行ないました
その結果
えー翻訳モデルを持つえーとー先生えー
話者ごとに行ないました
赤いえー棒グラフがえーの
音声にえー日本語音声認識のスコアのみを用いたえー単語誤り率
いい香りもグラフはえー翻訳モデルを用いたえー日本語音声認識の
えー
方グラフになってます
えー
一番右にあるのはえー平気になってます
その結果
えー翻訳モデルを用いた音声認識は平均の値でえ単語誤り率が一三．一さパーセントから四十二．４０パーセント
で削減され
え誤り削減しそして四．八四パーセント削減となりました
ただえーこの
翻訳モデルを用いた音声認識はえーモノホンモデルを用いており
えー二つ
他のえーＰＴでもトライホンモデルを用いた場合の
えー単語誤り率を調べてみました
その結果平均〇五．３０パーセントから五．五三パーセントの
えー現象がはつえー改善は少なくなりました
これはえー最もこのベースラインの音声認識精度は高過ぎると他は少ないということが
あります
しかし
実際の話し言葉の音声認識精度はこれよりも低い為相手の可能性は×だと考えました
続きまして
えーん音声認識の精度はその程度必要なのかというのを今回えー
発表さしていただきます
え先程の予備実験ではえー
日本語の音声と英語の対訳テキスト一を用いてえー日本語の文字としました結果です元よりも誤り率が五四て八十パーセント意見ということが分かりました
そこで
実際にえー音音声認識を行ないました
その結果英語の認識文がえー
出力されました
その英語の音声英語の音声認識文のえー単語誤り率が一体何パーセントならば先程も正しい対訳テキスト
体をまー二を用いた場合と同等の結果が得られるのかつまり日本語の文字列がえー先程と同じような改善が得られるのかっての
えー調査しました
ここで
えー
上の文音声認識文とえー音声学会ではテキスト文を用いた場合で大きく変わってくるのがこの四角で囲ってある
でなぜえー二の後えー前の二し
つまり
えー
翻訳モデルスコアになります
この翻訳モデルスコアを正しく評価することによって
テーマ
単語誤りえー認識部の単語誤り率が何パーセントならば
早くテキストがえー用いた場合と同等の結果が得られるのかというのを調べてみました
詳しく説明します
先程の翻訳モデルスコアによるえー目的言語の一単語当たりの平均予測する
これを翻訳モデルパープレキシティーと呼びますを利用しました
この翻訳モデルパープレキシティーという名前はえー言語モデルの
評価によく用いられるえーパープレキシティーをえー今回はえー参考にした為その名前にしました
この翻訳の面パープレキシティーの方が下の知識のえ文の部分にあえー
ただしえーおテキスト二四と
えー音声会話音声認識文えい家が与えられた時の
親子モデルパープレキシティーの差は
がえー
対象としました
そのそれが小さい場合には
えー日本語の音声認識の最終そこはまー近くなるということが分かります
また
その結果えー元の音声認識文利益を用いても
えー
あーいうものが対訳テキストの歴史を用いてもえー日本語の音声認識の精度改善がどんどん家があるかと予測が付きます
そういうことでえー
この
翻訳モデルパープレキシティーの寒いとえー単語誤り率の
えー三を調べることでえー
で
あー英語音声認識文の単語誤り率が
んえー
どのぐらい影響を与えるのかというのを調べました
経営の温泉にえ結果です
でこう音声認識の認識率と翻訳モデルパープレキシティーの関係についてえー図にしました
横軸はえー文音声認識の認識率
縦軸は翻訳モデルパープレキシティーの変動になっています
母相関係数は〇．四六三を取り
えーこれはえー建物音声認識の認識率が
んでなれば翻訳モデルパープレキシティーの変動も小さくなるということが分かります
また
えー
この丸で囲った単語誤り率が四十パーセント以下
その場えーのところでは
翻訳モデルパープレキシティーの変動が小さい値を持っています
この四十
パーセント以下の英語の単語音声認識のがえー単語誤り率四十パーセント以下ならば
えー
んー
えー
それをえー組み込んだあえーと二音声認識では
えー
精度の改善が得られるということが示されています
また
この四十パーセントからえー六十パーセントのところなんですけどもえー結構半分ぐらいが小さい値を取っています
これについて言えることはえー半分程度
つまり四十単語誤りさ四十パーセントから六十パーセントの半分程度の誤りを含んでいても
えー翻訳モデルを用いた
えー
文字音声認識というものが有効であるということを示しています
前半のまとめです
国際会議でその音声認識について今回発表さしていただきました
そん中でえー同じ内容の異なる言語
例を用いたマルチチャネル音声の音声認識について今回提案さしていただきました
その結果です音節その中ではえー予備実験として日本語音声認識時にえーのテキストを翻訳モデルを利用したものお予備実験として提案さしていただきました
その結果
翻訳モデルを用いた音声認識の文が機能することを確認しました
また
翻訳モデルパープレキシティーに基づいてえー影響の調査について後
えー
発表さしていただきました
尊敬が翻訳モデルを用いた音声認識が十分に機能する為には
えーえ音声認識の単語誤り率が四十パーセント
程度であることが必要であるということがえーと二から分かりました
以上で発表終わります
えー
えー
えー
えー
んー
えー
えー
んー
えー
はい
で
んー
えー
で
えー
んー
えー
えー
に
んー
えー
えー
えー
えー
父は後半の発表を使うと発表生成いたします
えー前半では国際ニュースえー国際放送ニュースの値を対象とした
音声情報処理の手段として
再翻訳モデルを用いながら同時に処理する方法の差は発表させが来ました
またえー国際放送ニュースあの音声ドキュメントは
いうことはこう通じてはいすいそれ詳しくは報道される場合は多いことから
まーすそれが音声認識与える影響を調査を行ないましたえーそのえー
発表さしていただきます
えーネットワーク上のおーセグメントを警察の為にはえーキーワードなど人でえそしてえー
付与することが重要であります
声にえーインデックスを使用する為にはえー音声認識概要です
これまでの一般的な音声認識の推定量は対象は
四十八キロヘルツサンプリングえー二六ビットを選定量子化のちらし構成が用いられています
しかしえーネットワーク上のセグメントは
元気水やえーえーし逆ＭＬ法して圧縮され方や土が行ない対話を行なっています
こう例としましてえーインターネット上ではえーＢ水
いう自転車もそれはえー詞の形式を持ちあります
小屋形式は最悪らしくである為
この明日の波形は人間の聴覚影響しないようにえー情報が設定されています
またえー圧縮音声からは元の音声は完全には発見できない為
このような気が八日付けである音声を
認識対象とし用いる場合には何かそう対策が必要と考えます
しかし音声圧縮が音声認識与える影響を調査はこれまで十分にお前で行なわれていない為
ポストでき検討としましてさまざまな形式
あそいで圧縮した音声を認識実験を行ないました
え音声認識実験を大きく三形に分けて行ないました
それぞれえー適応音響モデルはと一日二つ目にはベースラインを音声認識システムとしまして
従来のえー自動的られる数字六六と後圧縮音声ではすした音響モデルを用いた認識して
月には音響モデルを入力環境への適用として
いう環境を考慮した音響モデル
三つ目には音響モデルの話者性とを入力音声情報への適用として
いう環境とを性を考慮した音響モデルを用いた認識実験を行ないました
母がえー認識システムです
デコーダーはＪｕｌｉｕｓ
音響モデルは全盛学習者トライホンモデル
言語モデルは語彙サイズ六万語を新聞で開発した単語トライグラム
学習データーにはＩＰＡ九十八テストセットを付けました
それからえーそしてえー後半はえー通常の音声認識とありませんが
で勿論マスクした音声を認識数でえ前半死
えー対象とある音声をまず手法一特徴があります
でこちらはベースライン音響モデルを用いた音声認識実験の結果となります
え横軸は人れと人れた日に程おー一つは気がします
縦軸は標本指標で用いたえー単語誤り率
またえー音声圧縮にはえー減衰えー真であるえー上の三形式を用いました
え初めにえーベースラインとなるし圧縮音声を用い
え対象とした認識では
勝手にさんのワードエラーレートを得ました
次にえー三十日より別のえー音声の
認識結果は
生徒のケースにおいても一パーセント前後のまー出られる早い方から
これをな音声を対象として認識を行なう場合には
従来のシステムでも大きなものでナイフは分かりました
ビットレートが二十四二十三ページの前にえーおいては
え方式よって対話数が誤りはどうすんとは思いました
具体的には
えー鉛筆一九四の場合ですと三〇．五四パーセントえーＣの弟子テストを二十二．五九
多分連盟の
．ですとえー一三．八九のお与えられてはえ分けられました
えーこう事件に
こう実験でえ用いた音声ですが
学習時は自動キロヘルツ一二三度の方向性から
しかし実際にえする場合はま思考量です
で本当あらゆる環境と音響モデル二はそうしたと考えます
こうでえ入力環境にえー入力音声つまりま指向性にマッチした音響モデルを用いた認識実験を行ないます方法えしました
本来的には
えー手伝いを音声モデルをＭＬＬＲ適応を行ないました
でそれにえー適応の対象として用いた手法音声は
で最初の実験においてえー三十四．五四のワードエラーレート得られたえーえー推定式
白い鳥ですよもうこうなります
ただえー適応データーはＪＮＡＳコーパスに加える音声約四十八時間
え先程述べましたがえーらしく
クエスチョンを用いた指向性がいるＰ推定七十九五の一つのもの
まここでは一応はえー第二はいる話者はどうできました
えこちらは入力環境にマッチしたモデルを用いた音声認識の実験絶対
音響モデルをえー圧縮音声に適用す
先輩のえー認識結果は
えー二十三．一〇のワードエラーレートを得ました
これは最初二における音響モデルはベースライン入力音声があり一二
つまりモデルと音声がピッチの場合より
とえー比べるとあんまりお約三十パーセント削減しました
しかしえー入力音声が一圧縮の場合に比べると
誤りは約三バイトを七つ
ここからえー利用環境にマッチしたモデルを用いだけでは
城が非常に別な尽くされた音声
認識女性が不十分だと考えられます
えーそこでえー音声のペットを検索には音声を自動的に行ないにし
えインデックスを付与する早くうーそのような音声認識の場合は
認識結果と認識対象の音声データーでえー繰り返し提示を行なうとで
音声認識の精度向上が得られるとはこれまでの研究で明らかになって
そうでえこの繰り返し音声で適応の効果を確認しました
これは理想的な形成を認識精度を調査誰々
結果四つ二つある与える影響したい適応を用いました
適応データーをＩＰＡ九十八テストセット音声
本当から入力環境とは声道情報についてをすると考えます
え適応の
分析を用いたあ指向性は
えー最初の実験における
別に推定し二六キロの場合とえー二十八の場合の二つを用いました
ＸはＡえーＢ政治の町にですのを整理
を適用した音響モデルを用いたりしてる結果となります
縦軸は先程は実は出られると横軸は使用回数
また適応方法はＭＬＬＲとおーまこの二つの方法を用いました
ベースラインの方分けられとか三時四ていう方五パーセントと思い対して
えー三回繰り返して行なうとでえーメールＭＬＬＲ適応では二十．五八
ま結局は一二点の四の得られるま得られました
ここから繰り返し適応を行なうとで二六五四三え精度な思考セグメントは処理結果を面とありました
しかし一方八十三ベースの人の場合ですと
えー別材料は約九十パーセントの分けられるに対して
適応行ってもＭＬＬＲでは六十五パーセント
なくては約四十二パーセントは取り敢えず加えましてられました
本当はえー
二十四ＢＢＳの場合は繰り返し適用行っても圧縮された音声てるんではインデキシングは困難だと考えられます
え方法のまとめです
音声の決めたり音声認識を行なってえインデキシングを行なうと想定した場合
で一つ目に合宿して保存する際には三十日よりベースの人へとか個性は自分であろうと
二つ目に印より形成は音声認識と音声モデルを適応方法に繰り返すことでえー
そいで系統性型の
えー処理できる可能性が可能性を分かりました
えー全体のまとめです
えー前半では翻訳文翻訳モデルを用いた統計的音声認識の文
方についてのでえーその予備実験と評価を行ないました
えその結果翻訳をモデルを用いたあー言語同情音声名詞の組み合わせを凄く分かりました
また星が十分に使用する為には各言語の音声にせるは四十パーセント程度の音は出られる場所やっと分かりました
が後半ではあ指向性の音声認識についての検討を行ないました
その結果あ三十三四五デシベルと言うと加工すれば十分であること
ただ一．二ケースでは音声認識と音響モデルを適応法に繰り返すことでそいで一つの制約は
分かりました
で発表を加え以上で終わります
#############################


#############################
# query = 増ええーえーとで行くとでいる人があー英語の翻訳家が日本語五の四月にえーその日本語の音声日本語の発話っていうのは五三と違った一人のっていうのだけど例えばどういうことを言っていいのかっていうのが普通みたいでんで
# rank = 2
# slide = 12-15_fix.match_word.jout.txt
# value = -2.33870065098502
#############################
はいえーっとそれでは流行が大学の南道が発表いたします
えーとタイトルは毎日同時通訳音声の音声に
いうことで始めます
切ってい球を全部禁煙とえ検索ということでえーとーまー音声認識その中での音声認識技術の話のえー
発表になります
でえーっと今回対象としてんのはまー同時通訳の音声というものの音声認識です
え同時通訳音声の認識っていうのは
まどういうことかと言いますとなど
んえーとですねあのー国際会議とかですね
まーあのテレビの放送とかですとま子音生徒とく音声みたいな感じでまーる日本語の発話に対してえー
まーその対訳となるような英語の発話とかま他の内容確認発話っていうのがあるとまそういう状態になっ
んでそれぞれ
ま音声認識して今まで音声認識してまー字幕とか作ったりとか一二六作ったりとかそういうことをしていました
えー
中から
えー
ですがまここで注目したいのはまー基本的に同一訳ですのでま同じ内容な発話がなされていいうことがある
いうことでワインそれぞれ音声認識した後にまーここで組み合わせてやるともっといい
結果が得られる子は何か
そういう発想でえー緊急をしていて
んんでえと今回やることは毎日同時通訳音声の一中の英語と日本語音声認識するんですがまそれぞれ普通に音声認識した後ま英語の音声認識と日本語の音声に
えーと
組み合わせでより良い結果をゆいうことが目的
んでえーっとまず
普通に同時通訳の音声認識をやってみるとどれぐらいなるかということをまず調査しました
でえーっとー
使ったデーターはＣＩＡＩＲの同時通訳データーベース
いうことで
えー
ま名古屋大学で
あのー九分であったんですけども
その二な政治の六検討経済の四件後実験の
音声ですで英語の音声が本があってま逆もあるんですけど今回使ったのは英語の音声が下で
んんでそれに対して日本語の同時通訳が入って
いうようなものです
一年後の音声認識はまー普通のえーっと
システム行動を作りましたとま具体的に行かないですＰＣで配っている
えーと音声認識の英語の音声認識きっと熱を使ってるんですけども
音響モデルは話者適応教師なしで三回
やって頭を使ってやります
一万語なのはあのー普通にやった結果ですでえーっと
横軸がワードエラーレートでえーと縦軸は五十講演それぞれのまー結果でえーっと構築程悪いんですけどま大体
まこれが非常に悪いんですけど他は
ま二十五パーセントぐらいのところにあって
前のあのー音声認識
ではえー
一読み上げ音声の認識システムみたいなのでも結構多くということが分かり
一例と日本語の方は
えー
まーもうちょっと普通の日本語とは性質が違うんですがえーっと例えばその自然食による約一つとか二四九によりＸというのがされてまして少しあのー違う
．特徴があるということが分かっていますでどういう食見える訳数というのは
．まちょっとおお間違ってるんですけど
私達は作文を書きまして
ま悲惨なせんその人について書きましたみたいな風にま一回今は〇としてのでま英語のおじに引っ張られている先に
あーの星が出てくるとかそういう風な訳し方がされることがあります
すそれからえーと同時通訳だとえー
あのー喋りに追い付かないのでえー
あの要らないと思われるところですねこういうたま赤で書いてあるこれが
日本語にはま同じグループをバスとか後すぐ音というのが出てこない
いうなことになり
んでえっとーまー同じ内容の発話とか行きながらちょっと違うということがあるそれから日本語の発話としては個人が少し
数とは違うことがある
いうことが問題
んで
んでえっとーまーそれ音声認識するということでまーちゃんと考え内的なんですけど
まーあのん同時通訳の書き起こし定数で言語モデル作るのは多分一番何だと思うんですけれどもまそのデーターをたくさんないので取り敢えずＣＳＪでやってみて
まどれぐらいなるかというのを調べてみますとで音響モデルの方は人を出した教師なしの話者適応三回やって言語モデルは二つのトライグラム作ります
でやってみるとんえーっと
ん大体三十五パーセントぐらいのワードエラーレートになります
えーいうことです
んでえっとーまＣＳＪの
二十公園とあの認識タスクですとおー話者適応度とするともうちょっと
こっちがですね二十パーセントとか二十五パーセントぐらいの頃に
くると思うんですけれどもまそれに比べると少し
述べられた高い
．は正しいえっとー今回の話題が政治経済だったり
することを
終わりますし
一はあちょっと話題が四つデーターてない可能性がありますので
その同時通訳だから
難しいとかいうところは本当に
それぐらい難しいのかっていうのは一ちょっとまだきちんとを整理四五匹な
とにかくまーあのーやってみるとこれぐらいになります
いうのが
えーとまずはそういうきっかけ
でえーとこっからが
人テーマでして
えっと大変あのー二温泉にし
いうのは提案してる手法で
んでえーっとまず年も前ですが
イメージ
けど
顔とてないですね
えーっと
んー
えー
えー
えー
まえーのの音声がなってから前の音声認識初めて日本語の音声を認識し始めて姉とこんなと日本語の音声認識する時に前の情報を使って直しているという感じなんですけど
ま見ていただくとここら辺の形態というのがこの辺のえーこの三から
えーっと多分経済の方の間違いだということで治ってたりえーっとこここと下顎
紅葉とかに戻ったですですね
これは高校時代はできないんですけどま五．三とかと共起確率が高くてんでまー出てくるというな感じになり
格好いいイメージで
やっています
んでえっとーまーその概要をもう少しちゃんと説明しますとま日本語の発話と英語の発話が
まーおんなじ内容が
食べられてるというのが分かってるという前提なんですが
それが
てえ音声認識をして
一例等を
ってここでですねま中間結果を持ってきて一年後二年後の音声認識の結果を持ってくる
んでえーっと英語と日本語の
えーっと太陽道を表わすような翻訳スコアというのを与えて
んで一もう一回この音声認識結果を並び替えて出すというなことが
行なわれます
んでえーっとまーちょっとすいませんこういうこんなしょうもない
あったりなんですけど
一マウス音声認識をやってで友達が来るまで待っているという発話に対してえーま幾つかこう法を出します
一音音声認識はスコアが付くとで英語の方は前前にずれるとみんな彼と出てきましてでこれえーっと
えーこれを見てえっ
多分これになるんだろうなということを
実際に式で書くと式で書く取って最も
ペアを作って
んでこれとこれの太陽道を掛かっていく訳ですね
ってマーカーと車ではあまり体をしなくてこのえ分布このＭは対訳になっていない可能性が確定スコアは低いとでここはスコアを高くなってここはまー適当なスコアって言って
根本のっ音声認識のスクワット加えて
一一番高くなるのはこれで提供出てくるのがこれになります
いうような仕組みになってい
で形式化しますとえーと日本語音声Ｘと英語の音声Ｙが与えられた時に日本語のまいもっと良くなる文字列を求める問題として定式化できましてでこれをまあの色々展開したりすると変化してることだとたりすると定義をこういう形になるんですねでここはこの上の部分に書いてあるのは結局ま日本語の音声認識のスコアに一えっと二英語と日本語の
体の音声認識結果とまその日本語の今の仮説とも翻訳複合語
えっとーいいうものを落としてまだはもう一殆どはこれだけで音声認識してるんですけどもそれに別の情報も行くかしてえースコアすると
いうような形になります
でさっきの翻訳モデルのスコアを与えるモデルとしてはえーと統計的機械翻訳のモデルを与える場合ということになりますのでそれを学習しましたでそれはいいモデルスリーというモデルを学習しましてえーと大体ん五百五万単語ぐらいのえーっと
えー
文文についとしては百八十境界の文についから学習してえー翻訳モデルを学習します
って評価データーは先の国な人
んでえーっとポイントはここなんですけどもま日本語の発話に対してま英語の
同じ内容の発話が分かっていないと全然第二の二つあっ
えっと子が聞き取れていないと
一つ前の情報を使う訳無駄でえー違うものができるということになる
ん何てまずここ
取り敢えず
え指導電話対応付けて見て正しいものを与えるとどうなるかという実験歳選手
一つな父午後の
対訳を自動で
本当推定してえ使ってみるということをやりましたえー
いうことをやりん
姉と手動でまず
えー
対応付けるんですが
まーあのこれ音声認識の結果声に公演だけでやっているんですけども横軸がワードエラーレートです
ま公園がい一つ目二つ目です
で一つ目は顔色がもう日本語だけの音声認識結果そしてあを二回以上は
それ人の情報を加えて
認識をしたものになりますとえー
って見てみますとまどちらも英語の情報を使った方がワードエラーレートが下がっていという状況になり
一〇四の方も音声認識結果使ってまして一つ目の講演に対しては
については五十五パーセントぐらいのワードエラー率なんですがえー
まそれでもまー使ってやった方がえー
一幾つか世界の単語が入ってると思われる文て言っ
もっと良くなる
いうことやと思います
んで今度はあの太陽を自動で推定
てやります
んでえっとーお対応付けは
あっ今回は時間情報だけに基づいてやりますと
えー
で実際には
まー同じ内容の発話なんですけど文単位と変わっ
話し言葉なんで
何が問題か分かんないので取り敢えず無音区間に区切って
んで日本をね日本語の発話に対しているを幾つか
対応付けるということであります
結構笑っというすそういうやります
一年まこういう時間があっ
って〇二二同時通訳ですのでま英語があってその後日本語を話すというような状況ですでこれとこれとま対応付けていくというような形なんですが
そんなアルゴリズムとしましては
ままずんー日本語が発話される前に必ず英語の発話が
あるだろうということでえー
えーと直前の発話に対応付けるということをします
それからまこういう短い発話があるんですけれどもお短い発話は
短い発話は
んま何が四八だっだけだったり
えー
んーまそういうことが多いですのでそう対応付けはやめますと
んで
ここが
どこに対応作っかと言うとえー
ここはこっちの対応付けということをしも
んで真の値を水で何度もありますので
それは
．んまーんこの後の発話に対応付けてまこういうことをします
んでえーっとこれぐらいにやって
何講演経験
やってみましたで一単位の対応付けするんですが
まそれが完全に一致した部分が
えーっとまー
六十パーセントとか四十パーセントぐらいです
んでえーっと正解
その太陽指導が付けた正解の太陽と
まー自動で対応付け鉄の一部が一致すると
いうような状態今で考えると
ま全部
んが一致しています
んまつまりんどのデーターにも
一部分はまーあのー
一致する内容が一致する発話が
てられてるということになります
でえっとその自動で推定したえーっとんデーターを用いて
実験しましたところ
本当先の顔が音声認識敬語日本語だけで音声認識してつで
何かが
想定でえーっと
このこの発話に対応すればこれですよっていうの教え
結果です
国緑は
自動で推定した結果でして
えーっとー
んまー自動で推定してまー多少色んなもんに含んでるんですけども
かも音声認識も
ペアも含んでるんですけれども
まそれでもやっぱり使ってやると少し認識精度の改善が得られ
いうことが分かります
でえーとこれが実験全部で評価したんですけれども
えー
えーっと
ま結果から言うとまー実験一文献で精度が向上してま一権利は
彼は分かって後五四件では少し悪くなったというような状況になって
んでえーっとーまＮベストリスコアリングで
あのー
最終的に翻訳モデルを使ってこのスコアを使ってＮベストリスコアリングしてい並べ書いてるんですけれども
まテンベストの中に一番いいのがあってそれ選ぶと
まかなり良くなると
まただ赤がまー一日みたいなもんなんですか
パンダも良くなる可能性は
ありますということが分かり
んでえーっとま反対文献にもやってみて
ま言わば発話を認識する時に日本を
の情報を使うということもやりました
んでこっちもまー好きかと一緒にあるんですが
今後が
反対に気になりますまこちら英語の音声認識のスコアで
ここが日本語と英語の発話の太陽のモデルなんですけれどもまちょっとごちゃごちゃと式を変形していくとまき九これにもホッケー
ま翻訳モデルは学習し直さなくてもいいと
．んまー二時五個の翻訳モデルの使ってもいいので
ということが分かっている
で今回は新たに学習
せずに先使った
六モデルをそのまま使い
んで発話の対応付けも
えーっと
先どうも先の発話の対応付けを判定させて
対応付け
いうことをやります
でありますと映画だけの音声認識した結果が大勢
で緑が日本語の情報を使っ
状態になりますなんかは常にしみたいなもん
って言いますとまーあのーやはりえ実験条件ぐらいで
えーと精度向上が見られていてえー日系二変わらない
んでえっとーちょっと軽く熱があるという同じ音
って実際の改善にはま最初に見せました
夏と同じなんですけど
テーマ
ですね黒え好みがあって掲載が経済
このがこういう風にかん母音二日
えーっとここの文は
子供との文学
食料の不足と言っている
んなんですが普通に音声認識すると
まここに間違って日不足となるんですけども英語の方ではそう提示ずっと認識されてまして
んで
この母はなくなって不足
いう風に認識され
まこういう結果がえーＴ
えっとまとめますと
毎日同時通訳音声を
音声認識しました
んでえっとーままちょうど同時通訳の音声認識のところが
ま三楽譜はないんですけどもＣＳＪ使ったりしてま基本なやつだけやると
ま大体これぐらいの精度になって
んそれに対して
まあのー自動で
同じ内容の発話がありますのでそれを対応付けて
一んでえーっと日本語の音声認識をする時には英語の情報を
ペアの音声認識する時には日本語の情報
というのを用いてやると
えーっとー
実験し冒険とか六県で
精度が向上して
で変化がなかったのが一軒家に来ぐらいで
え後の残りの四検査人間とかでちょっと悪くなってしまいます
そういう結果になります
んでえっとー
まー
てでそんな金まだまだ向上する候補はありましたので
もう少し
えーっとによる検討する必要があると思うんですけれども
まーあの先程対応付けの話し合いの意見で評価してたんですけれども
その人間やるやつもか所見てみますと
えーとー
同時通訳者によっては事前に銀行だいぶ読んでまして
えーとー英語が発話される前から日本語喋り始める〇とかも
あるんですねそういう例だとうまく対応が付かない
いうようなことがあります
でそういうところではあまり精度が向上心ということもあります
いうことが分かってきましてもう少しちゃんと二と対応付けをすることと
パンもやはり
音声認識誤りや
えー後にも日本語にもそれぞれ含まれてますんでそういうのもちょっと
採用していった方がいいから
考えております
発表は以上です
#############################


#############################
# query = 温泉のえーっとドキュメントの中から何かえーと検索するえーワードを一回検索するシステムについてはでえーっと下なんですけれどもえーっとそのえーとー論文にはんーん原因としているのはもう検索の幸福かっていうことでえーとーの検索するえーフォワードをおーんそう列ですかねそれをえーっと分割してでえーっと検索を行なうっていうことだったんですけどもその時に後そのー検索する音素列をえーっと固定長で分割してえーっとあんまりが出た場合はそんな思いはテールっていうことをだったんですけどもえーとそのあまりっていうのをもう無視するということはえーっとシステムについてシステムに対してえー何らかの提供をっていうのを後はダイエットをないんでしょうかとーそう言えばえー点火する方法としてんー固定長じゃなくてそのー検索するもうそれ遅延をこう分割てまー選択するという考え方もあると思うんですけどもとーそういうえー考え方っていうのはえーっと試したりはえーたのでしょうか
# rank = 1
# slide = 09-05_fix.match_word.jout.txt
# value = -6.176981894464
#############################
叩きます
よろしくお願いします
平均年齢文章の父はえーあえー音声などの
えコンテンツの利用機会が増加しています
えまたそのコンテンツ体の数のえー急激に増加しています
えこれらを効率的に利用するにはえー音声に対するキーワード検索技術が
で必要となってきます
えしかし
え従来の研究は検索性能の向上に主眼を置いたものも多く
え高速検索えー高速性をの
んー向上を目指したものが少なくなっています
え近年では高速な音声検索の研究も幾つか行なわれて
きますがえこれらは大規模な索引データーベース
高校一九する必要があり
えーえ高速にアクセスする為にはえー高速なん二十記憶装置が必要となっています
えそこで本研究ではえー高速化するデーター領域な小さな音声検索手法の実現を目指しています
でそのプロットしましては
えコンパクトな検索用データー構造である三十二類を用いましてえ音素単位のマッチングを行なうことで
え音声検索を行ないます
え本発表の後について説明します
えまず初めにえ従来手法である三十二類を用いたテキスト曖昧検索について説明を行ないます
でその後おこの手法をえー音声検索に提供する為のえー提案手法について説明します
で最後に提案手法の評価実験についてえ説明を行ないます
えーそれでは従来手法である三十三類を用いたテキスト曖昧検索の説明に入ります
えー三つある一つはえー文字列検索用のデーター構造のことで
えーテキスト中の全てのサービスを相当したものです
え右の増加翻訳されの例なんですが
えこの例では
えー八分の方ブラというテキストに対して三つの例を構築しています
えこの下はあのー
部分が採録され
なっていましてえー
この部分があそっとされたさ三つで
でこの右のインデックスというのはその一つはテキスト中のどの位置から
で始まる顔しえ表わしています
でこう三百される特徴としましては
えー任意の文字列を効率的に検索できるというものがあります
え例えばこの三つある一から三四型という文字列を検索をしたいと
持った時にえ二文探索を行ないまして
えこの一二三八例が
で制限することが分かります
でインデックスを見ますと八と一つあってんでえーテキスト中では
え八五の一つをえピッチの一二三やれば失恋するというのが
え検索できます
でまたもう一つの特徴としましては必要な領域が小さいというのがあります
えこの三つあるいは実際には
先方のインデックスの並び書き起こししていれば良いのでえー
生のデーター領域が小さくて済みます
二十六二十三二類を用いたテキストを曖昧検索について説明します
曖昧検索とはえー誤りの類似性を考慮した検索のことで
えーこの手法はえー電話したのが提案しているものです
えー三十九つあるいは木構造となってましていきマッチングを行ないながらこの木構造を探索します
えその際にえー係を行なうことでえー効率的に木を探索します
でこれが軽いというのはえー探索の音まで
のえー系列と
えー検索キーワードとの力距離を計算しまして
えーその距離がある閾値を超えたら探索落ちるという処理です
で実際に油か多分分からやるえ
ポケットを探索する場合を例としまして
えアルゴリズムの説明を
えー行ないますえここで残りの式
訳生き方をします
えまずえールートノードから
探索を入れまして
えーノード一つ
二度食べに行って距離を
計算していきます
えそしてその距離がえー閾値をこれから
そこでやっぱり行ないましてそれ以上深くはえー探索を行ないません
で同様にして距離を計算しえ高い行ないながら
え探索しまして
やっぱりが行なわれずに
えー
二下の弟の
道を
え検索結果として出力します
えこの手法ですが
えー音声検索に提供するにあたっては幾つか問題点があります
まず一つ目はえーテキスト量の検索アルゴリズムであるということです
えーそうまでは音声データーの検索にも知ることができます
えもう一つはえ係の閾値の増加に対して
で処理時間が指数的に増加するという問題があります
えこれは
採録されの探索範囲の質的にしろこの為です
猫に示しています時構造を模索され
と考えますと
返し一日
で検索した時にこの二日三まで
え探索が必要だとしますと閾値を増加させる
するとえー閾値二ではこの
はえー一九五三ではこのはいという風に
え探索範囲が質的に広がります
えその為に
え閾値が
えーっとそれから閾値はえー検索キーワードの
えー長さに
奇麗させる必要がありますので
でそうしますとを検索キーワードの長さに対して処理時間が
え質的に掛かっするという問題が
おります
えこれらの問題を解決為の提案手法えーこれから説明します
えまず音声検索への適応ですが
でこれは音素単位のマッチングを行なうことで解決します
え音素を用いることでえーと音声をテキストとして扱うことが
できます
えー検索対象の音声データーを予め音声認識処理においえ音素列えーっと変換しておきます
えそして
え音声認識の結果得られた音素音素列に対してその一つあるいは構築し
え検索を行ないます
えーただこの音声認識の処理はえー音素によって誤りやその
え異なります
ですので
えーと朝からサリンの事件マッチング
で用いる局所距離にはえー音素間の音響的距離を適切に
で表わすものも知る必要があります
えそこで本研究では
音素弁別特徴の距離を
利用することとしました
え音素弁別特徴というのは二等がえー提案しているもので
え調音様式や
え一音一を表わす
二十五次元の素性で音素を弁別しています
日本素性というの例えば舌の位置が高いか低いか
やえーとー
あのー有声
文であるかそうでないかなというのあります
でえーこの素性
のハミング距離をえー音素間の距離として定義します
え例えば
ＰとＰという音素の距離は
えー
スピードのこの素性の系列と
実はこの素性の系列の
えーハミング距離を取りましてで二という風に定義されます
え同様にＰとＧＡでは
え一方事例のタレント移りまして八という風に
えー定義されます
え次に
えー検索キーワード長に対して処理時間の中するものについて
の解決方法え説明します
えこの問題に対してはえ企業の町えキーワードを分割して検索を行なうことで解決分かります
え検索公開しますとえーキーワードをえー固定長の分割し
にえー分割しましてえーこの分割されたキーワードをそれぞれに対して
アサリ鎖を検索します
見たら
え音素
時期は途中の音素認識の誤りは一応
ではないのでえー文化
木の一部はえー検索結果の
検出されないという
えー可能性があります
でそこでえー
え検索結果として
ん得られた一をえ候補としまして
えその前後に検索キーワードの力マッチングを行なうことで
えーその
ここの位置に本当に検索キーワードがあるかどうかっていうのを検証します
えただ全ての方向に対して検証を行なうとこういつもございなってしまいする時間が
えー大きくなってしまいますので
えー
できまし六を御覧前にこの方法数を削減すること
えー考えます
えその方法としましては
普通の文化が好きで検知されている方法はえー見つけまして
えそれ以外の方法ふりを起こします
でただこれを行なうには
え正解か所です少なくでその後の二つの文からスキーを検出できる必要があります
え現在の閾値設定では正解一で最低一つの
えー
あの敵が検出できます
え例えばキーワード全体で閾値が三であっ
二十するというえー
これを三分からすると文化月の
で閾値をそれぞれ一になります
えこれ検索しましてえー結果
え二つは
えー閾値をわずかに声え検索結果から落ちて
てしまっても全体でえー閾値
この日は全体で
えー閾値が一であれば
残りの一つはえー検出することができます
でもしも三つ共
えー実験と結果からえー起きてしまった場合はそれは
平均を全体でも閾値を超えてえーそのその一二は
えー検索キーワードは出現しないということになります
えーっと
えー現在の閾値を設定は先程のようになってるんですが
でこれ
をえー分割一の閾値を増やすことで最低二つ
あー分割しようえー検出できるようにします
でこれにはえー
ここにあります
式を用いて音素当たりの閾値を変化させます
あこの式中の日はえー分割の数でえＴは元の閾値です
えー先程の例
人達をこの式をえー適用しますと分割日
の閾値は一．五になります
えそしてそれ検索を行ないますとえ一つは閾値をわずかに超えて
え検索語の中でもえー全体で敷地内であれば残りの二つの県
分割日は
えー検索できます
はい検出できます
もしえー二つ
のえー検査
閾値を超えて
感じる場合にはそれはえーっと全体でもま閾値を越えて
えその中にはキーワードを指定しないということになります
えただ分割の二の場合
この式を適用しますと
え音素値の閾値を元の人場合になってしまいます
えそうしますと
え分割木の閾値五本の木は全体と同じになってしまい自分達ない場合よりも処理時間が増加
でしてしまいます
でそこで
三分割以上の場合にのみ分割を行なうことに
まず
え例えばえ六音素で分割する場合ですと録音数一二音素の際立っ分割せずに
二十八音素以上の場合にのみ分割を行ないます
二十二に
検索における閾値の設定について
えー説明します
え音素値の閾値にたい対する特性としては
えー閾値を起こしますと
記載されの検索
の範囲が狭くなりますので
で処理時間が短くて済みます
でまーその
よりえーと
検索キーワードに近い
結果しかはえー検検索されませんのでえー検索精度が高くなります
え京都に閾値を高くしますと
えこの処理時間と検索精度はえー二つになりますが
よりえー誤りを置く距離をした結果を
言えることができます
えそこへ実際の検索においてはえー低い閾値で
え初めは検索を行なって正確な結果を高速にユーザーに提示します
えそしてユーザーが結果を確認している間に
二回閾値で
で検索を行なってえより多くの結果を
提示するえー反復を検索の方法
後
取ります
えー
でここで提案手法のまとめを行ないます
え提案手法では音声認識処理結果の音素列に対して三つあるよ
えー適用しました
え音素間の距離の数弁別特徴の距離を適用します
えー検索キーワードの分割え検索方を導入しました
ですから低い音素値の閾値から反復をして検索を行なう
こととしました
えー四つ目に
この提案手法の評価の実験について説明します
んえ実験の
え環境はこの通りです
えおんす
えー検索対象のデーターにはえーＣＳＪの何せはさっ三百九十時間分の音声データーを
え用いました
でこれを
使って認識する
あのにはえーＪｕｌｉｕｓを用いました
でその音声認識の結果得られたえー音素列に対して三つあるよ
えー構築したところ約五十二メガバイトとなりました
でこのサイズであればま十分日本メモリーで処理ができると
あります
え次に
キーワードの分割されてですがえー予備実験の結果六音素で分割する場合が最も高い性能を示しましたので
えこの実験では六音素で分割を行なっています
えそれを検索性能の評価の
え実験
の説明を行ないます
え本実験では検索結果のリコールとプリシジョンおよび一人の時間を計測しました
え音素当たりの閾値を〇から一．四まで
え変化させて
んえー検索キーワードにはえー録音室を一に音声一二三十四つの名詞を
用いて検索を行ないました
えここで音素値の閾値の目安について説明します
えーこの図は独り暮らしという
え音素律の誤りをの例を
示しています
えー
この部分が誤りの
あー〇でえーその左側の数字は
えーこの誤りを許容できるえー音素当たりの閾値を表わしています
ですから
音素値の閾値を〇として検索した場合ですとこの結果が得られます
〇．六ですとこの範囲の結果が
一．〇だとこの範囲結果が
え検索結果として得られた
えーでは実験の結果です
えこの
えー図は
左上から六音素のキーワード一二音素の九十八の三時四をそ
もう一ワードをえ検索をした場合の結果で
えー過去グラフの横軸はえー閾値になっています
えーグラフ中の曲線は
えー三角印がありホールでえ近く
父はえ市場
で八千はえー
はい処理時間
を表わしています
日本傾向を見ますと
で低い閾値これは
で処理時間が非常に短く
ですんで検査ん
二箱泣いています
で閾値れ〇の場合では二ミリ秒閾値〇．二
たとえ二十ミリ秒以下で全ての場合
検索できています
今他の
一二音素以上のキーワードでは
えー高い正解精度を
保っています
えこのことから
でこれ式一の結果から提示するという手法が有効であると言えます
あなた〇．二までに限らずもう少し
えー閾値を分けた場合れた八グラム述べた場合でも
えー十分に高速にえー検索が来ないでいます
えただそれ以上
え閾値を挙げますと
九十八音素二十四音素の場合では
〇コーパス中に音素に比べまして急激に
で処理時間の増加しています
えこの違いは何かと言いますと分割を行なっているか行ってないか的違いがあるんですが
えーこれだけを見ますとえ分割を行なわない方が
えーいいのではないかという風に
見えます
えそこで実際に分割をせずに
で検索した後についても計測を行ないました
えその結果がえーこのグラフ
ですが
えー
見ていただく
って分かる通り実際には分割行った方は処理時間は短くて
えー住んでいます
健康のことからやはり分割検索を有効であると
ことを確認できました
え次に
あー更にえー
検索対象の時間を増やしまして一万二万文の音素列を作成して
で検索を行ないました
えこの一文字単語の音素列ですが
でこの七割
えー音声の収録時間を持つコーパスというのは存在しまして
存在していませんので
先程の実験で用いましたＣＳＪの
え音素列のサイズを下に新聞記事のデーターを変換してえー作成しました
でこの一文字間の文の音素を列から
えー
二千時間戦時下の曲一二十二日一文字単語の音素列を
えー切り出しましてえそれぞれを対象としてえ検索の実験行ないました
えその結果が
でこの下に示してるグラフです
左のグラフから
えー閾値は〇って二の場合〇．六の場合に一年〇の場合の結果です
んでグラフの横軸はえー検索対象のデーター長さで
えーグラフ中の曲線は
えー検索キーワードを
ごとのえー処理時間を表わしています
えこれを見ますと
〇にの閾値でえー一万時間を検索した場合
配置最も時間が終わって二十四音素の場合でも百二十ミリ秒程度で
えー検索が行ないいいます
えまた
この
えー結果全体を見ますと
検索対象のデーター町に比例して処理時間が増加しているということが分かります
えこの理由ですが
え検索
処理時間の内訳を調べたところ
え採録されの検索よりも検証のピッチマッチング
何をするえー時間が支配的となっていましたえまたこの現象のピッチマッチングの
えー対象の候補の数は
あえー検索対象のデーターの三日で静岡
できました
えこのことから
え全体の処理時間が検索対象のデーターの差に比例していると考えられます
で最後にまとめとしましてえ本研究では三十二類を用いた
高速な音声検索手法を提案しました
えー検索キーワード長に対する処理時間の増大の問題を
えキーワードの分割検索法の導入により解決しました
えまた実験により構成となっ検索結果を短時間ていうだけ二日の
んーであることを確認しました
えーマッサージ
こちらの実験により
えー処理時間が検索対象に比例してそこは
するということが分かりました
え今後の課題としましては一四国際分割できない場合の分割方法
やえー分割検索の
え検証のＧＰマッチングの高速化が挙げられます
発表内容は以上です
後楽し
#############################


#############################
# query = 温泉のえーっとドキュメントの中から何かえーと検索するえーワードを一回検索するシステムについてはでえーっと下なんですけれどもえーっとそのえーとー論文にはんーん原因としているのはもう検索の幸福かっていうことでえーとーの検索するえーフォワードをおーんそう列ですかねそれをえーっと分割してでえーっと検索を行なうっていうことだったんですけどもその時に後そのー検索する音素列をえーっと固定長で分割してえーっとあんまりが出た場合はそんな思いはテールっていうことをだったんですけどもえーとそのあまりっていうのをもう無視するということはえーっとシステムについてシステムに対してえー何らかの提供をっていうのを後はダイエットをないんでしょうかとーそう言えばえー点火する方法としてんー固定長じゃなくてそのー検索するもうそれ遅延をこう分割てまー選択するという考え方もあると思うんですけどもとーそういうえー考え方っていうのはえーっと試したりはえーたのでしょうか
# rank = 2
# slide = 10-15_fix.match_word.jout.txt
# value = -6.18480435784023
#############################
あーえーでは
ＣＳＪ音声ドキュメントを検索タスクコレクションを対象とした
部分否定区間の内容検索タスクのせっ
でえーっとーその検索手法の検討について豊橋家内の本のこう後ろが発表します
えーまず背景といたしまして
音声認識の高度化に伴い
音声データーを文書として活用することが可能となってきています
その中で音声の活用の一つとしてえー検索が必要とされてきています
本研究では内容検索を対象にタスクを設定しています
内容検索とはキーワード率が自然言語文で表現された情報要求と
あっ検索対象の音声文書集合を入力としてえーその情報要求に適合するような文章を見つけるタスクとなっていましてえーキーワードの出現位置を見つけるキーワード検索とは行なっています
キーワード検索では
このような
単語のクエリーに対してそれが
音声ドキュメントのどこにあるかというのを検索しますが内容検索では
このような文章などに対して
です
特訓なく面倒コレクションから適合する時念頭に付けていきます
研究の目的です
えーＣＳで音声内容検索テストコレクションに対して
可変長となっている正解区間を見つける為の内容検索タスクの設定を行ないました
そしてそのタスクに対してえーベースライン手法の提案とその評価を行なっ
いました
ＣＳＪ温泉内容検索
テストコレクションとはえーＣＳＪの学会講演と模擬講演を対象にしていて
えーその公園のい一部五発話程度なんですけれどもその可変長区間が適合となるような三十九の検索質問を持っています
参考文献はこのようになっています
えＣＳＪにある文章のサンプルなのですが
えーこのような文書に対してえー情報検索性能を評価する人はどのような方法があるか知りたいといった検索タスクが存在しており
その回答としては
このような部分区間
んの
えー
えー部分空間となっている部分を正解として持っています
えー
まずこれまで使用してきた検索タスクについて説明をしていきます
これまでの検索タスクでは講演を一定値音の固定区間に予め分割していて
それを検索対象とした内容検索タスクを設定していました
で評価はこれまで一五発話三十発話六十発話の三種類を使用してきました
これまでの検索タスク
についての
ですし
詳しい説明なんですが
先程のような文書に対して
快適に二十五発話ずつの
区切りを
作成しその区切りに対して検索をあ
こう行ってきました
先程のような例では
このように
えー二つの文書に跨がっ
て正解が
出てくることがあります
その場合は
一部でも含まれていた場合は正解というようにタスクを設定を行なっていました
えっとしかしこれまでのタスクの問題点としてえー
一．五は三十発話六一発話っていうのを使用してきて
ましたがこの固定長の幅というのが
適当のに決めた幅であること
またＣＳＪ自身に
可変長の正解君が
用意されているのに対して固定長を
検索するというのはその対応が取れていない
という問題がありえー正解と合致した二分割か可変長の区間を
検索した方が有意であると考えました
でその為固定長ではなく可変長を検索するタスクを設定しました
可変長の区間を検索する場合の問題点としては
可変長区間の一の遠くてえー開始位置と資料一を特定する必要があり
更にその後ん内容検索という二つの問題をとく必要が出てきます
多数の検索
問題を解く必要があるのですが
可変長監督程度ん内容検索まー別々の二つ
問題となっている為に
この中からえ内容検索のみを評価するようなタスクを設定します
先程言ってた
んないのですが
このようなのに対して
えー部分空間を特定する必要があります
そしてその部分区間を見つけた後に検索を行ないどこが
適合している
部分であるかというのを検索する必要があります
えーこれに対して
可変長を測定する問題を分離する波に
可変長区間の一発話を見つけて
そのー
見つけた一発話がえー正解区間に含まれている場合にまーその正解区間を全体を検索したもの
としました
または検索する
えーっと下
方法を変える為にえー
にえー正解判定の手法もえ変化させました
えー
えー正解区間内の一発話は検索されたらえその正解区間の映画全体を検索されたことになる為
同じ正解区間内をん
の
発話を
選択した場合にまー同じ区間を二回検索したことになってしまいます
えーその為一の検索された区間内容に会場を検索した時は
二出来事するようにしました
例として
えーさこのような世界区間がある場合に
んー最初にこの発話が検索された場合には
この区間全体が検索された者として適応とします
しかし同じく家内のものが検索された場合は
この区間というのは常に検索されている為に
えー適合世界という風に
評価を変更します
で評価尺度にはえーえＰ注意して平均精度を用いて
えー
検索性能は常一千件を求めてえー日を計算し前検索クエリーでそのＩＰの
平均を取りました
えー
タスクに対する検索手法とその評価についてえー話が移ります
んー
音声ドキュメントを対象とした内容検索のベースラインとなる手法として
えー
ん大語彙連続音声認識によって検索対象の音声ドキュメントをテストに書き起こし
そのー
書き起こしたテキストをその索引付けに使用し
する
方法もん
行ないました
えー検索重みはっていう風ＩＤＦを使用しています
えー今回は一発話を見つけるタスクという風になりましたので
この一発話のみを索引付けしたものがベースライン手法となります
え実験けっ
がです
えＣＳＪの持つえー自動書き起こし文ちょっと一で書き起こし文章この両方に対して実験を行ないました
えー自動書き起こし文書というのは大語彙連続音声認識によって自動的に作成された文書で
人手書き起こし文書というのが人間がその音声を聞いて書き起こした文章となっています
自動書き起こし文章
に対して行った検索で〇．〇九八
えー人手書き起こしたし文書に対して行った検索で〇．一二二という検索精度が得られました
次にえー検索手法として文脈を利用した文書拡張の手法
で実験を行ないました
えー検索対象の区間の前後には関連した内容が現われるということが多くなっています
その為その前後の文脈を利用して文章の拡張を行ない索引付けを行ないます
戦後の区間には前の発話を持っ
前の発話六．五点の発話文を使用して
えー検索対象区間と文脈の重み付けを行なっています
えー元の部分の一発話文のＴＦがこの部分で
えー文脈となる部分が
この部分になってます重み付けとしてえーデーター場合していてこのデーターに今回の実験では腰をしています
んー
えベースライン手法ではこの部分のみ索引付けしていたのですが
その前声が発話を
もう
この部分の
書くん時点に使用しました
えーこの文脈を利用した文書拡張の実験結果です
えー文脈には前後
一発話から一五発話モデルを使用して
縦軸が検索精度となっています
文脈を使用することで
えー検索精度の上昇が見られました
えー次に
検索者タスクのこういう
の検索手法について
説明します
えー提案したタスクではえ一発話という非常に小さいん単語を検索対象としている為
通常のタスクでは使用できないような方法
検索手法として取ることができます
で最初の手法として
従来の検索タスクとして行なってきていた
ここで区間長に対する検索を使用する方法
という実験を行ないました
えーこれは
んこれもです行ってきた固定長区間に対する
検索を行なった後おーそのー検索したこと行くん町の中心の一発話を検索結果とする手法です
えー実験には
んこれまでの従来のタスクでは一語発話三十発話六十発話を使用してきたのですが
より小さい子発話一発話になっても実験を行ないました
えー従来のタスクでは
このような
そこで小区間に対してこの部分を検索しこの部分全体が高いと異なっていたのですが
えーこの中心神様
検索結果とし
で
えー検索結果どうする手法です
えーこの方法で実験も行ったところ
検索精度の上昇は見られませんでした
えー
この結果を見てえーっと中心の結果としているのか大雑把であるとして
えー
これを発展さした手法として
えー固定長区間で検索した結果となっている
部分を一つのコーパスとしてみて
そのコーパスに対して一発話文も
検索するような
手法
用いました
あっえー
えー
このような
固定区間長が検索されたと
この部分全体に対してえー一発話ずつベースライン手法のように索引付けを行ない
再度検索を行ないました
んそして結果として
で中心街の部分が出力されるようになります
この手法を使っ
た実験結果です
えーっとーが
えー
固定官庁の中心も
強くする方法
あのまー
え再び検索する手法です
えー中心を
あのー
結果すると
手法に対して検索精度が上昇しています
また
一発話中の発話の二つで
えベースライン手法よりも高い検索精度が得られました
でその為ってより小さい範囲の検索語
実験
も行ないました
英語発話一発話中五発話二十発話二十五月の三十発話とお発話器官に固定長区間を設定し
実験を行なったところ
え中国その時にえー検索精度が最大となりました
この時えー約〇．一二となっています
すえー最後にえー近傍駅の力を与える手法
用いました
えー検索した結果の近くには
えー可変長を発話区間内にある可能性が高くなっています
特に文脈を用いた場合は見た部分を索引付けに使用している為にそれが特に顕著であると考えます
えーその為
常に検索された結果の近くにあるような検索結果に対してえー形Ｔを与える手法を用いました
この時文脈照応
文脈を利用した文章拡張の実験と併用
に対してもう実験行なっていますが
この時文脈上には何な発話を使用しています
んー
とー
既にこの
部分の
検索が行なわれている場合には
そこから前後
え発話文となる場合の検索結果が出てきても
それは結果とせずにえー
結果から排除することをこのペナルティーの簡単な実装として用いました
ベースライン手法では殆ど効果があってナリティーのとなる発話には
五七十八一五
二十五個一も用いて実験を行なっています
えーこの間は
ベースライン
半分
でえー
今回用いた手法で
えーこの紫がベースライン
そのー
黄緑が
えー
文脈に対して
んー今回
近傍駅な力を与えた結果となっ
って言います
えベースラインでは殆ど効果がなかったのに対して
え文脈拡張ん
行っ
えーとものに対し
えー
えーっと近傍訳な力を与えたところ
検索精度はの向上が見られました
えまた文脈に何の発話をしてどうしているんですがそれと同じ何の発話のペナルティーを与えた時に検索セット
精度が最大となりました
んーんえー今回えー提案した検索手法のまとめです
ベースライン手法を文脈を利用した文章拡張
えー検索語
固定長で検索した後その中心おー結果する手法を
えー固定長
もう検索者ともう一度検索を行なう手法
常に検索した結果にたいの近傍に対して再びペナルティーを与える手法の一つを
提案しました
えーそれぞれの結果です
父つらいん手法に
大して文脈拡張と
文脈拡張時もいつなるっていうを与えた場合
それとえーっと定常で検索したと思いした検索する手法を用いた場合に検索精度が上がりました
また文脈拡張と
既に検索したものの近傍へのペナルティーを併用した場合に
最も高い検索精度が得られています
えーまとめと今後の課題です
えー部分空間を検索する為のタスクを設定しました
またタスク固有の検索手法を適用して
それに対する評価を行ないました
でそっの結果文脈拡張時にも悪くなるとしよう
与えることを併用した場合にここは大きいということが分かりました
今後の課題としてはえーっと検索精度を向上させる手法の検討評価を行なうことです
え発表は以上で
#############################


#############################
# query = と音声の時メントの中からそのえー文字列とか後検索するシステムの高速化っていうえー論文の中でえー二えー講義音声のデーターベースに対してえー実験してその考察の中であのー未知語に対する考察っていうのがでもえーフォークえーされていたと思うんですけどもえーえーとんーとー六日後音に対してこう何らかのえー対策といったものえー男するということはえーっと考えているんでしょうかえーっとあーえー考えた時て実際にえーそのような未知語に対する対策っていうのをシステムに加えたとするとまー今回はえーっと高速の検索手法っていうことでの高速化っていうのはもうえーもう少しえー後悔してしまうでえーっとー若干遅くなっちゃうとかなと思うんですけどもとー今後はでえーっとそういうシステムとかえー変更っていうのはえー考えているでしょうか
# rank = 1
# slide = 08-15_fix.match_word.jout.txt
# value = -5.0927450708147
#############################
とそれではえー肯定音声認識の為の上文章を用いた言語モデル適応かと思い選択という題目で
山自体は二音が所が発表さしていただきます
と発表内容はえーこのようになっていてえーまず研究背景研究内容説明とい言って
えー内容のウェブを利用した話題適応化
語彙選択についてで最後にまとめ
えー今後の課題です
えー研究背景ですがえー講義音声を認知する為
の言語モデルとしてえー講義音声は話し言葉なので
ＣＳＪ日本語話し言葉コーパスを使うということが多いと考えます
しかし飛行機のように特定の話題を確立された内容の八巻はできません
その為にえー未知語率が高い確率が高いということがあるので音声認識率がえ低下してしまいます
そこでえーインターネット上にある情報をまーインターネット上にある情報が容易によできること
えーに着目し
講義の話題に
提示さページをうまく利用性は認識できた場合は学習できるはないかと考えました
えー研究概要ですね上を用いた言語モデル適応化ではえー文書を集める為の検索例について調査しました
検索利用者の注意をして
え調査しています
えー言語モデルん
でえー認識時の語彙テントの検討では
特定の値を認識するのには
えー必要なものは最低であればいいということで
凄いよくや制約逆に入り易くなっすることで認識率の改善を図りました
ではえー
適応化の概要について説明します
まずえー
ね対象音声を認識システムによく正解認識結果を得ます
本当記事をする元のまではＣＳＪからが指定しています
次の処理はえー検索
認識結果が
検索家を構成しウェブ検索を行ない
上文書を生成します
えー検索に
はえー認識結果二の名詞からえー
え名詞を利用しています
また上文書にはＰＳまー本当が含まれている為に
えーそれらをテキスト化する
えーＨＴＭＬファイルはえータグ除去するなどの処理を加え
設定します
そして制限した上文章を使って
えー言語モデルを適応化し一応ま言語モデルを作成します
最後に適用の適応までのモデルを使ってえ再び
えー音声認識を行ないえー最終的な認識結果はいます
上の検索に用い駅が後はコーディネート認識結果から抽出しています
合計名からはこう一名の名詞にしてからは
法律名詞複合名詞を抽出しています
えー孤立名詞は名詞一二グラム団体の名詞で
複合名詞文名詞バイグラム
多数の名詞を使用しています
これらからえー二種類の中八月一日をえー
付けています
一つはこの
こう奇麗な名詞と孤立名詞のＴ私の
もう一つはこう奇麗な名詞と複合名詞のキーワード集合です
えーとこちらがえー孤立名詞
あー
そのー
これ爪視野が充実してる孤立名詞の
ね非常になります
えー
途中数の条件はえー
頻度Ｎとしてえー最大頻度Ｎマックス
上で流す分のＮを算出しえーそれが〇．三以上のものはえー歳
えキーワードとして採用しています
えーとこれの三見るとえーとープログラミング入門
にはえー数値計算えー
えー線形な性格うーのにある
どう見るとおえーっと音とか
えー人とか
ちょっと
こう人は関係のない
単語とか
元にえー効率名詞ではえー
含まれています
と次に複合名詞のえー
とおー記号です
えーこちらも同じくえー振動はえー
えー最大頻度Ｎマックスとし
上のます分のＮが
えー〇三色んなものを採用しています
その
名詞バイグラムの場合ではえー
えーと頻度が高い
ものにじゃ
過去に関係のある要は
え頻度の高いいー
えー
頻度が高いです
と次にえー検索
現在の方法について説明します
選択を主に使用しました
まず一若干の検索
多分聞いあの使用してやり方です
とこのような気がするのがあった場合
まず治ったんで検索し
えー上文章を収集します
次にえー言語でえー検索
とー文章をえー追加してきます
ついえー収集した文章はえー設定を行ない学習データーに変換します
もう一つのえーやり方はえー同時検索同時に複数のキーワードを使用するやり方です
どちらの精度を一遍に使って
あー選択し
上文章は生成します
収集した文章は同じって成形して学習データーに変換します
と次や後二
前のキーワードを
を使ってえー道への検索を行なうので
検索例が四つになります
こう決めた効率面ちょっとずつえ要するにラムスアンド検索
合計名と複合名詞を一つ釣りをするまイスラム単独検索
方言えーと効率名詞を同時に
利用する
えーよりあの当時検索
×がえーコーディネート複合名詞を同時に
薬をすれバイグラム同時検索の様子になります
と次にえ適応化の方法です
と適応化はまずえーあー
とＣＳＪの学習テキストウェブテキストの集合をそれぞれからＮグラム頻度
えー算出します
ただえー二つのＡくらいの頻度を重み付きでえー足し合わせ重み付け混合音
そのＮグラム頻度を出します
えー
ＣＳＪからは
えー二万単語の上り
フレームでしたからはえーっと全語彙を
えー前後の
語彙いー
後五回の作りえーそれぞれを
なる
それらを使って
それらと
混合した五グラム頻度使って
適応が元のモデルを構築します
まーそのーまたえーこのいーですが
とーさまざま場合この四つの名前が考えられますが
えー
今回
今回は全てに対して行なっています
評価実験ですね
評価実験はえー実験音声は山梨大学工学根底になる訳分から
のデーターサイエンスを正解とされた四五六のものを使いました
音声認識してはＪｕｌｉｕｓです入れたり以上の三．五．三です
音響モデルはえＣＳＪから学習したあトライホンモデル
んえー一二次元の
えー
え名詞一ΔＭＦＣＣ
ホテルだΔＭＦＣＣ
とえー一次元のΔパワーΔΔパワーの三十端点です
評価項目は
単語正解率
えー単語正解精度名詞正解率です
とＡまずこちらは大人他の言語の結果えースポーツま他の言語は
えー
でえー使用されている
総単語数が千三百
六十四単語です
でまずえーこの表をアグラフえっと一番自体が
ＣＳＪ適応化前の結果で
えー
その中であその水が二年三度検索×らの単独検索家の同時建設×アンド次元削減の
適応化へのまー適応化の結果です
えーっとまず
ＣＳＪ教科前と
えー適応化したもの全体を比べると適応化することになって
えー
認識率が
全て海前されています
えーとー
次にえーっと検索地方の比較ですが
アンド検索と同時検索
を比較すると同時現在の方が
えー改善され認識率が高いです
とーこれは
あのー
何度検索
の場合え単語を一つ一つえー使う為に
検索けっ検索の際に曖昧性が生じてしまう為
えー話題とは関係のあり方が関係のない文書が多く集まってしまっ
いう為だと考えます
と次にえーキーワードの
キャベツが
揺らぎとバイグラムでは
えーバイグラムの方が
認知率が高いです
とーこれはえー
どういう五グラムの方は
んー
先程のあの表になっており
えと採用されている世の中に
話題とは関係ない
ものが入ってしまうことを
とえーま
がある
というのと
んバイグラムにすると
えー言語的制約を取る分野えーま
と関係ないものな反応ができるので
販売えー名詞バイグラムの方が
より
関係のある
分野を
ま文書集めるのになってきていると考えます
変わったえー未知語率とパープレキシティー
ですが
て評価することになって
大きくうーされることはできています
次にえプログラミングにはまー
えこちらはえー相談にそう単語数は二十一が一番いい音声の約四時四単語でした
あーですええ
とこちらの
適応化することによって
認識率は改善されています
えーまた
この上毛まー
えー当時検索の方が
その結果距離の文認識率が高いです
またはいいなと×らの比較でも
バイグラムの方が
んーより改善されています
道のりとパープレキシティーですが
えー
二十リストは名詞があ一番
避けることができたのは五年当時検索
なっていますが
とこれは
えー
いう五グラムうー後あの
四四グラムで採用先がかつてそのーが多かった為に
えー検索される
文書数が多く
えー
他為に
未知語率試しは変わっています
しかし
明確でない文書は
後
単位に
認識率の方はバイグラムと次元するのが
高くなったんじゃないかと考えます
と次にえー線形代数約一
この時は
えー外まつわる
六千四百四十七です
えー
で
とこちらの
この方言の
えー適応化することによって
に結果が改善されています
男の子いわゆる当時現在のが
音二四つが一番改善されましたえー
これあのーまた
えー未知語率が嬉しいも
いうの事件が一番
って言います
実はできできていますができるんですけども
ところの×です文書数自体が
すバイグラムバイグラム当時検索に比べて
僕収集できたのに
そのーこの講義ではいる同時検索が
一番二比率が改善された
されていました
と次にえー数値計算法です
高齢化の方にはえー午前三百八十四単語ですです
えーこの方言の
音適応化することによって認識率が改善されています
とーまた
えー
三つ四つをまクリスティーは
言える同時検索が
一番実は出てきていますが
認識率Ａの方はバイグラムと実験ですが
えー
一番改善されていました
えー
あのー次に
んえー語彙の選択についです
どうにθを改善する為には未知語率をされるということが考えが
またえー同程度の未知語率であれば児童言語モデルの語彙サイズが小さいものの方が認識率が高くなります
えーそこでえ適切な語彙の選択肢じゃなさいとできるだけ小さくすることで二四つの改善分かりました
とまずえー
えー語彙選択することによってどの程度
でにんしえ高い認識が改善するのかということを調査しました
これは
後適応化したえー言語モデル
凄い八五二英単語以上
から
えー手動でえー正解単語のみを選択し
えー
ね
手動で前
で正解単語のみを選択しえー二実験行ないました
猫の適応化というのは×らの同時検索うーでの結果です
えー
二つを選択でえー
正解単語のみを
選んだ結果なんですけどもそれでまーす
父の固有の
認識率が
改善することがあー単語正解率
に正解率が
設けるえー改善しました
と次にえー自動で
んーん語彙選択をする
語彙選択を行なう手法の検討を行ないました
えー
手法一はえー上文節の命でした
ＣＳＪの名詞以外の単語のみの辞書に登録しました
地方には認識結果の単語と兄が音韻の単語のみをあの医者に登録しました
手法を三は認識結果の単語と同じようになっ単語のみを
登録しました
ねここで言うようにな音韻というのは
えー
認識結果と単語辞書を
の
元の
そうで二つの単語を一化する際
そのー
単語の単語の音節列を
包摂ですから
えー子音をな雑誌
母音母音列に変換しその母音列が完全にするものを似ていると判断しました
同じようにというのは
えー
七月の
音節列が同じ完全にししたもの同じ音韻
という反応しています
次にえー
そのーそれらの手法で行なった
実験の結果です
えー
えーまずオートマトンと言語なんですが
そのー
認識率自体は
の
手法三三名正解率がじゃ段階でしていますが
それ以外は
ほぼ変わらないという結果でした
またはえー
二十リスト語彙数の変化ですが
手法一え手法にえー手法三と
えーの順番で
え語彙数は
低下しています
また地方さんでは
資料三では語彙数は元の語彙選択した場合に比べ
えーとー一パーセント以下のね
材料とできています
いたし役に未知語率Ａの方はえー調査をしてしまっているんですけども
の四
赴任し
していますが
とー
認識率自体は
後大きく悪くなるということも
ありませんでした
次にプログラミング入門の結果です
動物であーのー
えー
手法に手法がこちら手法に手法さんで
名詞正解率が
えーと若干こちらの若干改善されています
また
えー
未知語率と語彙数の
変化の方では
こちらのえー手法さんで
自分約一分の一ぐらいまでは
えー
語彙サイズを
非常する場ができました
しかしこっちがまーえー三中央率の方は
の上昇をしていて
していますが
まー
と認識率が悪くなるというもの
生徒は
ありませんでした
次にえ線形大学一です
えーと
このこのＤでは
父は手法一手法に手法さんで
に正解率が
改善されています
んでえー
後三時をリスト語彙数
の変化の方でも
この語尾の手法三
で
十分の一
ぐらいまで
語彙サイズは
く喋っています
でまた同じように未知語率は
変わってしまってるんですけども
えー認識率が悪いということはありません
四月四計算法ですえー政治経済面では情報たんで
単語正解率
単語正解率透明性が一は
向上しています
えーあーのー男性が一度も若干性能向上しています
でえー
やはりこの方言を手法さんで
大きく
んー語彙数を
食べることできています
んーで同じように未知語率が徐々していますが
えーんー
認識率が悪くなるということは
ありませんでした
えー
とこの手法三でどの語にも未知語率が徐々していると言いましたが
これは
この四月あのー最初のＣＳＪのものよりも
高い
ものになっています
しかし
えー
このようにえー
下がるということもなくうー
むしろまーまたあー四十二よりも高い上
えーと適応化
ど同じ程度またあーもしくはえ少し高いぐらいの
結果なので
語彙選択えー
過ごしたいとされるということは
まー
二型の方がないかと考えます
とまとめですが
増え文章を用いた言語モデル適応化によって
えー
認識率は回転しました特に正解率は大きく向上しています
語彙選択の検討では
えー適切なあー語彙選択することで認識率若い人であること分かりました
認識実験ではえ若干の改善でした
その方の手法でえ名詞正解率が最大で一二パーセント改善しました
理想的に行なえれば
二十六から二十二パーセント
の改善が期待できます
今後の予定は語彙選択の検討を進めていきます
そのー言語モデルただ
今考えてる訳のでの学習の選択する程度です
例えばえー不要な分
を削る
あー
そのー五二はす
母音の
文選択して
いるので
の学習文の中に
未知語が多い文というのができていいいるはずなのでそれを削る
えーまたえー上文章
収集した上文書ながら
我が校とは関係ない上文章を除いていくというなことを考えています
発表は以上です
#############################


#############################
# query = と音声の時メントの中からそのえー文字列とか後検索するシステムの高速化っていうえー論文の中でえー二えー講義音声のデーターベースに対してえー実験してその考察の中であのー未知語に対する考察っていうのがでもえーフォークえーされていたと思うんですけどもえーえーとんーとー六日後音に対してこう何らかのえー対策といったものえー男するということはえーっと考えているんでしょうかえーっとあーえー考えた時て実際にえーそのような未知語に対する対策っていうのをシステムに加えたとするとまー今回はえーっと高速の検索手法っていうことでの高速化っていうのはもうえーもう少しえー後悔してしまうでえーっとー若干遅くなっちゃうとかなと思うんですけどもとー今後はでえーっとそういうシステムとかえー変更っていうのはえー考えているでしょうか
# rank = 2
# slide = 11-10_fix.match_word.jout.txt
# value = -5.09336542817105
#############################
えーそれではえー画像の曲線先生基づく音声中の検索件数というのはどういう風いたという題目で
えー入力でえうー第二世紀は発表させていただきます
えー聞けないっていうのですがもうつ先程あえー発表された
病院は二つ多くの頭子音のはいである
少し発話え続いておりますが
後はもうえー
構文あえー検査を禁止する
はえー音声認識率数により音声をテキスト化する方法はえー自分もそのーおーえー用いています
でこの方法はえー問題点として
音声認識誤りがあるとえーまー三十分
テキスト型の検出だけでは難しい
という意見が
あまりあります
えー先行緊急の
えー一つうー
んー先行研究のベースはしえー
画像中の非線形性
基づくえ点数を検出っていうのはありまして
さてえー
さてえー検索語
ある語に音声認識結果を置き
各方式ってにえー音節間のてるようなことで
その重要文だと思う見ると
このような画像が現われ
結合は現われる一二曲線が現われるので
音声中の検索現実問題をえー雑音喫煙率問題に迎えることができます
しかしこの手法二の問題がありまして
えーこのようなうちの誤りに対してはこの問題にはならないのですが
んえー削除誤りえー八挿入誤りがあると問題になってっつうぐらい泳い
あるとこのように進ん船が途中でえ途切れてしまうので
直線鉄は非常に難しいという
ことになってしまいます
それは〇の場合は音節がえー
えー連れてしまいます
そこでえー提案手法のベースは
んえー調整検出だけではする誤りや
すえー挿入誤りは対応できないので
え直前検出を行なう場合に
画像に対してフィルタリングを行なうことで
えー先誤りや挿入誤りに対応している方思います
えーまずこの直線上するデーター
っていうものですが
これはえーすであまり家そうにあえー
で後対応する為のものです
音圧の
ま色合いの
がその中で
最も黒い三つの活動の平均をおー中心がそのー
方に置き換えます
これをすると
声
しえー検出自体中世の部分
があるのですが
デザインを掛けることによってえー
えー
え直線バック六現われる音
えーこれえ直線が緊張して使われます
私まーこのようなところに
想像図二の二音が現われる雌は
まーそのようなえー
雑音が
ま二つの起点となる言える
ことはあります
後えー雑音
後はえー誤認識しその言葉あるいは
そこで
雑音中で事例データーというものを書いてます
まずえー先程のような雑音
前の
雑音をを重視するものです
この図の
回路の範囲の数がそのー中間一応
おー中心のそののによっ買えるもので
で
コンピューターを直線九十三等を掛ける前に行ないます
そうすることによって
これでえーまー
少ない
えー
そのー
少女時代部分だけが
強調されて
えーその部分が付く
なることで
えー
貢献する
で
えーここにあります
えー実際の直線検出法について説明します
がそのー例えばえーと総数を
気そういっで
旅行の
何か総数をえー九
します
でこの音節間の距離を
試合中六と
えー
んー
直線状も各
何かその
五の合計値を
連接種類としてち事例時は
そっち事例を
えー
えー
縦の
えー
検査語長のす
夏は
で
持った第四
えー平均累積値よりえ見て
と思っています
えー
これをえー閾値
あり方
に掛けて後は未満なら
で
えー検索を終わるとして
それ以外から結合は
バイトをします
で
えー
薬があるをえー
検索システムのアルゴリズムですが入力としてえー係数は
入っていた時に
音声認識結果の一発話文をす
えー検索行動は
組み合わせて
それがどうを作成します
その部分に対して
そして検出を行ない
えー接合なければ
雑音推定値データーと喫煙という結果を掛けた上で
もう一度えー
直線幻想を行ないます
えー
自然が
あるいは
これをする集合の方はえー
これをえー
全発話文
繰り返して
そのー
えー
方でえーし
今回用いたサブワード大会のえー
音節音節音は面しているのですがすえー
この音節頭を求める為に
です感じ量を求めます
まー
さて大きさを感じるようを二例ですと二十四名のですが
えー音節を
支援と思いに分割し
それぞれの
スポーツ界データー対二で割った値をまー
を続けているとするのですが
一え数ではえー考察関係で
ＣＢはえー
もう疲れてるに
なります
でこのＣはす
支援に語っており
二四五母音になります
まーやえーのそのー
えー
一音素からなる
えー実は
それと後えー
を同じ音声として扱います
でそれを求める為の
を支えてるのもそういうえーことですが
ホテル尺度として
各
音素ＨＭＭの私割合という
利用を用います
えーこれで今回用いたのはまー
まこういうえー今回用いたＨＭＭは
中高校モノホンの男性用の音響モデルを用いました
うん
えー
この式があー考察できるのですが
二番という通話ともかく
音素のえー特徴ベクトルのえー五人で
えー四分も悪くも通話えー
計算機をもう三四五に当たります
えー
この三時
んーこう
用いいるのですが
政治家はしないと思うしいうことはできないんで
えー
後
後用いいうことで正規化します
でこの式
〇一そのーデーターっていう値をし
えー
この正規化をする際の
小説での係数
で今回は
二．七おー
っていう値を用いました
で
実際の実験なんですが
今回はえー
ステージ用テストコレクション
を用いて
えー
えー検索対象として
ＣＳＪのおーえーペットのな一の方へ九
四十時間の
音声認識結果
を用いました
これはえー
単語トライグラム
そうですがえー用いたものを用いました
検査語は
そのー講演の
この講演をあの自分を五十検索行動
えーっと既知語五十検索語を用いました
えー
未知語を実験なんですが先程説明した
直線件数も
えー
閾値α
一の値を
えーこのように
〇から八十もえー
んえーとコストは
結果をおーしています
えー
直線上昇
により
えー
戦場助詞の言葉に比べえーす
ま全体に再現率えー向上してるのですが
えー
えー
で
適合率は
えー
小さな市に比べると
えー
生活しているということを分かっています
えー
雑音適応
をすることによって
ほぼ同等をえー一つえー上昇しするしただけの結果とほぼ同等の
失敗に二つを得られたあー得られ
かつえー
四五六というのを
で最後に終わってきました
えーこちら自分を評価結果の比較んですが
えー未知語をえー
二十一ドル
あのー
えー音声
認識誤りであり幸いモダリティーを
えー検出したあー完全一というえー結果がこれで分かるんですが分かんないし
材料を取ると
未知語は殆ど再現率は得られない
結果を終わっています
えー
従来法の一つはえー二
の結果とおー
このショートセンテンス
えー朝鮮検出法
のおー比較すると
採用人数
まほぼ同等でＸ
適合率はえー
向上しております
これは連続ＤＰの一つえー僕は
えー
編集行けるのは〇一
の検索用になのに対して
直線上にそのー
給食後は
えー〇から百五十語の音節数〇っていうことを
がによる効果だと
考えております
えー
次に
ま直線でそのフィルターなし
とー
今回提案した直線状子音プラスうー雑音推定した結果のＳは
あのー
朝四歳にする
ま高齢者ですが
えー
考え後
それで自立を比べるともうどうこうはですが
喫煙所でしょうというでした与えられると低下した結果と思っています
えーんそこで
んー
利用率の低下を調査しました
んえー児童は滞在して
そうですね傾向を調査すると
検索音声す短いで最後に
誤検出が多いことが起こりました
検索を町に悪いえーことが閾値を用いて実験を
ええ思いました
えー具体的には
検索音声よって
三つのグループ二分割しました
録音一つ三万
そのー
六音節以上二音節にまー
後音節以上
それぞれ
ここら閾値を用いました
えー
こちらはえー検索音声
子供結果をベースは
こう左母の実家はえー閾値を
固定した
後は言いまして
えー右側の結果は
して位置を変更して
で口が最も高い値を夫は
えー
式えー中では最も
ある私ちょっと確か五分
え七頭の場合だと
おー六本ずつでもあのー実家を
あのー
使用率
があー低い
でえー音素数はえーなっており
えー
閾値変更はして位置を変更すると
えー
四十八五えーっとある文数は
まーえー
再現するか
非常に低い結果と場所の
まー六音節以上二十二音節三四はま閾値もう殆ど変わらない
というのもあるんですがほぼ同等を持つ一方という
私音節以上に関しては
これは
最近ＡＩＤＳが
向上しました
でえー子音の結果を
見たところ
再現率は
ほぼ同等で
四十八率は向上しました
それはあー一言も
えー評語で言ったのですが
既知語の場合は
考えし
えー実は
場合でも
えー
えー課題と大体一日
と適合率を得られて
まず
連続ＤＰをおー
た場合えー
えー
えして利用
用いてる中でも
重要視した場合えー適合率が著しく伝わってしまうもんで
まー
考えると
後まーくえー間に一地域は一二は最も高い値にあるという
で月様は
えこの結果を載せました
えー
えーただし
の場合と
えーと
終戦余剰
発音する
のえー結果
送られるとまー未知語の
私と比べるとし
改善率は用いたようですが
さいえー実は
相当で
適合率は向上する
しました
えーまとめです
今回
えーどのえ直線で二つに基づくえーえその検査
性能向上させる為に
二そういうフィルターのしん
水を行ないました
えー
まー実験結果なんですが未知語セットに関しては
すフィルター処理により際にえ実は
向上しましたが
適合率は
といたしました
そこで
え検索音声
によって行なわ閾値を用い一ここで
歳リゾートそれともう一つ的効率をえーえ二三から
〇．八に向上させることができました
え七五セットに
関しては
まー
未知語と同じ手法を用いいうことです
えー未知語程ではないのですが歳二つ多いという強く適合率の例二十三から
〇．八の二
向上して
する言葉が出てきました
今後の課題といたしましては
えー短い
て最後に
感じで
まー未知語大きくはあまり落ちて分かったので
えー
短い結合に関してはえこの手法を組み合わせ一つの
考えようかと思っております
以上で発表をおります
#############################


#############################
# query = 動画のえー島ってのを場所についてえーとどこの場所に置いたら気にえー理解し易いのかについて教えてください
# rank = 1
# slide = 09-11_fix.match_word.jout.txt
# value = -4.12587054520569
#############################
えーではえー音響情報を用いた外国データーをクラスタリングというテーマで
で法政大学大学院の御発表いたします
でまず初めに
えーライフん語について説明をいたします
えーライフんますのはえーと
個人の生活や
えー体験も記録でまカメラやバイクＧＰＳ加速度方法のおーわざわざ
えー形で記録されます
を利用法としましてはえー
二四六八個に気を自動作成今日の体系というなどへの応用が期待されています
そこではない黒くなるんですがそのーデーターは説明する辞めていく為に
て多様化放題で
ま冗長というような特徴があります
えーっとまその為にま効率的な利用の為にはえー検索要約が必要となってきます
畑作り要約の為には
後インデキシングんー系まクラスタリングなどの処理が必要となってきます
えここではない部分の先行研究といたしましては
そのー生態取ったものがありましてえー
構成さ情報の御家族のじゅ
後
僕は言ってえーその時のウェブの情報をえー三ページケーキ屋でゆいう素敵だと
からまー画像検索キーを
抽出して
辺がメーターカメラの画像検索を行なうというような
システムが提案されています
えー
また外国空いてるというものを提案されておりましてまこれは携帯を
使用して
波形は計測した後位置情報夫婦の感じを行なっています
えまたえー第六画像をクラスタリングやセグメンテーションについての研究もえ過去四行なわれていまして
上の方に分かれている研究では
このく二．五二日のデーター二と三十四種類のラベルを付けまして
実験三四クラスタリングという時間的に近いデーターがおらです
クラスターに含まれ易くなる
クラスタリングを行なっていまして分水報道を改善する方法
ちょっと報告されています
また
知ら下の方の
研究ではあの一日千七百八十五枚を
それに属した画像からなるまえーっとおー
こうま二次元一にあるか
えしましたえー二時間以上
では一度電源が大きくなっているところでま一つの分割を行なっており弁当ごとのセグメンテーション方法を
行った上でまイベント事仕事の
その可能言えるとセグメンテーションを
行なうという方が
後はえーやったセグメンテーションが提案されています
でこのセグメンテーションをあのつまりある画像の
一メートル以上により
セグメント境界を求めることで行って
でまたえーと映像が契約音響情報を用いた研究もありまして
えー
シラブルの方に書いてありますのはえーまー記憶支援システムというので
えーと位置情報を音声認識の結果を
えートリガーＩＴというものです
はですが音声認識の会話ここのデーターに音声認識を掛けると
誤りを含む可能性が態度で
あー認識下顎の信頼度ものを設定することで
えユーザーのソースを矯正するというシステムが提案されて
えまたえー
音響情報を用いまして実験を自動作成をするという方法も提案されています
本研究ではえーユーザーの二を最小にする為に使用しているでは一二は
ホーム指向性マイクとＧＰＳのえー
軽く一二時間のデーターで重要かそのラベルを付けて
あるいは都心からレストラン事業といったあのー柱状況を比べて
えー
まこれはデーターをこのスペクトル情報を利用してセグメンテーションや
クラスタリングを行なっています
でまこのように
利用されているホーム教育論情報ですか
ま得られる情報にはま音声や音楽環境音のとか
あります
あのー音声からは
調べ
えー
で
あー会話の内容であるという話者情報が得られたり
の音楽
発表用の
えー
えー
はいユーザーがほぼ一定でその方っていうのは職場ということを一型ではまもしや状況が分かる
んー
でまた環境音からはそれ以外に行動っていうのは
測ると考えられまして
補正をこちらの
フランスこう
っていうことなんですけどももうそん時の方とはあのー人がやってると思います
試み色々な情報を含んでいる音響ライト六十を
情報ですが
は非常に
情緒不のこういう情報となっています
音声長はこういうえーてます上昇といいますのは
あのーお父のま含まれていない
とそうでは含まれていないというのはまー
特に
ざっと見たそうみたいな
食そうみたいなものだけしか含まれていないかショーや
ま含まれてるお父があのそれを聞いただけでは
んー何か分からない場所というのはまー
冗長性があると言えると思います
えー
これそこでえーま本研究ではまー冗長語を省きまクラスタリングを行ないました
でまたそのクラスタリングの時に使う特徴量について
子供の効果的かということについて調査をいたしました
えー
あー水泳まーマイクロホンそれぞれにおけるま一般的な問題点について説明いたします
えー
バイクがほ編集された映像はテレビ番組あのー映像とは異なって
詳しい人が一回と機械的にま安定したりとかっていう
効果がだいぶ
ま人やものはカメラの場合は行為易いということで
私の一階が不明瞭であることはあります
えまた音響情報では
販売からの距離より非常にこう思うようにばらつきがあったりするような問題があり
ここでのことを中心的には考えてまだえっとー
これ
えーえまたえークラスタリングを行なったりするけどもセグメントを単位の長さですか
えーと従来研究ではま五分程度の処理が行なわれている
姿まこれは識別をしたい環境は
二十億と言われてる長いもの
ということが前提にありましてはこの程度の
え分解能でま処理を行なうという
後になっているのですがま実際は識別をしたい
環境はまー長時間とか特徴時間八時間のものがありまして
ま用途によって異なってくると考えられます
んー
白の
えっと予測としましてはまー例えば四があ環境を
にはあるような場所は環境ようなある程度時間を
えーえーっとー
二十円と呼ば掃除がありん型の町時間のセグメント向いているのではないかと考えますが
あの音声や音楽環境音といった
そのー環境の中で三十クラスタリングを行ないたいという場合には
また時間のセグメントを使うのは一二を考えられます
まそこで本論文では短時間セグメントの場合を扱いました
あの固有短時間と言いますのはまそうしより構成内容を
話者や後
最低限話者が分かるという内容をまー
発表は
えー環境音がそのことはないか分かるというな形としてあの五八程度
僕がそれをセグメンテーションを行ないました
えーっとところこれをま基本の単位としましてま冗長部分ん全部やっクラスタリングを行なって一
えー次にえーデーター収録について説明いたします
えー収録経済は
いう場合のアルバイト
ＰＣＭの方に気が法華経るをある〇型とであのペット楽しＸという時代を
用いていは
んーずれてますけど
えーっとこの
二つをおー使いまして
七分ま四十時間を収録を行ないました
二十落ち
雇用区分はえーえー議論は〇九で人文化
でまたのおー
えーレコーダーで
記録をいたしました
残り二つを使いまして
えー消えてしまっているのですが
えーっとマイクロホンを収録期間ていうのはまだ一年にも分かることはそうされますので
そそれも一四十四が短い為に四の変化に対応できるようなあー処理を行なわなければあーえっと
考えたのであまり大量の方を使って主としました
えまたえー
母音を以下の本来
えー
とー耳に到着して使用するものですが
あーのそういう状態をまそう時間の収録は
はいユーザーの負担になると考えられるので
畑に
嫌いの私の方が気にして
収録をいたしました
この状態で日常生活音をまサンプリング周波数四十八九付ける
ヘルツ
考慮した人数が二十四人とは重要文という
このレコーダーによって違う一つ
使用した人数でえ記録を行ないました
えー
では×収録された面もそう思うは収録音声です例えば昭和の研究して教室が
えー
えー大学×ですとおーレンタルビデオテストマーケットで
えーとそこで収録された音というのは
ま先程の音声やパソコンを操作していると多分
文の音楽あのー
ゴルフ場だ車をその場記録されました
えー
心がまー幾どう影響情報から不要なセグメントのま冗長分野からセグメントを削除する
感じるするということを行ないました
誇りを
先程二つまーえーと不要なあー状況としたデーターですが
歩行者の何が含まれているあのー分からないというものは
あの非常に他の音声とは特別するの難しいので
で今回は
方法もおーセグメントについて勉強ございました
えー手法としましては三つの特徴量が閾値以下のセグメントをさてあー
方法で行ないました
えー
その三つ延ばし特徴量ですが
ねそれができたスペクトルの頭の方は
でもこれは
えー
資料八つの四日本はまースペクトル包絡いないんですが
のえスペクトル情報その楽器を持ってきた取ってきたスペクトル包絡というものですが
とこれのえーフレーム間の差分をそもそもで
とこれが文の場合ですと
千葉のように
非常にま差分が小さく思われます
んー
二もう一つの
特徴量としましてまそうあのーサブの最大値
ですねこれは瞬時に変化する音を検出するということで先程の
数法というような
音など
がまー誤っている
提示されないようにこちらの
少量を用いて
後それと後はされている
あちらの式ですが
えー予稿集の式とえとなっているのですが予稿集の式は間違いですので
白の方に訂正を思い出します
こちらの式はですねえー
繰り返しんん差分の方は
いうことで
えー詳しく差分を求めているようですがまレコーダーによって
相当の大きさが異なってしまっているので
それを正規化する為に
えー
後振幅のそのセグメント内の振幅
平均振幅によって
ま的化を行なっています
えー
んー
んー
えー
で次にえー
あのー
この前の項目の三つの特徴量を用いたのですがまそれの閾値の決定の為の
実験を行ないました
えー
四十一時間のデーターを全て
えー約五四点目と二分のところ
三枚百五十あのセグメントに分割されました
結構だからランダム二百セグメントをやり指導でえラベル付けを行ないました
その結果三十一セグメント不要なセグメントで
えー
後三十七生の四月二十セグメントはあのーセグメントでユーザーセグメントが
生まれることはないか分からないっていう船がセグメントでした
えーこれをする必要なセグメントは自分されてしまうのは実は少ないので
えー
不必要なものが提案されないように閾値を定めますと
あー結果実践とは設定できて永久セグメントはもうもうで一つセグメントはあそうだと
生まれるとか目をセグメントでした
で閾値の方なんですがえーこちら三十一グラムてまして方法が
え各特徴量
あのー
全てのセグメントを
分布になっています
で赤い方のえーばはえー不要なセグメント分布になっていて
は正規化スペクトル差分の
二十分平均の一つはそうでは
えー何か
えー正規化スペクトル差分の最大値では一酸化
政治家
振幅の平均では〇．一以下というような閾値を定めてなりました
えこの閾値を用いましてえー
別のランダムに選んだ百セグメントに対して不要なセグメントの軸実験を行ないました
でこっちはこちらセグメントもえー手動でえーラベル付けをしたところ
三十四点目と二四でそのうち一名セグメントはあのーセグメントで実習生名とは食われることはもう
二名のセグメントでした
でえーえー病気のえー
えー連接しましたえー
んでです方法
適応させましたところ
母セグメント場所されてその後六セグメントはまあのーセグメントで
えセグメントがその他
六四えーっとでした
とこの結果から
まある程度の有効性があるよと考えられます
えーこのようにしてえーま不要な
セグメントを取り除いたあの残りのセグメントに対して波形ビーズ法によるクラスタリングを行ないました
で今回は夏の特徴量を用いてクラスタリングを行ないました
えまず
二つの特徴量としての平均スペクトル包絡を
えー正規化平均スペクトル包絡うーことで
知らえー先程のまー多分
私と同じのですがまこれを
方ますの野菜は全てのスペクトル包絡をの平均して一つのものでした
えー正規化しては妹伝わっ正規化してないものと
そのー両方でクラスタリングを行ないました
でこのスペクトル包絡を用いることで分類した音同士のクラスタリングができると考えられます
でまた明日の場合ですとま正規化によって
えーまー録音機の違いによる影響受けたことができるのではないかと考えられます
えまた平均スペクトル包絡放送をそのーお和としまして特徴量の一つとして扱いました
えーえ残りの六つの特徴量は
んー
えー振幅差分の最大値と
後先程の例をえー用いた三つの特徴量です
とこれらは環境音や音声が含まれている場合に大きい値をその傾向があります
あー逆に端的に音声という場合にはちっさくなるのでま環境音と
環境音や音声とまそのー一九一二分類されると考えられます
えー
これらのまー閾値を用いまして四五のセグメントの授業を行なった
九十五えーっとークラスタリングを行ないました
パーセントにはえー
まちょっとましょうとそう含まれて大きなベルが付けられています
えー
てクラスタリングの結果ですがこちらの
表四になりましたこちらはえー適合で書いてあるのですがまーしたり
その対応するえ場所が書いてあり
えー
んー
正規化をしてはえ特徴量を用いた場合にはえーの後期の違いによる影響が強くてしまいましてあまり
でクラスタリングはできませんでした
これはま世紀から音料理関係のない特徴量を使用することで
あの解決できる問題と思われます
えー
日本一の正規化した特徴量ではまスペクトル
あの平均スペクトル包絡が
良好な
結果でした
そうですがえーこちらんー
こう見て本当にえー
工場というのは研究室のクラスターのですが
既にクラス数を読ん非常にした場合には
えこのように研究室の方は
同じ場所のクラスターがいつもできてしまうというは
えーっと利用がえーですおきました
えー
あのーしたがってまースペクトル包絡ではまー特徴量そしてま不十分であるので
他の特徴量を持っているかま他のものを組み合わせて使うということを扱う
評価と思います
えー
このえー音響情報について
僕が上に
着目してクラスタリングを行なった場合の結果こちらになります
え対応する
組まれていることはこちらのようになります
とこちら見て分かる通り
他スペインがあのー結構全くできていないという形になっています
ましたがってその
生徒の兵器やあのこちらはこう変化なんですが
まー結果はまー
えー音響情報まそれにあまり
ていないのではないかと思われます
えー
また今回スペクトル包絡なのですが
そのー
えー四千九十六
定型文を使って
含めた
えスペクトルを始めてまで
えー特徴
初めてにして
あのー
だったのですが
えー
そうすると今回はいかない可能性があるということが考えられます
えー
私がここに九っていったあー研究ででした音の識別をしていたのですがまその時は
自分ってでも
えーそれなりに識別ができていたのですが
それ風呂には含まれてる音は
かなりたったえーま色々含まれている為
えー
おー一やっぱ可能性があります
えこの結果をま従来研究の
との比較を
えー行ないました
えーっとでえまー比較したのは二．七
二の比較を行ないました
え文献ならでは
トラベルを使わない学会の二六ラベルを用いてまたの一を用いて二五クラスターには一
そこのセグメント長は一分で
はその一五クラスターの中四クラスターでえ再現率精度共に七十パーセント以上
土置いて
他のクラスではもう片方が高いかま両方が低いという結果の一
入っを本論文の手法ではまクラス数多く出すと
この図はそのクラスター二できてしまうという傾向はあります
ことを検討して考えられますのはやはりセグメント長が短いということを言わないと思います
えー
これはですねえー
同じ場所大クラスター
あー同じはそもそもセグメントでも
方法があるというあークラスたり
で分けられてしまった場合にその方としてみると実はロボットが含まれているということが
ありました
ん伝わってまー
えー
まそれが悪いんだと考えられます
えしたがってその場所をクラスタリングはまある程度一二というぐらいのまあるてると時間をセグメントを見ているのではないかと
考えられます
えまた
えー
あーそのことによって
クラスターは普通に分かれてしまったということから考えますと
閉鎖時間のセグメントというのはあのー音響情報に関するクラスタリングでは有効かもしれませんが今回用いた特徴量ではあまり有効とは言えません
えー最後に
えー
これ話すとなるのですがまマイクを扱う上で非常に重要となってくる問題についてお話しします
ぐらいグローブはですねま常に
特に音声の音声画像を
では×え収録している為にもありがとう音声や映像は取れてしまうということはあります
えー
方でまー従来の研究でもプライバシーについてのことを
カバーや使われて適用されているのですが
えーまー
とーその例としまして高い要するをする場合に関する情報の収録は可能であるという風に言われています
ですが発言内容をそのー
結局は収録してはならない
いう風に
そう言われています
えー
ま今後はそういう
を行なう為にはま一つのフレーム内を御自由ように分割してランダムに理解というような手法は
提案されていてもこれを行なうと発話内容を一つスペクトル情報が残ってるという風に言われている
またその許可を得たユーズユーザーというこういった形からのその発話内容をお水は
は非常に精度の高い話者認識が必要であるとも言われています
えまた一般的に利用
一般的神様の為に解決すべき問題として
多分水道局が必要かということと
あー誰がデーターにアクセスの各を
片方適用方法や
あー社会的な規則についてもはっきりさしていかなければならないという風に述べられています
そこ四十
まあのープライバシーを面からもまたそのー
データーの数はえー
とーデーターの処理はえーとーやっぱり音声があったりしてはもう凄い音にえ表記があるのでま音響別のう情報の処理も非常に重要になってくるという風に考えています
えー
最後にえーほぼあの種を求めます
えー
この文ではえー
音響ライブ用データーをクラスタリングを行ないました
えー事前処理としてもうセグメント付けを行ない
二月の特徴量を用いて警備クラスタリングを行ないました
えーその結果まー正規化スペクトル包絡比較的良好な結果をいるのですが
僕らと数を増やすことで余計なクラスターができてしまうという
問題がありました
ま結果特徴量としては二自分ではないかと思われます
えまた
えー過去の研究比較
との比較からまそう時間のセグメントあまそのクラスタリングにもい言って
畑からセグメントは音響情報をクラスタリングにおいている
可能性があるという風に考えられます
でまた
今回のデーター収録は倍音マイクを用いてえーとなったのですが
あのー結構そのー優先のマイクを用いると邪魔になることはありますので
ファクターを減らすには物凄いこう使うべきではないかという風に思います
でまたタイトルは初期の発達収録されるのでま複数の講義はマイクを
用いて収録したデーターの処理を行なってここでは一と思います
その方の課題としましてはまクラスタリング手法特徴量やセグメント長
あのー
×ですそのクラスタリングのうちインデックスを付ける為の手法や
これは四の問題について
考えていかなければ
んーないと思っています
以上で発表終わります
#############################


#############################
# query = 動画のえー島ってのを場所についてえーとどこの場所に置いたら気にえー理解し易いのかについて教えてください
# rank = 2
# slide = 08-05_fix.match_word.jout.txt
# value = -4.1452141990907
#############################
ええーん習ってたんだとかはまずえー
すえー本日は結局のようなタイプでえー私達が二年間音を利用しております
できたちゃんとだろうという一項内に設置してる音声はまシステムの場所を回答をあそこで収集されているえー発話でユーザーデーターの
あの予備的な分析結果というのをえー紹介させたいと思います
えー
ま最初にあの前半えー来た人の方のサービスんどういうサービスをしていくということを
月一えーせしてる環境
えーでまー
あのーあんまり詳細なことはお話しできませんが音声認識処理と
えー応答生成したり
について説明さしていただいて
でえー後半えーユーザー発話データー
えーちょうど二音の方に玄関口におがえー始まってから立つんですが
とその全ての入力については
えーユーザー入力はえー収集しておりましてまそのうちま最初の一か月分の
で人手による書き起こしと
えー話者情報ですね返したのは資料また話者に対する
え情報テーマ一人でえー付与できる範囲でえーと付与した結果がありますので
でそういったものをえー紹介して
できた感じであろうこと今二つ
同じシステムをこのあのーまー同じようなシステム役に置いているんですがまそのー
えー違いインターフェースの違いについて
えー一階の観点からそのデーターがどう違うかといったことを考えたいと思って
まーあのーま概観
まー
えーこんな感じなっておりまして
絶対にあるような一文
んーまー
がえー話題の森えーなんですがそこにえー人間もあると述べておりまして
えーまこれ配達の
え普通は時に
あーのー
パターンという対話システムとやることへ対応してももう本当に横に
並べてまユーザーが好きな方法を使ってもらうというな形でえー
ま基本的な受け付けあんまりえーっと差別のことを
そしてまたているんですが
あーのーまどういう風にどういうえー四つで動いてるかというのを
ま簡単なビデオですがいただきたいと思い
えー
んー
んー
えー
えー
えー
まー
んー
えー
えー
えー
えー
んー
んー
えー
んー
んー
んー
んーんー
んー
えー
えー
んー
んー
えー
んー
んーまこういう風にあのー
ま簡単なそういうあのー
画面ですけどもえー形をしては
テーマ
えーと私達のこの節点の先行システムとしてえー例えば部分というのがあのー開発されておりまして
そこの
てデーターを使った研究というのもあの時々発表さしていただいているので
音節からあのー御存じでのいらっしゃる方も
いるかもしれませんがまその建物んというのは
えー近くにあるやり近くにある
あーのー
コミュニティーセンター
で
えこちら
えー丸
え五年
以上に渡ってあのーやはり継続的に運用しております
では見た感じはあのーこのように
えーエージェントがあって
えー
節の形のマイクに話し掛けて
発声情報こちらで
で出力して応答音声で
えーお話を返してというえー
話でやっております
でま非常にあの大まかのあのえなんですがま音声認識部と
で応答生成部とまー二つ大きく分けますと
えーま先程もえー見ていたたいと思いますが
は自然文を用いて
あーかなりえー
えー安定に
あのー思わライブをやってきとかまいけない方とかえー雑音
の格がえー適当に
んで
えーま音声認識部では勝手に肯定的なあーそのーモデルを使って
えーまよくあのーま標準的な地方でやっておりまして
で応答生成のまー統計的なあのーやり方でできるとま統一的にできていいんですけれども
あのー実際思い
あのーわりとそのーデーター
あのーす
益々ねとかそういった問題で
あのーうユーザーの発話のデーターをえー使ってそれを
えーえ質問用例として
えー利用して
であのー
新たにえーユーザーの発話時やその質問
用例との参照によって
えー音を書いていった
えーより別の応答生成を行なっております
でまそれらのモデルやあのデーターベースを
行なうと子供別にえー用意して
てあげることで
えーま音声音声認識精度とおーおー
ま応答生成するってことを向上させると共に
あのー
まどちらのことなかっものかといったまー発展もまーえー一文を用いてできますので
えー音音声も
えー年齢差も凄い大人には
あのーえー
えー子供にはあー普段
話し掛けるとあのー父が
えーえータイトルは
で
ま見ていただくように
あーの市も一度方式というまー
最近よく受け付け案内というま目的に
ままホテルで
二回対話は残念ながらまー病気をされないだろうし
味付けもこんなということもえっと一文と方式で
あの履歴とかは使わない
それを
でここまではあのー本け先行しても例えばの
えー
で後昼間導出さして
思っているんですが
んました方も守らないように
二つのあの見て見た感じは全く違う
えーインターフェースロボットは例えばま従来の地域
を用意しているというのが
あるので
それで間違いをえー何とか
ん効果的に生かそうという風にえー考えておりまして
でもう一つの
まー特徴としては
べきの環境
まー大体測定すると六十二重ぐらい
二月になって
まそこでの
辞書事件がま可能である
でえー現在はあーそのロボットの方もあのー対話システムの北の方も
おー接話マイクに声であのー話し掛けてあのーただ日本でして
あのー話し掛けても載っているんですがまそれは
ま将来的には
後一つの
二ましたり
でそうするとまたあのー
四五四
ついてなあのー評価ができるんだろう
ではないかと思います
えっと負の部分との比較で言いますと
相手の獲得前にいて
んで
えー例えば文があのー設定してある
えー
地名データーですがえー二層とま非常に
表現下の場所ですのでま細かい違いが
あります
でま海感じた
えー
駅の方も
あのー動いてる駅が動いてる間は
二十一回読んでずっと
えー
場合にえー毎日やっております
．んんでえーと情報案内ま具体的なサービス
えー
あのー
の二つのえー
二つのま方式であのお互いに講義内容というのことで取りまして
ままずあのＮグラムによるま連続音声認識結果
とー
あのー先程お話しさ
共に用例
えーデーターベースと
参照して
んー
それにえー対応する方法が一つ一
えー
特定タスクの為にはあの手で
文法記述して
でそれによってま認識して
えー音を書いといった二つの
あのー枠組みを用意しておりまして
ま最終的なそのうちあのーどちらか
あー適切だと思ってる方の
えー
認識結果を用いてえー音を書いてるんですが
まそれでの為にちょっと若干を娯楽があるような形で
あのー
起きないや
風にしており
その言葉の数まこれはまーまこのえー
あーの軽減どこに基づいて作っているものなんですが
お喋りとかまたその何が好きなのか
あーのー
踏まえての説明川周辺
ですとかそういったことを忘れてま種類としては三百
それ
でその応用しておりまして
えー
まこちらの質問よるのかも
あーのーデーターベースを大きくしていたりも変わってく訳ですけど
ん現在のこの
まず高いについてはもう
の方もですね一応ずっとそのくらいの文数の
つまりこれをえー
用いております
んで
廃棄にありますのであのー
駅の
当然検索ファンの理解あのいとこが
えーしてあげれば非常にまーあのー実用的なシステムうー
えーなる訳ですけどあのー
えーっとそれのまー用例の手順ですま非常にされてありますから
あーのー文法で解析近くの
えー例えばまーあまり御三丁目とかそういったものを
えー
って最も
文法で記述することで
あのー色んな
んー
ユーザーの日に対応するといった
としてます最も郵送さ
ですねあのー
えー
記憶戻ってとか
えー
えー
次に一対二ってまそういったほぼ文法でえ採用して
んでまーま今の
サービス内容のまとめですが
ま例えば船もあの簡単なところをまー
あの文法書いていたんですけどもこの二としての本格的に無料で一を
もう始めたという
えー
んーとー
ことにやっと
でえーっと音声認識部
なんですが
まこれもまーあのー
もし基本的なも
古いいー音声区間的と後二六時間と
歩くこともの閾値で
えーやった後に
んーま音声認識として
えー
応答生成には出す訳ですけどまそれとまあの並行して
んーちょっとん違う
まＧＭＭはま大人用の
音声モデルと子供用のモデルとは第二対一と二つ音が用意された
んで
えー認識の方は
あのー先程言いましてどうにも行ない音程思いをまー用意してあるというのと
あの文法ベースのものと
えーと五グラムですねものと思いをしてる
でここで結局まー
四つの処理があるんで
で
ま最適な御と言うとを見て
もうどれが一番
あのー
俳優座の質問をちゃんと
適切に反映してるかというのをま考えてま応答生成部に私は
えー
で応答生成部
まー
んでえーまー
大人子供ができ結果と二ステップのまー
えー貰える訳ですが
まー文法ベースの場合は
ま今日とても丸二したがって
ありまして
で被験者の場合は
このＮグラムによりチケットの場合は
あのー先程質問料で
もう携帯その
えー
のマッチング受けた数形態素単位で
えー
ま全体中で
え含まれている形態素の個数
えー
あの用例の本当につ結果の方で
まー低い方
の一個
を見るといった形でま全て行列音声に対して
そのスコア言語スコアを出してま対応する
一番高い高いスコアが出た
つまりに対する対応する夫も返すという
出すということをしており
んで
でまー私達とのユーザー発話データーベースをまー
たった一分の二三とてる訳ですけど
まその前にま立場の文
んでえー五年
えーと五年
が
えー運用しておりますので
文をしておりましてまその中で他については書き起こし
いう場所情報のラベルを
で付与したデーターがあります
で
方達だろうこの最初の四の時も
過去のデーターを彼が作ったモデルやえー四用例データーベースなど
行為に利用した訳ですけど
できればやっぱり駅の側から
まずまま評価としても見て認識率がえーとーももっと世界一の
でまたえー作成するえー
評価している訳ですがまーデーター
まシステムを置いてあるじゃ本当のあのー実際の場所のデーター
でえー作ったまま本当はやっぱりいいんじゃないかとも思いますけれども
さすがに年間分の書き起こしこう新たなデーターではその非常に
あのー該当数の掛かる訳で
で
まー従来のデーターが
どのくらい
えー
応用できるか
で従来のデーターに対して
新しいデーターはこうどのぐらい
だけあの書き起こしデーター
あー十分実用に
えーん実用的な
でモデル化できるとえーっとまーそういった
あーのー
ポータビリティーの評価
などという形で
あーのー新しいデーター
あって
えー
言っても
えー
頭近い状態数に
システムにするよって止まりますんで
ここのデーターの
同様のデーターとして二十対
えー入力データーや残響まーあのー
んーこれから接話型でのパン作り推薦の友達であの問題なります大学出たなと思って
んー
で
多数がモデルやデーターベースをえー改善していく
というのもありましたと
えーしていくことも
てまそういった研究はまあのーあまり良くて参考文献です掛けてるようなところで
あのーお勧めできているんですが
でまここで
は
の元と大きい話でそのデーターをあのー分析した結果というのを見ていたの方
思います
で
で
話し手のインターフェースとしてまロボットと
四事例でまたあのーある意味そのえーエージェントというのがある訳ですので
まそれを
えー
そういうユーザー
その
えーえ違いがあったり
もう発話内容に違いがあるとあるいはない
というのをえーと見て
えー行きました
うまく適用
まこの二つのデーターこれは
判定についてはまこれからですが
この二つのデーターについて
発話のえーっとユーザーのユーザーその
間違いをま見てみて
んーまー
あのー音声対話システムを新たに作る時にま何らかの視点
んでのようなものが入れていれば×一まーないと
で入手デバイスまーあのー違い
もう改めて音がしますと
後父ちゃんていうのは
二．七分と
同じような
テーマ
同じえーシステムの提唱しましてまーすー
×というないというまそういう事情で八日出てすぐにしているという
パセリの違いなんですがま下の子
の方は
で元々ま今ロボット非常にあの盛んな
盛んになっておりますので
これがロボットに
話し掛けるについても
がま要求されるという思いますんでま
こういった
えー
ただあのー
んーいちいちこれじゃったら火を三次元化したロボットを作りまして
えー
まそのインターフェースとしております
でこの時もうあの人に対して話し掛けるような感じでえー介護を
連れていきたいと思いますので
まーすー父のこれデバイスまーあのー外す
いう風にしました
でえーっと
そしてま大きく大きな違い
その後にあのー二通りの違いなんですが
ってとは別にあの×がなくなることによって
プラザの操作というのが来てあのーロボットの場合は音声でしかも的なそういった
ところがまーえー
そこも海と
んでえーシステム入力データーベース
まー全ての
えー入力データーはま波形データーして
んー
応答生成と理解
もう一ファイルどこを一発話間そしてえー
んー
引っ越しを書いてあります
んで
ま発話データーを
二つ音のみの入力もあの全て
えー
収録しております
すいユーザー書き起こしユーザー発話データーの方は
あのー
そいで収録さ全てのデーターに関しましてま一か月たんですけども
んー
人とさんがえーっと音声で書き起こしが
後あのー
それにまー
一つえー速さともかく
もう
発音したり
えーしましてそういう
いたしましてまそれも書き起こしテキストとして
えー整理しております
んで
後はまこの三つは
んー
えー
つまり若干そのー
んー町主観主観的なものも入るのですが
んーそのー
えー発話がシステムのお父になりました
食情報と
話者が
えー
年齢層こともま八時から
元のあのー高齢者の程度の年齢とか
ということと
例えば男性女性
であるかというのますま主観によって付与しており
するとえー先程のような用例一の
えー
えー
えー
えーをよりでしてえー使って出す音のどれが
適切な
えー回答がてると
まそれ以外の文法で何をしてる
えータスクのうちどれが
えー適正であるか
というのはえー
情報網利用しており
でえーとシステム
あーえーっとと他のシステム入力なんですが
んー
まこれはあの二者の毎月お父も
えー入力数で
のことも
ま一度ＧＭＭによる識別結果
がえーの子供との
えーっと
一対一場合
またとんという風に
後まー
んで
え短い入力と言うか
風にえー二三タイプ分類しているのですが
ま基本的にあのこれは盛んで
で終わ下の子なんですが
んーほぼ下顎の方があのー
パソコン時代なってる時代は
ほぼ同じような
あのー母
よく相関を取っています
ダムでえー
んあのーち適切とかあのーそういったものに影響される
あーのー
このこのみたいなまーどうやら
こないだＣというでこれが大体お
えーちょっと見ていこうかと
持っている
でえーっとちょうど補足なんですが
で先程えーとこちらのデーターというのはあのーＧＭＭによる内語識別結果
でまどの程度精度があるかという
こともあるんですことがあるんですが
五十実用上は
えーとこれは
あーの実際のユーザーの発話
ま幼稚なことをまでやはりお力をえー高齢者の
についてあのー自動識別した
結果が
あのー
子供になっているかどうやってるかと言うと
えー図なんですがま方法
あのー
んま奇麗に
えー結果の施設結果でも
まいうあのー自分使える上にあるというのがえー見ていただけるかと
えーと背景雑音
あのー際してえーとす
ＩＴというの雑音として
あのー外にあるのでまーハゼとかだから
歳のことからま昼間は記号とかま色々
後ですが
えー
えー
ま結果から言いますとその
室内の雑音で作った一年目で後野菜というのも今もう殆ど
この問題
がもない訳ですが
ん外に置くと
あーのー家庭というのはもっとあー三十六ま二十秒ぐらい
いう分かってえー吹き続けて
それがずっとトリガーが入った状態なったりするというのは
えーまー外で見をする
えー
んあのー
ま対応すべき問題として
あります
ただそれ以外は
あーの文字レベルで
んであのー一年生名で棄却され
いうことはあーありました
んでえー冬が発話
データーの比較なんですが
もうこれはまー
えー人による発話の年齢ともえーシステムには違いと
えー全部あの
違い
内訳の違い
えー質問内容の大きな内訳
表の内訳というのを見ていたタイプ
えー年齢層なんですが
そこであのー
反応データーをどうもあのー
んノイズが入ってるようなえーとこれ無視していただければと思うんですが
えー
ちょっとちゃんについてはえー
複数こちらがあったとでいつ仕事のえー子供を
で幼児からえー高齢者までの
えー
水なんですが
二単語についてはまー殆どま先程見ていただけていたのと同じような
性格が
えー
ちょうどダブル凄いなるような感じで
んーやはり発話の方も入っていると
被験者の方なんですがま詳しい話は
当時
できないんですが
情勢
えーっと
んー米が
えー
えー
データー子供したが大人で
えー三が下の方は大学だったのですが
んー
んー黒いものが女性
それからえ相手との
で
まー見ていただけるとお分かりかと思いますが下の方の方が
なぜか女性がえー
使用してる人は
やっぱりトマトとそれだけするのもあり得ないとまー
それ結果はえー
でえーっと子供の
その前の内訳
こちら北の方でこちらはし方なんですが
子供はまその後建物との挨拶プロフィール
どういうことが好きだとかそういったことで
えー水がされてまして
殆ど差がないという早く何とも勿論
とー女がないなんですがもう大人になりますと
えー
大人の方はえー
例えば
で
えー一素性はえー情報を何かないなとまちゃんとした
情報システムとしてとてもしているのではないかという風に
と思われます
でちょっとあのーちょうど介護も違いましてあのー方法としてしまいますが
できたちゃんと娘についてえ聴覚紹介させていただくと共に
でデーターベースについてえー簡単なえー一対応さしていただきました
ここのこの三頭が
あまり頭に思わする予定ですので
そのデーターの分析をえーしていきたいと思い
んーと
えー
#############################


#############################
# query = 言葉を検索する時にえー父話すように話し言葉で検索するシステムを教えてください
# rank = 1
# slide = 08-04_fix.match_word.jout.txt
# value = -2.31873886560951
#############################
可能性対話システムと質問応答システムの上系による質問応答対話システムを実現と
えー対話システムえ話者四型と題しまして
えー私技術科学大学のえー解き方が発表さしていただきます
あるそうです
えー近年えー人間とコンピューターのコミュニケーションというのはえーとても注目されてましてえーその中で人間にとって自然な振る舞いをするシステムというのはえー一つ注目を集めています
えーそういうそのようなえーっと人間にとって自然な振る舞いという風なものに注目しますと
えー一対例えばマルチ文対話システムの解明まして後であるとかえ下とシステムえー
九一つが挙げられると思って
えーこちらのえっと有名前システムというのはえー音声対話やえー辞書もまー声帯はが可能となっています
えーこれはえーただ単にえ音声だけを用いた対話よりも
えー舌下を用いるであるとか
まーそういう風な色々な情報を使いますので
で人間と例えば直感的なコミュニケーションは取れます
テーマ二
えその当日についてはどうかと言いますと
えー
一般のやっぱりえー情報検索システムであれば
です
えー入力として与えられるものは
クエリーと呼ばれますのでつまりこれ自然言語とは限らない
でしかもえーまーうーであるとパイプであるとかの検索エンジンを使って出てくるものは
やはりえー回答そのものではなく
出てくる訳はえー回答を含んでいるであろう文章入ってきてしまう
でそれはやはり人間にとっては使いにくいものですので
えーその点をえー自然言語の質問文を入力しそして回答そのものを対してくれるという質問応答システムを
え直接的なやり方でえーやり取りができますので人ととても普通えーっとー
扱い易いシステムである
という
でここでえーまた千人我々がやろうとすることはえこの有名なシステムというシステムを変形させたシステムを作るというところです
えーこれによって得られるを受けというものはえーま
旧システムというの機能を持っていますので
えーその音を
こう
えー対話的におーこのシステム二つ目の
ま便宜上をおー一つの音対話システムと変化さしていただきますが
えこれはえー年前システムと旧システムがそれぞれ一二と優しい
えー
インターフェースをどう思っていますので
ま人にとって自然なコミュニケーションはこれのシステムとなると
えそしてえーと九例っていうのも
単純に競馬一文という風に変えることもできてしまうんですけども
でこれ二名のシステムの会話というものを付与することでえ対話的なスロットを行なえるのではない
という風な方法であります
んでえーそしてえーっとまー構築するだけではなくえーこれは実際にどのような方法昔増えるということも確認さ
日本語五名のシステムにはえー我々みたいにですね開発してきましたがえー方言を使います
えーただしえーと有名なシステムと言いえーと今回はえー音声対話を
平面いたしますのでま音声対話システムとして利用します
えまたえー休日の方はえー先程の空間そのー
え結論で公開されて今する際にえーその三でシステムを使わしていただきました
がえー五年前システムというものそういうものというのをえーま改めて説明さしただけです
定年前システムの有名前とはえーま一本インターラクションも訳でして
えーっと複数の間隔を組み合わせをこの対話ということもできます
で先程も言います通りえ言葉仕草表層の道を混ぜてえー対話を行なうことができる
で人間としては中学二に怒られていることなんですけれども
もうこれを実践するコンピューターで実現するのはなかなか難しい
えー例えば
えーっとまどこかでえーまマクドナルドとかでえー幅があった使おうとした場合
えー
店員さんに幅を三個くださいって言ってもいいですけど
でもそうするか歌いメニューがあるんであれば
えハンバーガーの図をさしてこれを二個くださいっていう風にはですね
えーつまりこのですからその今みたいに処理がぱっと出てくるんでえーとーまーこの二種類に対して
えーコンピューターがそれぞれ対応しなくてはならない
でそういう風な喉頭化音えーそういう風なものを
え実現するシステムをいっぱい見え見えましすると呼ばれます
えー
あー実際にま人間とコンピューター
と言われた
でそういう風の心をするとえー私対応のニュース力が必要となります
でま三点目はえーシステムを実現できたのであればそのシステムはパスタ用のニュース入出力が可能であると言えます
うそして
えーこの夢はシステムえー三竹で作ってきたと言ったんですけどもえー我々の使ってきた方法の提案法瓶というシステムは
えーフロントエンドとか言わせることに法政で構成されているえーシステムです
過去の構成はこのようなえーメリットを持っているかと言いますと
えーフロントエンドをえープラットホームごとにえー実装すし直すことで
えー
で
生地を
えー移植性がとても高いシステムであるという
で実際に
えーフロントエンドは人間と対話を行ないえそして対話制御文を絶対問診交換するという風な構成になっていまして
えそしてこの対話制御というものはえー身体の四者におい見なすことができましてえこれによって書いてシステムと連携したえー前アプリケーションが実現できます
まこのようなえー
で空き地になっているんですけども
で実際にえー
えー
本当にもう見てもらえれば分かる通りえー入力とする空間的にフロントエンド
えー
何とします
でそして入力されたデーターは全てえーこの対話制御文となりましてでそこでえー解釈が行なわれます
でえーます力
に関してもえー出力内容を決定するのやはり対話制御部で
で結局のところえー
ユーザーに伝えることんユーザーから受け取る方法というものは
えー全て海の制御文て解釈二三
となります
でそして
えー
外部のシステムの四十八つもんーどうもえー対話制御
えーそしてまたそのー実際にどのような対話を比べて
というものをえーっと対話したりまこれももう一つ一するんですけども
でそれも帰ると冷たさは体を落とし
えー対話制御で
実際に実行させる
まつまりフロントエンドというものさえ
とにかく作ってしまえばその場所からでもえーレベルを介してえー
つまり仕事にたくさんのあのーこの
という風になって今
えーまここまででえーメンバーシステムの場合終わりまして
でそうし改めて簡単に共有性について説明を軽くさしていただきたいと思います
客観的にはえー情報検索システムとシステムであるという風に見えてしまうと思うんですけども
後何より一大きいのは自然言語を入力できることとそして回答そのものは帰ってくるとえー
えー
まそれを単語としてんのはえーこの構成してる三文の中のえーと一番初めますの解析
えー最後の回答抽出
もうえーっとーま一般的にこう子供が疲れているかなっていうぐらいでまー
入る大体の質問をえー指定しました
え設計システムでは
ま見て構成になってると思いますが
その中の部分で下えーっと情報検索を行ないそして
深い第一点第一の数を解析と回答抽出で
人間に優しい
えーインターフェースを提供するという可能性があります
えー
実際に使わせていただいたえーと体に提唱されるシステムで勉強って言ってたのせていただきます
結構その文システムはえー
えーその上位個を書いてありましてえーと四試合にアクセス方法で
えー
ま使うことができます
て入力には質問文を用いましてえー自然言語で入力させることができ
で素性必要の設問タイプまーえーと意味カテゴリーと捉えて
いいと思いますけども
とそれをすえー指定することもできます
え初期状態はしてましもんですけども
えーま指定しないというものを
えー除いてあその決勝
これ青少年ということというのも九種類
えそしてもう七生をしなかった場合は
えーその人から自動的に認識して
増えるというシステムです
んで実際にそのバックグラウンド使われてるものはえーっと新聞記事数一年結構聞い高校生であると思いますがえそれとニュース記事こちらの方はセグメントのものとなっています
で色々検討する際にはえっとー実際に新聞記事の方使わせていただいてえー最終的にんえーニュース記事に対応したシステムをこうえー
えー辞めましすると組み合わせた
えーシステムを構築するという風にまー
えー統制を取ってまいりました
でこう
話すの強くというものは
ま普通の単語だけを変えその一つのえシステムであるだろうという風に言われてしまいそうなんですけども
あ実際にちょっと他のシステムと連携させるという点でえーっと色々町を提供して
くれています
え一つは
えー
質問タイプをえー指定しなかった場合
えーその分
からどのような
カテゴリーをえー認識ししたのか
というもの
えそして
えーっとー回答もそういう語彙については
えー
えー解答の単語そしてその前後の表現そして複数すぐ分かりますでそうすこうものを
元々あったしもう少しえースコアが提供されます
で実際にこのえー
え名のシステムと旧システムをどのようにえー連結
連携させるという話なんですけれども
えーまこの夢まシステムから提案方言の方はＣＧＩを呼び出し気に思っていてすそう生活定型の方はＣＧＩとして提供されている
発話えこの二つを単純に結び付けてしまいないんですけれども
を
ただ一つ二を一つほぼその問題あります
実際ＭＬ倍システムの方はえー町プラットホームでえー生成の力方もあっていますが
対称性が高いという
反面えーあまり
二つの処理を行ないます
えーですのでこの第二回調査員システムの
視力が三四ちょっと複雑なものだったとしたら
えー上はシステムではちょっとよあー使えないという風元となってしまいます
でそれで実際にえーカイ二曲を選出することのものかと言いますと
えーま基本的にえーっと人が見てえーと解釈できるようなもの
発話コンピューターで直接う解釈するの難しいものとなっています
えーすですので
え実際にそれのえー一九円もすることをＸＭＬ形式の変化をする政治家の方はえー実装しましてえこの装置としてえーっと一九えーっとー
えーんー
空手はこういうも連携させるという風な
手法というえー手段を取りました
えもう一つの問題に
えー処理速度問題があります
で実際にどんどんどんどんをえー速くなってコンピューター速くなっていってますし
えーまそれに応じて質問をおーもっと早くなっているんですけれども
あー実際にはかなり覚え処理をして
暮らしたいますので
えー
実際に対話にえー組み込む起こした場合にはえーっとその処理速度の問題が出てしまいます
でこれをえーＸＭＬとのすそのーその後一に合宿へ登ってまして二法則を図りました
で実際にえー構築したものはもうむ始めます
えーっとー
一番んーま音声を説明しますと一番以来のユーザーがえー質問文音声会社テキストでえーフロントエンドに対し
えー入力します
そして二十二タイプでは
えーっとーここではえー
事例を使ったんーんー
えーっとん実際に計算を行なっていますので
えフロントエンドとの対話制御では
その人のテキストの形で構成されの
んーそして対話制御文はえーと
ＸＭＬとのこうもうこうしていて一定にえー質問をえーいつも思う問い合わせを行ないます
でそして一型の方でえーっとー得られた相撲というえー
実際に帰ってくる回答というのはま一ませんしあるんです見るのもちょっと小さいですけれども
まＨＴＭＬに入ってても
んでえーそれをＸＭＬからは都合の受け取って
えー実際えーＸＭＬ形式に変換しそしてありませんよねでえーＸＭＬ形式の
えー
二本の結果を受けて
でそしてこの対話制御部はえー
こっちの方で想定したあるいはシナリオに沿って例えば一番上のものだけをえユーザーにします
やっぱそういうまそれを行なっていても
実際にそのような値をこのように進めていくかという話なんですけれども
と今回は簡単にえー変形させるという風なことをまず第一目標でしたのでとても形のものになっています
でまーえープログラムを開始するとえーまず質問文話者一日だけを行ないえユーザーの下の受け付けます
えー受け付けたあ質問文はそのー体中に問い合わせを行ない
えーそしてえーその結果帰ってきたものは
えーもし回答履歴にある回答は含まれています
ならば削除し
で後輩と力というのは後でもう一つ示しますがえー障害児には全くありませんのでまー
一番初めの場合は一九八入ってた個体のそのま模擬ユーザーに示しております
んー実際にこの回答方法も仕事をどのように行なっていたと言うと
えー
回答丸々です
という風に形に答えてしまいます
でもしこれがえーっと先程着いてから帰ってきたスポーツをそうしましてもし第一項が低いようならば下タイプを指定してください
コンテキストスコアが必要なのはすもう御理解ください
ソース行低い音がもう初めからやり直した方がいいです
というなことをする上するようにしています
でえーこのようなえー
指定しえーシステムからの発話はえーシステムからのプロット受け取っ
えーフルートをえー受け取り
ユーザーがどのような
方法ホストというのは次の
えまずここで一つですもううえー回答を一つ示されていますのでままず示された答えを回答の地域に追加する
でえーまーそれはシステムの処理ですけれども
えそして実際にユーザーが何をしたいのか
えー
まず何かえー回答示されてそれがその回答で満足したのかそれともう
それで満足しなさいとの
砂糖はやはりえーとシステムに言われた通りにえー質問文とを入力してどうするか
という風なもので分岐します
え大変満足した場合はもうそのもうありがとうございましたシステム発話してえ実際にその二つか種類タイトルにもなるのであれば別の方法を表示
そして見るこそ空であればもうシステム応答少子化してしまう
という風な形のものに持っています
でこの大量に沿って実際に
えー構築したシステムをえーでもそれその六．四三つあのーそれとも
えー
えー
んー
んー
んー
えー
あーてこれでえー操作の方はまー属しましたのですもう父は終了となります
で若干ちょっとノイズとこう来て聞き取りに買ったかもしれませんですとした結果大切です
殆どそのえー質問文で申し訳ないんですけども
で一文字の質問は問診票が係った事件は何ですかと言えます
でえー実際にシステムの問い合わせでえー一つ上に上がってきた者があーうえー各二次元です
えーですがえー質問文を言い替えることでより良い
回答が得られるかもしれませんでも四つ
えつまりこれはえーコンテキストスコアが低かったという方法を用いまして
で実際にもしかするとここで何か質問文理解辺もうちょっと様子をすると
ハイパス目でいい答えがあーかもしれません
端点ちょっとこう発見し事件というものも舌を中にえーかかわってる事件なんですけれども
本日はちょっとえーとー
質問者は
この個体を本当に正しいかどうか分からないもうこちらもあったんじゃないかというな感じで
えーま正当かどうかは別としてまずこちら
ですのでまここで
違いと違うと思います
という風に発話しています
でそしてんそれでえーと第一の答えはまー既に答えていますので問題にえ性を当然視仮説の意識ですで後ですか
あーそういうそういう風な事件もあったなということでユーザーは満足して入っ
で最後にまー
一応そのんーどういう風なことを決定したというなことをえーこのやり取り地元のホテルも
最後に表示して終わります
言わばこのニュース記事を持つ方のですね
えそしてえー新聞記事を使った方でもえ同じようなシステムを構築しました
えーこちらの方もえーっとーまだりも対応と言うか
えー
後それに答えたものをえーあーはいそうです分かりましたと答えてるだけですのでまあまり変わりはないですけどもま音声システムの構築でき
えこのようなえーっとおーシステムを構築したんですけども
と実際にこの質問をおー対話的に行ってその後もう気が得られるだろうかって考えたんですけどもえー実際にこのえーユーザーが何も総合満足できなかった時にえー質問文を実際本当に変えてしまう例えば口語表現から文法表現に極端に書いてしまうのを行なった場合
テーマは実践ちょっと正答率が上がる
えー正答率があると今使わえーと正答見つけることはできるケースが幾つか確認されました
でその上の言い替えというものえま実際にも有効であるということ示されているんですけども
あ実際に機械的にどのどれぐらいえーっと
快適に書い行って
どれくらい有効なのかなという風なものを検証しました
最も簡単なものですけれどもえーと四類五八六回でまた複合語の生成というものを行なってみました
で実際にえーっと正答率の構造にえーと従来研究というのはえー質問を構成する傾向進められてると思うんですけども
橋本代表的なものの一つにえー意味カテゴリーの細分化というものです
でこれは四つこれはま正答率というのはえー適合率報道させるタイプで二回目そのー衛生統一ほーまこれもとても有効に働くであろうと考えられます
えしかしえー質問を言い替えた場合どのの異なること言うと
えーどちらかと言うとどういう両方の回答方法を取得する方法この本を目的になりますので
あー適合率ではなく再現率方法とさせてるの方向にえー求めます
でえーと実際にえーと形態素解析悪いとしてもおー使いえー機械的にいー帰った結果です
えー
んえーまそこそれぞれ三つ試したんですけれどもえーそその質問文がえーっとーサンプルが全部違うんですけども
えーと同様類を用いた言い替えはえー三十五その二回えー一回の中で一回はしなかったのに一対一九餌だけを使って却ってその個体の中に生徒はあるかどうかを判断した結果が
えーもう一の二十パーセント
でこれに対しえーっと英語を英語に一回行ったケースが
え正答率七十五四三パーセント結果となったと思います
えそしてえー複合語の生成これはあのー
方に質問文を形態素解析して上昇取って
でまー一つの単語に求めてしまおうというだけのものですけども
毎回しなかった場合は四十四パーセント
えー
この言い替えを行なった結果
えーセット一の五十二パーセントんー
で同じえーすえー
この一二三同じえー質問もえー手法を使ったんですけども
で今度あのー
快適にする前右手人間にやらしてみたらどうなるとをやった結果が正答率六十八パーセント
ポケット言い替えというのは
かなり有効に働くものであるということが確認されました
でただ問題がありまして
えー機械的にえー行なった場合えーと言語というんというもの
えーコストというものを使うと
えーまー
飛行機方法一個一事項とか色々まー
分類はあるんですけども
色々なもの星をすると
とーその単語にえー七十個近くのそういう方は
それでもケースがありまして
場合によっておるとその質問文をえーま古いことをここに書いていくと軽く百方法てしまうようなえーつまり
えまたえ複合語の生成の方はえー実践展開される方数は少ないんですけれども
えーん
実際ちょっとどこを見てみると引用されている記事が変わらないまこれはすもうこうシステム
のえー特性でもあるかもしれませんが
あー一般的検索結果をあまり変わらないような感じになって
えーただえー
えー
一型がファイルでそうであるのに対し言い替えを行なうことによってま幾つかの
えー
別の
回答方法が得られるという意味では
ま一応方法をえー正答率は構造しすることが言えます
えー
ここまでの化粧はえー自殺しえ新聞をコーパスとして扱ったものでしてえ実際にこれを音声認識したえーコーパスを使ったらどうなるか
という風なものをやってみると
日本のあのー数学の
えっとこのま下のし方をしてもえー
ってコーパスの中に生徒はなかったものというのもえー含まれてると思うんですけども
ま理解なしの場合二十七パーセント言い替え歩いて
一九パーセント
えー
文の数から言ってしまえだったら体に一言だけえー正答が導かれたという
あそこ残念な結果になってしまいました
まこれの原因としては学校もその規模の問題がまず一つと考えられます
え新聞をコーパスとした場合は一一年分の記事がありましたが
えーニュース記事ニュースの場合はえーと
数字の上では一年発話をもう少し少なかったと思うんですけども
あー二す二セットとそれだけの差はありますので
まーその中での正答率というものはあなたのあるものではないかという本があります
でもう一つは質問えー質問文を設定して二つありましてえー発話中のものではないと言えます
の下にあります
でまー
さて置きえー見ましするというシステムの連携により人間としてのをするシステムを構築できました
あー直感的なシステムそもそもえー自然な対話もある程度続けてきたと思っています
えしかし
まーえーより自然な対話シナリオの設計まつまりユーザーのえーシステム発話をもう少し見ししてみたりするのか
後は
えテキストのおーシステム切り替えて扱うようのことができればもう少しえー
実用的なシステムとしてえー決定してるのではないかなという
本発表は以上になります
えーとですね
#############################


#############################
# query = 言葉を検索する時にえー父話すように話し言葉で検索するシステムを教えてください
# rank = 2
# slide = 07-04_fix.match_word.jout.txt
# value = -2.40942596009203
#############################
でそれでは一恒常法を用いた疑似学習支援システムについて発表させていただきますとえー舌内の理由です
存在でしたね始末
えまず研究背景ですけれども
えー近年抗議の為の
で後氷の復習学習の為に二ランニングがえー用いられてきていますけれども
その後利用復習する際には
こう日々を取っ方でしたらどう時させた講演再現システム面白いことが一般的になっています
てしかしこれはいい内部の問題なんですけれどもとしてもそのコンピューターの前一人で勉強してる際には
で効率とは二つますので近所お母や集中力を持つことが難しいといった問題が挙げられます
えー例えば
って九十分からがえー方位ビデオを
あのずっとおーま面から見ているのはまー大変ですしえー勿論その集中力があー
消えてしまうと今度は容易にえー考えられます
ってですので
で生計をま学習してもらうのではなく学習者があのー自分が
で理解できてなかった部分ですとか日の話者数を重点的に学習歴ような
個別単位を型のえ学習支援が必要だと考えられます
でそこで本研究の目的ですけれども
えー学生の一恒常法を用いた辞書学習支援システムを発します
で通常の公民再現しても別に
えー学習学生からして〇一九されました実行情報により
で個人の状況に応じたえー四十学習して予定としこれにより学習の効率化を考えます
えー関連研究としてえー二つありました
でこれらのえー研究は
えー個別対応させる為のえー学習支援システムですけれども
えーこれを実現する為に学生の学習操作の主観的関係や
で面明日えぺしたり聞いデーターを用いています
でしかしながら
えーなぜそのおー学生がその状況になったのか例えばまー頭が止まってるですとかずっとその六ページ歩いていると
どうせそのような状況になったなということまでえ分析することは難しいですので
えーまそれだけではなく長く性能ま色んな受講してる時の状況のデーターをもう一ことより
えーえ学生に
各学生に定義した支援法というのを考えます
で本システムの全体像ですけれども
えー大きく分けまして二つ挙げられます
でまず方言集
のえーには終わらないえ例ですとえシステムを用います
そしてえー日本が終わって復習をする歳
で本
本システムの辞書学習時に設定しても
でも
まずあの攻撃中の場合えー〇システムについて御説明します
えこれはあの教室を持つとえー声道が持つとまず分かれて
後にえー対話をえー先生の学生もコンピューターの前に
えーここで進めていく形ですけれども
えー
後に
先生が用いるつらいのがえ表示されます
でま一回えー機能がありそしてえーこのスライドに書き込む為のでしたねうん
えー機能がある
そしてこちらには学生からの質問あったらそのーそれに対する回答する機能ですとか
まこちらに
取りづらいんですけどもタイトルと
で括弧面ロボットの学生の前に帰ると一つ重要な機能
次に各成果物の方です
えー
ここにえー先生が用いてるスライド
が連続的に表示されます
でそして
で順々に質問する為の機能がありまして
でこれは例えば
テーマ一日一することもできるんですけども
えーケプストラム分析えー水でよく分からないといった場合にこれをトラックして初めて
言葉ですかもう一度説明してるということますとま二同時にま簡単に
えーとこのホームに入るような
でちょっとさっきのは
熱で
でこの質問内容なんですけれどもえー先生にも勿論あの食べされるんですが学生も見ることができます
えーですのでえーこの誰かがその札のに対して自分もまーその質問をしたいと言った場合
この同様保つことでえーそれがやっぱり
二十表示されます
でそして
こちらなんですけれども
えーま
学生がまースライドを見て先生の授業
あの話を聞いてるとえーまよく分からない場合
その
分からないとか後えー今は学習を手に入ってますけども
理解ま類似類似してないというのをまー合成用のボタンを用意されています
これによってその理解となるものを計算しています
で次にえ今なえー例図を用いましてえー教材先生学生予想されるよう取得します
で次に
えー一本情報として
先生のデーターというま正解情報を用います
これはあのー実実験したえー風景なんですけれども
の先生が先程はえ例図を用いて
またこの成人名データーをし特性の為のま特別な試合に座って学生からの絶対情報を取得します
でこれらのデーターを用いて二者学習支援システム
で後
でえーその二者学習支援システムについて御説明します
って言ったんですがまこのようなえー画面になっている
構成になっています
でもう二をしてる日のビデオえっとー仮説の数がえーちょっとお巻き込まれたでも
え表示されます
でそして
でこちらですけれども
これはあのー
先程成人のデーターとすると言いましたけどもとにかく戦争を分析してえー非常にさせます
これがあの引用訳で性能は二回低いまーどちらでもない計算するには出て
えー音声データーとして表示されて
そしてなって実この
ま学生の情報を用いると
ま学生が見ることによりえーアクセントないけど買った場所ってのはその方に教えてないってのが尺度ですので
その
木の形かかわらず優先的にえー学習することができます
えそしてえこちら二十五情報として表示されているのが同じよう中にえー質問をした内容ですとか
納豆をまよく分からないってことでそういう一二とかもあるんでつららの情報が表示されますで
授業中に自分がまーどのようなものを持っていたのか
どう後ま知られては今よく分かんなかったりとかっていうのがこれで一泊二にすることができるような
でそして最後に検索機能です
ええー検索機能はあのーま単純にスライドとおーま音声から検索するような機能なんですけれども
音声検索のあのー
ＤＰマッチングを使ってこの
えーん
検索キーに
があー発せられたと思う表にしてるんですが
えーまそれが別に
ま正確性の情報がありますので
えーそのうん制度が変化があってそっから
でえー検索結果が表示されるようになって
またこちらも理解の変化とはそっからえ検索結果を表示させています
まこのように
で学生がその授業中に一の話者数ですとか
えーま理解できなかった活動をえーまー重点的に
勉強できるように
な機能を持たせてい
えー以上えーまとめますとえ教師の方にね忠実に再現させる機能を持たせて
舌の上にえー潜時のデーターをえーですとかと重要情報を表示することになり
えー完全な理解できなかったかと
ケーキ型の話者数という点でえー学習するような
ことが可能となります
えーっと先程言い忘れてしまったんですけれども
でこの
でえービデオですけれども
その学生では
でえー高かったという風に聞いて私の
ずっと見るのは
まあのーあんまりまー効率性の良いこととは言えませんのでえーと
とにかく戦争がえー高かった箇所に関しましては自動的にえスピードはもはや送り
されるようになっています
で最後にえーっとその検索機能も欠かせない低いか所と理解できなかったらそう優先的に表示させることにより
データーの遷移をしたような支援ていうのを提供してます
えー
で次にえーデモをお見せしたいと思います
でこれはあのー実際に作りましたシステムですけれども
最初に
まよく聞いてんだということで
でえーちょっと動きがかなり早くなってるんですけどもまずまー要約になって
二人あのーまー聞いて後はまー
飛ばすはい送りするということが自動的にされています
こちらづらいと思うんですけれども
ま書き込まれるとは
メモなどもえー
表示され
でえーと検索の部分が
で例えば
実にまホストへ
んであのー
検索キーを入れた場合
現在結果はえーまこの全体で日本されてまして
これ例ですと三つ持った後そのスライドが表示されると
えー
次にえー音声検索
えー私も字売れると
えその後まざっと発せられたところから
でそれ支援される
でこの検索順位の
えーアクセントとい
ところから経験されてるは
とされて
好き声ないんですけれども最も近いかという風にまー
発せられ
で次にえー情報の情報ですね
えー
バスできもうえっとー
の
分娩がこのように使用されて
であのー
えーと
テーマそうしますとこのホームが消えてしまうのでこう食べるような機能
こう
まーちょっとした部分なんですけども付けている
で以上がデモですけれどもえー次に
えーこの二つ前の
評価する為に実験を行ないました
でここでえー仙台情報からアクセントおー
で現在あのマイニングしてるんですけれどもその精度がまだあんまり良くないものですから
でこう体にデーターを用いて実験行ないました
でアクセントの高いはちょっと低い要するにね無理していた部分というのを
何で何データーに作ってそのデーターを元に
えーま教材を作りました
で作り方なんですけれども
えー元の方でこういうデーターがありまして
でその中から
えー各全体これが使用感とします
でまそれを繋げることにように
えーま昨日はその少年ていった活動というのをまー作り
掛けて
そしてえー音って言った方来ていたいましたでえーっとえーデーター遊びからえー後もう一つ
で問題を作成しました
で実験の手順ですけれども
最初に
でえー探索法につい要するにあのーん
起きていた場所からなるようなえーデーター月の生まれた短縮コンテンツを
でにでもない
そして
ページの起きていた後から発話された問題をと言ってもらえま
次に
えー似ていたじゃ行った示唆されている問題を置いてもらいます
この問題はどこ際には
でオリジナルなえ文が
えー限定されたあービデオを見てもらいながらえー学習してもらうんですけれども
えーグループ一の方にはえ本システムを持ち
でも
でこの問題解いてもらいました
そしてグループ二の方は
でビデオと
スライドをえー
表示されるシステムを用いて
次に実験結果ですけれども
で被験者はグループ一ように
グラフに更にです
そしてあのー問題の内容によってえー差が出て
出てきてしまってはいけないので
で問題はＡもＢも簡単な問題を作り上げました
で結果なんですけれどもえその問題との時間を測っています
このように
ええっと
テント類要はそのー
で起きていた×というえーデーター数を問題なんですけれども
高度に有意差が存在しますのでえーこのことから
えーずっと
日の朝のそうは後で矛盾するには
また第な時間が掛かるということがえー考えれます
そして最後に
で本システムを用いた場合友達ない場合
このようにえ風に入れるぐらいの差が生じています
でこのこととこのことから
えー国家制度へという部分を屈折する為な
良くないな時間を用意し
そして学生なのになった部分を重点的にえー学習することが
全体の二重の効率化に繋がるという風に
そしてであのもう七十面も持っていることになりアクセントの低い部分の国種時間が短縮されました
でこれにより
で学習の効率化に役立つということが
提出されました
えまとめますと
えー学生の重要情報とアクセント情報を用いた時間が主人システムを開発しました
で本システムがある種のこういったね話すことが示唆されました
でそして覚醒剤の方の
えー即ちです
木のなさそうに重点的に学習することが
不可能になることが示されました
で最後に今後の課題ですけれども
んえー音声情報テキストをさせたい情報などさまざまな情報分かった二つを総合的学習システムを構築してもっともっと
ですと言いますのも今回は
えー事業に演出でした学生を対象としてますが
で設定した学生にも
えー
法律的に学習できるような支援ていうのを考えています
で例えば
でえー重要づらいと思い政治させる
ということで
えーその重要な発想から
えーままとめでえー勉強してもらってると
ま一つ挙げられます
そしてえー検索機能がえー営業したんですけれども
かなり
でえーま精度も良くないものですからまそれにえーその検索時に設定したつらいのがあのーばらばらに上映されてしまうので
でですねその検索キーに適した面得るとそのく更に反映させられるんほです
でえー適用した方が
あのーまとめて学習ができますので効果的な学習に繋がるという風に考えて
そしてえー語彙の進め方とはたいのは休んでる文とお事実だなもえー開発してもという風に考えてます
以上で発表
えー
#############################


#############################
# query = 論文の最初の方の他の金というのを紹介意味だと思ってえーそのーんーと本当に複数の認識えそのー用いた音声一検索オーケーですとかのところでえーえーとー楽器椅子だったり今日以上ネットワークを使ってっていう紹介があったんでけど僕ちょっと言い真っ赤緊急で呼吸上の昭和九を用いた手法親って言っ本当思ってるとこなんでえっとープラス一っていうのがでよく分からないてどちらについて体をきしたいなともう少し詳しく知りたいなという風にあのー
# rank = 1
# slide = 10-12_fix.match_word.jout.txt
# value = -1.8415729249815
#############################
はいえーっと端からの関係者ですとえございます
えーっと本データー部分距離空間どの索引付けに基づく音声ドキュメントからの検査の検出という発表いたします
でこの発表はあの機能から発表がございますし僕んたのでセクションの発表です
でえーっとその島どんな文で対象に関してあの新しいえー全く新しい手法を提案したいと思います
ただあのーえーっとまだ評価のところ十分ではなくてあの実験結果非常にあのー準備段階の予備的なもの二十限られますけれども今日の発表はアルゴリズムを中心にあの御紹介したいと思っております
はいでまず研究の目的ですがこちらはあの木の中でもあのー何ではありましたので言うまでもないと思いますけれども
えーっとー凄く何でセクションというのは音声ドキュメントからえー入力したパターンが発話されているピッチを特定するという問題です
でえーこのえー凄くだんだんですのでえー手法には色々ありますけどもその中でえーなるべく高速で高ストレートであるというなし方が望ましいという風に考えてます
で更に言いますと
あのーえーと
手法はあのできるだけ利用し易いと
色んなとこに応用できるというような手法が望ましいだろうという風に考えられますと
でえーとこの発表はそのＳＴの問題に対する新しい手法をあの提案します
え本発表では先程述べましたように提案手法のアルゴリズムを中心に
報告をすると
いう風にさせていただきたいと思います
はいでまず最初にあの復習ですけれども
あーの温泉の面倒検索というのは二つございますでえー検索語原子というものと内容検索二種類ございます
で検査語ですが今考えてるものでこれはあのークエリーとして与えられたパターンがえー現われている一応音声ドキュメントから特定しようという問題男とそういうえー
問題です
でこれに対しましてないよう検索の方は縁としてはユーザーがこういうもの節とこういう文章が欲しいという表現を与えて
その表現に合致するような
えー適応する
えー文章というのをあの文書コレクト七日から話しましょうとこういう問題ですね
で
えーっとだから下の方はから後もう何もま一致する必要がないのです
でえーっと普通でその分野だとあのー検索と言います下の方の内容を検査の方をいたしますけれどもあのー音声の場合ではあのー上の何でその方もあの自然の文ではないのであの
むしろこちらの方が盛んに研究されてるという状況にございます
はいそれでえーっとそのすこうこんダムでセクションに関する関連研究ですけどもまとめますと大体こういった手法が提案されています
で一番あのですからあの基本的な方法は連続ＤＰ町これとこうという方法です
ただ連続的な二のですとあーので検索対処の文書全部駄目なできませんので効率が悪いと
でそこで
連続索引付けをすることによって効率化しようという手法が幾つか提案されてます
で一つ目の代表的な手法これまー殆ど後はこちらなんですけども今でとファイルを使いましょうという方法ですと
でこれはまできそれもよく使われる方法でま言わば辞書を作っておきましょうということですね検索したい
ものの辞書を作っておいてその辞書のというものに関してはその一応
あのーすぐにしてるというような作品を作っておきましょう
いう必要が
あのそういう非常になってます
でえーっとこちらの方はその事情があっても必要でそこへのてないものを持った検索されないはですね
まそこが
あのちょっと音声ドキュメント対象にする場合は問題で
えーっと一音声のん時などはトイレがありますので必ずそのえ全ての
えーと
あのー
文字列とここに乗せるってなんですから下容易ではない
でまー昨日のお店が全然なかったこちらの方で
えーとまずこの索引付けの方を色々と工夫されて
色んなパターンの設定というの本発表たったと思います
ってもう一つの方法は
あのー親しくた例を使うという手法でこれは
あの木の御発表ありました
えー飾ら先生の発表に相当します
でこちらの方は
えードイツ語はかと言うとその検索対象のドキュメントの方を
えー短縮しましてえーっとその
んドキュメントの共通部分をえーツリー上にタスクしてえーっと
同じところがまとめて検索できるようにすると
いうことでその上でＤＰマッチングしてやろうという手法ですね
で
えーっとからえーとこの方法だとえーと音声ドキュメントまやはりその
認識に入れなるというところが
あのー船で
問題なりまして
えーっとできた丸一二あの決まるのでえーとこれはすぐがうまく行きますけれどもえーと恐らく方も多いような認識こ方の認識法がある中で
えーとその中でえーと共通部分を見つけるというな
なかなかなり扱いが難しいだろう
いう風に想像できます
でまだいずれの手法ですね従来のいずれの手法も
えーっとその検索の問題に対しては閾値を使ってると
えーっとその検索したいものがどのぐらい
えー誤りが許されてるかという閾値を設定してその閾値内の
えー距離を持つような方法出すというような問題を
えー置いてるという手法になってます
えー
はいで
えとこの関連分野としてテストの分野ではその揺れを許して他の誤りを許して検索をするという問題は近似モデル照合という分野で研究が行なわれています
でその権利もです中中証拠の中で代表的な手法というのこちらの百円でてる町で代表で菓子はこちらの三つの手法になっ
で今
でえーと最初の二つは先程の二つ目ちょうど対応してると
いうな手法になってると
でもう一つ
鳥空間上の作品というのがあるんですねで
本から四はこちらの×空間上の寒いというの使うという手法になっ
で簡単にこれらの手法の紹介をしたいと思いますがまずたり薬を使う方法ですけどもこれでまー細かくは説明しませんけども
あのツリー上に一旦対象文書の共通部分これ発見でしとかですねあの話としておくと
そうすると共通部分をここの上で
きついマッチングすることができるということになる
そこで
えーと探索をしていて誤り紹介をしたところ間がありましてある
それでえーっと深さ優先探索するとここが
ちょうどあのーＧＰ評価サークルに疲れ支えて
他のバックトラックすることでまた別のパソコンは水曜日
探索的とこういう手法になっております
はいてもう一つのあのＮグラム作品を使うという手法ですけどこちらはパーティー商人太く
呼ばれる方法を使って検索するという手法が知られてます
こらということかって言うと
あのー誤りフィルターれる誤りのえーと
つはずですねこれを得られると
言いますがえーとその得られてるプラス一個分にパターンを分割してあると
いう手法です例えば
田村が大振らっていうのがありますと
これをえーと誤り二十万で許して
えー検索しましょうと
いう時にはこれを
三つに分割する訳です
三つのパターンに
えー分割します
そうしますとこの三つの中の必ず一つは
あの誤りなしでえーその後
えーと一ドル存在する誤りなしで存在するということが保証されますのでそこに関して
え六グラム作品を使って去って検索しましょうと
そういうとこですね
で
えーっと例えばバイグラム索引を使いますとこのパターンをバイグラムに分解してあって
えーとテキストで索引付けされているいるバイグラムをサラダです
そうするとここのえー水泳で言えと言うとが見つかると
でこのが見つかるとこの結果近辺にあのーえーと答えがあると
いう風に
ある可能性があるということが分かるので後はこの二え周辺で
えー本来の近似モデル照合手法を使ってえー探索をしましょうということになります
で最後のあの距離空間上の索引付けですけどもこれは
えーっとんどういう方法かと言うと
あのーグリーン空間がありましてそこにオブジェクトが点在してると
いうような状況を考えます
でそこで
えーっとクエリーこれもまたオブジェクトでえー検索率のまここ日本と与えられたで距離空間上で
えーとこの中で一番近いものオブジェクトなんですかというのがまーそそういう文だとこう
いう手法です
で
えーその時にえーっとこれら全部をですね全部に対してえ距離を求めてやると
あのー効率が針を作っはですね計算コストが高くなっても
そこでえあの索引付けをしてこのこれを効率的求めましょうということをやっていきます
でんどういう索引付けをするかですけれども
あのま手法は幾つかあるんですけども
代表的なのは五ぼうっとを使うと
あのオブジェクト中からえーっと
幾つかの総数の規模取っというのを選んでおいて
でこの規模夫から他のオブジェクトへの
距離というの予め計算しておくと
いうことをします
そうすると
えーっとクエリーがまこれを索引付けと記憶はですこれは寒いんでしょうと
でえ新しいクエリーが現われた時はその時骨董との距離を
あのー
計算すると
それで
そうすると予め求めておいた通り量を使って
えーっとこの間のオブジェクト間の距離が
えーと近似的に計算できるということになります
んで後遺症で効率的に参加しましょうという方法が
えー距離空間との索引付けという手法になります
はいえと関連研究簡単に説明しましたが提案手法はこれらの手法の一
えーと今まであのーＳＴ問題なんであの使われていなかったこの辺空間の削減とこれを使いましょうという手法に相当すると
いうことになります
はいでまず最初にその提案生の一文献について簡単にあのまとめたいと思いますえーっと提案手法は距離空間どの索引付けを利用すると今言ったように
えーそういっ町になっ
でえーっともうちょっと細かく言うとより空間を部分空間に分けるんですねでその部分空間上で距離を測って
えー索引付けするという方法になってます
一つでまた別の見方をしますとえ提案手法は
そのＩＴ問題を直線ケースの問題と設定したものであるという風に考えることができます
でそこであのーんカードではそん時前点数法と周波数変換では知られてます
でこれを
あのーＳＴで問題提起を応用した手法であるという風に出る子供ができます
んーんでん特徴としましては
あのーまず一点として閾値を
必要としないという大きな特徴があります
で閾値を設定から予めこのこのぐらいの教えてましてえ設定する必要がない
でえー提案手法だとその距離順にしておくするということが可能になります
でもう一つあの
えーっと音声認識だとその
えー認識の候補がいるそれでえー
来るんですけども
その複数候補の扱いがえーあのーん
非常に容易にできますアルゴリズム変更なしに
あのー
そのまま適用できるという特徴があります
はい
それでえーっとではこの提案手法について説明してまいりますと
えーっと提案手法はそのＳＴの問題直線です問題とセット二の考えをえこれをどうこれはどういうことかと言うと
こちらの図を見ていただけると分かると思うんですが
えーと検索語を縦軸に取って今検索たいボールえーっとパターンところ縦軸に取ってえ対象の音声ドキュメントを横軸に父これは非常に長い
あの音声学などの音素列ならですね
でそうするとこの平面上のこうしてんには
あのえーとおんす
音素間の距離が終わってあのー与えられると
いいような
あのー
えー平面が与えられるということになります
でえーっとまー距離が近いあのー
ずっと多いということでま画像で言うとあのん学の本みたいんに相当するような点があのこの平面上に定義されるはですね
でその中で
あのー
まその他の行為つまり距離が小さいような点を結んでここに得点がこう現われたと
でこういう得点を検知するという問題として決定木の問題を考えましょうと
いうことに
ができます
でえーとたらＦＦＴに二の場合はですね固有の特徴を使うことができると
いうことですねあのーん画像んの直線でその場合にはその復活を
あのー画像がその場で与えられてもないんで
えーこの直線を
テニスしなきゃいけないんですけども
であのーてＴＤの場合はこの予稿ですね横の
えー
検索対象のドキュメントの音素ベースこれは予めえ与えられてます
だからまー処理できるとここは
体が二名与えられてるという大きな特徴があります
でこれを使って
えーと猫が与えられているので
九八九とこれたくさん酒常に区切った
えー各音素ごとの
えー距離のベクトル
ですね高校は予め計算しておこうと
ができると
いう大きな特徴が
あります
ですので検索をは入ってきたらば
思ったんだと上のえーっと距離ベクトルを
ま検索語の音素順に並べてやると
この
えーまそう平面がそのまま再現できると
いうことになります声特徴がある
で更に
えーっとこのえーっとまー
うー距離ベクトルですねこれは予め
ソートしておくことができます
ここは距離があのそれぞれ一で
あのー
定義されている訳ですけどもそれを
との距離順にソートをしておくと
いうことができますとま一番最もらしいかと
いうのを予め調べておくということが
できます
でえーっとでソートをして
でまー実際距離は必要ないんですがその一応
ソートして送っており順に一をソートしておくということをしておきますで
このソートされたベクトルこれを索引し
役員として使いましょうと
いうのがあの提案法のアイデアです
んーはい
んであのもうちょっと細かく提案を説明しますとまず
あのーまい処理としてえー今のあの距離順にソートされたベクトルを作ってきますでこれはあの音素ですね音素の種類ごとに
検索対象町だけ
あのーまーま提案された距離は必ずしも必要はないんですけども
三の一のベクトルというのを作っておくと
ちょっと説明の為距離と六一の何てありしてますけども
あのそう本当に人だけ取り扱うということになります
で
えーとこういうえーと
えーっと行列を作っておいて
んでえーすここをあの距離一に相当しておくと
いうことを予め全ての音素に対して
やっておくということをしますこれが索引付けに相当します
そして
あのー実際に検索の時にどうするかと言うと
あのー計算文のパターンが入ってきますのでこのパターンに従ってえー今の
えーと音素のベクトルですねこれを並べてやると
いうことはことをします検索語のパターンに従って
その音素を
予めえー求めておいたベクトル一から取ってきて
並べてあるということをします
んで
えーとこれはまーあの先程言いましてね距離順にソートされてるんですね
でえー一番距離が小さいもらってあのー上の方で
入って
んでえーこれをスタック的に一から昨年使って
距離が小さい方っていったところという風に見なしてえー付与するということをします
そして
えーっと
まこの作っておいて後
あのー
検索対象の各位置について投票箱というのを応用しておきます
でここに対して
あのーどの投票していく訳ですけども
えと要はここの
えーとスタックのトップですねここから五距離の一番小さいものを一つ選んで
でそれに相当する位置に飛行機をすると
有効ですね
んでえーっと今の場合ここ
経営の
えー
一番ある程度距離が小さいところ高校二と二二
でこれに対して直線でに対応する困っ斜め方向のここに
行っこれに関する検索率になりますのでここにいて
一応公表するということをやっ
これを繰り返していくはですね
で次の増えて最も小さい子ものに対して同じように特徴をすると
いうのをどんどんどんどん
繰り返すと
いうことを
やっていくと
いうことをします
そうすると
あの最終的にはあのーここが投票箱当てはまると
検索勿論まで溜まるというところが
見つかりましたここが
まさにえっと今見つけたかった官能検査語が現われたところ
いうことですねここを出力しましょうという風に
やっていくと
でこれを続けていることであのーんん特にスキーと
設定することなく最もらしいものから
あのー
二十あー最もらしい
えー発話数を自分に高速な検査も検索可能になるとまこういう権利で
ございます
はいで今のは非常に基本的なところ
説明したんですけどもま一番あのー単純なアルゴリズム説明しましたけども
あのーこれこのアルゴリズムをあのー一般化するとまあの実際にその場面に適応するという方法が幾つか考えられました
ふ一つはその最適解アルゴリズム実はあります倒壊した事項はあの必ずしも距離の一番小さいものからえられるような保障されないんですね
でこれをもうちょっとあのー考えてやると
あのー必ず一番小さいものからたのだということをさせアルゴリズムを合成することができます
たらちょっとあのー
クラスになりますのであの予稿集の方に載せておりました三つ興味のある方そちらを御覧なさいとこらちょっと説明
書かせていただきます
で
えーっと二番目の
は一般化方法として複数認識候補に
対応しましょうというのがあります
でえーっとこの提案手法はですねコンフュージョンネットワークとか
六で表わせたそのー政治だったの複数
候補に表現にその値をすることが可能ですこれはちょっと後で説明し
んでもう一つ
あのおー得点ケースと言いましたけども実際はその
二あのお分かりの二つ挿入とかだ座る脱落形はあの低得点者ならばですね
低得点に対応を得点になるその二
えーっと
その折れ線に対応するという為に何か会社としだけです
とここに声帯たくさんの手法が幾つか考えますと
えーとこの二
後半の二つについてちょっと説明したいと思います
えまず複数の認識候補の扱いですけどもこれは非常にストレートで
えと提案手法っていうのは
その各音素と検索一の間の
距離を
あの使えばいいとそれは定義されればいいと
いうことになりますと
つまりこれに対しこの一別
あのーどういう距離かというのが分かればいいしだから
あのここんなあの複数の候補になっても
あのーその複数方法とこの各音素内での距離が定義できるか
いい訳ですね
そのーそういった距離
ていき料理が手にできれば
何アルゴリズムでそのまま
あのー複数候補が使えると
いうことになります
でそういう距離としては例えば
あのえーっとその政治だったり複数候補が
あったとした時にその距離の流れ重み付きで最初のものを使うとか
まこうい行きたいような例ドラマ一つの例ですけども例えばこういうような
えー一人をえー何か用意すれば
あのー普通誇り対応できると
そういうことになります
次にえーと挿入削除誤りへの対応ですけれども
あのーま実際にはあのー直前にはならずにこういった折れ線ならですね
これんどう対応するかですけども
七
一番単純な方法はこの折れ線に対応するような投票箱を用意して
パソコンであのー
投票数を見るというのがまー
あのー単純な方法ですが
えーっとまーその
候補の数が非常に多くなっ色んな方を見つけたあの四しなきゃいけないのでこれは
大変になると
まーちょっと工夫が必要だと思います
でもう一つの買い方解決方法としては
三のおーその距離をやっぱりあのー操作をしてあのー多少これまーなっていても対応できるような距離尺度にしてしまうという方法が考えれます具体的にはその隣接する音とですねそのー優先する音一に関しても
あのー考慮した一人尺度を与えると
で例えばそういう例としてはあのー
えーとこれもこれのえーっと最小値を使うとか
えー途中子音を重視した重み付けで距離を作るとかまこういった
えー
距離
えー関数を作ってあると
でそうすると
えーとまま言わばそのー
曲線の直前の時のえーとー直線をちょっと太くしたような特性を経営するというなことに相当しますけどもまたその一
奇麗にそっとあの対応できるというような
方法になる
いう風に考えております
はい
で最後に
えーと非常に簡単な評価実験をやってみました
でえーっと
先端事件はその音声ドキュメントワークショップは金グループ
えー構築したあのー
二型単語を検出のテストコレクションの
後は講演を対象にしているものを使いましたこの三つのセットと
既知語系ペットを使いました
それでえーっとベースラインとして連続についマッチングと比較して
評価というのを
あのー比べてみました
でえーと音素間距離としてはまこれ何を使ってもいいんですけれども今回はあのーきちっとあの比較的利用者使った音素弁別特徴の
えーハミング距離を使ったこれはあのえ昨日の×先生の
はまってる使われた距離に相当します
あそれでこれがね独立町ですね
はい
んで
えーと実験結果ですけども
あのー
ま累積距離〇でま取り敢えずあの
あのーことが可能かどうかてる調べた程度なんですけどもえーっと連続ＤＰと提案手法でま精度は
あのー変わらないと
でえー処理時間に関しては
あのー一応こうサッカーできるということを確認しました
だけどもあのー高速化できたんですけどまだまだまだ十分ではないとあのー
自然の力や索引付けなしの手法の寒いのでしょう
あなた頭のまー当たり前の友って一応まーその確認をしましたという程度の結果です
で
えーそれにしてもまだこの歌って等まだ十分じゃないかなという風に私一とした考えてます
で
しえーと何であまりはずなんかなかったということなんですけどもまー理由の一つとしては
あのー音素でえー索引付けすると
あのー最初に距離〇でマッチするとが結構あるんですねてそこに感謝の全部投票するということになってしまうので
まそこで
えーと結局の土台あのー検索対象大部分のところでま後私だけなんかいうことになっま側問題だろうと
いう風に考えてます
はいでまとめますえーっとスコープ何ででしょうねかん対する新しい検索あり方でも提案しました
でえーっと索引付けの手法になっていって
えー式んと大きな特徴は閾値を必要とするしないで
尤もらしい候補から順番に検査結果を
えーテスト
でえーと音声認識の結果の複数コホートのまー疲れというのも特徴になってます
であの木の方が先生のお話ありましたねアルゴリズム二三十の方がいいと
でまあのー先程見ていただいておりむあのこのＲこれ非常に単純です
単純なアルゴリズムで構成そのー
いう特徴もあります
んでえーっとま予備実験でえーまーあのー一度確認はしました女性のまだまだ自分ではないと考えてます
でえーっとまー癌対策としては音節とか音節とかですねもうちょっと距離に差が付くような
大きな単位で索引付けをする
えー必要があるあるいはその距離尺度もちょっと見直して
えーと距離に差が付くような
えー尺度が必要であろうと
っていう風に考えております
はい以上で発表終わりますその時見ました
#############################


#############################
# query = 論文の最初の方の他の金というのを紹介意味だと思ってえーそのーんーと本当に複数の認識えそのー用いた音声一検索オーケーですとかのところでえーえーとー楽器椅子だったり今日以上ネットワークを使ってっていう紹介があったんでけど僕ちょっと言い真っ赤緊急で呼吸上の昭和九を用いた手法親って言っ本当思ってるとこなんでえっとープラス一っていうのがでよく分からないてどちらについて体をきしたいなともう少し詳しく知りたいなという風にあのー
# rank = 2
# slide = 08-05_fix.match_word.jout.txt
# value = -1.8725887906445
#############################
ええーん習ってたんだとかはまずえー
すえー本日は結局のようなタイプでえー私達が二年間音を利用しております
できたちゃんとだろうという一項内に設置してる音声はまシステムの場所を回答をあそこで収集されているえー発話でユーザーデーターの
あの予備的な分析結果というのをえー紹介させたいと思います
えー
ま最初にあの前半えー来た人の方のサービスんどういうサービスをしていくということを
月一えーせしてる環境
えーでまー
あのーあんまり詳細なことはお話しできませんが音声認識処理と
えー応答生成したり
について説明さしていただいて
でえー後半えーユーザー発話データー
えーちょうど二音の方に玄関口におがえー始まってから立つんですが
とその全ての入力については
えーユーザー入力はえー収集しておりましてまそのうちま最初の一か月分の
で人手による書き起こしと
えー話者情報ですね返したのは資料また話者に対する
え情報テーマ一人でえー付与できる範囲でえーと付与した結果がありますので
でそういったものをえー紹介して
できた感じであろうこと今二つ
同じシステムをこのあのーまー同じようなシステム役に置いているんですがまそのー
えー違いインターフェースの違いについて
えー一階の観点からそのデーターがどう違うかといったことを考えたいと思って
まーあのーま概観
まー
えーこんな感じなっておりまして
絶対にあるような一文
んーまー
がえー話題の森えーなんですがそこにえー人間もあると述べておりまして
えーまこれ配達の
え普通は時に
あーのー
パターンという対話システムとやることへ対応してももう本当に横に
並べてまユーザーが好きな方法を使ってもらうというな形でえー
ま基本的な受け付けあんまりえーっと差別のことを
そしてまたているんですが
あーのーまどういう風にどういうえー四つで動いてるかというのを
ま簡単なビデオですがいただきたいと思い
えー
んー
んー
えー
えー
えー
まー
んー
えー
えー
えー
えー
んー
んー
えー
んー
んー
んー
んーんー
んー
えー
えー
んー
んー
えー
んー
んーまこういう風にあのー
ま簡単なそういうあのー
画面ですけどもえー形をしては
テーマ
えーと私達のこの節点の先行システムとしてえー例えば部分というのがあのー開発されておりまして
そこの
てデーターを使った研究というのもあの時々発表さしていただいているので
音節からあのー御存じでのいらっしゃる方も
いるかもしれませんがまその建物んというのは
えー近くにあるやり近くにある
あーのー
コミュニティーセンター
で
えこちら
えー丸
え五年
以上に渡ってあのーやはり継続的に運用しております
では見た感じはあのーこのように
えーエージェントがあって
えー
節の形のマイクに話し掛けて
発声情報こちらで
で出力して応答音声で
えーお話を返してというえー
話でやっております
でま非常にあの大まかのあのえなんですがま音声認識部と
で応答生成部とまー二つ大きく分けますと
えーま先程もえー見ていたたいと思いますが
は自然文を用いて
あーかなりえー
えー安定に
あのー思わライブをやってきとかまいけない方とかえー雑音
の格がえー適当に
んで
えーま音声認識部では勝手に肯定的なあーそのーモデルを使って
えーまよくあのーま標準的な地方でやっておりまして
で応答生成のまー統計的なあのーやり方でできるとま統一的にできていいんですけれども
あのー実際思い
あのーわりとそのーデーター
あのーす
益々ねとかそういった問題で
あのーうユーザーの発話のデーターをえー使ってそれを
えーえ質問用例として
えー利用して
であのー
新たにえーユーザーの発話時やその質問
用例との参照によって
えー音を書いていった
えーより別の応答生成を行なっております
でまそれらのモデルやあのデーターベースを
行なうと子供別にえー用意して
てあげることで
えーま音声音声認識精度とおーおー
ま応答生成するってことを向上させると共に
あのー
まどちらのことなかっものかといったまー発展もまーえー一文を用いてできますので
えー音音声も
えー年齢差も凄い大人には
あのーえー
えー子供にはあー普段
話し掛けるとあのー父が
えーえータイトルは
で
ま見ていただくように
あーの市も一度方式というまー
最近よく受け付け案内というま目的に
ままホテルで
二回対話は残念ながらまー病気をされないだろうし
味付けもこんなということもえっと一文と方式で
あの履歴とかは使わない
それを
でここまではあのー本け先行しても例えばの
えー
で後昼間導出さして
思っているんですが
んました方も守らないように
二つのあの見て見た感じは全く違う
えーインターフェースロボットは例えばま従来の地域
を用意しているというのが
あるので
それで間違いをえー何とか
ん効果的に生かそうという風にえー考えておりまして
でもう一つの
まー特徴としては
べきの環境
まー大体測定すると六十二重ぐらい
二月になって
まそこでの
辞書事件がま可能である
でえー現在はあーそのロボットの方もあのー対話システムの北の方も
おー接話マイクに声であのー話し掛けてあのーただ日本でして
あのー話し掛けても載っているんですがまそれは
ま将来的には
後一つの
二ましたり
でそうするとまたあのー
四五四
ついてなあのー評価ができるんだろう
ではないかと思います
えっと負の部分との比較で言いますと
相手の獲得前にいて
んで
えー例えば文があのー設定してある
えー
地名データーですがえー二層とま非常に
表現下の場所ですのでま細かい違いが
あります
でま海感じた
えー
駅の方も
あのー動いてる駅が動いてる間は
二十一回読んでずっと
えー
場合にえー毎日やっております
．んんでえーと情報案内ま具体的なサービス
えー
あのー
の二つのえー
二つのま方式であのお互いに講義内容というのことで取りまして
ままずあのＮグラムによるま連続音声認識結果
とー
あのー先程お話しさ
共に用例
えーデーターベースと
参照して
んー
それにえー対応する方法が一つ一
えー
特定タスクの為にはあの手で
文法記述して
でそれによってま認識して
えー音を書いといった二つの
あのー枠組みを用意しておりまして
ま最終的なそのうちあのーどちらか
あー適切だと思ってる方の
えー
認識結果を用いてえー音を書いてるんですが
まそれでの為にちょっと若干を娯楽があるような形で
あのー
起きないや
風にしており
その言葉の数まこれはまーまこのえー
あーの軽減どこに基づいて作っているものなんですが
お喋りとかまたその何が好きなのか
あーのー
踏まえての説明川周辺
ですとかそういったことを忘れてま種類としては三百
それ
でその応用しておりまして
えー
まこちらの質問よるのかも
あーのーデーターベースを大きくしていたりも変わってく訳ですけど
ん現在のこの
まず高いについてはもう
の方もですね一応ずっとそのくらいの文数の
つまりこれをえー
用いております
んで
廃棄にありますのであのー
駅の
当然検索ファンの理解あのいとこが
えーしてあげれば非常にまーあのー実用的なシステムうー
えーなる訳ですけどあのー
えーっとそれのまー用例の手順ですま非常にされてありますから
あーのー文法で解析近くの
えー例えばまーあまり御三丁目とかそういったものを
えー
って最も
文法で記述することで
あのー色んな
んー
ユーザーの日に対応するといった
としてます最も郵送さ
ですねあのー
えー
記憶戻ってとか
えー
えー
次に一対二ってまそういったほぼ文法でえ採用して
んでまーま今の
サービス内容のまとめですが
ま例えば船もあの簡単なところをまー
あの文法書いていたんですけどもこの二としての本格的に無料で一を
もう始めたという
えー
んーとー
ことにやっと
でえーっと音声認識部
なんですが
まこれもまーあのー
もし基本的なも
古いいー音声区間的と後二六時間と
歩くこともの閾値で
えーやった後に
んーま音声認識として
えー
応答生成には出す訳ですけどまそれとまあの並行して
んーちょっとん違う
まＧＭＭはま大人用の
音声モデルと子供用のモデルとは第二対一と二つ音が用意された
んで
えー認識の方は
あのー先程言いましてどうにも行ない音程思いをまー用意してあるというのと
あの文法ベースのものと
えーと五グラムですねものと思いをしてる
でここで結局まー
四つの処理があるんで
で
ま最適な御と言うとを見て
もうどれが一番
あのー
俳優座の質問をちゃんと
適切に反映してるかというのをま考えてま応答生成部に私は
えー
で応答生成部
まー
んでえーまー
大人子供ができ結果と二ステップのまー
えー貰える訳ですが
まー文法ベースの場合は
ま今日とても丸二したがって
ありまして
で被験者の場合は
このＮグラムによりチケットの場合は
あのー先程質問料で
もう携帯その
えー
のマッチング受けた数形態素単位で
えー
ま全体中で
え含まれている形態素の個数
えー
あの用例の本当につ結果の方で
まー低い方
の一個
を見るといった形でま全て行列音声に対して
そのスコア言語スコアを出してま対応する
一番高い高いスコアが出た
つまりに対する対応する夫も返すという
出すということをしており
んで
でまー私達とのユーザー発話データーベースをまー
たった一分の二三とてる訳ですけど
まその前にま立場の文
んでえー五年
えーと五年
が
えー運用しておりますので
文をしておりましてまその中で他については書き起こし
いう場所情報のラベルを
で付与したデーターがあります
で
方達だろうこの最初の四の時も
過去のデーターを彼が作ったモデルやえー四用例データーベースなど
行為に利用した訳ですけど
できればやっぱり駅の側から
まずまま評価としても見て認識率がえーとーももっと世界一の
でまたえー作成するえー
評価している訳ですがまーデーター
まシステムを置いてあるじゃ本当のあのー実際の場所のデーター
でえー作ったまま本当はやっぱりいいんじゃないかとも思いますけれども
さすがに年間分の書き起こしこう新たなデーターではその非常に
あのー該当数の掛かる訳で
で
まー従来のデーターが
どのくらい
えー
応用できるか
で従来のデーターに対して
新しいデーターはこうどのぐらい
だけあの書き起こしデーター
あー十分実用に
えーん実用的な
でモデル化できるとえーっとまーそういった
あーのー
ポータビリティーの評価
などという形で
あーのー新しいデーター
あって
えー
言っても
えー
頭近い状態数に
システムにするよって止まりますんで
ここのデーターの
同様のデーターとして二十対
えー入力データーや残響まーあのー
んーこれから接話型でのパン作り推薦の友達であの問題なります大学出たなと思って
んー
で
多数がモデルやデーターベースをえー改善していく
というのもありましたと
えーしていくことも
てまそういった研究はまあのーあまり良くて参考文献です掛けてるようなところで
あのーお勧めできているんですが
でまここで
は
の元と大きい話でそのデーターをあのー分析した結果というのを見ていたの方
思います
で
で
話し手のインターフェースとしてまロボットと
四事例でまたあのーある意味そのえーエージェントというのがある訳ですので
まそれを
えー
そういうユーザー
その
えーえ違いがあったり
もう発話内容に違いがあるとあるいはない
というのをえーと見て
えー行きました
うまく適用
まこの二つのデーターこれは
判定についてはまこれからですが
この二つのデーターについて
発話のえーっとユーザーのユーザーその
間違いをま見てみて
んーまー
あのー音声対話システムを新たに作る時にま何らかの視点
んでのようなものが入れていれば×一まーないと
で入手デバイスまーあのー違い
もう改めて音がしますと
後父ちゃんていうのは
二．七分と
同じような
テーマ
同じえーシステムの提唱しましてまーすー
×というないというまそういう事情で八日出てすぐにしているという
パセリの違いなんですがま下の子
の方は
で元々ま今ロボット非常にあの盛んな
盛んになっておりますので
これがロボットに
話し掛けるについても
がま要求されるという思いますんでま
こういった
えー
ただあのー
んーいちいちこれじゃったら火を三次元化したロボットを作りまして
えー
まそのインターフェースとしております
でこの時もうあの人に対して話し掛けるような感じでえー介護を
連れていきたいと思いますので
まーすー父のこれデバイスまーあのー外す
いう風にしました
でえーっと
そしてま大きく大きな違い
その後にあのー二通りの違いなんですが
ってとは別にあの×がなくなることによって
プラザの操作というのが来てあのーロボットの場合は音声でしかも的なそういった
ところがまーえー
そこも海と
んでえーシステム入力データーベース
まー全ての
えー入力データーはま波形データーして
んー
応答生成と理解
もう一ファイルどこを一発話間そしてえー
んー
引っ越しを書いてあります
んで
ま発話データーを
二つ音のみの入力もあの全て
えー
収録しております
すいユーザー書き起こしユーザー発話データーの方は
あのー
そいで収録さ全てのデーターに関しましてま一か月たんですけども
んー
人とさんがえーっと音声で書き起こしが
後あのー
それにまー
一つえー速さともかく
もう
発音したり
えーしましてそういう
いたしましてまそれも書き起こしテキストとして
えー整理しております
んで
後はまこの三つは
んー
えー
つまり若干そのー
んー町主観主観的なものも入るのですが
んーそのー
えー発話がシステムのお父になりました
食情報と
話者が
えー
年齢層こともま八時から
元のあのー高齢者の程度の年齢とか
ということと
例えば男性女性
であるかというのますま主観によって付与しており
するとえー先程のような用例一の
えー
えー
えー
えーをよりでしてえー使って出す音のどれが
適切な
えー回答がてると
まそれ以外の文法で何をしてる
えータスクのうちどれが
えー適正であるか
というのはえー
情報網利用しており
でえーとシステム
あーえーっとと他のシステム入力なんですが
んー
まこれはあの二者の毎月お父も
えー入力数で
のことも
ま一度ＧＭＭによる識別結果
がえーの子供との
えーっと
一対一場合
またとんという風に
後まー
んで
え短い入力と言うか
風にえー二三タイプ分類しているのですが
ま基本的にあのこれは盛んで
で終わ下の子なんですが
んーほぼ下顎の方があのー
パソコン時代なってる時代は
ほぼ同じような
あのー母
よく相関を取っています
ダムでえー
んあのーち適切とかあのーそういったものに影響される
あーのー
このこのみたいなまーどうやら
こないだＣというでこれが大体お
えーちょっと見ていこうかと
持っている
でえーっとちょうど補足なんですが
で先程えーとこちらのデーターというのはあのーＧＭＭによる内語識別結果
でまどの程度精度があるかという
こともあるんですことがあるんですが
五十実用上は
えーとこれは
あーの実際のユーザーの発話
ま幼稚なことをまでやはりお力をえー高齢者の
についてあのー自動識別した
結果が
あのー
子供になっているかどうやってるかと言うと
えー図なんですがま方法
あのー
んま奇麗に
えー結果の施設結果でも
まいうあのー自分使える上にあるというのがえー見ていただけるかと
えーと背景雑音
あのー際してえーとす
ＩＴというの雑音として
あのー外にあるのでまーハゼとかだから
歳のことからま昼間は記号とかま色々
後ですが
えー
えー
ま結果から言いますとその
室内の雑音で作った一年目で後野菜というのも今もう殆ど
この問題
がもない訳ですが
ん外に置くと
あーのー家庭というのはもっとあー三十六ま二十秒ぐらい
いう分かってえー吹き続けて
それがずっとトリガーが入った状態なったりするというのは
えーまー外で見をする
えー
んあのー
ま対応すべき問題として
あります
ただそれ以外は
あーの文字レベルで
んであのー一年生名で棄却され
いうことはあーありました
んでえー冬が発話
データーの比較なんですが
もうこれはまー
えー人による発話の年齢ともえーシステムには違いと
えー全部あの
違い
内訳の違い
えー質問内容の大きな内訳
表の内訳というのを見ていたタイプ
えー年齢層なんですが
そこであのー
反応データーをどうもあのー
んノイズが入ってるようなえーとこれ無視していただければと思うんですが
えー
ちょっとちゃんについてはえー
複数こちらがあったとでいつ仕事のえー子供を
で幼児からえー高齢者までの
えー
水なんですが
二単語についてはまー殆どま先程見ていただけていたのと同じような
性格が
えー
ちょうどダブル凄いなるような感じで
んーやはり発話の方も入っていると
被験者の方なんですがま詳しい話は
当時
できないんですが
情勢
えーっと
んー米が
えー
えー
データー子供したが大人で
えー三が下の方は大学だったのですが
んー
んー黒いものが女性
それからえ相手との
で
まー見ていただけるとお分かりかと思いますが下の方の方が
なぜか女性がえー
使用してる人は
やっぱりトマトとそれだけするのもあり得ないとまー
それ結果はえー
でえーっと子供の
その前の内訳
こちら北の方でこちらはし方なんですが
子供はまその後建物との挨拶プロフィール
どういうことが好きだとかそういったことで
えー水がされてまして
殆ど差がないという早く何とも勿論
とー女がないなんですがもう大人になりますと
えー
大人の方はえー
例えば
で
えー一素性はえー情報を何かないなとまちゃんとした
情報システムとしてとてもしているのではないかという風に
と思われます
でちょっとあのーちょうど介護も違いましてあのー方法としてしまいますが
できたちゃんと娘についてえ聴覚紹介させていただくと共に
でデーターベースについてえー簡単なえー一対応さしていただきました
ここのこの三頭が
あまり頭に思わする予定ですので
そのデーターの分析をえーしていきたいと思い
んーと
えー
#############################


#############################
# query = えーそのー間の一でそのー頭部の中でえ二つのそのー単語のアラインメントの方法として間に新聞いっぱい法と何かもう一つ歌い方の説明があったともんですけどえーそのーそちらあのー数値三十分一杯方のそうする式についてでよく理解できなかっので分かりやて乗せていただく体のその今
# rank = 1
# slide = 09-16_fix.match_word.jout.txt
# value = -1.92373051710361
#############################
えーっということなんですけれどもまーあのー音楽四のレコードを使って録音して後ソニーの
えーハードディスクのビデオカメラに振るとそのＡつまり先程のこういうその学会ですけれども実際に思いますマイクを使って取って
ってなことを行なっております
えーやってでえー学生が嫌だと思ったんですが結構癖
てカラオケ整体っていうだけではなくて生まれた時からかビデオカメラで取られているすると
いうことが分かってきました
んでえっとーまーそれを表現としてもおいしくないかということですと
と千九百八十年代提案法で今後の練習しないとねって感じだったんですけども
その後おー作文とか口頭発表プレゼンテーションって思えるようになりまして
んで二千年ぐらいたってから
書き掛けてえーこういった音で練習を始め
下降学生は殆ど自分で勉強してくれるというなことが分かってきた
いうようなことだと
でえっと〇一二次のお後期のおー収録とかですねドキュメント化ってのがあるかと思うんすけどもえー私の粉ってのは講義ではなくて授業えー英語の授業です学生同士のインターラクション
これをそのものと
ってできれば一人一つのマイクを持った設定ってに役立つとか対応物みたい
例えばあのーえー二の中で作文を書いてる時間と先程練習する時間なんですけれども夫名詞が提示か部屋もかなり批判もあります
明らかに一体化音と思って学生学校緊張したり各国へしているということを彼は
そんなことを取りたいんですが今できないので取り敢えず
えー音声を収録してて気持ちも後人手で書き起こして
で一度で書き起こして一年掛かってもえーっと集めたデーターの百分の一の書き起こしできないで
何かもうちょっと功利的な方法ないかなと思ってま今日も色々あのー勉強に伺ってるんですけれどもえーっと文教育分けるとなかなか貴重いけないので×ですただ一つ一つ一つです
えーっとーおーでえーま事業というものを分析していく上でペットと適当な重要だと思うんですが二秒前の状態二秒後の状態
歯テストなんかですとえーっと二秒前二両方で
スコアがだったみたいな間違いかと思うんですけれども
でえーっとここで言うのがその他に数値が表わされるデーターだけではなくてもっと学生の態度と対応するあるいはあっていいよう飛んでいるんだけれどもどういう風に感じてい四本ているのかなって思うところも
本当は見て一体
と申しますのは英語学習の目標ということでえーと昔を学習がここで定めっていうのも
てコミュニケーション測ろうとする態度を育てると
とそういった表現
であるいはあー一つはえーい文化を理解するうーとかまこういったことが盛んに言われているんですけども
テーマ英語と言うとまこういっとかあのーそういったものも勿論当然必要なんですけれども
でその上でえー二等えーっとー言葉っていうものに対してどういう風に考えるか
あるいは英語学習というものと捉えてこのカテゴリー化一だということが第二次数が重要ではないかと
てえっとー私に九十年代にえー他の大学全体の情報を教育を担当していたんですが
情報教育の分野ではまーえー情報が付与実践力情報の科学的言い替え情報社会参加する態度
この三つを柱として教育を考えてるんですけれども
てこれを利用すると英語教育に関しても英語も日本の
それから英語に対する科学的な理解
それから国際情報社会参加する態度まこういった人の点から捉えることができるかなっていう風に考えて
ってそんなに考えますとで英語の学習に関する学生の状態前後と言っても
こういったタレントというものを是非捉えていた
テクニカル
データー収集ですけれどもえーま学生
で三発話だけでなく一人ずつうー試験を受けともなっています
えーで教育とかもやってみたんですけどスケジュールとかいう風な処理がうまく合わないけどみんなをやめています
でえーその他あの学生に
ってことをえーこの表を表現力が少し研究の受け取っています
適用はコンピューター教室行なっておりますので作文のファイル
あるいはポイントのスライド
あるいは事業がえー宿題で孤独
で非常に私書かれた英語も毎週一冊本読むというのやってますのでどんな方な時間を掛けて歌ってきてる方って人もいて
でこういったファイルはこれまでもう一番目記憶が詰めているけれども
で授業中の音声という流れていってしまっていたものを何とか記録に残したいというは基本的な考え方
んで
作文をですけれどもお知覚する
てえー三十分間程行かれてるかって言うと一五六人評定と宿泊
ま本当はただ掛けるんですけども選んでしまってちょっと変えてで開けることも
コンピューター言われていないと思います
てずっと練習しておく投資が千百個三百語をえ末には夜はえー×という風に
えー長さに関して一調査という点では明らかな向上が見られ
テーマ構成についても多少良くなっていたとえーま文法易い高い文中にてること分かってるんですけども
じゃ発話の方を四月う言えると雛が
凄くあ設定ま色んなあ現象の近くそのものが出ていないって言うもんで殆どこう体の上中学生も多々あるんですけれども
で結んだと結構四十五度それに答えている
っていうような様子が見られます
んでえー集めてるのは授業九十二文字が九十二文字がもうあのー二十
分二十二本ぐらいの練習の部分なんですけれども
主としてえー後でえー私の利用した人も読み上げる
それに対して別の学生がその人も聞いて答える
という面が中心
ただ信仰について日本語で操作した日本語であるとか
あるいは一次音に関係してますが暫くして今
えー終わってから関係ないとつしてる場合もそれで私の方で
えー今日その日を使って
指示をしたりまーＴ会
カメラを持ってバッテリー切れちゃいました父は相談をして
こんなものがえー入っています
んでえーっとーま授業では毎回一つのテーマに関連して一個一個を用意して嬉しいサイズの方にえー二つをして
ではセット二と三人ずつのグループ目的は
で一以外の一人が答えると一人がビデオカメラで撮影だと
適当なごとに評価用紙に記入して役割を答え
んでこれは音練習してやり方はしてなくてえその時話し合った内容について作文を書くというのが授業中の課題あるいは宿題としてまして
ま二週間で終わった行くということを行なっていますので
と思っててもいるだけです
んで姉ま学習者の言語的な特徴というのを見てこう
えーそれからまこれはえーここ数年ではなかなか昔と思うんですけれども本当はその日本語の部分もおデーターとしてると鳥を起こしてえー
え総合学習と言うかそうしたことという両方ある程度かっていうのが
えーま具体的に解明できれば嬉しい
いう風に思って
それから大学生動詞の基本的前の発表ですで
あのー
そういうデーターって言い回答をないのかもしれないえー
えっと色んなその使ってるんですけれども仕事やってますので下手な使い方をして苦労していました
ビデオ撮ってますけれども取り敢えず今取ってるだけです
えー音声妥当誰が何をすると考え
あるいは三人に一つのマイクですので男子学生が二人三人でえーっと雑談戻って日本語喋っちょっとどっからどこが可能か
音声だけだと全く分かんないことも多いんですけどビデオで見ると結構あるとか
まーううもしかしたら将来的にその使い方ができるかという風に思って
でえー書き起こしをやってきて作業したんですけれどもファイルのサイズ大きいとか
数を使うのが難しいとかってことでなかなか学生アルバイトにする人も行けなくて
テーマ声を掛けて練習してもその中数嫌だってあると一の
方が続いておりました
でえーっとウェブのインターフェースを使ってえーまある程度おー大きく切り分けたものでえー書き起こし作業っていうのを考え今年に掛けて利用しまして
てようやくえー昨年度の授業をＨが一二分の一つのクラスについて一年二大雑把書き起こしができた
ような状況で
でえーまーあのー
書き起こしのツールでは分けてえ分布の方に盛り上げ
んでえーデーターベースを使ってもえーそれぞれの大学生というなことをやっていますで書き起こしごとに仕事が割り当てられ
でそれぞれの学生についてえーっと例えばテストですとか
あるいはあー四十二個高校の出身括弧一九七日とかあるいはアメリカにたことがある同一時間で暮らしていました
そういったデーターも取っているのでまーよくよく倍音が検索できる
ということを期待して
今の段階としてはえーっとまーあるテストで観点からなってんぐらいの人がえーこの質問に対してどうこうてるかそれは検索ができるようになってきています
えーっとー
ということでまー文法を使うことでま先程もえーっとー届けするみたいな宿だってれば
本んーうまくあのーんまー目を置いてきた方が良かったなと思ってもし悪かったんですけれども
て少しずつうー作業環境を用意して
んーと
であの光線の方が困難な運動をえーっとー何でこんな下手糞なあーお収録の資格をしてると
えー
こういうう一人一つの形のマイクで一人一つのおー例えばもっと奇麗取るじゃない
いう風にお考えなると思うんですけれども
一般書を一つに取材を持ち込んでまー設置してで重要なと次の授業が入りますので
全部一研究といったそういう時間的な制約はあります
んでえー現場でもその一つの録音して持ってって中にこのケーブルマイク用意して一でビデオ
えー昼休みに行って一日一四十分ぐらい前のて私と×と二人でできる授業時間は
父集の方はま慣れてくると一人で三四十分でえ主できる
ような状況ですので人数分のマイク用意するってのはちょっと厳しいというのが現実でした
それからえーっとーやっている学生が非常にやりそうにしてるのはまースポーツ慣れてくるんですけどま思ってて
何も自分の声が聞こえ方で
あれっと思うと
点数緑状態になってるので非常に変な感じがす
えーっと何となく追加のマイクを水とかってちょっといじってもう凄いですが録音されてしまって人が起こっています
一テープでまこれもあのー
例えばコンピューターウイルスが出ますので一つの壁に提示して
んで何かあー六音のツールで録音してファイルをおー八プロットさせるとかってことは勿論考えられますし
であるいはその試験音についてえーそういったことを試してみたこともあるんですけれども
んえーと学生のポスターに
私の最初の凄く不安で
ってコンピューターが出てると言っても約四つうーこういううーを使うとか後音の設定あちこち二の経験ていうところで結構不安
いえーようなことでま現状だ録音機のような感覚っていう時材料を使っています
それからもう一つの欠点はまーあのー先程申し上げましたけれども
自分の声が聞こえてしまうということで英語があまり得意で大学では非常に緊張する
でえー益々言葉だけでこうなくなってしまうところがありまして
えーこれをあのを
学会例とポスターセッション見てでつまりどは喋ってるので
自分が何かあんまり好き次第です
いうのがあのーまー
積極的に下手な英語で喋ってくれる人ときっかけになってるので
そこのところをあの自分のこういう聞こえることが縁から一秒だなという風に考えてえーします
んでえっとー周りは別の接続とかってことができるんですけど三十六番とか拒否とかちょっと考えるととてもコスト的に入れて
っていうところがあります
えパソコンあるいはあのー簡単なあのー整理いあのー録音一一一でのとするよう差はない訳ではないですけども入るのかひその他が
不安というような状況があります
二えーっとーでえっとー
後二三分で
えー
先程から
えー別の試験のスコアっていう話をしてますけれども
これはあってものこう同様能力を図る
自動試験というものがアメリカで開発されておりまして
えーこれについてちょっとだけお話したいと思います
で英語のスピーチの能力をそのコストをまー従来は人間の試験かっていう用意して被験者を訓練して
人の面接に対して二人三人の主結果を用意して
えーやり取りをしてえじゃこの人あこれぐらいの
後はっていう風な評定をしていました
でこの大量にある難しい例えば早稲田大学う受験者がえーっとおー
一万人一緒浮かんでくるんですけれども
これにそういう試験方法とてもてけないて機械を使って何かできないかというので
えーアメリカの方でこう文章というカイ二に挙げた会社がえー九十八年ぐらいで開発して
九十年代の水に目を付加してます
被験用紙を持って電話を使ってしておきます
えーしかも中身はまーえー印刷された問題を読み上げるであり聞こえてきたし文をおー
そのまま繰り返す質問に答える
と言ってももう
最後に改善される第一音えー
えーっとー野球を見に行くとしたらまー友達と野球場に行くのがいいかと共自宅で適応んー何か二ですかみたいな質問だけで
一えー六十問ぐらいありましてえー一分間で終わります
で被験終わる頃にはスコアが出てきて
六分でえ確認でき
えー英語のスピーチの五人力を測定しこれによってことをえ語の音を有効予測するというのがこの被験です
まーあのー構成できてるか否定文ではからインターネット数
それで読んでて
あった場合に繋いでとか家の放射能のえーデーターベースに送って一度ここに書いていますで聞くんです
えーま音声認識の仕組みそれから一母語話者英語学習者のおーするとえー
人間による書き起こしと思ったんですよ
言語モデルといったこと減って
えー後えそれを組み合わせて一個という
あって日本人あまり英語が得意では行けるってですが
実際えーまーえー二千二年ぐらい後ホテルで比較してみるとえーオランダの二十四歳の職業中学校の学生もすこう
イタリアの大学生対話のではどう法学部一ですね
いったような感じでえースコアの違いっていうのがま分布の状況っての人と
あるいはえーデーター非常に近いんですが若者も私立中学校中学生
高校生頭の方もえー
それから企業に勤めて一年前の社会と思って
ほいで比較ができる
んでえっとーこの試験を二千年頃に学生に行け伴ってま非常に難しく地球全体難しいんですけども
大量の自由を共ところが極めて難しいって言うのかって言うかそうで
日本語で聞かれても答える
えっとーこれはあの北米的な文化っていうところもあるんですけれども
人を書く時に形にその人に正面から答え
いうことが強く求めます
て日本語の場合話もそういう文化ではないということも
それから英語に慣れていないってことも
食べ方と言うとえー実験を決定とか意味でえー二つを使っ文に対しての一二の一日二日
それもっと持っているところもあって
で練習をしようと思って始めたのがこの音をえ手法きっかけです
てえっとーま音練習をした後更にえー作文をする
いうなことををやっていたんですけども
やってみたかったのは学生のコミュニケーション能力低いこれは英語があんまり得意じゃないか一ではなくて友達が作れる
知らなかったんですけども二千年以降の大学生っていうのは
共存中に入って中学にえー入ってたまたま側に座った学生からすると
それ以外の学生と人間関係が殆ど披露
ということが分かりましてショックを受けましたでこの事業の方では毎回座席配置を却って組み合わせを変えてえー
から三人のえーシステムをすると
っていうことでこのことをやるとですねあの出席率が向上し
クラスもまた雰囲気で位置にあるという
でこの事業と全く関係ない方もいるんですが
こうしたところが大きくえー変わってきました
でえー一年生の地形えー学生に対してえー保障をしているえー一一発話ですが
三十分で四変更部分が企業
一週間てまーか考えの方百ページとか後二ページくらい読んでえー
で後もう一文に取り敢えず文しかも英語で答えてるの
て使用人数でその中でインフォーマントにえー本発表でき
というのが英語の話なんですが人の顔を見てにこやかで話ができるよう一日
クラスの中で友達ができる
であるいはコンピューター教室で毎週コンピューターを使ってますのでそこが使える
こうならなかった場合はどうと人とえー
んなくてえー
うじゃ時間が必要ですので取り敢えず
発表終わりにさせていただきます
#############################


#############################
# query = えーそのー間の一でそのー頭部の中でえ二つのそのー単語のアラインメントの方法として間に新聞いっぱい法と何かもう一つ歌い方の説明があったともんですけどえーそのーそちらあのー数値三十分一杯方のそうする式についてでよく理解できなかっので分かりやて乗せていただく体のその今
# rank = 2
# slide = 08-15_fix.match_word.jout.txt
# value = -1.93242807798632
#############################
とそれではえー肯定音声認識の為の上文章を用いた言語モデル適応かと思い選択という題目で
山自体は二音が所が発表さしていただきます
と発表内容はえーこのようになっていてえーまず研究背景研究内容説明とい言って
えー内容のウェブを利用した話題適応化
語彙選択についてで最後にまとめ
えー今後の課題です
えー研究背景ですがえー講義音声を認知する為
の言語モデルとしてえー講義音声は話し言葉なので
ＣＳＪ日本語話し言葉コーパスを使うということが多いと考えます
しかし飛行機のように特定の話題を確立された内容の八巻はできません
その為にえー未知語率が高い確率が高いということがあるので音声認識率がえ低下してしまいます
そこでえーインターネット上にある情報をまーインターネット上にある情報が容易によできること
えーに着目し
講義の話題に
提示さページをうまく利用性は認識できた場合は学習できるはないかと考えました
えー研究概要ですね上を用いた言語モデル適応化ではえー文書を集める為の検索例について調査しました
検索利用者の注意をして
え調査しています
えー言語モデルん
でえー認識時の語彙テントの検討では
特定の値を認識するのには
えー必要なものは最低であればいいということで
凄いよくや制約逆に入り易くなっすることで認識率の改善を図りました
ではえー
適応化の概要について説明します
まずえー
ね対象音声を認識システムによく正解認識結果を得ます
本当記事をする元のまではＣＳＪからが指定しています
次の処理はえー検索
認識結果が
検索家を構成しウェブ検索を行ない
上文書を生成します
えー検索に
はえー認識結果二の名詞からえー
え名詞を利用しています
また上文書にはＰＳまー本当が含まれている為に
えーそれらをテキスト化する
えーＨＴＭＬファイルはえータグ除去するなどの処理を加え
設定します
そして制限した上文章を使って
えー言語モデルを適応化し一応ま言語モデルを作成します
最後に適用の適応までのモデルを使ってえ再び
えー音声認識を行ないえー最終的な認識結果はいます
上の検索に用い駅が後はコーディネート認識結果から抽出しています
合計名からはこう一名の名詞にしてからは
法律名詞複合名詞を抽出しています
えー孤立名詞は名詞一二グラム団体の名詞で
複合名詞文名詞バイグラム
多数の名詞を使用しています
これらからえー二種類の中八月一日をえー
付けています
一つはこの
こう奇麗な名詞と孤立名詞のＴ私の
もう一つはこう奇麗な名詞と複合名詞のキーワード集合です
えーとこちらがえー孤立名詞
あー
そのー
これ爪視野が充実してる孤立名詞の
ね非常になります
えー
途中数の条件はえー
頻度Ｎとしてえー最大頻度Ｎマックス
上で流す分のＮを算出しえーそれが〇．三以上のものはえー歳
えキーワードとして採用しています
えーとこれの三見るとえーとープログラミング入門
にはえー数値計算えー
えー線形な性格うーのにある
どう見るとおえーっと音とか
えー人とか
ちょっと
こう人は関係のない
単語とか
元にえー効率名詞ではえー
含まれています
と次に複合名詞のえー
とおー記号です
えーこちらも同じくえー振動はえー
えー最大頻度Ｎマックスとし
上のます分のＮが
えー〇三色んなものを採用しています
その
名詞バイグラムの場合ではえー
えーと頻度が高い
ものにじゃ
過去に関係のある要は
え頻度の高いいー
えー
頻度が高いです
と次にえー検索
現在の方法について説明します
選択を主に使用しました
まず一若干の検索
多分聞いあの使用してやり方です
とこのような気がするのがあった場合
まず治ったんで検索し
えー上文章を収集します
次にえー言語でえー検索
とー文章をえー追加してきます
ついえー収集した文章はえー設定を行ない学習データーに変換します
もう一つのえーやり方はえー同時検索同時に複数のキーワードを使用するやり方です
どちらの精度を一遍に使って
あー選択し
上文章は生成します
収集した文章は同じって成形して学習データーに変換します
と次や後二
前のキーワードを
を使ってえー道への検索を行なうので
検索例が四つになります
こう決めた効率面ちょっとずつえ要するにラムスアンド検索
合計名と複合名詞を一つ釣りをするまイスラム単独検索
方言えーと効率名詞を同時に
利用する
えーよりあの当時検索
×がえーコーディネート複合名詞を同時に
薬をすれバイグラム同時検索の様子になります
と次にえ適応化の方法です
と適応化はまずえーあー
とＣＳＪの学習テキストウェブテキストの集合をそれぞれからＮグラム頻度
えー算出します
ただえー二つのＡくらいの頻度を重み付きでえー足し合わせ重み付け混合音
そのＮグラム頻度を出します
えー
ＣＳＪからは
えー二万単語の上り
フレームでしたからはえーっと全語彙を
えー前後の
語彙いー
後五回の作りえーそれぞれを
なる
それらを使って
それらと
混合した五グラム頻度使って
適応が元のモデルを構築します
まーそのーまたえーこのいーですが
とーさまざま場合この四つの名前が考えられますが
えー
今回
今回は全てに対して行なっています
評価実験ですね
評価実験はえー実験音声は山梨大学工学根底になる訳分から
のデーターサイエンスを正解とされた四五六のものを使いました
音声認識してはＪｕｌｉｕｓです入れたり以上の三．五．三です
音響モデルはえＣＳＪから学習したあトライホンモデル
んえー一二次元の
えー
え名詞一ΔＭＦＣＣ
ホテルだΔＭＦＣＣ
とえー一次元のΔパワーΔΔパワーの三十端点です
評価項目は
単語正解率
えー単語正解精度名詞正解率です
とＡまずこちらは大人他の言語の結果えースポーツま他の言語は
えー
でえー使用されている
総単語数が千三百
六十四単語です
でまずえーこの表をアグラフえっと一番自体が
ＣＳＪ適応化前の結果で
えー
その中であその水が二年三度検索×らの単独検索家の同時建設×アンド次元削減の
適応化へのまー適応化の結果です
えーっとまず
ＣＳＪ教科前と
えー適応化したもの全体を比べると適応化することになって
えー
認識率が
全て海前されています
えーとー
次にえーっと検索地方の比較ですが
アンド検索と同時検索
を比較すると同時現在の方が
えー改善され認識率が高いです
とーこれは
あのー
何度検索
の場合え単語を一つ一つえー使う為に
検索けっ検索の際に曖昧性が生じてしまう為
えー話題とは関係のあり方が関係のない文書が多く集まってしまっ
いう為だと考えます
と次にえーキーワードの
キャベツが
揺らぎとバイグラムでは
えーバイグラムの方が
認知率が高いです
とーこれはえー
どういう五グラムの方は
んー
先程のあの表になっており
えと採用されている世の中に
話題とは関係ない
ものが入ってしまうことを
とえーま
がある
というのと
んバイグラムにすると
えー言語的制約を取る分野えーま
と関係ないものな反応ができるので
販売えー名詞バイグラムの方が
より
関係のある
分野を
ま文書集めるのになってきていると考えます
変わったえー未知語率とパープレキシティー
ですが
て評価することになって
大きくうーされることはできています
次にえプログラミングにはまー
えこちらはえー相談にそう単語数は二十一が一番いい音声の約四時四単語でした
あーですええ
とこちらの
適応化することによって
認識率は改善されています
えーまた
この上毛まー
えー当時検索の方が
その結果距離の文認識率が高いです
またはいいなと×らの比較でも
バイグラムの方が
んーより改善されています
道のりとパープレキシティーですが
えー
二十リストは名詞があ一番
避けることができたのは五年当時検索
なっていますが
とこれは
えー
いう五グラムうー後あの
四四グラムで採用先がかつてそのーが多かった為に
えー検索される
文書数が多く
えー
他為に
未知語率試しは変わっています
しかし
明確でない文書は
後
単位に
認識率の方はバイグラムと次元するのが
高くなったんじゃないかと考えます
と次にえー線形代数約一
この時は
えー外まつわる
六千四百四十七です
えー
で
とこちらの
この方言の
えー適応化することによって
に結果が改善されています
男の子いわゆる当時現在のが
音二四つが一番改善されましたえー
これあのーまた
えー未知語率が嬉しいも
いうの事件が一番
って言います
実はできできていますができるんですけども
ところの×です文書数自体が
すバイグラムバイグラム当時検索に比べて
僕収集できたのに
そのーこの講義ではいる同時検索が
一番二比率が改善された
されていました
と次にえー数値計算法です
高齢化の方にはえー午前三百八十四単語ですです
えーこの方言の
音適応化することによって認識率が改善されています
とーまた
えー
三つ四つをまクリスティーは
言える同時検索が
一番実は出てきていますが
認識率Ａの方はバイグラムと実験ですが
えー
一番改善されていました
えー
あのー次に
んえー語彙の選択についです
どうにθを改善する為には未知語率をされるということが考えが
またえー同程度の未知語率であれば児童言語モデルの語彙サイズが小さいものの方が認識率が高くなります
えーそこでえ適切な語彙の選択肢じゃなさいとできるだけ小さくすることで二四つの改善分かりました
とまずえー
えー語彙選択することによってどの程度
でにんしえ高い認識が改善するのかということを調査しました
これは
後適応化したえー言語モデル
凄い八五二英単語以上
から
えー手動でえー正解単語のみを選択し
えー
ね
手動で前
で正解単語のみを選択しえー二実験行ないました
猫の適応化というのは×らの同時検索うーでの結果です
えー
二つを選択でえー
正解単語のみを
選んだ結果なんですけどもそれでまーす
父の固有の
認識率が
改善することがあー単語正解率
に正解率が
設けるえー改善しました
と次にえー自動で
んーん語彙選択をする
語彙選択を行なう手法の検討を行ないました
えー
手法一はえー上文節の命でした
ＣＳＪの名詞以外の単語のみの辞書に登録しました
地方には認識結果の単語と兄が音韻の単語のみをあの医者に登録しました
手法を三は認識結果の単語と同じようになっ単語のみを
登録しました
ねここで言うようにな音韻というのは
えー
認識結果と単語辞書を
の
元の
そうで二つの単語を一化する際
そのー
単語の単語の音節列を
包摂ですから
えー子音をな雑誌
母音母音列に変換しその母音列が完全にするものを似ていると判断しました
同じようにというのは
えー
七月の
音節列が同じ完全にししたもの同じ音韻
という反応しています
次にえー
そのーそれらの手法で行なった
実験の結果です
えー
えーまずオートマトンと言語なんですが
そのー
認識率自体は
の
手法三三名正解率がじゃ段階でしていますが
それ以外は
ほぼ変わらないという結果でした
またはえー
二十リスト語彙数の変化ですが
手法一え手法にえー手法三と
えーの順番で
え語彙数は
低下しています
また地方さんでは
資料三では語彙数は元の語彙選択した場合に比べ
えーとー一パーセント以下のね
材料とできています
いたし役に未知語率Ａの方はえー調査をしてしまっているんですけども
の四
赴任し
していますが
とー
認識率自体は
後大きく悪くなるということも
ありませんでした
次にプログラミング入門の結果です
動物であーのー
えー
手法に手法がこちら手法に手法さんで
名詞正解率が
えーと若干こちらの若干改善されています
また
えー
未知語率と語彙数の
変化の方では
こちらのえー手法さんで
自分約一分の一ぐらいまでは
えー
語彙サイズを
非常する場ができました
しかしこっちがまーえー三中央率の方は
の上昇をしていて
していますが
まー
と認識率が悪くなるというもの
生徒は
ありませんでした
次にえ線形大学一です
えーと
このこのＤでは
父は手法一手法に手法さんで
に正解率が
改善されています
んでえー
後三時をリスト語彙数
の変化の方でも
この語尾の手法三
で
十分の一
ぐらいまで
語彙サイズは
く喋っています
でまた同じように未知語率は
変わってしまってるんですけども
えー認識率が悪いということはありません
四月四計算法ですえー政治経済面では情報たんで
単語正解率
単語正解率透明性が一は
向上しています
えーあーのー男性が一度も若干性能向上しています
でえー
やはりこの方言を手法さんで
大きく
んー語彙数を
食べることできています
んーで同じように未知語率が徐々していますが
えーんー
認識率が悪くなるということは
ありませんでした
えー
とこの手法三でどの語にも未知語率が徐々していると言いましたが
これは
この四月あのー最初のＣＳＪのものよりも
高い
ものになっています
しかし
えー
このようにえー
下がるということもなくうー
むしろまーまたあー四十二よりも高い上
えーと適応化
ど同じ程度またあーもしくはえ少し高いぐらいの
結果なので
語彙選択えー
過ごしたいとされるということは
まー
二型の方がないかと考えます
とまとめですが
増え文章を用いた言語モデル適応化によって
えー
認識率は回転しました特に正解率は大きく向上しています
語彙選択の検討では
えー適切なあー語彙選択することで認識率若い人であること分かりました
認識実験ではえ若干の改善でした
その方の手法でえ名詞正解率が最大で一二パーセント改善しました
理想的に行なえれば
二十六から二十二パーセント
の改善が期待できます
今後の予定は語彙選択の検討を進めていきます
そのー言語モデルただ
今考えてる訳のでの学習の選択する程度です
例えばえー不要な分
を削る
あー
そのー五二はす
母音の
文選択して
いるので
の学習文の中に
未知語が多い文というのができていいいるはずなのでそれを削る
えーまたえー上文章
収集した上文書ながら
我が校とは関係ない上文章を除いていくというなことを考えています
発表は以上です
#############################


#############################
# query = あのー一って言いを使っえーと水を使って三四五八認識誤りに対してえー対処するっていうんーもう精度を決めそのーまーでえっとーおの公園があったと思うんですけどそのーえーっと確かは一って言います方でえ連続ＤＰます新婦っていうのがあっでそれに対しでそれが時間分かってしまうっていう問題はっていう立川さてこういうだけを使ったえーし知恵ので手法っていうのは示したいとだと思うんですけどそれについてのそのーが知りたいです
# rank = 1
# slide = 09-02_fix.match_word.jout.txt
# value = -3.02382343315512
#############################
んー中で四十一個ないし
えーっと未知語に頑健な音声側面と検索手法の検討というのでま一般的な考え方を中心にですね最初
言ってですねえーそのような実験結果を評価すると
んーです
ま特に音声を対象とした検索で
非常に難しい問題というのはまー日我慢ですね
少年に対してどう検討するかというのとまーしかも細くやりたいという
それな考え方で六の考え方が
発話条件としていきます
まこの研究の背景と目的とまー
殆ど常識的な話なんでんまー二として
まー
海流の音声データーに対してえーえ高速に検索したいということですが
まそんなイメージであのー運転してはなら途中で生じるということででどうするか
あるいは未知語に対処するかと言うとですね
はテキスト検索の場合は内語というのする程まー問題にならないかもしてますけどま音声認識の場合は
んまー二十吸収してもえーえー二本
何万語とよくまー本
たとえ登録してもですね未知語が一匹
んー結構多くなるとま特に検索したい単語というのは
考える一応多いとかまそういうあー報告がありました
例えば検索するうー知られたもの家のですね
まー三十パーセントか四十パーセントは未知語であるとか
まーそういう何で
非常にこう固有名詞とはですね
そんなね普通の単語辞書にはないようなあーものが検索対象であると
いう方法です
適応に解釈をするかと認識誤りんえっとす
んー
電車がまー例はまー三種類普通はありまして
んー
例えばあーあーこのフレームカウントしたらですね
んー
挿入誤りとかあー
常
んーそれとあー
んー
一回ま一年
んでえーっとまーあー
まー問題だっ脱落我々がまこれはまーあのー音節列で認識した場合の話なんですが
二．五回の場合には単語間での挿入とま一時間とか脱落形なんですが
ん自分に対してはま音節列
ま一つはですね
本節別で認識しようということなのですんその前にはこれら三つ誤りの対処しました
で先行研究についてはどういう風な解釈してたかと言いますとまその後楕円で認識するということの一つはあの未知語に対しま例えば二万語対んーんとか六万語の大語彙でえー認識して
それで並列にえー砂漠化んえーししておく
えー要するに
でそれももうあのおー結果に対してはある訳ですよね
ある油を表現
から高校一ネットワークのえーネットを読んでなど色んな表現をあるんですがまそういうな認識たり
対してえー検索を行なうと
いうのはいただける怒られているんですがまーこれには
二表現にしてもですね
かなり
認識えーこの
表現の中にえー認識結果あー
正しく入ってなかったらやっぱり予測できないというので
そういう音が脱落おー考慮した表現になっていないということになる訳
まそういう問題に対しどうするかということで合計属性を二つの方法があるかなと思うんですね未知語に対しては
んでまーこのショートの方としてはまー大語彙音声認識しておくということ
それでえーまーこれ理由があっ一言あれば
まーこちらで検査をするということで
それが
あー未知語であれば
その前に実は六万語の辞書にない場合は
その音声単位のあのー認識結果に対してえーその一つ
そういうことになっ
ま同じようなあーま構成ですがあー少し違うのは
えー
例えばこういうををですねえーまー
んー保たれてサーチすると
いううーこれ見つかればいいんですが見つからない場合は
この結果をおー
こう大語彙の単語単位の認識結果ですがそれをその道の手術置き換えて
この川口連鎖に対してえ三十
いうことも
考えます
でそれでも見つからなかったらその途端意識しておいた結果に対して
その読解の集中する
計算すると
まこういうな考え方もあると思うんです
ま我々はどうするかということですあーま基本的なまー
先程あのーまー
二つの方法をとあーあるいは見てですねまーまー大語彙音声認識して用いるって
二十一本あればこれがですね既知語であればこの結果に対して検索すると
んーま基本的な考えは一緒なんですが
んー
未知語であればですねあのー音節認識結果を出してですね
でそれに対して検索音節列で検索して
方法です
んでそれでですねあのー
二音節で二十一結果が大聖堂は曖昧なあんーでまー検索結果の方はたくさん出てきますので
んーまー性別のま一二三分の一ですね
それによってもう少し精度はえーっとえーこの
木の候補から絞り込むと
えー四年
てえーし最終的な結果を出すという構成します
んーまー調子に考えればですね
やっぱり既知語に対しては大語彙認識結果
を使う方がいいかなというのは実験的な考えでやってると思っ
ま全てのおー一語であの未知語であろうは全ての単語をですね
その後は個体の認識結果で計算上ではちょっと無理かな
多数の研究もあると思います
んーそうでおります
んでえーそれで高速に検索する為はどうかという考え方方法でちょっと考えていただけたらですが夏はこう置換誤り挿入誤りと
いうような
系列うーうーがあるものに対して
高速に検索したいと
いうのは音声とこれの問題だと思うんですね
で二つのＸあれなんですがあーまここ浅草と砂糖だとかなっているえー行ってるんですが普通まーこういうな
朝行く数をおー二種類にえー
何て言う訳ですが
えここで考えたトライグラムを真水メールを検索を単位としています
んー趣味を
そういう名前はあーこうまー一つ二つの検索者というのを作成えーっと尺度をするんですね
凄く
桜とかあーまそのの五分類
一音一ずつずらしながら
湖いーのですね
えートライグラムを作って辞書順にソートしておくと
そういうことなんですね
これはまー認識結果そのまあー
正しく
うーできておれば問題ないんですが時間
挿入
んこれはまー
えートライグラム応答を表現するか数字同様音するだけの話です
あー少年は〇脱落のん丸一からなる場合どうするかという話になる訳
んー例えば先程えー挿入誤りこういうやり方でいいなとかですね
えー途中そういう何か気になるとかあーうーきああーんん脱落するとかそういうな
時にどうするかと
いう時には挿入誤りに対しては
ん認識結果をですね脱落をまで考えて
えーまーその挿入と仮定されるま家庭というのは
システムには分からないですから全ての
包摂を挿入誤りとかですがですね
でそれを満足させてトライグラム作るというように対処し
一個
んで時間の理解してはあー認識方法をスリーベスト女優さんで様でえー併用してえーま対処するとまそこにモデルとどうするかというものはですね
女優さん
高校に入ってなかった場合も対照的なとこもあるのですが
ピッチを利用したよそんでその頃演劇
テンベストという本ができますけど一応その子様
ということしてますね
で脱落誤り対象に刺激結果に四音節んがあー長くしてしまったまー言わば
声の方を脱落させて
検索する
んそういう風に考えてえー私一
そうすそうですね
この挿入と脱落を組み合わせのは語彙認識結果が出て
本当食べさせる
これいい例うー形をさせると
んー
そそうねあの主結果でそんなことしてトライグラムとそこの三年月
こういう数これを組み合わせると置換誤りにも回収できます
まそういうな方法うー
んー例えばですね歌えると言えばま一つはこうやって後はですね
ここにあの誤りがないとした場合はこういう一応接続をしましてトライグラム作っていくんですが
こう注射一
んー二つ落としておけば高速に検索できるということでま一日で年収をなんですが訳です
検索では
それを挿入誤りに対しては
とま例えば手掛かりをする為にまー
これが挿入誤りと
仮定するとですね
まそこ音楽をさせた
こんな人というのを考えるという有名です
だから二んーの
空気中のまそんなのも一応登録しておくと
いうことで
で時間あんまり大してはまだうー三五まで考えていますからこう
んーやり方で参考までに入っておればあーこの首が想像されると
いうことになり
本当の方にする数が
ま増えますけど
これでえー解釈できる
六
もう一認識結果に学の本があーあった場合ですね
はえーと例えばフーリエが抜けていたとか
そういう形が脱落して認識されたとかねそれが場合は方法二つのえー理由を出すのさせて
いうことで対照表
いうことでやっては
んでそうすると今三つ目ですからあーんんもう少し長い単語の場合どうするか
んー五音節の単語とかですね
んで女の音節単語とするとま湖のおー
うー組み合わせで考えると
例えば五音節の場合だったら形態素だったらって言ったというですねえーっと階層というですね
これで検索して
不良共開かれダイエット
いうことですね
歩行えあー
んー五文の組み合わせで単語を検索すると
いううーので体長
テーマ
でメモリー量としてはですねえーどの程度いるか
あるいはこれのグラフが三グラムですけれどもトライグラムですねで音節数が九つのコース
まー参考まで考えてるんですがそういうのまで
そうします
そういうようにしれた事象情報検索対象の音節列で表わした時の清掃
下のえーっと人ですね
んでまー一つのえー行なう必要な面も三理由を言ってやると例えばですねまーこれはまー一六バイトであれば
あー一つの登録ができるとしてですね
うー全てのおー目盛りはこの程度であると
いうことなんですが
もう少し具体例ではあ奇麗だの方に音声で
必要なああいう要領というのは二十四メガバイト
んー根がバイトぐらいで
まー音声ファイルよりも少ない
という程度でえー表現できるとま百時間の講演音声であれば一一．四が
タイトル
ん何でそのー実際温泉はいるうーと比べて
まーそういううー数も少なければ問題ないである根本的な問題ないだろう
えー
思う訳で
本当困難でえー後とですねちょっと曖昧になるのであのーうーのおーまー検索されます
それを主語ということで文章って言うかといったまーあのー歳の
あーこの入力系列というのを先生です
ま今音節というお単位でんん言ってまして話者訳ですしね
それで町です
えーいうことをやって×まこういうな傾斜制限であって
ただまー本質的にはまーあー二つの言葉挿入というのはあまりゆ許すと
ですねえーちょっと
んー
制約をまー有するもので
報酬ペナルティー与えてます
そうねとか脱落
に関してはですね
全くそれともう一二ちょっと考慮する一つの脳があるのはあーもう一入力としては母と喋ったと今になってしまった
これが脱落してしまった場合ですね
ま二うー
ん奇麗な町で距離を計算しえーこれとこれのてるとこれのこれを重要警察んですが
がちょっとまー作って
この大型の閉じたままになったというのあー
こう形になったということを解釈すれば
本当マンはまよりですねしてこれとこれを計算するのこの後のを計算するというでして
角がいいかなと思って
ちょっとそれは曖昧ですね
五万も集合となった場合
これは実もそれ計算してもいいけども
この本当こ計算するならばえーこのおーま分かれたというレポートといっ
えーうー距離を計算するとまそういうまー修正をする人は
いうことですね
でその距離のおー定義ですけどこれはまー形あるいは注意を使っていますまー音声をの音響モデルの音響モデルあーまー多次元
正規分布に表わしていますけど
その子同士の距離
えー
包摂だなっていう風にしても
んーどういうあのーんー
えー
集約します
まこれはえ一例です距離あのー音節間の
距離ですね
これがないじゃを使って音節四文節同士の
んー
おーっていうでえーす
んー元のえーえー
たくさんの方を絞っているという
それ声の方でどれだけの能力があるかとちょっと
おー考えてみようという二つのお前半ですけども
そうですね例えば三次元境界が三音節を考えてるんですが
後まー全てただしえではこの三つ目としては正しくえー計算されます
それともう一つの持つ方法のまーここままあー間違った場合ですねで次は楽しかった場合
まこれはまー挿入誤りとか
ああですね置換誤りとかま色んな誤りが違うはですね
ん脱落思うかもえーやりましては女の人それが正しい文
あのこのここの場所間違った場合この場所の一名前とかま色んなパターンが考えられます
で何をんんん御説明ししましたあーまーあー対策ですねそういう形です脱落誤り
解釈
中間生まれてしまうというようすれば
まーこういう言いたい対処できると
んーそうですね
んでそうするとそのような形でまたそう行ってですね
えーでえーっとＡＢ理由を色々変えんーそうですね怒らがｐが明らかに対応するんですけど
精度でして上の兄が四は
例えば九十パーセントなれば
んー
正しく九十五パーセント
検索できるとまそういうことなんですが
もしかして音節の認識でですね
あー九の四十おーおー
現われとか八割というのは非常に難しくて
んー
んまここらあれができれってもこの程度であるということですね
まーこの一．八つから後はですね我々が提案しているうーの誤りです認識誤り対策を一文でトライグラムで高速に検索すると
いう方法を使った時のイチゴのですねえっと分類手法ですが
え純音を検索精度
二十一世紀
んー実際にま日本の実験やってみたんですがあーこういう音声に対してですね
んーやってみたんですがまずうーうーの音節の認識精度これは多分いい精度がどので得られてるかとちょっと
あーのおさらいしますとまー朗読音声ほいで夏のうーデーターベースなんですが
あー単語認識率
てですね二万単語の場合ですけどあの登録単語
すまそんなうまい訳が四百九十三パーセントとかコレクトである九十五パーセントぐらいあればですね
丁寧に読んでいるというような音声に対しては
で音節別の認識に対してまー気がし八十三
本節うえーそれで育った九十三パーセントぐらいとか得られません
でこれを飲まれるとですね
うー問題なくうー計算を用いると明治八十三と書いたんですが
怒らないんですね
方法なんですから未知語に対してもですね
んー
かなりです
検索できるという話なんですが実際の仲間難しくて講演音声になるとＣＳで
あーの講演音声になると我々は抽出例ですけれども
単語対Ａでの認識率最後に四音節の音声認識で
七割弱ですね
これで七十三パーセント
本節で三月まで考えても思って
ってとこな工業ってなるともっと難しく
いうをですね
でこれをですねあのー電話も五六十パーセント認識
本節でもおん農村部するベストを使ってまーちらしで六割ぐらい
二．七割ぐらいですね
まそういうなことでで挙動を思い出して後ですねあのーこれ評価実験あのこれ方法にもこれをやってしまったんですが
もうちょっとんえーっとあー
精度の良いいい結果を使ってある方ですがこのえー認識結果に対して一本えー特徴としては
そう酒は一が悪い訳なんで
先程振り返ってみるとこれ理解をします
また未知語に対してま半分ぐらい検索できる可能性があると
いう程度なんですね
でそれでやってみました
まそれがこれが結果ってこれ適合の場合
他の講義音声大衆きま聞き方であります
で九州の三十一語をおーまあーのー何かが出てきますからあー述べ四百五十八語ですけど
ん九十五に対してですね単語認識いい結果データーもたいけどまーそれはまー音節別に変化してからやってんですけど
ま考え継続しても音節別に変換してもそんなに変わらなかったですね結果として
まー再現率八十七パーセント適合率九十一パーセントとして
ま講義音声で
んまー結構おー
今日です分かったんですが
んー
んー五十六パーセントとかね
それで何でもま九本当はカウントして認識されていると
公園や
例えばこう上でですね
こんなのがあったという正しく認識されていたということに対応してると思うんですけども
まこの程度だったという
でそれにおいて未知語に対しはどうかというはですね
で未知語に対してはあーことが一型とは感激とま仲間と
まこういうあのーはあー辞書に登録されてなかったですでまたあのー
でこれの四十五種
七八五一
娘に対して検索実験をやったと
いうほ
んーまーあー三名のんー七十分ですかテレビ六十二
あのーこういう音声に対して
計測したらですねまこうたんーなったと丸の三が五十個あったんですが検査語でから七十一項というので
大体半分じゃっすね
うんだからまこれも前かもしれないけどこのまーえー予想と言われ季節
先程の
野球の四が
んー情報は約四十八パーセントという人もいたんですけど大体一致してです
んー四十年のま分です色が一致してまこれたまたまこのし一つは
もしかしてですね
えーっとちょっとおーおーおー検索をおーすぐですねしかしんー
経済もあるしまー離婚はあー
んー卒業できるとしてページのある
でそれでえ今の方法でまあ色んな会社をなくしたんですが元々対策なしと挿入誤り対象に近い形でそのー脱落誤り対策
んーまそういうあのー
九文音声の方が第行って全て使ったら
この人が四十七パーセントであったという全て試合が
非常に笑って三パーセントってま非常に訳だし多いと
でその理由はっちゅうので
で減らそうということでやっとですね
年々まー
砂糖百五十五に対して
んー二千歩以上えーすされているいる訳で
でこれを減らそうということ
んでこれで一あったのはまー経験な中のでいると一回であるとまー妥当なぐらいの数字手法があー一番上ですね
こうこれぐらいで二百八十六合計数
だということでえーその女性がまー四十から
ということで
まー
えー実際に計測したかあー中五百五十五だったので最終的なリコールは
でえー三一
で知られていて
まこういうされて
まーちょっと検索対象という気が誤りの多いものであったので
まこの程度で終わったということですね
発表の音をあ今考えるものも結構あのーもうちょっと名詞性という
最初であれば行こうかなと
うーえっとー
なのかと
えー
二以上
んー
#############################


#############################
# query = あのー一って言いを使っえーと水を使って三四五八認識誤りに対してえー対処するっていうんーもう精度を決めそのーまーでえっとーおの公園があったと思うんですけどそのーえーっと確かは一って言います方でえ連続ＤＰます新婦っていうのがあっでそれに対しでそれが時間分かってしまうっていう問題はっていう立川さてこういうだけを使ったえーし知恵ので手法っていうのは示したいとだと思うんですけどそれについてのそのーが知りたいです
# rank = 2
# slide = 12-10_fix.match_word.jout.txt
# value = -3.09794306713748
#############################
えーそれはえー複数音声にシステムを併用した
えーお父の作品にある
検索性能の改善と題しまして
えー定式近く大学の駅が未決定が発表さしていただきます
えー
えまず全体流れはえこのようになっています
えまーまずえー研究目的と背景ですが
えー
音声を含んだえーマルチメディアコンテンツの増加に伴い
でこれら功利的に検索する手段っていうのがえー望まれています
えしかしながら
えー
えーこういった音声を一つで書き起こすということにまーが非常にこう差があります
そこでえー音声認識システムを用いてえー自動的に書き起こす必要があります
しかしながらえー自動で書き起こした結果にはえー認識誤りが含まれていまして
で更に大語彙連続音声認識えーでえー認識した後には
えー辞書に登録されていない単語一語
がえー書き起こされないという問題があります
そしてえー更にその従来手法であるえー連続ｄＢえーではえー長時間の世界に対して処理時間に問題があると
いうのがえー金銭の問題としてあります
えーこれらを踏まえてえー目的として認識誤りや未知語を含んだえ長時間の音声ファイルに対してえー高速な検索手法のえー提案と評価
というのをえー挙げています
えー
そして
えー今回の発表ではえー特にえー挿入脱落この距離のえー緊密化とえー複数認識システム併用
でこれを用いたえー性能の改善にえー弱えー着目しています一
まずえー概要ですが
って英語音声データーから英単語を検索したいと言った時には
え一般的にはえーとこの音声データーをえー自動音声認識
でえーテキストに書き起こすと
でそれを
含めます
その際にえーっとだいぶ連続音声認識でえー認識しまうと
ふえーま
んー
ん辞書に含まれていない単語が認識たり強くされないという問題があります
えーそこでえーさまざまな研究でえー行ないできるのはえー単語単位の中でえーそれ小さいさまざま単位でえー認識をして一つに書き起こすといった方法が取られています
ふん本研究ではえー音節認識を用いてえーテキストに書き起こします
えこのようにえー
音節認識することでえー後子供に必要ができます
しかしながらえー認識誤りの問題がありましてえー置換誤りや
え脱落誤り
そういう誤りといったものがあっあいあります
一としてえー検索の従来法としましてはえーまず一般的なのがえー連続ＤＰにあるワードスポッティングが挙げられます
とこの他にもえー作品を用いたこの先されてはえー単語集合を用いたえー単語数といったものが挙げられています
本研究ではえー朝までの距離月のという
方法を提案しています
えーとステートにもえ人優しさをえーす
え話者照合について説明します
へ我々のえーシステム内容がえーこちらの図になっていまして
えまずえーユーザーからえー検索語がえー適当で与えられます
そしてえーこの検索語がえー未知語が既知語がえーのえー判定四大語彙連続音声認識の辞書を使って判定します
ってもしこれがえーっと未知語やった場合に
えー音節認識からえ予め作成したえーと五月の作品
こちらからえ音節単位で検索を行ないますえー
そしてえーもしえー既知語であった場合はえーそれに加えてだいぶ連続音声認識結果
えーを用いたえーと単語単位の検索
こちらを併用します
そしてえーＮの索引の構築の方向をえーここで説明しますえ本研究ではえこの犬なのＮをえー
三としましてえーとー音節のトライグラム
こうえー作品としてえー採用しています
船の索引がえー一つですとそのートライグラム
の映画でえー構成されていまして
各ポジションで
えーっと例も作っていきます
そしてえー作ったこれらを
えそれに相当しておくことでえー高速に検索が可能となります
そしてえーこの作品からのえー検索方法ですが
えーこのえー検索語がえー例えば
二二という検索別れ際に
えーこれをまずえー複数のおトライグラムに分割します
えー
そして
えーまーこの場合ですとえー二三というそれがま特に家という二本トライグラムに分割してこれをそれぞれえー作品から検索をします
そしてえーそのそれぞれ検索結果
からえー出現数連接を確認しましてえー言説が確認できたものをえー最終的にという風にしています
えーそしてえーと認識誤りに関しましてえー探索を行なっていまして
えー
我々はえーどっちかうんそういう活躍する前出して探索を行なっています
えまずえー使われただけではえー認識以下のえ複数の候補上位Ｎベストを用いて
トライグラムを作成してえ索引を構築することでえー対処しています
また
えーそう山高く
ではえー音節を一つ側さ三つ組み
はいそれでも作成して索引登録すると
いう方法で対処してます
そしてえ脱落誤りに関しましてはえー検索の際にえー
検索語が書かせてえー検索することで
えー探索を行なっています
えーそしてえーまー
これらのえー認識はま探索行なうことでえーぼけ画像化してしまうという問題があるんですが
これに関してはえーその認識誤り探索をどの程度行ったかという情報を
えー距離としてえ索引記録することで対処しています
え実際にえー例で説明しますとまず使いあまり高くはえーこの例ですと認識
こう頭にし結果のえー次ですあまり
をえー使ってえさまざまなパターンのトライグラムを構築していきます
てこのようにすることで
えー新しい音節があこのツリーですに含まれていた場合にえー力の人達できるといった方法になっています
でこの時の距離というのは
えーこの場合ですとからのえー距離で
えー×できるよう使ってえー定義しています
えー
そしてえっとー次にえー住んだ二百の作品という別の力価格のえー元さ手法としまして
先に説明したつかの大学ではえーと複数個に含まれている場合は安心できる
形態素が含まれてる場合を対処できるんですが
えーその検知できないというのが多く存在していまして
これを解決する為にえーと二音節でもマッチするようなえー包摂アスタリスクを何としてえー索引登録しておくという方法でやっています
えー
えーっと実際どういうものかと言うとえーこういったえーあってリスク
をえートライグラムにつき一つ何でして
えー
作品を作っていて水にを付けて登録し力という方法になっています
でえーこれはえー何の距離というのはまーえー先程の形で距離にえー比較えーっと比べましてえ比較的高いこと一九のえー採用しています
一個の音することでえ複数個に含まれない近いあまり御対処するができます
でえー次に凄いあまりことに関しましてはえー
そんな全くではえーっと
日英二次の作る際にえー一応テストバスはえー二つ文をえー作っておくと
いうことでえー
このバイクを飛ばした二つには言葉一つ二つに
これらをえー
タグに登録しておきます
んー
でこの時のえー距離は従来手法今までえー気がした手法ですとえーと〇か一えーそういうの結構人間社会で背中の日で表わしていましたが今回はこの距離を気に使わするということでえー後程詳しく説明いたします
んー
そしてえー脱落誤り
えーの対策に関しましてはえー検索語からえー
検索語の文節を
えー脱落させて
えー検索すると
いうことを行なっていまして
まえー検査語からオブザだけで二回検索するということいたとしています
で
てこの処理もえー今回えー従来手法では
二つあった二音節の方
をえー距離として
採用していましたが今回は厳密これをお見せしました
またえー挿入とえ脱落こちらの探索を組み合わせ方でえー四から六月にもなります
え例えばえーこの例ですとえー文えー
二二というえー単語が復元とえー各二つ書かれてしまった場合に
えーまずそう山高くて
えー一つはその一二をフーリエという一二を作ってお
そうします
でえー検索の際に脱落誤りが削減えー検査語から後活躍させた検索語フリーで検索することで
えー認知結果に
えーが含まれて置換誤りがあった場合でもえー一つが可能となっています
えー
そしてえっと本手法のえーＧＰとの類似点としましては
えーまず
その挿入と脱落のことというのを何設定することはできるという点が挙げられます
て逆に相違点としましてはえー聞いていることがあってその日日は検査語と認識以下のえー
音節別の二十九位を正確に警察ができるんですけど本手法はえこれをすぐはできないと
いうえー
違いがあります
んまた
経理ＢはＡの展開しているこの挿入誤りとお肉のＮ個
も脱落誤りでしていますが
本手法ではその二たり
ん〇一音節に
という風にここ来ています
え本手法の方が制限が厳しい為にこれは減少してしまうんですが私は向上すると
いう風に考えられます
でえっと今回提案する調査しましてえ距離に使うということで
従来手法では先程説明ストーリーにえ挿入脱落うーこれは距離はえー
えー
挿入の有無をえー脱落の音節の数
防衛として定義していましたで今回えー喧嘩するにあたって
え誤りとかって通常舌の前後のコンテキストのまたそれ距離を採用しました
典型例に挙げますとえークラスをにあまり高くの場合で
えー
この服もえー挿入誤りと
えー仮定して好きですがまトライグラム作る際の距離というのは
えーこの
そうやめたか警察俳優の音節で
えーこの場合と二と三のえー距離を計算しまして小さい方を対応すると
いう方法を取っています
それでえーと距離はえー先程〇か一日の日だったのものをえーこのようにえー変更しました
えー
ってまたはえー
今回はあその左えーつ挿入と仮定した音節のえ左コンテキスト母音群も考慮して
えーえ距離
を定義しました
後マイナスとＡとＢという
えー音節第一第コンテストがあるんすけど存在の
え母音部分にある
これもえー距離に考慮して
距離として考慮しました
そしてえーと複数人システムのえー四ということで
えー
本研究では店の検索性能が改善の為にえー二つのシステムを使って
えー各予稿つきましてそれぞれの検査結果を統合するといった方法を取っています
まずえーベースの認識実験中ばえー本研究で方がデコーダーに二つ二つ二つを
買って
え音響モデル音節モデルを使っています
そしてえー今回新たに併用するえー認知システムの方はえーデコーダーは二十五月を採用しまして音響モデルはトライホンモデルとなっています
あっそしてえーっとま
と二を複数認識実験用のえー流れなんですがえーまずえー
えー二つのえー
一認識かとえー近くにして書か
えーそれぞれえーＮグラム作品と単語の認知インデックスエ作為の
それ作っておきます
で
て
えー
んー予めえー二つえーとお酒を作っておきに
え検索を与えられ際に
えーこの索引がそれぞれ検索を行ないます
そしてえーこの二つのえー認識掛から作って検索結果とえー一つの検索結果
こちらのどちらかにえー
組まれていればんすすると
いうような方法でえー併用行ないました
でえー
え評価実験に入ります
で今回えー検索対処しましたのはえー日本語話し言葉言葉コーパスＣＳＪの行データー約四十時間を使っていて
えー検索語をにはえー音声雑音処理はグループの
これが継続長えーこちらドライバーを使いました
えー未知語既知語はそれぞれ五十種類となっています
えそして
えー
認識に用いたえーっとおー
条件としまして二つプロセスの方では音響モデルは左コンテキスト依存の音節モデル学習には九二に千五百二十個声を使って今
で言語モデルはえー音節のグラフの言語モデルでえー学習はえー本当モデルとどういう風になっています
八十四つの方法はえーこれは沿線でないんのえーワークショップで配布されましたえ認識がこちらを使っております
えー
まずＡプラスプラスプラスのえー認識システムのえーポーズにし結果はえーこのようになっていまして
えーと五月まで考慮するとあの九十五パーセントえー非常に高いグループになっています
てえーＪｕｌｉｕｓの方はえーこのような結果になっていましてえーＪｕｌｉｕｓの方はえーとー宣言全てのえーＮベスト使っている為え確率が低いのではえーこれとはえー八十三パーセントとなっています
そしてプレゼントもして用いてえー連続ＤＰはえー大雑把に
んでのえー連続ＤＰで
えー中には
音節ＨＭＭに基づく形で距離
ん使っています
低認識科目数候補を用いるということでえ今回はえー二つ結果の語ですと
一二つの個別と使いましたえー
父の定義はえーこのような式になっていてえー明日はえー
示している通りになっています
え実験内容はこのようになっています
えー
えまずえーっとー従来手法とえーベースラインのえー
んえーグラフをえここに示していますえー横軸にこれで勝手自覚したんだとなっていますでところが後まー従来手法でもえー
ベースラインよりもえー性能が良いというような結果がえーあります
えー
でえーとこの一の従来手法に対してえー距離の現実があって後で
んで挿入誤りの距離を現実化した際のえーグラフがこちらになっていますえーピーク値のえー最大値がえー従来法が〇．五六番なのに対してえー
二十八手法でえー村や形の距離を変化することによってえー約二パーセントのえー改善が得られます
でえーそして夏はかなり一方脱落誤りの方はえー
ってこちらが多い気になるんですが
え従来法よりもえー性能下がってしまうというような結果になっていますえーこちらの方ちょっとまで原因がよくあります
あれ
そしてえーっとーまそういうの距離の平均一日二際にえー母音の考慮えーした場合としない場合のえー三つの歳で一語こちらに示していまして
えー母音のこれはえー竹刀よりは母音を考慮した方が良いというような結果になっています
えー
でえーっと挿入句脱落えーこちらの図に
二のえー両方とも
喧嘩した場合のえーグラフが紫の線になっていてえー口で見るとえー
最も良いえーこのえーく比較して中では最も良いっていうな結果になっています
あってえー次に二二システム変容ということでえー
えーベースライン
えーまい従来法がえーこちらになっていますでこれに対して
えー
Ｊｕｌｉｕｓの個別の音節認識のえ個別の結果を併用したのが青い点が出ています
ところ挙げますとおえー従来法よりもえー二値型三パーセントの改善が二三パーセント程の改善が抱いていて二日ぐらいにでも
あえーをここに書いできるということが分かると思います
ましかしながらえー
で全然別やコンピューターネットワークこれらを使いますと
えーこう数が増えてしまう為かえー湧き出し誤りが映像化してえー精度が下がってしまうというような結果になっています
んん
そしてえーっと既知語の方
えーこちらの方はえー従来法にもえーベースラインと従来法がこちらのようになっていてこれそれぞれえー二つの醍醐認識が
えー
えーからえー作成さセンチインデックスを採用して
展示インデックスを使っな方法になっています
ってでこれに対してえー提案手法
えーにえー
通常質問一つの鉄の個別の規格化したのがお以前
それに加えてえーすＪｕｌｉｕｓの場合誤認識の結果こちらを足したものがあるのでやっていますで何えーっとー認識しても併用することでえー個別と
を併用するとでえーえ口で約二パーセントの改善が言われてますん仕方がないと第五日のえー結果を併用することを
でえー
まえ従来法よりは良くなっているんですけどまーん
この人最大値は〇一の餌が詰まってますがえーまほぼ同じ程度というような結果になっています
んー
でえー最後に検索時間のえー比較なんですが
えーまず
えー今までのえーＧＰマッチングとえー従来法の検索時間の比較がこちらになりまして
え従来法ですとえー
ピッチマッチングのえー
で約六百枚
えー事例えー従来法はえー一見てくれ
一九五〇．一見てくれんけど〇だ可能となっていますで
誰でも
ＢＢが気の毒なことというような結果になっています
んー
でえー今回えー提案したえ複数認識システム
んえー後はえー谷のえー含めた場合の
えー検査結果がこちらになっていましてんー
えー弾力がありことでえー検索時間はえーと
分か
行ってしまうんですけど
えーまたその二つにしてもうまく利用した場合でもえー日目でく程遅くなってしまうというな結果なっていますがえーこれのえーＧＰに比べて約五十代
のえー高速に検索することが可能となっていますえー
んで
言ってえーまとめにえーなります
え未知語検索ではえー世論
んー距離のえ均一化によるえー性能の改善が
であると
えー挿入母音脱落の距離をえーただ一句よりが
えー
でえー一度でえー下の方が得られました
んーまがあえー普通に自然の変位をえーこちらはえーま未知語既知語共にえー性能
オープンし結果のえこれその
利用することで性能が改善することを示しましたまー
えー
て検索時間に関しましてはえー紙を用いてえー数えシステムの併用行っても平均一えー一九八人一さんとお花非常にこうすぐに検査ができるということをしてしました以上で発表終わります
で構成されございました
#############################


#############################
# query = ＡとＢ二適合性広場こう使うそのーとおー音声ドキュメント検索うーの公園なんですけれどをくれたしそのーえーっとー時計メールと長音使っていたと思うんですけれどをでえーそのそう従来のＰＲえすうーで聞いある人がどのような問題がばかっていうのを知りたい
# rank = 1
# slide = 13-09_fix.match_word.jout.txt
# value = -3.48766329074505
#############################
えーそれではえーっと決め多少考慮した二つ適応性フィードバックによる音声ドキュメント検索という題目でえ龍谷大学にしようが発表
いただきます
えー
近年数〇二の第四四回あネットワークの構造化により道がデーターが増加しており
これらに対し比較に検索する手法が求められています
この手法に
音声ドキュメント検索という手法がありま
え先行研究ではこの音声的面で検索のドキュメント車輪の為にインデキシングやドキュメント拡張といった研究が行なわれてきました
本研究ではくれ拡張について研究を行ないます
提示拡張とは
ユーザーが入力スタックへ入り
でえー何らかの知識源を検索し
その知識源から
クエリーに関連する語を中止
四元のクエリーに
追加することを言います
これによってどのような効果が期待できるかと言いますと
音声だけメートル
検索ではどうかに含まれる音声を音声認識し
テキスト化したものを検索します
そのえーテキスト化され
する際にえー
音声認識誤り
がえーくまれることがあります
ユーザーが入力したあー短いデーターこの音声認識誤りを含むと決めては
検索結果として得られない場合があります
そこで
クエリー拡張行なって
短いくれるなすることによっ
で
この得られなかった検索結果がえられるようになることが期待できます
本研究ではこの経理拡張の手法に二的合成フィードバックという手法を用いました
疑似適合性フィードバックでは
ユーザーが入力したクエリーって一回目の検索
行ないその検索結果の上位何喧嘩を疑似的に適合文書として扱います
その適合文書から
クエリーに関連する語を何個か抽出し
後その辺追加推定で拡張を行ない
再度検索することによって
えー検索結果を得ます
えー千先行研究えー音声と決めて検索での二適用性えたばこは先行研究で一二日行ってきましたが
え先行研究では政策対象となるドキュメントの
長さがえー
それ分割され話題ごとに一で分割されていてえー短く
えー
関連語の抽出が
簡単であるという問題がありましたそこで本研究では
で地面土地をえ検索対象となる時目との長さが長い
もしくはえー分割
えー二度
自動で分割されて要らない分割
えーっと
タスクでえー
実験を行ないました
でえー
検索対象となるドキュメント化
て長い
場合ですと
えー検索けっ
定位が検索結果の上位に適合文書があった場合でも
その適合文書に話題が複数止まる場合があり関連語抽出が難しいを
ことがあります
でえー自動
どのように言っているドキュメントを自動分割したかという方法について御説明さしていただきます
本研究では
日本語話し言葉コーパスを検索対象として用いたのですが
でその公園ドキュメントを頭から一定の長さで
で今回ですとえー六十発話単位三十発話単位中発話単位
て実際に一発話単位の発話単位
ことに区切って
えー
分割をしました
えーこの時えー
分割単位がえー小さくなればなる程ドキュメント数は多くなり
反対に
えー
時メントの長さはえー短くなるが
えこの二つの関係はトレードオフにあると言えます
実験条件について述べます
で先程も申し上げましたように
えー検索対象には日本語話し言葉コーパス
を用いました
でこの時公園
と決めた後えーすうードキュメント数は二千七百二十になり
それをえーそれぞれ六十発話三十発話中の発話中発話五発話タイミングギター
場合の好き面倒数は
え表の通りになりまー
定理二は二十二十五件の定理を用いて作成等の評価にはえー一言ってえー人生という
評価尺度を用いました
まずえー拡張マイクえーお実験結果について述べさしていただきます
縦軸が注意点平均精度横軸が検索対象を表わしております
二十一点平均生徒の
えー評価尺度では
えー一一が
えー最大
検索精度となるのですが
えグラフを見ていただくと分かりますように
講演単位
など長いと決めたであればそもそもえー警察は簡単
えー〇．五などで
そこそこ
の
えー検索精度で得られるんですがえーそれが短くなればなる程えー
検索性とは異なり
そもそもの検索が難しく
なると
言えると思いま
えしかしえー反対に
えーえ講演ドキュメントなど長いドキュメントでは実は大学もある可能性があり三年五十三難しく
あるのですがえーと発話など短い
発話単位の
検索では
そのその検索精度難しいのですが
その検索で一日目の検索の時の
上位に
適合文書があるとえー話題が複数含まれることはない為に
えー関連語抽出が簡単に行なうことができるタスクであると言えます
このようにえー本研究ではさまざまなタスクで
疑似適合性フィードバックをんの効果の検証を行ないました
え続いて疑似適合性フィードバックの実験条件について述べさしていただきます
実適合性フィードバックではえー上位何系を二．二五つ
せーえー疑似適合文書として扱うか
その中にえー適合文書から関連語を何御注意するかというパラメーターの他に
えー
求めていいんどれだけの重みを付加するかというパラメーターの三つのパラメーターがあります
てそのパラメーターは
えー次の条件の範囲で変化させ
そのパラメーターオリーブの後で評価を行ないました
その時の結果はこちらになります
ただえー先程と同様に縦軸が付いて平均精度
横軸があっ検索対象を表わしています
グラフを見ていただきますと分かりますようにえー
四えー
検索対象となるドキュメントが短い場合ではえー二つ二四対三度バックの効果はあるのですが
えー講演単位あ六十発話単位といったあ長い
時メート検索の場合にはえー
一二適合性フィードバックによって検索精度が低下していることが分かります
平日適合性フィードバックによって検索精度が向上したクエリーの割合を調べてみたところ
えー
これその結果をグラフにした者なんですがえ縦軸は検索精度の向上提示数を表わすより有効時間検索対象を示しているんですが
えグラフを見ていただきますと分かりますようにえー講演単位は六十発話単位って言ったような場合ドキュメント検索では
えー検索精度は向上していの割合が五十パーセント以下であり
んで長い時メート検索への疑似適合性フィードバックの効果は小さいのではないかと考えます
考えられます
でこの原因について調べてみたところ
でこれこちらはえー
二十四対一度刷毛で検索結果を行なった事例なのですが
えアボリジニーとはどこの国
人いるかという
クエリーで検索してえー左がえー講演会長い時面と検索を行なった場合右側一は発話単位えー短い
って決めて検索を行なった場合
となっておりますそれぞれ関連語はえー
その関連語の
右のとこに
並んでいる語が抽出されたのですが
講演単位ではえアボリジニー
とは全く関係ないオーストラリアの夏について
の
関連語を抽出されていると考えられます
えー反対にえー一発話単位の関連語はえーアボリジニー
とー関連するかは多く抽出されていることが分かります
でなぜこのような結果になったのかと言いますとえー講演単位ではえーそのその検索精度は
高くえー水
世界ハエでもえー
世界に決めとは検索結果とし得られているんですが
このようにえー
話題が複数あり
えー本来ならば話題三から
で関連語は抽出ある程度
されるべきなのですが
謝って話題にから
関連語を抽出されてしまった為検索精度の低下に繋がったと考えられます
えーこれらのことから
結局その話題が組まれ音即ち一つの話題しか含まないドキュメントから
関連語抽出を行なった付けて疑似的合成フィードバックの効果は高いのではないかと考えられます
でそこで本研究ではその
えー
一つの話題から関連語を抽出あー
為の
えー手法としてえドキュメント長を考慮したり
疑似適合性えーたばこという手法を提案しました
え従来のお爺適合性一度バックとどこ具体的にどこが違うかと述べますと
え従来のえーこちらの今の
でえーアルゴリズムは従来の二つ二構成三度バックを表わしているのですが
えこのようにえ関連語抽出を行なう
えー作品もえー検索を行なったクリームを同じ索引用語用いられてま
で本研究え
また我々が提案した手法ではこの索引用語
えー関連語抽出や作品と検索用の索引に
分割し
この関連語抽出用索引にえー一つ
が
二は
一つの値しか含まないドキュメントを用いました
そのえー一つの話題
がえー
含まないものをどのように提示したかと言いますと
でえー以上のような公園発表ではえースライド一枚
認識えーし大体一つの話題
があーなされずえーその長さおよそ三十秒から一文となって今
えこのことを考慮しえー本研究でえー
えー用いた検索対象の長さがの平均が
えー二十一つのドキュメントの長さの平均が三十秒から一文の間にある
体中が発話単位と一発話単位を
彼の抽出しよう索引に
利用しました
でその時の結果について述べます
えーまずえー一発話単位で関連語抽出を行なった場合の結果について述べます
て先程とどういう人に縦軸が付いて平均精度横軸は検索対象を示しており
黄色がえー拡張前テレビえつらい
の結果
水色が従来の二つ適合性一度バックの結果
ピンク色が提案手法の結果を示して今
フレーズグラフを見ていただきますと分かりますように
従来の二つ以上付いている訳よりも提案手法の方があって
さあ二回検索精度は得られていることが分かります
続きまして一五発話単位で関連語抽出を行なった場合の
絶対について述べます
えーこれも同様にえ縦軸は実験平均精度横軸が検索対象を示しており
え水色が従来の疑似適合性フィードバック
ピンク色がえー関連語を一発話単位情報
関連語抽出を一発話単位で行なった場合の結果
生地緑色が
関連語抽出の一は発話たいんで
行なった場合の結果となっております
えー
グラフを見ていただきますと
えー
自由発話の
一発話単位で関連語抽出を行なった場合と比べて
えー検索精度は低下しているものの
えー長いドキュメント検索において
えー
従来の疑似的合成四度バックより高い検索精度が得られていることが分かります
えこれらのことより
提案手法を
でえー提案し
我々が提案してはえー短い
検索対象から関連語抽出を行ない長い
時メート検索する手法は有効ではないかと考えられます
で更にえー短い
五発話ドキュメントをおー関連語抽出用に作為に用いてで二
支援を行なった結果についても述べたいと思います
えー先程と同様にえ縦軸が一一で平均精度横軸は検索対象となっております
でえー三次水色が従来の疑似適合性二度バック
君よりは女子発話単位で関連語抽出を行なった
場合の
んで等
えピンク色が
一発話単位で関連語抽出を行なった場合のグラフとなっております
えグラフを見ていただきますと分かりますように英語発話単位ん
て関連語抽出を行なった場合はえー従来の二ステージ合成一度バックより検索精度が
えー低下するということの
えー
なりました
えこれはえーっと発話単位ではそもそもの検索ユーザー難し過ぎ
ページを検索結果の上位に
えー適合文書は存在せずえ関連語抽出がうまく
行なわれなかった為だと
考えられます
えー提案手法によって検索精度は構造をした体の割合について調べてみました
えこちらのグラフは関連語抽出を一発話単位ん
益々えーとピンク色のグラフが提案手法で
の時のえー検索精度を向上した定位の割合を示しているんですがこれは一発話単位で関連語抽出を行なった場合のクラスとなっております
先程と同様に縦軸は検索精度を向上した定位する
丁寧終わりあー表わしておりえーえ横軸が検索対象
となっております
えグラフを見ていただきますと分かりますように
えー提案手法の方は従来の事実女性二度バックより
検索精度の向上して提示数の割合が多いことが分かります
えしかし
えー
講演発話えー講演
×の検索ではえーと関数
以上の
定理でえー検索精度が変化がなかったり
えー悪影響を
二適合性一泊四によってえー悪影響を
受けて
対し
日常にえー
またえー二十以上の政治経験作成では向上している六十発話単位三十発話単位中発話単位中発話単位の発話単位の検索においても
えー
三四十パーセントから
五十パーセントのページでえー検索精度の
に変化がない数適合性見るバックによってえー悪影響を受ける結果となって
よりも
でそこで本研究ではこの
八十四対一度バックによる悪影響を低減させる為に
拡張マイクへと拡張五ページの併用を行ないました
えどのように拡張前定理と拡張子体の体を行なう
かと言いますと
え検索えユーザーが入力したケース
クエリーで検索を行なった場合
えー
各文章ですがえー類似度を元にランキング付けされて算出されます
えー
これらのえー類似度をそれぞれ三された類似度をえー
下の式
でえ線形
五感
えー線形代数補間することによって
でああー類似度を元にえー
にランキングされた
検索結果を
評価して
し評価します
であ先生んでえー本し
で
そのー
提供する場合にえー
重みを付けて併用するのですが本研究では
えっとこの重みを〇．一から〇研究の間で変化させ
理由は後で評価を行ないました
その時の結果が
こちらになります
体がえー先程とどういうような
にえー縦軸が付いて平均精度横軸があっ検索対象を表わしており
えー黄色のグラフは
んベースライン
水色のグラフはベースラインと
従来の疑似適合性一度バックの併用
ピンク色のグラフが
ベースラインと
提案手法での重要を表わしております
グラフを見てたらできますと分かりますように
えー併用によって
ベースラインよりも高い検索精度が得られています
また
えー
従来の実用性えーと×とベースラインの栄養よりも
提案手法とベースラインの西洋の方が建設高い検索精度が得られていることが分かります
えまたえー
拡張前後のページによって
検索精度が向上したクエリーの割合を調べてみたところ
縦軸はえー検索精度を向上さくえーすること検索対象となっているのですが
っていうん
実適用性フィードバックのみ
え提案手法の三
で検索を行なった場合よりも
え四を行なった場合の方が
検索精度の向上を提示数が増加していることが分かります
またえー
従来の
えー二つ調整フィードバックベースラインを併用した場合よりも
提案手法とベースラインを併用した場合の方がより検索精度はこう
常したクエリーの割合が増加していることが分かります
でまとめとしまして
えー二適合性フィードバックを用いた音声で決めて検索ん
を行ないました
えー本研究では検索対象が
えー
んでえー簡単な
えーそもそも検索が簡単であるタスクから難しいかつて六まで
また反対にえー
検索が簡単な場合は関連語抽出が難しくえ検索が難しい場合は関連語抽出が簡単であるさまざまなたせいで
二適用性フィードバックの効果の検証を行ないました
でその結果あの長いドキュメント検索で
えー
検索精度が低下することが明らかになりました
そこでえードキュメント長を考慮した二つ提示音声フィードバックという手法を提案し
関連語抽出では簡単なタスクで関連語抽出をしてから
生理拡張を行ない再度検索するという方法を
行ったところえー従来の疑似的おー政治いたばこと比べて
より検索精度が向上しました
えーその
えしかしえベースラインと比べてえー長い
後面と検索ではえーまだあーベースラインの方が検索精度が高いという結果になった為
えー
実適合性フィードバックによる悪影響を軽減する為に
拡張前後の手入れの併用行ないました
その結果更なる検索精度の向上が得られ
えー全ての検索タスクにおいて
ベースライン以上の検索精度が得られました
またえーベースライン当日従来のえー疑似適合性フィードバックの併用よりも
ベースラインと提案手法の併用の方がえ
効果の高いことを示しました以上で発表終わります御清聴ありがとうございました
#############################


#############################
# query = ＡとＢ二適合性広場こう使うそのーとおー音声ドキュメント検索うーの公園なんですけれどをくれたしそのーえーっとー時計メールと長音使っていたと思うんですけれどをでえーそのそう従来のＰＲえすうーで聞いある人がどのような問題がばかっていうのを知りたい
# rank = 2
# slide = 12-09_fix.match_word.jout.txt
# value = -3.50267140952091
#############################
あっはいえー音節継続時間を利用したえ直線検出に基づくＳＤ手法
というテーマで
えー対話し記述各大学自然言語処理研究室の方のは気をさせていただきます
一えー現在ウェブ上のノードでえーマルチメディアコンテンツが増加していまた音強くマルチメディアコンテンツが増加しています
ってえーその中でえー大量の音声中から検索要求に応じてえー特定の単語の発話位置を気にする
という問題が考えられます
えー
えこのような問題はえーすＴＤと
速い音声検索を検出ＬＳＰ係数を簡単にセクション
早くしてＳＴ
と呼ばれますえー
一ＡＳＴＤでは例えばえー自然言語という検索要求があった場合えー大量の音声中からその発話一を検出してくる
という問題なっており
え先行研究として完全これはえー法だけがあの直線現実にも二直線減衰量〇スピーディーというものがありますえーこの手法ではえー音声認識によりえ検索対象の音声を音節別に変換します
またえー検索語音節列に変換し
すえーその二つの音節列で音節間距離えー年を構成します
作ってその構成した音節間距離平面を画像と考え
でその画像上でえ直線検出を行なうことでＳＴＤを実現しています
んー
世界こらはこの音節間距離平面の効率的な索引付け手法を
提案しています
えーＣＤを実行して四つを図で説明します
えー
えー横軸がえー
検索対象の音声の音声認識結果音節列で縦軸がえー検索語の音節列です
でこの音節間距離平面の
え白いところが音節間の類似度が小さいと
本節関係がチーズってを聞いて
えーとー
一つ黒い線が
えー音節間の類似度が大きいと
えつまり音節間距離が小さい意見ということになりますえっと
えー
この要四十五度の直線上に
黒い点
七の部分が
えー音声中で
えーと検索語が発話されている一と対応することになります
えー
えこの黒い線が並ぶ
部分を体験することＡＳＴＤが実現できます
えー
えしかしえーを実際の音声認識の際にはえー認識誤りが発生します
えある音節が脱落する
脱落誤りの場合
え例えばこの場合えー自然言語が自然言語
と認識されてしまっていた場合は
えこのちょっと傾き一の直線係数というものでは検出できます
えー
えしかし
実際の音声認識の際におこのような誤りが発生しますので
えーっとこの
脱落誤り挿入誤り
こえー
えーこういった
とえー認識誤りに対応する手法が必要となり
えー
えー
え次に提案法の説明です
って提案法では
えー音節継続時間を考慮した音節間距離年面を構成し
でその上でえ直線係数を行なうことで
一え検索性能改善行ないました
えー
えー先行研究となるかねこの手法では
えー音節単位で音節間距離平面を構成していましたでそれをフレーム単位で
えー
んー構成することになります
えー音節化
音節継続時間を考慮したえフレーム単位の音節
短距離平面を構成する為には
えー
検索対象となる音声ドキュメントおんすえー音声ドキュメントを
と認識結果の音節列とで検査語の音節列両方についてえ音節継続時間情報が必要となります
してまずえ検索対象である音声ドキュメントの音節列にはえー音声認識システムの出力のえ音節継続時間情報を付与します
えー
えこれに対してえー検索語はテキストで与えられる為
えー音節
えー音節継続時間情報を持っていません
えっとそこでこれは音声えー音声認識結果から
一え音素文脈を利用してえ推定することになります
実験検索対象の音声ドキュメントから
英語音素音節へ音素という三つが見
の平均音節継続時間を
後
えー計算しておきます
え検索を与えられた場合
てその前後の音素
を考慮し
えこの平均音節継続時間を付与することで
えー検索をの
えー
えーっと音節継続時間を推定します
えしかしで必ずしも
検索対象の音声ドキュメント
がえー検索語
英語音素音節音素
という湖
歯を持っていると分かりませんえー
えー一えそこでえー
でこれ以外に
え音素音節
の組のえー平均継続音節継続時間
またえー音素コンテキスト情報を持たない音節
この平均継続時間
えっとー計算しておき
これを必要に応じて使います
んー
えまたえー必ずしもえー検索対象の音声ドキュメント中に
え検索語を
の音節数が発話されているとあります
でそこで
え殆ど懸命えー本選
音声ドキュメント
彼らもえー音素
音節音素
という三つ組みの平均音節継続時間
人形音素音節というえー
継続つえーこれのえー平均音節継続時間
二音節の平均継続時間を計算して大きい
んーこれらを必要に応じて使います
えこれら二つの音節継続時間を考慮した音節列を用いてえー
一えー音節間距離変化を構成し
その上で直線検出を行ないます
後
えー提案法は認識誤りに対応する仕組み
方図で説明します
って認識誤りで済ませたえー音声認識の際にまあるまた脱落誤りが発生した場合なんですけれどもえー
えー
えこの場合えー
えー
本来その音節があった部分は他の音節によって置き換えられていると考えられます
えー
で例えば自然言語をが自然言語と認識されてしまっていた場合
んえーとん脱落した誤りは一個の音節によって置き換えられています
えー
でそこで
この音節継続時間を考慮した直線です行なうことで
と認識誤りに対応垂直センテンスを
によって
発話位置を検出できる
えっとー分かります
えー
えー
でここまで図を用いて提案法を説明しました
えここで提案法の直前検出を定式化したいと思います
えー
えー
えー
えー
えー
とし数式が汚くて申し訳ないんですけども
え検索語のフレーム
ＩＴ
家族する音節をえーあり
一えー音声ドキュメントのフレーム二重
んが属する音節をＢｊ
えー
え検索をフレーム数をスモールｎ
音声ドキュメントのフレーム数をスモールｎ
一〇二でえーそれは×とフレーム前の
こう点の
フレーム間距離をＤ開いてえー
機械検索語の音節数を
即ちＭとします
えー
一えここで
え検索対象の音声ドキュメントフレーム
１１Ａ
一からえー傾き一の直線上のえーフレーム間距離Ｄ残っている遺跡距離
ＤＪを計算します
で規制が
えー適当な閾値よりも小さい一次会
こ
発話一
と四つの候補として出力することで
えーえ発話一の検出を行ないますんー
えまたえーフレーム間の距離の定義について二つ
出入りしました
で一つはえーフレーム一杯
家族する音節えー文
んーとえフレーム性が属する音節
起きて
の間の音節間距離もその使用するというものです一
でもう一つはえーその距離にえ重み付けを行ないますで
えー
二でこれは検索語の各音節の推定フレーム数で正規
で正規化と書いてるんですけども重み付けを行なうもので
えー
計算法の
えー音節の推定フレーム数が長いもの程小さな重み
え短いもの程大きな重みを付ける
というものです
んー
えー例えばえーここの例ですと映画を
検索語クエリー
というもので
えーフレーム数が二
えーえ撮影を音節が
えー一音節くがフレーム数にえ音節映画フレーム数差は
本節りがフレーム数一
であった場合は
えー音節く
には
思いってこう
八んえ音節へ庭をおー道一
本節りには思いさんが付く
というのたいなと
え次にえー傾きを可変とした
直線ケースについてです
えここまではえー傾き一
んである直前件数
について説明してきましたがま実際には
えー音声ドキュメント中の正解の数えー生活は間の
えー音節継続時間をさまざまに変化しています
んー
でその為えー検索語の音節えー音節継続時間の推定
今誤差が生じることになります
え例えば
え音声とテントを音節列が
で推定の音声で音節継続時間よりも
なかった場合
まこの図のように
傾き一直線検出
で検出できません
えー
えーまた同様にえ音声ドキュメントのあのー音節列があー付いている短かった場合
とこの図のようになって
ところを検出できないということになり
えー
でそこで
でこのように
えー傾き可変の直線検出を行なう
行ない
えーこれそれぞれでえー累積距離合計三四五
この中でえー一番累積が小さくなったものを
え音声ドキュメント
これは事例一事例
体の例セキュリティー性として出力しも
えここでえー傾き海辺の場合の
え直線件数が
について定式化を行ないます
え先程と適合あるいは同じで
図がえー新しく
傾きの主語名詞を肯定しました
んー
って先程の例の傾き一の直前検出というのはまこの利子を
中に配置
一つしかない
状態
同じです
してこのでしょというのはえ直線をどうパターンが設定
鉄を行なうかというもの決めるものでありますが
え例えば傾き〇．九
傾き一傾き一センチ
の直線でえー検出を行なう場合ここの下のようにをの三つの数詞が入ることになりのこの三つの傾きで
変数を
二記事を決めるということになります
えー
二フレーム間距離についてはその先程と同じ
えー音節×そのー使うものと
えー
検索語のえー音節数のフレーム
長音を推定
長さによってま重み付けを行ないます正規化を行なう
文の
えーと二つ
僕は今
え次にえー累積距離の閾値の素性についてです
えーこれはえー検査語の音節数により悪いセキュリティー事例
の閾値を変化するという問題
えー音節数が少ない検索語はあの起き出し誤りが多く発生する
と考えるられる為
集まっていセキュリティー前に対する閾値はま厳しめに設定した方よりも
と考えられます
またえ音節が多い検索語はあーのこの手法の場合えー
ってフレームの推定の
えー誤差が
大きくなる為えー
まこれは厳しめが緩めに
設定するのが良い
という風に考えられます
えー
でその四季がこの以下のようになっております
えー
で構わ
えー音節にかかわらず一律で
えーま閾値を設定する場合の閾値です
で
えつまり彼は普通は顔もえー月調査を行ないもない場合は顔まで
です行なう
ということです
えー
しかしでまー後はま基準の音節
ってβはえーこの閾値調整を
今度レコード聞かせるかというのを決める女性のパラメーターで
一でラージＭは検査語のせずとあります
えー
えー
でこの
節点八とそういうのが基準の音節数で英語の音節が少ない検索語というのと
音節数が多い検索語というものをまー中間の
値をまー設定するものとなります
えこのβというの調整パラメーター一となっていてこのデーターが小さければ小さい程えー
えーこの
えーっとこの傾きが
を聞くなって
ま閾値調整を強く引かせるということになります一
数の設定が小さければ小さい程
です
んー
え提案法を実装しえー実験を行ないました
えテストセットは
えーＮＴＣＩＲのえー音声ドキュメント
えー検索タスクで配分してＬＳＰ人のテストコレクション
からえー検索対象はこの百七十七号えー
えー
あ検査語は既知語のセット五十個です
でこの必要性
そうなんですけれども
あのー音声認識
後
音節連続音節認識で行なっている為ま既知語を
未知語を
女性であると思うんですけれども
どちらも特に
えー
一つえーその既知語未知語であることにま特に三はありません
で検索対話発話で発話を見つけてこれをまー正解ということに今
ステップちで検索対象音声ドキュメントなんですけれども
えこれはまテストコレクションで配布されてるものを使用しました
連続音節認識でえー
えー御正解率は八十五八パーセント
またえーフレーム間の距離は
まそれをおーま音節間の距離
ともいるんですけどもこれまた性や距離保証します
えー
えーえ評価値をです
で今回の場所には
え二名で丸二を使用しました
星が付いはま以下のようになっております
えベースライン手法についてです
えベースライン手法についてなんですけども
これはあのー
木の最後の発表で
だったんですけれどもえー
んで私の研究室で
えー提案している
えこの音節単位の
直前系列のですＴＤ
というもの最適化アルゴリズム最適化アルゴリズム
を使用したものを
をベースラインとしましたえー
んー
え詳しくは元々本お手元の発表資料
もう御参照ください
えー
えまず一つ目の実験ではえー傾きを可変とした直線検出を行ないました
経験一直線の傾きを変えることで
え検索語の
音節列の
あー
えー継続時間が空いて
というものは保証できるか
多数のずれを保証できているかどうかということを確かめる為
あっえー傾き一
のみの場合と
あっえー
働きを一から二十パーセント面して
九段階で
検索した
えー三十パーセントずらして一三段階で検索したもの
この三つで行ないます
んー
えーえ実験一の結果です
経験直線の傾きを
えー変更することで
の検索性能を向上していることは分かりました
とこの処理によりま検索語の音節継続時間の推定のずれというものもある程度保証できている
という言葉を取ると思います
んー
ま当然のことなんですけれども
ケース直前の
あの角度変更の範囲というもの調べれば広げることを計算時間フレーズ
まず
えー
まそれとえー検索性のトレードオフの関係となっている
と思われますが
ま今回えーその二十パーセント面した場合と三十パーセント面した場合で
そそれ程検索性能の
喧嘩はなかった為えー
父の頃
格の変更もその程度の範囲で行ないばいいかということは
方法を検討する
必要があると考えて今
えー
え次にえ実験二ではえーフレーム間距離一
服を
んえー検索語の音節継続時間
によって
で正規化行なうかどうか
ということを
そのえー違いで検索性能の変化
後
えー
調べました
えー
テーマ正規化を行なわない場合は文のま二つを正規化を行なう場合を飲まないぞとしました
で今後の画像というのはえー形成した行なわない場合ってことで
で長い音節程重要視する検索語の中まー推定した
持続時間は長いもの程
重要視するということになっていて私的用法の方はどの音節の一つの
こう見て評価するということになって
二
で結果です
え二つの最大値で比べると正規化を行なった場合の方がまわずかに行ないました
ましかしのイコール〇瞬間を見ると
ま必ずしもいつも
正規化行った方が良いという訳ではないことあります
えー
そして適合領域では
えー検索性能向上していますが氷こう領域ではは逆に落ちているという結果になっています
この原因について使わも氷こう領域ではま適合領域に比べて認識誤りが多く発生しているということがま考えられると思います
でそういう場合はえ音節継続時間が短いような音節というのはま脱落したり
また挿入誤りが色々発生したりということは考えられて考えられます
ずっとそういう場合は長い音節程
重みを付けて重要視して検索した方が
検索精度良くなるのではないかというに考えます
えー
で最後に実験三ではえー累積距離の閾値調整を行なうことによる検索性能の変化を調べました
切って先程の
本出したんですけども体がんまの女性でえー
えっと閾値でえーそこの場合五のジャスト
えー
γがしゅ
て調整した閾値で
実験そこの場合はテストとしました
で今回なんですけども
えっとー
基準の音節数まー後
五音節
んえー調整パラメーターはえ三三としましたあすいません
そういう
えー
低い結果ですえー閾値調整により全面的に検索性能向上しました
えー次調整行なえない場合に比べ五十四パーセント良くなりましたが
失礼つらい二千語に私ませんでした
んー
二型あのーお手元の資料の
設定つらいんの手法とちょっとあの
んこれえーこちらは最新の値になっていてとても後はちょっと思っ振る訳になっています
んお洒落分かりませんでした
えーでまとめです
んー
えー
えー二の方えー
えまとめは以上のようになっ
って言います
また今後の課題は次の通りとなっていますで
御清聴ありがとうございます
#############################


#############################
# query = 収録データーの話なんでけれどもた音声認識をするっていうことでそんなような音声データーをそのー品詞の為に使っているのかっていうので例えば四つのあ四歳だったりどれぐらいの時間それから喋っいる発話するとかそういうのはとー父はデーターセット全体の収録時間ですっていうのを知りたい
# rank = 1
# slide = 09-11_fix.match_word.jout.txt
# value = -4.4402325823374
#############################
えーではえー音響情報を用いた外国データーをクラスタリングというテーマで
で法政大学大学院の御発表いたします
でまず初めに
えーライフん語について説明をいたします
えーライフんますのはえーと
個人の生活や
えー体験も記録でまカメラやバイクＧＰＳ加速度方法のおーわざわざ
えー形で記録されます
を利用法としましてはえー
二四六八個に気を自動作成今日の体系というなどへの応用が期待されています
そこではない黒くなるんですがそのーデーターは説明する辞めていく為に
て多様化放題で
ま冗長というような特徴があります
えーっとまその為にま効率的な利用の為にはえー検索要約が必要となってきます
畑作り要約の為には
後インデキシングんー系まクラスタリングなどの処理が必要となってきます
えここではない部分の先行研究といたしましては
そのー生態取ったものがありましてえー
構成さ情報の御家族のじゅ
後
僕は言ってえーその時のウェブの情報をえー三ページケーキ屋でゆいう素敵だと
からまー画像検索キーを
抽出して
辺がメーターカメラの画像検索を行なうというような
システムが提案されています
えー
また外国空いてるというものを提案されておりましてまこれは携帯を
使用して
波形は計測した後位置情報夫婦の感じを行なっています
えまたえー第六画像をクラスタリングやセグメンテーションについての研究もえ過去四行なわれていまして
上の方に分かれている研究では
このく二．五二日のデーター二と三十四種類のラベルを付けまして
実験三四クラスタリングという時間的に近いデーターがおらです
クラスターに含まれ易くなる
クラスタリングを行なっていまして分水報道を改善する方法
ちょっと報告されています
また
知ら下の方の
研究ではあの一日千七百八十五枚を
それに属した画像からなるまえーっとおー
こうま二次元一にあるか
えしましたえー二時間以上
では一度電源が大きくなっているところでま一つの分割を行なっており弁当ごとのセグメンテーション方法を
行った上でまイベント事仕事の
その可能言えるとセグメンテーションを
行なうという方が
後はえーやったセグメンテーションが提案されています
でこのセグメンテーションをあのつまりある画像の
一メートル以上により
セグメント境界を求めることで行って
でまたえーと映像が契約音響情報を用いた研究もありまして
えー
シラブルの方に書いてありますのはえーまー記憶支援システムというので
えーと位置情報を音声認識の結果を
えートリガーＩＴというものです
はですが音声認識の会話ここのデーターに音声認識を掛けると
誤りを含む可能性が態度で
あー認識下顎の信頼度ものを設定することで
えユーザーのソースを矯正するというシステムが提案されて
えまたえー
音響情報を用いまして実験を自動作成をするという方法も提案されています
本研究ではえーユーザーの二を最小にする為に使用しているでは一二は
ホーム指向性マイクとＧＰＳのえー
軽く一二時間のデーターで重要かそのラベルを付けて
あるいは都心からレストラン事業といったあのー柱状況を比べて
えー
まこれはデーターをこのスペクトル情報を利用してセグメンテーションや
クラスタリングを行なっています
でまこのように
利用されているホーム教育論情報ですか
ま得られる情報にはま音声や音楽環境音のとか
あります
あのー音声からは
調べ
えー
で
あー会話の内容であるという話者情報が得られたり
の音楽
発表用の
えー
えー
はいユーザーがほぼ一定でその方っていうのは職場ということを一型ではまもしや状況が分かる
んー
でまた環境音からはそれ以外に行動っていうのは
測ると考えられまして
補正をこちらの
フランスこう
っていうことなんですけどももうそん時の方とはあのー人がやってると思います
試み色々な情報を含んでいる音響ライト六十を
情報ですが
は非常に
情緒不のこういう情報となっています
音声長はこういうえーてます上昇といいますのは
あのーお父のま含まれていない
とそうでは含まれていないというのはまー
特に
ざっと見たそうみたいな
食そうみたいなものだけしか含まれていないかショーや
ま含まれてるお父があのそれを聞いただけでは
んー何か分からない場所というのはまー
冗長性があると言えると思います
えー
これそこでえーま本研究ではまー冗長語を省きまクラスタリングを行ないました
でまたそのクラスタリングの時に使う特徴量について
子供の効果的かということについて調査をいたしました
えー
あー水泳まーマイクロホンそれぞれにおけるま一般的な問題点について説明いたします
えー
バイクがほ編集された映像はテレビ番組あのー映像とは異なって
詳しい人が一回と機械的にま安定したりとかっていう
効果がだいぶ
ま人やものはカメラの場合は行為易いということで
私の一階が不明瞭であることはあります
えまた音響情報では
販売からの距離より非常にこう思うようにばらつきがあったりするような問題があり
ここでのことを中心的には考えてまだえっとー
これ
えーえまたえークラスタリングを行なったりするけどもセグメントを単位の長さですか
えーと従来研究ではま五分程度の処理が行なわれている
姿まこれは識別をしたい環境は
二十億と言われてる長いもの
ということが前提にありましてはこの程度の
え分解能でま処理を行なうという
後になっているのですがま実際は識別をしたい
環境はまー長時間とか特徴時間八時間のものがありまして
ま用途によって異なってくると考えられます
んー
白の
えっと予測としましてはまー例えば四があ環境を
にはあるような場所は環境ようなある程度時間を
えーえーっとー
二十円と呼ば掃除がありん型の町時間のセグメント向いているのではないかと考えますが
あの音声や音楽環境音といった
そのー環境の中で三十クラスタリングを行ないたいという場合には
また時間のセグメントを使うのは一二を考えられます
まそこで本論文では短時間セグメントの場合を扱いました
あの固有短時間と言いますのはまそうしより構成内容を
話者や後
最低限話者が分かるという内容をまー
発表は
えー環境音がそのことはないか分かるというな形としてあの五八程度
僕がそれをセグメンテーションを行ないました
えーっとところこれをま基本の単位としましてま冗長部分ん全部やっクラスタリングを行なって一
えー次にえーデーター収録について説明いたします
えー収録経済は
いう場合のアルバイト
ＰＣＭの方に気が法華経るをある〇型とであのペット楽しＸという時代を
用いていは
んーずれてますけど
えーっとこの
二つをおー使いまして
七分ま四十時間を収録を行ないました
二十落ち
雇用区分はえーえー議論は〇九で人文化
でまたのおー
えーレコーダーで
記録をいたしました
残り二つを使いまして
えー消えてしまっているのですが
えーっとマイクロホンを収録期間ていうのはまだ一年にも分かることはそうされますので
そそれも一四十四が短い為に四の変化に対応できるようなあー処理を行なわなければあーえっと
考えたのであまり大量の方を使って主としました
えまたえー
母音を以下の本来
えー
とー耳に到着して使用するものですが
あーのそういう状態をまそう時間の収録は
はいユーザーの負担になると考えられるので
畑に
嫌いの私の方が気にして
収録をいたしました
この状態で日常生活音をまサンプリング周波数四十八九付ける
ヘルツ
考慮した人数が二十四人とは重要文という
このレコーダーによって違う一つ
使用した人数でえ記録を行ないました
えー
では×収録された面もそう思うは収録音声です例えば昭和の研究して教室が
えー
えー大学×ですとおーレンタルビデオテストマーケットで
えーとそこで収録された音というのは
ま先程の音声やパソコンを操作していると多分
文の音楽あのー
ゴルフ場だ車をその場記録されました
えー
心がまー幾どう影響情報から不要なセグメントのま冗長分野からセグメントを削除する
感じるするということを行ないました
誇りを
先程二つまーえーと不要なあー状況としたデーターですが
歩行者の何が含まれているあのー分からないというものは
あの非常に他の音声とは特別するの難しいので
で今回は
方法もおーセグメントについて勉強ございました
えー手法としましては三つの特徴量が閾値以下のセグメントをさてあー
方法で行ないました
えー
その三つ延ばし特徴量ですが
ねそれができたスペクトルの頭の方は
でもこれは
えー
資料八つの四日本はまースペクトル包絡いないんですが
のえスペクトル情報その楽器を持ってきた取ってきたスペクトル包絡というものですが
とこれのえーフレーム間の差分をそもそもで
とこれが文の場合ですと
千葉のように
非常にま差分が小さく思われます
んー
二もう一つの
特徴量としましてまそうあのーサブの最大値
ですねこれは瞬時に変化する音を検出するということで先程の
数法というような
音など
がまー誤っている
提示されないようにこちらの
少量を用いて
後それと後はされている
あちらの式ですが
えー予稿集の式とえとなっているのですが予稿集の式は間違いですので
白の方に訂正を思い出します
こちらの式はですねえー
繰り返しんん差分の方は
いうことで
えー詳しく差分を求めているようですがまレコーダーによって
相当の大きさが異なってしまっているので
それを正規化する為に
えー
後振幅のそのセグメント内の振幅
平均振幅によって
ま的化を行なっています
えー
んー
んー
えー
で次にえー
あのー
この前の項目の三つの特徴量を用いたのですがまそれの閾値の決定の為の
実験を行ないました
えー
四十一時間のデーターを全て
えー約五四点目と二分のところ
三枚百五十あのセグメントに分割されました
結構だからランダム二百セグメントをやり指導でえラベル付けを行ないました
その結果三十一セグメント不要なセグメントで
えー
後三十七生の四月二十セグメントはあのーセグメントでユーザーセグメントが
生まれることはないか分からないっていう船がセグメントでした
えーこれをする必要なセグメントは自分されてしまうのは実は少ないので
えー
不必要なものが提案されないように閾値を定めますと
あー結果実践とは設定できて永久セグメントはもうもうで一つセグメントはあそうだと
生まれるとか目をセグメントでした
で閾値の方なんですがえーこちら三十一グラムてまして方法が
え各特徴量
あのー
全てのセグメントを
分布になっています
で赤い方のえーばはえー不要なセグメント分布になっていて
は正規化スペクトル差分の
二十分平均の一つはそうでは
えー何か
えー正規化スペクトル差分の最大値では一酸化
政治家
振幅の平均では〇．一以下というような閾値を定めてなりました
えこの閾値を用いましてえー
別のランダムに選んだ百セグメントに対して不要なセグメントの軸実験を行ないました
でこっちはこちらセグメントもえー手動でえーラベル付けをしたところ
三十四点目と二四でそのうち一名セグメントはあのーセグメントで実習生名とは食われることはもう
二名のセグメントでした
でえーえー病気のえー
えー連接しましたえー
んでです方法
適応させましたところ
母セグメント場所されてその後六セグメントはまあのーセグメントで
えセグメントがその他
六四えーっとでした
とこの結果から
まある程度の有効性があるよと考えられます
えーこのようにしてえーま不要な
セグメントを取り除いたあの残りのセグメントに対して波形ビーズ法によるクラスタリングを行ないました
で今回は夏の特徴量を用いてクラスタリングを行ないました
えまず
二つの特徴量としての平均スペクトル包絡を
えー正規化平均スペクトル包絡うーことで
知らえー先程のまー多分
私と同じのですがまこれを
方ますの野菜は全てのスペクトル包絡をの平均して一つのものでした
えー正規化しては妹伝わっ正規化してないものと
そのー両方でクラスタリングを行ないました
でこのスペクトル包絡を用いることで分類した音同士のクラスタリングができると考えられます
でまた明日の場合ですとま正規化によって
えーまー録音機の違いによる影響受けたことができるのではないかと考えられます
えまた平均スペクトル包絡放送をそのーお和としまして特徴量の一つとして扱いました
えーえ残りの六つの特徴量は
んー
えー振幅差分の最大値と
後先程の例をえー用いた三つの特徴量です
とこれらは環境音や音声が含まれている場合に大きい値をその傾向があります
あー逆に端的に音声という場合にはちっさくなるのでま環境音と
環境音や音声とまそのー一九一二分類されると考えられます
えー
これらのまー閾値を用いまして四五のセグメントの授業を行なった
九十五えーっとークラスタリングを行ないました
パーセントにはえー
まちょっとましょうとそう含まれて大きなベルが付けられています
えー
てクラスタリングの結果ですがこちらの
表四になりましたこちらはえー適合で書いてあるのですがまーしたり
その対応するえ場所が書いてあり
えー
んー
正規化をしてはえ特徴量を用いた場合にはえーの後期の違いによる影響が強くてしまいましてあまり
でクラスタリングはできませんでした
これはま世紀から音料理関係のない特徴量を使用することで
あの解決できる問題と思われます
えー
日本一の正規化した特徴量ではまスペクトル
あの平均スペクトル包絡が
良好な
結果でした
そうですがえーこちらんー
こう見て本当にえー
工場というのは研究室のクラスターのですが
既にクラス数を読ん非常にした場合には
えこのように研究室の方は
同じ場所のクラスターがいつもできてしまうというは
えーっと利用がえーですおきました
えー
あのーしたがってまースペクトル包絡ではまー特徴量そしてま不十分であるので
他の特徴量を持っているかま他のものを組み合わせて使うということを扱う
評価と思います
えー
このえー音響情報について
僕が上に
着目してクラスタリングを行なった場合の結果こちらになります
え対応する
組まれていることはこちらのようになります
とこちら見て分かる通り
他スペインがあのー結構全くできていないという形になっています
ましたがってその
生徒の兵器やあのこちらはこう変化なんですが
まー結果はまー
えー音響情報まそれにあまり
ていないのではないかと思われます
えー
また今回スペクトル包絡なのですが
そのー
えー四千九十六
定型文を使って
含めた
えスペクトルを始めてまで
えー特徴
初めてにして
あのー
だったのですが
えー
そうすると今回はいかない可能性があるということが考えられます
えー
私がここに九っていったあー研究ででした音の識別をしていたのですがまその時は
自分ってでも
えーそれなりに識別ができていたのですが
それ風呂には含まれてる音は
かなりたったえーま色々含まれている為
えー
おー一やっぱ可能性があります
えこの結果をま従来研究の
との比較を
えー行ないました
えーっとでえまー比較したのは二．七
二の比較を行ないました
え文献ならでは
トラベルを使わない学会の二六ラベルを用いてまたの一を用いて二五クラスターには一
そこのセグメント長は一分で
はその一五クラスターの中四クラスターでえ再現率精度共に七十パーセント以上
土置いて
他のクラスではもう片方が高いかま両方が低いという結果の一
入っを本論文の手法ではまクラス数多く出すと
この図はそのクラスター二できてしまうという傾向はあります
ことを検討して考えられますのはやはりセグメント長が短いということを言わないと思います
えー
これはですねえー
同じ場所大クラスター
あー同じはそもそもセグメントでも
方法があるというあークラスたり
で分けられてしまった場合にその方としてみると実はロボットが含まれているということが
ありました
ん伝わってまー
えー
まそれが悪いんだと考えられます
えしたがってその場所をクラスタリングはまある程度一二というぐらいのまあるてると時間をセグメントを見ているのではないかと
考えられます
えまた
えー
あーそのことによって
クラスターは普通に分かれてしまったということから考えますと
閉鎖時間のセグメントというのはあのー音響情報に関するクラスタリングでは有効かもしれませんが今回用いた特徴量ではあまり有効とは言えません
えー最後に
えー
これ話すとなるのですがまマイクを扱う上で非常に重要となってくる問題についてお話しします
ぐらいグローブはですねま常に
特に音声の音声画像を
では×え収録している為にもありがとう音声や映像は取れてしまうということはあります
えー
方でまー従来の研究でもプライバシーについてのことを
カバーや使われて適用されているのですが
えーまー
とーその例としまして高い要するをする場合に関する情報の収録は可能であるという風に言われています
ですが発言内容をそのー
結局は収録してはならない
いう風に
そう言われています
えー
ま今後はそういう
を行なう為にはま一つのフレーム内を御自由ように分割してランダムに理解というような手法は
提案されていてもこれを行なうと発話内容を一つスペクトル情報が残ってるという風に言われている
またその許可を得たユーズユーザーというこういった形からのその発話内容をお水は
は非常に精度の高い話者認識が必要であるとも言われています
えまた一般的に利用
一般的神様の為に解決すべき問題として
多分水道局が必要かということと
あー誰がデーターにアクセスの各を
片方適用方法や
あー社会的な規則についてもはっきりさしていかなければならないという風に述べられています
そこ四十
まあのープライバシーを面からもまたそのー
データーの数はえー
とーデーターの処理はえーとーやっぱり音声があったりしてはもう凄い音にえ表記があるのでま音響別のう情報の処理も非常に重要になってくるという風に考えています
えー
最後にえーほぼあの種を求めます
えー
この文ではえー
音響ライブ用データーをクラスタリングを行ないました
えー事前処理としてもうセグメント付けを行ない
二月の特徴量を用いて警備クラスタリングを行ないました
えーその結果まー正規化スペクトル包絡比較的良好な結果をいるのですが
僕らと数を増やすことで余計なクラスターができてしまうという
問題がありました
ま結果特徴量としては二自分ではないかと思われます
えまた
えー過去の研究比較
との比較からまそう時間のセグメントあまそのクラスタリングにもい言って
畑からセグメントは音響情報をクラスタリングにおいている
可能性があるという風に考えられます
でまた
今回のデーター収録は倍音マイクを用いてえーとなったのですが
あのー結構そのー優先のマイクを用いると邪魔になることはありますので
ファクターを減らすには物凄いこう使うべきではないかという風に思います
でまたタイトルは初期の発達収録されるのでま複数の講義はマイクを
用いて収録したデーターの処理を行なってここでは一と思います
その方の課題としましてはまクラスタリング手法特徴量やセグメント長
あのー
×ですそのクラスタリングのうちインデックスを付ける為の手法や
これは四の問題について
考えていかなければ
んーないと思っています
以上で発表終わります
#############################


#############################
# query = 収録データーの話なんでけれどもた音声認識をするっていうことでそんなような音声データーをそのー品詞の為に使っているのかっていうので例えば四つのあ四歳だったりどれぐらいの時間それから喋っいる発話するとかそういうのはとー父はデーターセット全体の収録時間ですっていうのを知りたい
# rank = 2
# slide = 10-20_fix.match_word.jout.txt
# value = -4.48482444528739
#############################
はいそれではえー立命館第二の三ですけ発表いたします
え発表内容はこれ取ります
最初に背景目的思いましてえー人手によるだなくて実験を決定木を用いたえちょうどなくなって
そしてまとめと今後の課題となっています
一万最初の背景ですがえー非常に大きなえー四四のえ記憶装置が普及していることから
音声ドキュメント化値より蓄積されましたしかしえー音声ドキュメントは短時間でのえー情報多くの情報後のこんなうありまして
また蓄積されるされると
データーがえー増大するとえー検索でも行ないなってきます
すしかしえ音声認識の性能はこう女性で音声ドキュメントの後文字テキスト化することによってえー音声ドキュメント横に活用できないか
ということを考えます
しかしえー音声ドキュメントＮ音声認識をした結果というのは
えー本などしただけでありまして非常にえ水なものありますすその為にえー以下のようなえー
本て全て面倒四分割をする為の手法が挙げられますがえー以前私の
で研究してた文としてえー自動要約をえーしていたのですが今回はすえーと段落分の方を
研究をしてしています
え冗談泣く訳についてですがえー左の数がえー音声認識をした結果でえーえん
非常に読みづらいものであると
これをえー段落分けすることによって読み易い六つ目と作成できると考えられます
でえー常段落は形容行なうの取ってえーその手法の開発やえ評価音を聞いてすえ人手による正解となる段落訳実験結果というものが必要となります
で
しかしええーそれによって決定者だなというものはえー被験者間で必ずしも高い位置をしますと分かりませんすその為にえー安定したえー人手による段落は結果はえー必要になります
では本研究の目的としてえーまず最初に一つにある何らかで実験を行ないましてすえその結果が実際に
二つの手法の評価開発に使えるものかどうかってものを
と分析する為にえー段落の一致度というもの評価いたしました
二人にえー
段落境界
えー自動的んだなとは強固なのにえー韻律情報を利用する
とことを目的としています
あっそれではえー人手による段落は定位実験について説明いたします
て今回使用したデーターはＣＳＪのえー
文字声を二十個使用いたしました
ではえーその実験のえー環境ですが経験者はえ二十名でえー使用データーは先程のＣＳＪの二十模擬講演を使用しました
えー
えーこのＣＳＪのおんす
音声データーでえー書き起こしされたえデーターをお発話単位に分割してんでその発話単位でえー段落
後
被験者五人の数決定してもらいました
法的にえー実験二に音声を使わ汚いかでん段落は結果に影響があるかどうか分析する為にでまず実験者均等に二チームにふえー分けまして
この二講演音声のデーターセットをえーＴセット一と二セット二を作成しました
本当にけえー二セット一と二セット二ではえー従属節二という公園が一九四のように作成いたします
そしてえー
この先程分割したチーム一んばえーを二セット一の音声を聞きながら実験を行なって
Ｂセット二の音声を聞かずに実験を行ないます
でチームにはその逆で二セット二を音声を聞いて実験を行なって二二セット一音素比較に実験を行ないます
です日本的にえー音素を聞く場合はえー音声を聞きながらえーテキストから段落境界え段落とのところおえー決定します
そこれは実際に
実験に使用実験したい例ですがえー神様媒体として
私立中の書き起こしデーターを
発話妙に分割したものを一つしてあります
そこにいー被験者がえー個々人段落があるだろうというところにえ予稿頭派と思います
そこの
段落と決定するところは五文段落境界って風に呼びたいと思います
ではえー評価方法です一度の評価方法ですがえーまず
被験者体験者の一人ど一人の一致度を評価したも
そしてえー
え被験者グループと被験者グループとこの複数人同士ですえーい一度おー評価したものを二パターンを分析しましたんこんだけ用いた評価尺度としてはえーκ値
を用いています
えーと
使っこちら体の解釈はこの右の図のようになって今
えー
一八万最初に被験者間の一部ですが
んー
えまず一つのチーム中にえー二十人の被験者を二つのチームに分けているので一つのチーム二十人中から
えーん
人で二人を選出します
そしてえーその各被験者がえーこのテキストから
段落境界を決定して遊んだな境界の一度というものを三つします
この時にえー全ての被験者の組み合わせとして一人か二人に来たその第四十五通り
ありますでこれの平均を取ることによってえー各講演のすここちら算出されます
それではその結果はこのグラフですがえー横軸がえー講演音声データーの種類
んで
こんて言うっていうのは女性の場合でえー六ってのは男性の声のデーターを示します
で縦軸はκ値です
でえ被害の青い場合は音素について実験を行なった場合で例えば今は音声を聞か釣りん実験行なった場合の結果です
えっとこの結果からはえー被験者間の比較においてえー比較的高い一致度はえーることができたと言えます
またえー殆どの方において音素聞いた場合の方がえー一度はあの
高いってことは言えます
じゃ次にえーグループ間の方の一致度について説明します
す先程はえー一つのチーム一人か二人を抜き出したんですが今回はえ従属せずに
定年人のグループを二つ作成します
でそんことグループにおいてえ二人以上ベランダ許可を
グループの段落境界とするんですがえーＮが
その時三人のグループを二つ作成する時の例を示します
ＫさんＢさんＣさんの確定がえーテキストから段落境界を決定します
そして
二個のグループにおける段落境界を決定する方法として
でこのようにん二人以上が選んだところ境界を
んグループの九段落境界と設定します
んー
先程も言いましたらえー一人から
手縫いのグループを二つ作成します
えー
んで
えーその各グループ二の一
受けるえー段落境界
そういうものをえー
決定しましてその各グループの
一致度をえー算出します
これを
んこれ一年中から二つのグループを抜き出す方法としてえこのような組み合わせ通りありまして
まその平均をして
行為におけるκ値を算出してそれに一本全てを平均を取りました
とその結果ですが
えー
横軸はグループ人数のＮでえーのがイコール一の月というのはえー先程の被験者
漢の時におけるえ結果となります
で何が二三四五の時がえーグループ間におけるえー
一点を評価レース
誰地区はκ値で
左側のえ祖母が音声聞いた場合で高い方が音素してなかった場合です
まーこの結果よりえー
ホテルイコール一の被験者間だけでも
グループ監督の方が一度は上昇していることが確認されます
えーまたえー実験一に音声を聞いことによってえー一度はえー高くなっています
ところ残っておりでえー
被験者が一人で段落境界を決定するよりもグループデーターの教科決定した方がえー精度の高いですで段落はえー抽出できてるないかということとまた音声を聞くことによってえつまり韻律を用いいることによって
え段落分の精度向上
することができると期待することができます
でえー以前私はえ重要文抽出一二大学の方のえーじっ
広い研究行なっていたのですが
んーそん時のお人手による重要文抽出実験というものを行ないました
今度検索さがこの図はこれでえーこれはあ重要人手による重要文抽出実験の時の結果です
こん時は音声があるかないから分析をしてな勝つ為にえー七十まであります
八個の時も結果もえーＮがイコール一の被験者かの時よりもえーグループ人数が二人連れてえκ値が上昇しているということが確認されます
んー
このことからえー二段落はけ重要文抽出実験結果においてもえー被験者彼もえー
グループ間で
一比較を行なうことで安定した一どういうことが
できるということが言えます
ではこの
段落訳実験結果で得られたあ段落は一結果を用いてえー非常て金がなくて行なう手法の開発を行ないたいと思います
んー
それではえー自動ドアーな声で
．について説明します
んー
とまずお段落境界を自動的に決定する手順についてですが
えー音声をえー本研究用連続音声認識を用いて
えーテキスト歌手それでえー発話単位に分割します
んでえその発話
でえー今日価格協会談話境界候補に対してえー二言語特徴と韻律特徴さんそしてすその二つの組み合わせれることによってえー普段段落らしさであるえー段落境界取ってもそのすします
えその
二教会堂の上位数パーセントをすることによってえー段落許可を決定します
のこの各囲ったところについて詳しく説明します
えー
でえー店今回段落境界と予測する手法としてえーカードを用いました
これはえー決定木いーしてえー
段落境界をえ定量的に予測します
でえ今回はその方としたのかと六．二というものを用いました
一個のえーカードに
て決定木に用いる学習データーにおけるえ高いとなる段落境界でですが
これはえ先程の人手による実験の時の音素聞いた場合の実験結果
を利用しました
学習データーの球団の境界はこの式で表わされまして
これはい一人中のそのん段落境界候補となるところを何何だかっていう式で表わせます
あっではえー各境界に対する特徴量についてですがえーえ
言語特徴量二つ特徴四とえーこのようになっています
えっとそれはえそれぞれについて詳しく見てきます
えー
まず最初に言語特徴量の中の一つの段落境界候補前後の類似度というものですが
ところがあれば調音のえーえ前後をの発話内容が大きく異なればそこで段落は九八六では区切りれるのではないかという考えに基づいていますまずえーＴＦＩＤＦ値のえー上位百五の単語リストを作成します
えー
でえーこのテキストを張りまして
ここは今注目してる段落境界の後方になるところと
してえーその前の発話
後々の発話
だからえー
ここここ分析
服は二つ用いていましてえーい
こんて言ってたこの
んー二対一回の二十発話を用いました
えっとそのほ
二十八その彼らはえー
二単語頻度
この貝殻が参考データー論文という単語に声だっていう風にすえー単語頻度です
単語頻度ベクトル指します
でこの単語頻度ベクトルの類似度というのを表現を取ることによって算出しあり
すこれをえ全てをん段落境界に対してどの教科候補に対してえー類似度三つ四あります
んで
えーこの類似度はえー小さければ
え大きく内容が異なれば段落境界である可能性が高いということが言えます
えっと次に手掛かり語ですがえーこれは
段落空気を段落となるえー前の発話の文末では次の発話の文と二は二えー段落遅く卒業の言葉があるのではないかって考えに基づいています
えー
んー
揃っ
その単語をえ人手による段落で実験データー世界だな境界からえー抽出しました
その
普段
他駐車単語接続詞で
んその例をここに示します
で父そしてなどが挙げられますが
このような
一えー単語が今注目してる段落境界後方の
前の発話の文末えっと
次の発話のえー文頭にあればえーその教科に対して一四
なければ〇を付与します
たった次に韻律特徴についてですがえーあ
向こうの傷は
えー話す速さ
声の高さポーズ時間情報を用いました
音だけのえーポーズ時間中におおけるえー損失のし方ですが
えーまず発話の特徴算出します
本当けえー発話におけるえー
えー声の大きさや
えー
放送時間長が基本周波数の
平均値え最大値最小値えー幅を算出します
一んで今回は
境界をえー決定することからえ強化に対して特徴を算出する為に
んえー
店許可候補前後の発話のえー特徴の差っていうものも取れます
二九の各特徴に対してえー兵器や最大値を採取時レンジを算出するんですが
この間なんだなっていう境界候補に対してこの差を取ることによって
腰を付与してきます
じゃ最後の特徴としてえー直前の段落境界からの発話数ですがえ一般的に発話か言ってきたんたつごとにたい
連れてえ段落は挿入されてこのないかって考えに基づいています
例えばあこのテキストはありまして
値段など許可がここにあるとします
そん時ね今注目しているえ段落境界候補がここにあるとするならば
殆どの境界候補に対する特徴として
ここからここ丸のえー発話数を
算出します
これを全ての店境界候補に対して行ないます
言っで
ここもないのですが次に心んで後お母来ますので
ん次のこの
対する評価候補の特徴としてはえーここの他の評価からの発話数
という風になっています
一度はえー特徴量の組み合わせですが
言語特徴のみを用いた場合
言語特徴とえー方と時間長を用いた場合ん言語特徴に連続値を用いた場合この的に特徴にはこのポーズも含まれております
でえー先程述べた全ての徳中を用いた場合
その後四パターンと
えー発話内容を音声認識で決定した場合
後えー
その発話内容を人手で決定した場合
この八パターンについてえー分析行ないました
えーとこの時にえー括弧の中の数字がえー用いる特徴のカードを出します
えー例えばこの言語特徴の場合ですとえーん類似度と手掛かり語
といった形の
えー
んー
それではえー旦那教会堂予測する実験としてえ使用したデーターはえ人手による一つえー段落訳実験で用いた講演音声データーと同じように
二十講演同じ二十五円
で評価尺度はえーκ値とＦ値を用いました
本当池えー交差検定ほクロスバリデーションによるオープン評価を行ないまして
二十この一一九講演から学習データーを作成します
でえその残り一講演をえ評価してそれを
えー
一講演綴るずらすことによって二十個の平均を取っています
じゃ今度近年えー正解
でκ値がＦ値の対象と比較対象となるデーターですがえー正解
人手による重要文抽出実験によって得られた世界だな境界と
決定木によって予測された段落境界この二つを比較しますが
世界段落境界というのはえー音素を聞いた場合のえ先程の式ですねを利用してす
えーこの式の
えー
算出される教会の上位三パーセント五パーセント
をえー二パターンを用意しました
んえーえ次にえ決定木予測されたんだ境界としてはえー決定木によって予測される旦那教会堂お
一階定量的に予測されますので予測された値の三パーセント五パーセント
でこの三パス図の照合パーセント同士を
えー
活発に中で
で算出しております
その実験結果ですがえー左の図が
形によるもの右の図がＦ値によるものです
でえそのグラフの中でもえ左側連続音声認識によって発話内容を決定した者
右の図はえー人手による書き起こし結果によってえー決定した後
んで
んこの結果からえー全てのパターンにおいてえーこの言語特徴よくは言語特徴の時よりも
すえー韻律特徴量をこの緑の番
んですね
僕は主語が一度は上昇してるというのが
特にされます
また
んえー
この発話内容失礼書き起こした場合のおー言語特徴うーの結果はえ比較的腹
えー
一度は高いのですが
連続音声認識の場合はえー言語特徴がうまく
エラーが勝つ為に
つらかったと考える為にえー一悪くなっていますが
本時のえー
こちらの
上昇値よりもこちら上昇しのがえー高いっていうことが確認されています
んー
んでえー次に五パーセントのす場合ですがえー基本的な三パーセント五パーセントでは本当の町な傾向が見られたのですが
んえー
一応年の五パーセントの時の方はえー高い値がやられています
でこの時にえー韻律情報を先程同様にえ二つ情報を加えることによる後ろに上昇してはえー顕著に現われる変わっているってことが言えます
一本はえー
最後の特徴で
述べましたえー八ん直前の段落境界からの
発話数を加えた時によるえーす効果もえー五パーセントの
でえーっと評価理想パーセントの時の連続音声認識結果的す
においてえー非常に高くなってるとかが確認されました
んこの結果からえーえ
世界段落境界から発話数も
え言語っと情報が乏しいと近年えー非常に有効にんー
借りたいかってことは考えられます
えーん
でえー
いー前は用い
実験したえー要約結果がえーこの右の図なんですけども
本当経営
日前え重要文抽出実験結果あそこを右の図ですでえーこの時
長所を用いた特徴が違ってまして
この一番下あのが言語特徴よ
て二番目がえ言語特徴四とえー発話の長さ
で
この緑のバーがえー二つそれに韻律特徴を加えた結果となっています
じゃ
と言うかこの時もえーあ
なってから年もえ韻律特徴よくあることによって一度にある時はえー
い塩が少々下がってしまったんですが
で
本連続音声認識結果の時はえ韻律情報を加えることによってえー位置が高くなってるところが確認されます
このこと
ことからえー段落は体時もえー条約の時も
言語情報が乏しい時にえーと
だっ韻律特徴加えることによる
よってえーす一度から
下がると
いうことが言えます
またえー要約結果音一は一度の上昇してあんまりん
未熟だったのですが棚こちら時は
えー
おっきく二
イチローが上昇してるとこう確認されます
それではえーまとめですが本研究ではえ人手による段落訳実験とお店教会堂予測する実験を行ないました
んー本当一人にあれだなくえ実験結果からえー二つ情報も切ることでえー段落清潔交渉の可能性が示唆されまたえ被験者蛙もグループ化の方が判定者となっ詳しい実験結果得られたと言えます
そしてえー段落を予測した実験としてはえー
正確な言語情報が得られない時に
韻律情報を加えることによって
韻律情報は段落の長さを加えることによって
えー非常に段落
訳に有効であることが分類しました
で今後の課題としてはえー今は
えー発話の特徴量や境界特集をおー吸っ
一発話全体の特徴を用いてえ算出してるんですが
その発話の文法え文末によるえー特徴の算出が話者の話し方に喜んの分類をしたいと思っています
以上です
後ございました
#############################


#############################
# query = 信頼度スコアっていうのをっていると思うんですけども確信度スコアと信頼を確信度不幸はっていうのはということを元に求めているのかというところ素性とかま例えば一のモデルとか言うん国立とかあると思うんですけれどもそれ確信度スコアの求め方の詳細っていうのが知りたい
# rank = 1
# slide = 10-14_fix.match_word.jout.txt
# value = -5.26168089564209
#############################
相手それではえー複数の側と言語モデルを用いたえー音声中の検索を検出の構成どこと題しまして
え違和的に最悪の方のドラマ発表いたします
えーまず研究背景ですけれどもえーこれまでのえ発表にありましたように
えー
とマルチメディアデーターのようなえーその音声を含んだデーターが増えてきていてその為のえー検索機能というのを求められており
てえーまそれに対しえー
音声中の検索を検出の注目されて
てえー
いるということですになります
でえーま代表的なえーっと音声長の検査コンテンツ方式についてえー
簡単に述べたいと思います
えー
えとまず検索対象のえー音声ドキュメント
こうえーま汗をベースの音声認識とサーバーとベースの音声認識を用いてえー単語系列とサーバーとモデル系列
にえー認識をしておきます
でえーまこのようなイメージとなります
て検索語はえー一対五の場合は関係ですからえー未知語の場合はサーバーとモデル系列化といったように
てえー検索語のえーこの基地の
地下道化によってえーこの
系列を買って書いてと言うかえーまーその二つの系列を併用するという方式をんまー
えー
歯対照的であるという風に考えます
ってえー既知語の場合になんですがえー検索に統合することで
てえー高速えーとまー父もですのでま高精度に検出が可能であるという風に考えます
えしかしえー未知語の場合なんですが
すえー既知語と比べてえー素性を取るという風にされていいます
でこれって印はえー認識誤りがえー多く起こる為です
って側の人しか山に対するえー完全性がはえー求められます
そこでえー本研究では
でえー砂漠を用いた検索方式における英語認識に頑健な
検出の実現を目的としております
てえーこれまでにえー私達の研究してはえー幾つか
えーサーバー豆腐の方式について幾つか提案をさせていただいておりましてそれこちらについてえー紹介をしたいと思います
で一つ目ですがえ新しいサーバーとの提案ということで
てこの二分の一三分の一音素ごとＳＰＳというものを提案してきておりました
でこちらは〇のスライドでちょっと説明をしたいと思いますでまずにべん勿論そうですが
ふえーこ一ナイフをえー二分割した形で
で捉え方の前半部分と後半部分に分けて別形となっております
で三分の一音素と同様にえートライホンを三分割してえー
でこの中心部分をですねでモデル化した形となります
ってですＰＳなんですがえーこちらはえーっとーお
音素のえー中心部分と音音素間の
あえー遷移弁別のえー話題の部分をえーモデル化しているという形になります
んで更に
えー破裂音ですねのえー直前に行ってるで無音部分
についてもモデル化をしているということになります
定型これらのえーサブはどの検索性能を
でえー示したいと思います実験データーについては後で示したいと思います
てこちらを見ますとえー従来の
でえーこのこのトライホンと比べまして性能が良くなっているということが分かります
えー
で次にえー検索方式
そしてえー千提案しているものとして
え複数の砂漠の検索結果を統合による検索方式
えーというのをえー提案し取りますえこちらはえーそのー先程えー示しました各サブワードもえー検索した結果
その方法二を検索方式でえー
もう統合することによってえ検索結果に含まれているこう検出とを総合的にカバーする
というえー方式となります
でえーこちらの表を見てていきたいんですがえこちらはえー
検索ご喉頭のえー検索性能になります
て先程示し素性の一番下となっております
ってことは平均的な性能となっておりますで平均的にえーの精度で終わりにべん勿論その一番高い
．一つのですがえ検索語によってはえートライホンですとか三分の一です率が高い
そういうようなこともあってえーまこのえー表に示す通りえー検索性能にばらつきが見られます
でまこの結果を見るとまーそういったような結果がえー側と求められているということで
えーっと重することによって検索精度を改善するのではないかということも予想できます
でえー本研究においてもこのサブはその
え複数サーバーが最も方式交差えー用いております
でこの統語方式の概要について述べたいと思います
えーまずえー検索対象の音声ドキュメントのえー発話区間ごとに分割をしておきます
で兄がその区間ごとにえー各側とでサーバーと認識を行ないまして
えーこのえモノホン系列トライホン系列
えー二分の一といったような形で保存をしておきます
あって検索語はえー変換規則入れてテキストで与えて
えー変換規則に従いましてえ同様にモノホントライホンえー二分の一といったように変換を行ないます
既にえー同じたばこ間でえー
で作り比例マッチングを行ないます
てその結果はえーこの発話区間をえーそのＤＰ距離が大人に得られます
えー
てえこのＡってこの図に示すようにま複数のサブはとても検索結果が得られます
えー
えー
それでえー例えばえーっと
ペアは全て統合する場合の二つのこちらの式を用いて
えーまある区間でこの場合はえーですがえモノホンのえ二匹より
にえーαという重みを掛けて
行けるというな形でえー線形結合の形で統合を行ないます
えー
でその結果えーこのように
えーえ
二つ見づらいんですがえーラージＴということでえーともう距離
としていますがえーこの辺に従って再度えー発話区間が順位付けされてユーザーに提示されるということ気になります
えー
て重みえ先程αとしていましたがその設定方法として
えー事前に定めておいた重みを設定して統合する方式ということでえー単純えこの方法を三十先生と思っと呼んでおります
で例えばモノホンとトライホンを統合する場合
デモの方に〇．三トライホンに〇．七といった形で与えます
つえー
この方式ではえー全ての発話区間において
同じ
重いん終わったよでかつ工程の重みを与えるという方式になります
でえーっとまたばこの発話関係全てに対して
でこの重みのえー適切最適であるとはえー限らないというに考えます
そこでえー
今年のえー昨年え音響会で発表して一つせていただきましたが
え信頼度を用いて重みを設定する
という方法をえー提案しております
でこちら先程と同じえー状況で
でこのえー認識のえ信頼度の大きさに従って
でえー重みをえー動的に変えるというやり方となりますでこの場合ですと
えーえーモノホン
のえー信頼度母数トライホンの信頼度を比較して
えートライホンも信頼度は高いのでトライホンにえーこの関係ではえー
んー大きな重みを与える
一有意なことになります
ベビーではその逆で
えモノホン認識の信頼度が高いのでもの方に大きな重みを与えるというやり方となります
ってこんえー区間ごとにえー信頼度に基づいて動的に重みを設定します
でそこでえーっと発話間における信頼度をおえー区間信頼度として定義します
すえーこのようなえー状況をえー仮定しますえ検索語はえーっとＡＢＣとして与えられているとします
でこの検索語とえー発話区間のえサーバーのモデル系列を
えー連続ＤＰでま陳するとおえー今回お母さんとして
えっとーま要は検索本最も類似してる考えられます
て今回八日間のえーっと側とモデル系列はえーＧＢだとします
してこの二つのえーサバとモデル系列汗をえっとＧＰ法でアラインメントを取ります
でその結果えーこのように
えーっとえー
ぴいぴいアラインメント結果が得られましてえー一から検索語で携帯をか状態を区間にそれぞれ
えー
ってこうだから与えられる信頼度が付与されております
でこの結果を
えー
検索本一致するもの正解良い一致しないえー地下誤りですとか
ずっと対応区間のみに現われる挿入誤り後は検索もの見にあるえーえ
脱落誤り
こうおえー決定します
えー
てその決定結果からえーこのような式を用いてえーとその信頼度を計算します
えー
でまずえー分子の第一項が生成回帰モデルの信頼度の総和です
えー
でこちらのえー括弧の中でそのえーと誤りと挿入誤りモデルのえー信頼度の総和えーこちらペナルティーとして
用いていましてえこの地下誤りですとか挿入誤りが高い場合には
でその間にはその検索語以外がある可能性があるのでそれペナルティーとしてえー検査もします
えー
えーって文法化はえー正解置換挿入脱落の数でまーえー平均を取るような形となります
えー
でこちらのデーターはえー傾きの影響を変化させる係数として
え用いております
すえーこちらもえー
このえー菓子などの大きさに応じて英語によって決定をいたします
てここからえー本研究でのえー提案する内容になるんですが
え複数音響言語モデルの検索結果今後の検討ということになります
てえー今までえー複数のサーバーと検索結果と思うということで説明をしてきました
うこれはえー三ワードごとに得られるえー大量な検索結果を統合することによってえ性能改善掛かるという文を知っ
そこで本研究でもえーとの対応の検索結果を受ける為に
えー複数の音響モデル言語モデルとも知ることを考えます
すえーここで
えーその対応も結構いる為にはえーとーそうすればいいかとかそういうことをえー考えますでこちら示してるのがえーサバの検索の枠組みとなります
えー
っていう交差ワード検索結果
えーんんですがえーまこちらはえー音素バードー認識結果
にも依存してこう変わってくる
とえー考えられます
そしてこの認識結果ですがえこちらはえーこちらのえー認識率の歳のえ音響モデルですそこはえー言語モデルに影響受ける
てえー変わってくると考えも
でそこでえーとその学習データーがえーことなれば
えー多様な検索結果とえー得られるのではないかとえー期待できます
あってそこでえーこの図に示すようにえ学習データーをたくさん用意しまして
えーそれらでえーっと音響モデル言語モデルを学習しますでそれぞれえーサバと認識と照合を行ないまして
えーこちらに示すようにえーまたこの
結果は得られるとしますで
こちらのえー
結果を統合することによって
低精度の改善を図るという形
になります
でえーこのこれをえー
この方式をえ複数のたばこの場合に適用しまして
で単一のモデルを用いた場合よりも高い精度を
を目指します
てえー予備実験といたしましてえー言語モデルをえ先行側の検索性能について調査をしました
でえーっとモノホンモデルを用いましてえーＪＮＡＳとＣＳＪそれぞれ言語モデルを学習しております
えー
てこの結果をするで一番下はえ平均的女性の方でもそれ程変わらない結果となっており
生活を結構見ますと
でえーっとその節検索性能にえーばらつきがえー見られまして
父の結果が得られていると
っていうことが分かりますでま統合によって双方効果が期待できるんではないかと
え考えられます
二えーっとここで本研究ではえー言語モデルに着目しまして
え複数サブワードををｘえ言語モデルの検索結果と思っても検討いたします
で用いる言語モデルですが
えーこの三つのデーターを用いてえー構築いたします
でえー一つ目のえーＪＮＡＳ
となりますで二つ目のＣＳＪ
て三つ目がえーっとウェブ事象ということでえ百二十万単語文えーっと辞書も読み系列を用いてます
でこれをウェブから収集された単語からえー構築しております
え評価実験についたいと思います
えー音響モデルをえーとＪＮＡＳでえー学習しまして言語モデルはバイグラムと後ろ向きトライグラムをえーそれぞれ作っております
で検索対象はえーとＣＳＪの約一三時間もデーターでえー検索語は五十件
え専門用語など五十件を用います
評価指標をえ平均適合率の平均値を用いております認識エンジンはＪｕｌｉｕｓを用います
てえー評価実験のえー方法なんですが
えークロスバリデーションにより評価を行ないます
えー単純線形統合におけるえーっと重みの組み合わせと発話から信頼度におけるパラメーターとしてデーターがありまして
えーこちらのえー最適な訳屋台で
評価を行なう為です
んで検索も五十件ありあるんですが
でそこ分割をしてえー起こる
評価を行なっております
てえーまず初めにえーっと言語モデル別の検索性能を示します
歯えこちらを
でえーえそれぞれＪＮＡＳＣＳＪ例文辞書の結果となっております
でくえこちらを見ますと
えー二分の一音素三分の一音素ＳＰＳとライトモノホンの順でえ精度が高くなって
います
えーえ次にえー
私立中の言語モデルを用いてえ複数のサーバーとの検索結果を
放送の側の性能について示します
えー
えっと一番上にあるのがえーサバル単体での
えー最良の性能となります
えー
でこちらを見ますとえ反対の場合と比べて統合することによってえー検索性能が改善しているということが分かります
って更にえーと単純なやり方ではなくえ信頼度も知ることで
えーちょっと変わらない場合もあったんですがえー殆どの場合でえー約一二パーセント程度の性能が改善されております
でこのことからえー三本男か
ですとか後分かん信頼度も知ることの効果というの確認できます
ってまたはえーそう組み合わせの数が多いことをえー検索性能が改善する傾向がありました
というえー三つがはえー二つ統合する場合って
でこちらが三対四テストなんですが
てその組み合わせの数が多くなることをえ性能改善する傾向が
ありまして
えー
ま数が多い程そこの相関が大きくなる
と考えられます
でえ次にえー二箱一つでえーＪＮＡＳと言語モデルとＣＳＪの言語モデルの検索結果を方もした場合の性能
おしめします
てその単体最良とありますのがえー前はそうＣＳＪでの
えー
最良値となり
えー
一〇一二の三回最良値と比べますとえーと音をすることによってえー一から四パーセント程度ですね
補正の方はえー
改善しております
でまこの結果からえー
くその言語モデルを用いいうことで
って性能改善しているということも分かります
で更にえー名物の言語モデルを追加した場合無声の二ですが
増えたんだ開催量は先程と同じでもえーと三つの言語モデルでの最良値となります
五つの白いえーところがえーとＪＮＡＳとしえ先程示した結果になります
昼間ついて述べ文章を追加した場合の性能です
ふえまずえー単純線形統合の場合なんですが
えー半
とさせて二十以上のえー常するのではなくてえーサポートでえー一パーセント前後改善
しております
てまたえー信頼度を用いた場合にはえー全ての砂漠でえ改善ありまして
え最大でえ取らこの場合ですが三パーセント程度改善しております
え次にえー複数の差分を後にえー
ん適用した場合の性能について示します
え言語モデルはえー素性出すとＣＳＪになります
えーえーっとこちらも側の九月なんですが
えーとトライホンの場合えーっと多値がその衛生のちょっと低かったのでえー今回のＣＳＪのみを統合しております
えこちらを見ますと
えー
まず単純線形と面は
え半数以上のクラスが一パーセント程度改善をしております
価値を四十のみの場合と比べて
え一パーセント程度改善しております
あってえ信頼度を用いた場合にはえー全ての組み合わせで一から二パーセント程度改善
となっておりまして
えーうまこの結果からはえ複数の砂漠の場合でもえー複数の言語モデルを用いて
っていうこともえー効果を確認できました
えー
それで次にえー不辞書を追加した場合のえー戦後になります
てこちらの場合も同様にトライホンはえーとＣＳＪのみを用いております
えー
でまずえーＪＮＡＳと表わすんで単純線形と文の場合ですが
えーＪＮＡＳとＣＳＪのみと比べましてあえっとー僕ら比較しますと
えー戦後ほぼ同じとなっておりますてこの原因といたしまして
えー今回えーっと単純線形統語では重み法をえーと〇．一刻みで設定してまして
で更にえーっと重みが〇を含む組み合わせ方はえーと除外してえー実験行なっております
えーでつまりえっとーこのこの場合ですとえー
とー検索結果を一個使っていることになるんですが
えーっと全て〇と一一というえー
近所の重みとなっていってませんのすることを
改善しなかったのではないかという風に考えてえ
持っております
えー
で次に信頼度使った場合
ですがえーまーそう変わらない場合も
て殆ど変わらない場合もあるんですが
テーマ最大．五パーセント程度
改善する結果となりました
てえー元の元といたしましてえー信頼度語で
でその寝台車高いところも三をえー統合していった為であるという風に考えます
てえー最大でえー今回えー八十二．八九パーセントということで性能が得られまして
えサバを単体の最良値よりもえー七．四パーセント改善しまして
で言語モデル単体の最良値よりもえー２．〇パーセント改善する結果となりました
えー
ですで最後にえー検索時間について述べたいと思います
えーでこちらはえーサバ団体の検索時間でえーっとそのクラスは統合処理のみに要する時間となります
て信頼度を用いる場合このアラインメントですとかはえーその
って発話区間ごとに重みを計算するので
定義文をえーあ
性能化と
検索時間掛かるんですがえー
えー
ありますでアラインメントはえ照合時間もえー平均すると約二割程度の増加で
とかですのでまそれ程おーま大きな
えーっと伊藤ではないかなという風に思っております
正解にえー二分の一三分の一音素ＳＴＳについて
言語モデル三つ用いまして結果の信頼度を使って統合する場合へ行っちゃったり読んで
約四秒程度
検索に時間が掛かることになります
テーマこれ一のＡ対策といたしまして
えーうちＢをえーとその用いまして処理を並列化することを考えます
メーカー
て今回仮にえーま三つ前のモデルを用いますので三つのＣＰＵで並列化することで
でま三分の一程度に抑えられるのではないかという風に考えます
えーっとえーまとめます
えー
本研究ではえー複数のサーバーと複数言語モデルの検索結果と面によるえー音声情報検索の検出において
えー高精度化する方式の提案を行ないました
てえー最大でえー八十二．八九パーセントの検索性のえーということができえサーバーを単体と比べ
てえー七パーセント程度
言語モデル単体と比べて二パーセント程度性能改善しまして
え提案す方式の有効性との確認できました
って今後の課題なんですがえーっと検索性能の構成とかということで
えー今回三つ用いましたがえーそれ以上の数のえ言語モデル
思っていることで後音響モデル今回できなかったので複数の音響モデルで特にＣＳＪを用いる
ということをえーこん
進めていきたいと思っても一人も
てまたをえーサバと認識処理のえー区間がえー
夏の数を増やすことにも大きくなってくので
テーマ少数最良での結果が得られてい女はえー
サバ取ってそこは言語モデルの選択方法の検討を行なっていきたいと考えております
え以上で発表終わります
#############################


#############################
# query = 信頼度スコアっていうのをっていると思うんですけども確信度スコアと信頼を確信度不幸はっていうのはということを元に求めているのかというところ素性とかま例えば一のモデルとか言うん国立とかあると思うんですけれどもそれ確信度スコアの求め方の詳細っていうのが知りたい
# rank = 2
# slide = 11-15_fix.match_word.jout.txt
# value = -5.41215293198839
#############################
えーでは
後現存ネットワークを用いたしあれによる音声認識誤り訂正えー題目で神戸大学×研究室の中には発表させていただきます
えまず研究背景といたしまして
えー
えー音声認識精度
はえーニュースなどの正しい書き言葉で後画像九十五パーセント程の精度があるのですが
えー学会講演などのえ自由な話し言葉になると
後八十パーセントまで下がってしまいます
えーよってえー話し言葉でストレスのないえー音声認識を行なう為に
更なるえー音声認識精度の向上が期待されます
えー
えー従来の音声についてま簡単に説明しますとえ従来音声認識では
で言語モデルとして自然なえバイグラム
やっトライグラムの動画としています
えしかし
えーこのＮグラムの問題点といたしまして
えースムージングなどによりえー不自然なＮグラムが発生してしまうえーことがあります
えまた問題点が二つ目として
えＮグラムが自然だとしても
文章として自然な場合があります
でこの例文を見てもらったら分かると思うんですけど
別データー冷たいものが食べたくなかったっていうのは
えー自然な
で二グラムから生成されたえ文になっています
えー次に
えーこのえー冷蔵庫の中に面積をえ〇であるというのもえー自然がＮグラムからえー生成された自然な日本語です
えしかし
先程の分布並べますと
えー冷蔵庫の中に面積を入れてある冷たいものがあー食べただからだとなりましてえ冷たいものやえー食べるでうちはだから
え面積という部分に不自然さを感じるようになります
で現在のＮがものでではえーこのような不自然さにえー採用することができません
えーよって問題点が解決法といたしまして
えー問題でえー一つ目の
自然のＮグラム
自然のＮグラムの発声に対しましては
予めえーま識別的言語モデルといたしまして
自然のＮグラムを学習しておくことで解決したいと思います
で問題点の二つねでえーＮグラムでは分からない不自然さに対しましては
えーバイグラム
トライグラムよりもおー範囲の文脈情報
をえー取り入れることで解決します
猫でえーこの
後半えー文脈情報場所でえ文脈情報ということにします
で後え提案手法ですがえ条件文脈情報を用いた四あええ音声認識誤りをえ曖昧性性をえー提案しまー
えーまずえー自然
あー自然あるいはえ自然のＮグラムをしアレーを用いて学習します
えーこの為には予め
えー学習単語にえ最後ラベリングを行なっていく必要があります
えまたえ四八例によって学習する素性の一つとして
ちょっぴり文脈情報を追加することで
音声だけの二つの話題を考慮します
えーえ構造ここまででえー知られえ誤り検出モデルが
えー作成されますので
えーそれによって曖昧性識別された母音計算ネットワークを用いてえー説明
えーまずあのー平叙ネットワークについて簡単に説明しますと
えー
これはえーまークラスとクラスタリング圧縮することであります
えまたその過程でえーこのように
確率に信頼度が付与されます
えーこの
あ多い
点線の部分で
えー
点線で囲まれた部分はこの閉鎖音セットと言われていまして
上から順に第一候補
第二個おー第三方向という風に表現されています
えー
本研究ではえー四アレーによる誤り検出を用いてえこの
九ながら正解を探すことであんまり
えー誤り訂正を実現します
えまたえこのえー見にくいですけど水色で囲まれている
えー
入るんで表わされている単語はＮ付いて張りまして
でこの七歳を選択することで
えーこのヘッドセットスキップすることができます
えつまりこの
第一方法列を選択しますと
私価値はえー単語列が生成されることになります
えーこの音でサインを選択することでえ挿入誤りを決定することが可能になります
えー
知られによる誤り検出モデルについてまー簡単に説明いたします
えー私は頭から来た
っていう入力に対しましてえー誤り検出モデルをえー適用しますと
えー例えばこのようにラベリングを行ないます
でＣというのは背が得られ
いいっていうのが曖昧な縁になっているのでえここ
えーこの誤り検出モデルにおいて
えーこの私
っていう単語がえー誤りであると識別されたことになります
えこのえモデルの学習にはえー単語単語列に成功ラベリングが発生後ラベリング
されたものが必要となりますので
え音声データーを
音声認識器に通しまして
えー書き起こしデーターと比較することでえー先行ラベリングを行ないえー学習を行なって今
えーまたえー整合それぞれの学習えーそれぞれの特徴を学習するので
えー自然なＮグラムと共にえこのように
誤りを含んだ自然のＮグラムについても学習可能になり
えーこれはま知られうー
えーせえー二終わらせまー条件付き確率分布になってるのですが
えー
あー入力Ｘについて得られる場合が付与される条件付き確率で表わされています
えー後えーラベル場合っていうのは
えー本研究では生後ラベリングに用いますのでえーし
正解ラベルと誤りあるのに一位になって
えー試合二のえー学習はえーこの
素性に関して関するえその素性が重要であるλ
うーこう学習するのがえー学習型となっていまして
でこの条件付きか
条件付き確率
あのー対数尤度を最大にするように計算されます
えー
もっと具体的に説明いたしますとえー
頭別のように明らかにえー誤りだと分かるバイグラムは
えー誤り部分音のみよく出現しますので
えー
誤りに対する重みが大きくなるように先程のλが学習されます
で逆にこれは
のようにおだけでは正解誤りかを識別できないえーバイグラムに対しましては
えー
えー
重みがえー小さくなるように計算されますえー例えばえーこれは犬
えーこれは犬のようにえー犬です
のようにえーたちますと
えー
それはえー自然な
えーＮグラムになりますのでえー
正解傾向を示すＮグラムになるのですがえーこれは食べるようにえー指しますとでそれは誤り傾向を示すＮグラムになってしまうので
えここでえではえー正解誤りを識別できないということになります
えーこれはえー例としてえーバイグラムをさ既にえー説明いたしましたが
えーとこの音響尤度やえー品詞の連鎖など
でさまざまな素性を柔軟に設計できるのが特徴となって
によって
えっとそれの一つとして
名所けえ文脈情報もえー取り入れることにします
で条件文脈情報ってのはこれはえー周辺のえー認識結果単語を参照した時に識別対象単語が不自然でないかという情報のことになります
えー例えば音声
であえー会話
話者
対話っていう単語が現われる場合の中に突然大根
っていう単語は現われるのは不自然だと感じられます
えこのように出現単語の水データーをい三つとして大切な
えーこれによってえーバイグラム
トライグラムよりもえー後輩の文脈情報を考慮できるようになります
えそしてここではえ動詞形容詞名詞のみにスコアが今
えー
え次に意味スコアの算出ですが
えー
これはえー単語ｗについての水を求めるとします
えーそのその場合えー
その単語Ｗとえー周辺の単語集合
調べデーターのえー類似度をまず求めます
えそしてえーその周辺の単語ｗｉの各ｗｉにつきましても
えー類似度を求めましてえその平均分かります
熱でえその二つの値
からえー正規化を行ないえそれを意味スコアとして今
えーこのＬへ児童の計算にはえー星を用いていますがあまり形成について説明は割愛させていただきます
んえー提案手法の流れになりますが
えーっと以上のようにえー説明したあ手法を用いて提案手法をえ実現します
えまず
えー音声認識器により音声ネットワークを出力しま
えーこの音声データーは
私達は
という発話に対して出力されたコンピューターネットワークです
えーこのこのえーとネットワークに対しましてえーちょっとえ文脈情報としての
水を増やします
えー先程申しました通りえー形容詞と
名詞と動詞のみにえー三つかを与えるので
えここでは
えーまー名詞しか登場していないのでえー現われた名詞二に都合が付与されます
えそしてえー
この今日のネットワークと
私達はえー書き起こしデーターを用いましてってせいもラベリングを行ないます
えーそしてこの
このデーターを用いまして
知られずによって誤り検出モデルを学習します
えー
えーそしてえーその
流れ学習した誤り検出モデルを用いましてえコンピューターネットワーク上で
音声認識の誤り生成を行ないます
えーその生成手順について簡単に説明させていただきます
えまずえーま何らかの
えー音声データーを入力しまして
えこのような
ごみのネットワークが出力されたとします
えーこのエコーロケーションネットワークの
最尤法これ
えー第一次以降これとえー抜き出しましてえそれは私達は
というえー単語列になります
その単語列に対しましてあんまり現実を行なうと
えこのようにえー示されまして
えーかつて単語は誤りであると識別されました
あよってこの第二候補である
×と置き換えることにおいてえ性を行ないます
えーそしてえー活動着替え私達はっていう単語列ができますので
えーその単語列に対してえーもう一度
えー四アレーによる音声認識の曖昧で検査を行ないますと
でこのようにえー全ての単語がえー
正解であると識別されました
えこれには別訂正があり四といたします
えー評価実験といたしまして
えベースラインはえーＣＭですと書いてあるんですが
えこの併存ネットワークのえ最尤法これ
えこの単語列を
えベースラインとしての
えまたえー飲んセマンティックというのはえー提案手法の素性としてい水を用いない場合
えつまり
で知られてるによって学習パス
学習する素性がＮグラムだけの場合となります
そしてえープロポーズメソッドっていうのはえーそれにリスクを
えー
付与しえーい水を
祖先の一つとしてえー追加した場合
で更にオラクルというのは
えこの併存ネットワーク上の正解単語を全て得られた場合の単語列となりまして
え本研究のえー既存の値となります
で評価しようとしましては単語誤り率
まーデーターベースを用います
えー我々とはえーこの
えー置換誤り
削除誤りって挿入誤りをの葉をえ全単語数で割ることによってえー算出されます
えーコーパスといたしましてえー日本語話し言葉コーパスＣＳＪを用いました
音声認識はＪｕｌｉｕｓえー音響モデル言語モデル共にえＣＳＪから学習しています
でそして誤り検出モデルのえー学習には
えＣＳＪの百五十講演
で評価にはＣＳＪの一三講演を用いています
えー最後にえー知られの
えー誤り検出モデル
のえー学習に用いた素性といたしまして
え表層単語の意味であのーバイグラムトライグラム
えーそしてコンフュージョンネットワーク上の信頼度
で更に意味スコアそして今
んえー実験結果ですがえーまず単語誤り率についてえー評価したいと思います
えー
でこれがベースラインであるＣＭでさんがあるんですけどえー韻律句を用いない
家のセマンティック
でもえーベースラインに比べましてえー三．五三ポイント
えーま与えられたが改善しているのが分かります
え更に意味スコアを追加することで
えーベースラインに比べまして三．七五ポイントを改善しました
えしかしえーこの二そんな体であるオラクルと比べると
また
僕の誤りがえー残されているのが分かると思います
えー次に誤り種類別の評価をします
えーここではえー
意味スコアのない場合とある場合についてえー評価をしたいんですが
え削除誤りと
挿入誤りにつきましてはえーこの
えー
あえー誤りの数が殆ど変わっていませんが
えー
一番多く変わっていたのはえー
この置換誤りでしてえー置換誤りがえー
水を用いない場合とを用いた場合ではえー
曖昧が百個程
減ってる
という結果になりました
えーよってえー韻律語はまちょっとえ文脈情報は置換誤りに思い出に有効でありました
えしかし
えーっと
置換誤りにおいてえこのオラクルとの差が
えー大きいのもえー現状でして
えーもっと
流行な韻律句を見つけることでえーこれが改善できるのではないかと考え
えーまとめといたしまして
本研究ではえーこんえーとネットワークを用いて
四アレーによる音声認識誤り生成を行ないました
えーまたあー素性としてえーちょっとえー文脈情報である水を
導入しました
でえー提案手法において単語誤り率でえー三．七一ポイントを改善しました
えー今後の課題といたしまして
誤り検出精度の改善が挙げられます
えーこれはあの品詞情報の追加や
パラメーター推定法の変更などが挙げられます
また
本研究では
え今回あのー
えー
家のグラムを用いて
のえーＮグラム法を用いてえー月でした
えーの音声もあると
えー
家のグラムを水をえーえ素性として用いたえープロポーズメソッド
の比較をしたんですが
えーこの意味スコアはどれだけ
聞いたのかっていうのがあーこれだと分からないので
えーちょっとえ文脈情報のみをえ素性として用いた場合の評価っていうのもおー
今後の課題となり
えー以上で発表終わります
御清聴ありがとうございました
#############################


#############################
# query = えーとーこう簡単まいりセクションＳＴＤの話なんですけどえーっとー本すえーとえっと一個の音声認識器を使っててえっとこの一優勝ネットワークを構成してえーまー力マッチングを行なうという研究だったんですがえーっとーだとかえーＤＰマッチングのえーっとーまそのコンピューターネットワークを構成するとえーっとーのお父ノードの間にえっとー複数のあーくがえーっとできるらしくてえーっとそのーアクセントはく父をえっとーお力マッチングを行なう際にえーまーそのー提案しようと思います後はあのーえスコア付けがあるらしいんですけどもそこはえーっとよく分からなかったので説明をお願いしたいと思いの
# rank = 1
# slide = 11-15_fix.match_word.jout.txt
# value = -3.32355404717889
#############################
えーでは
後現存ネットワークを用いたしあれによる音声認識誤り訂正えー題目で神戸大学×研究室の中には発表させていただきます
えまず研究背景といたしまして
えー
えー音声認識精度
はえーニュースなどの正しい書き言葉で後画像九十五パーセント程の精度があるのですが
えー学会講演などのえ自由な話し言葉になると
後八十パーセントまで下がってしまいます
えーよってえー話し言葉でストレスのないえー音声認識を行なう為に
更なるえー音声認識精度の向上が期待されます
えー
えー従来の音声についてま簡単に説明しますとえ従来音声認識では
で言語モデルとして自然なえバイグラム
やっトライグラムの動画としています
えしかし
えーこのＮグラムの問題点といたしまして
えースムージングなどによりえー不自然なＮグラムが発生してしまうえーことがあります
えまた問題点が二つ目として
えＮグラムが自然だとしても
文章として自然な場合があります
でこの例文を見てもらったら分かると思うんですけど
別データー冷たいものが食べたくなかったっていうのは
えー自然な
で二グラムから生成されたえ文になっています
えー次に
えーこのえー冷蔵庫の中に面積をえ〇であるというのもえー自然がＮグラムからえー生成された自然な日本語です
えしかし
先程の分布並べますと
えー冷蔵庫の中に面積を入れてある冷たいものがあー食べただからだとなりましてえ冷たいものやえー食べるでうちはだから
え面積という部分に不自然さを感じるようになります
で現在のＮがものでではえーこのような不自然さにえー採用することができません
えーよって問題点が解決法といたしまして
えー問題でえー一つ目の
自然のＮグラム
自然のＮグラムの発声に対しましては
予めえーま識別的言語モデルといたしまして
自然のＮグラムを学習しておくことで解決したいと思います
で問題点の二つねでえーＮグラムでは分からない不自然さに対しましては
えーバイグラム
トライグラムよりもおー範囲の文脈情報
をえー取り入れることで解決します
猫でえーこの
後半えー文脈情報場所でえ文脈情報ということにします
で後え提案手法ですがえ条件文脈情報を用いた四あええ音声認識誤りをえ曖昧性性をえー提案しまー
えーまずえー自然
あー自然あるいはえ自然のＮグラムをしアレーを用いて学習します
えーこの為には予め
えー学習単語にえ最後ラベリングを行なっていく必要があります
えまたえ四八例によって学習する素性の一つとして
ちょっぴり文脈情報を追加することで
音声だけの二つの話題を考慮します
えーえ構造ここまででえー知られえ誤り検出モデルが
えー作成されますので
えーそれによって曖昧性識別された母音計算ネットワークを用いてえー説明
えーまずあのー平叙ネットワークについて簡単に説明しますと
えー
これはえーまークラスとクラスタリング圧縮することであります
えまたその過程でえーこのように
確率に信頼度が付与されます
えーこの
あ多い
点線の部分で
えー
点線で囲まれた部分はこの閉鎖音セットと言われていまして
上から順に第一候補
第二個おー第三方向という風に表現されています
えー
本研究ではえー四アレーによる誤り検出を用いてえこの
九ながら正解を探すことであんまり
えー誤り訂正を実現します
えまたえこのえー見にくいですけど水色で囲まれている
えー
入るんで表わされている単語はＮ付いて張りまして
でこの七歳を選択することで
えーこのヘッドセットスキップすることができます
えつまりこの
第一方法列を選択しますと
私価値はえー単語列が生成されることになります
えーこの音でサインを選択することでえ挿入誤りを決定することが可能になります
えー
知られによる誤り検出モデルについてまー簡単に説明いたします
えー私は頭から来た
っていう入力に対しましてえー誤り検出モデルをえー適用しますと
えー例えばこのようにラベリングを行ないます
でＣというのは背が得られ
いいっていうのが曖昧な縁になっているのでえここ
えーこの誤り検出モデルにおいて
えーこの私
っていう単語がえー誤りであると識別されたことになります
えこのえモデルの学習にはえー単語単語列に成功ラベリングが発生後ラベリング
されたものが必要となりますので
え音声データーを
音声認識器に通しまして
えー書き起こしデーターと比較することでえー先行ラベリングを行ないえー学習を行なって今
えーまたえー整合それぞれの学習えーそれぞれの特徴を学習するので
えー自然なＮグラムと共にえこのように
誤りを含んだ自然のＮグラムについても学習可能になり
えーこれはま知られうー
えーせえー二終わらせまー条件付き確率分布になってるのですが
えー
あー入力Ｘについて得られる場合が付与される条件付き確率で表わされています
えー後えーラベル場合っていうのは
えー本研究では生後ラベリングに用いますのでえーし
正解ラベルと誤りあるのに一位になって
えー試合二のえー学習はえーこの
素性に関して関するえその素性が重要であるλ
うーこう学習するのがえー学習型となっていまして
でこの条件付きか
条件付き確率
あのー対数尤度を最大にするように計算されます
えー
もっと具体的に説明いたしますとえー
頭別のように明らかにえー誤りだと分かるバイグラムは
えー誤り部分音のみよく出現しますので
えー
誤りに対する重みが大きくなるように先程のλが学習されます
で逆にこれは
のようにおだけでは正解誤りかを識別できないえーバイグラムに対しましては
えー
えー
重みがえー小さくなるように計算されますえー例えばえーこれは犬
えーこれは犬のようにえー犬です
のようにえーたちますと
えー
それはえー自然な
えーＮグラムになりますのでえー
正解傾向を示すＮグラムになるのですがえーこれは食べるようにえー指しますとでそれは誤り傾向を示すＮグラムになってしまうので
えここでえではえー正解誤りを識別できないということになります
えーこれはえー例としてえーバイグラムをさ既にえー説明いたしましたが
えーとこの音響尤度やえー品詞の連鎖など
でさまざまな素性を柔軟に設計できるのが特徴となって
によって
えっとそれの一つとして
名所けえ文脈情報もえー取り入れることにします
で条件文脈情報ってのはこれはえー周辺のえー認識結果単語を参照した時に識別対象単語が不自然でないかという情報のことになります
えー例えば音声
であえー会話
話者
対話っていう単語が現われる場合の中に突然大根
っていう単語は現われるのは不自然だと感じられます
えこのように出現単語の水データーをい三つとして大切な
えーこれによってえーバイグラム
トライグラムよりもえー後輩の文脈情報を考慮できるようになります
えそしてここではえ動詞形容詞名詞のみにスコアが今
えー
え次に意味スコアの算出ですが
えー
これはえー単語ｗについての水を求めるとします
えーそのその場合えー
その単語Ｗとえー周辺の単語集合
調べデーターのえー類似度をまず求めます
えそしてえーその周辺の単語ｗｉの各ｗｉにつきましても
えー類似度を求めましてえその平均分かります
熱でえその二つの値
からえー正規化を行ないえそれを意味スコアとして今
えーこのＬへ児童の計算にはえー星を用いていますがあまり形成について説明は割愛させていただきます
んえー提案手法の流れになりますが
えーっと以上のようにえー説明したあ手法を用いて提案手法をえ実現します
えまず
えー音声認識器により音声ネットワークを出力しま
えーこの音声データーは
私達は
という発話に対して出力されたコンピューターネットワークです
えーこのこのえーとネットワークに対しましてえーちょっとえ文脈情報としての
水を増やします
えー先程申しました通りえー形容詞と
名詞と動詞のみにえー三つかを与えるので
えここでは
えーまー名詞しか登場していないのでえー現われた名詞二に都合が付与されます
えそしてえー
この今日のネットワークと
私達はえー書き起こしデーターを用いましてってせいもラベリングを行ないます
えーそしてこの
このデーターを用いまして
知られずによって誤り検出モデルを学習します
えー
えーそしてえーその
流れ学習した誤り検出モデルを用いましてえコンピューターネットワーク上で
音声認識の誤り生成を行ないます
えーその生成手順について簡単に説明させていただきます
えまずえーま何らかの
えー音声データーを入力しまして
えこのような
ごみのネットワークが出力されたとします
えーこのエコーロケーションネットワークの
最尤法これ
えー第一次以降これとえー抜き出しましてえそれは私達は
というえー単語列になります
その単語列に対しましてあんまり現実を行なうと
えこのようにえー示されまして
えーかつて単語は誤りであると識別されました
あよってこの第二候補である
×と置き換えることにおいてえ性を行ないます
えーそしてえー活動着替え私達はっていう単語列ができますので
えーその単語列に対してえーもう一度
えー四アレーによる音声認識の曖昧で検査を行ないますと
でこのようにえー全ての単語がえー
正解であると識別されました
えこれには別訂正があり四といたします
えー評価実験といたしまして
えベースラインはえーＣＭですと書いてあるんですが
えこの併存ネットワークのえ最尤法これ
えこの単語列を
えベースラインとしての
えまたえー飲んセマンティックというのはえー提案手法の素性としてい水を用いない場合
えつまり
で知られてるによって学習パス
学習する素性がＮグラムだけの場合となります
そしてえープロポーズメソッドっていうのはえーそれにリスクを
えー
付与しえーい水を
祖先の一つとしてえー追加した場合
で更にオラクルというのは
えこの併存ネットワーク上の正解単語を全て得られた場合の単語列となりまして
え本研究のえー既存の値となります
で評価しようとしましては単語誤り率
まーデーターベースを用います
えー我々とはえーこの
えー置換誤り
削除誤りって挿入誤りをの葉をえ全単語数で割ることによってえー算出されます
えーコーパスといたしましてえー日本語話し言葉コーパスＣＳＪを用いました
音声認識はＪｕｌｉｕｓえー音響モデル言語モデル共にえＣＳＪから学習しています
でそして誤り検出モデルのえー学習には
えＣＳＪの百五十講演
で評価にはＣＳＪの一三講演を用いています
えー最後にえー知られの
えー誤り検出モデル
のえー学習に用いた素性といたしまして
え表層単語の意味であのーバイグラムトライグラム
えーそしてコンフュージョンネットワーク上の信頼度
で更に意味スコアそして今
んえー実験結果ですがえーまず単語誤り率についてえー評価したいと思います
えー
でこれがベースラインであるＣＭでさんがあるんですけどえー韻律句を用いない
家のセマンティック
でもえーベースラインに比べましてえー三．五三ポイント
えーま与えられたが改善しているのが分かります
え更に意味スコアを追加することで
えーベースラインに比べまして三．七五ポイントを改善しました
えしかしえーこの二そんな体であるオラクルと比べると
また
僕の誤りがえー残されているのが分かると思います
えー次に誤り種類別の評価をします
えーここではえー
意味スコアのない場合とある場合についてえー評価をしたいんですが
え削除誤りと
挿入誤りにつきましてはえーこの
えー
あえー誤りの数が殆ど変わっていませんが
えー
一番多く変わっていたのはえー
この置換誤りでしてえー置換誤りがえー
水を用いない場合とを用いた場合ではえー
曖昧が百個程
減ってる
という結果になりました
えーよってえー韻律語はまちょっとえ文脈情報は置換誤りに思い出に有効でありました
えしかし
えーっと
置換誤りにおいてえこのオラクルとの差が
えー大きいのもえー現状でして
えーもっと
流行な韻律句を見つけることでえーこれが改善できるのではないかと考え
えーまとめといたしまして
本研究ではえーこんえーとネットワークを用いて
四アレーによる音声認識誤り生成を行ないました
えーまたあー素性としてえーちょっとえー文脈情報である水を
導入しました
でえー提案手法において単語誤り率でえー三．七一ポイントを改善しました
えー今後の課題といたしまして
誤り検出精度の改善が挙げられます
えーこれはあの品詞情報の追加や
パラメーター推定法の変更などが挙げられます
また
本研究では
え今回あのー
えー
家のグラムを用いて
のえーＮグラム法を用いてえー月でした
えーの音声もあると
えー
家のグラムを水をえーえ素性として用いたえープロポーズメソッド
の比較をしたんですが
えーこの意味スコアはどれだけ
聞いたのかっていうのがあーこれだと分からないので
えーちょっとえ文脈情報のみをえ素性として用いた場合の評価っていうのもおー
今後の課題となり
えー以上で発表終わります
御清聴ありがとうございました
#############################


#############################
# query = えーとーこう簡単まいりセクションＳＴＤの話なんですけどえーっとー本すえーとえっと一個の音声認識器を使っててえっとこの一優勝ネットワークを構成してえーまー力マッチングを行なうという研究だったんですがえーっとーだとかえーＤＰマッチングのえーっとーまそのコンピューターネットワークを構成するとえーっとーのお父ノードの間にえっとー複数のあーくがえーっとできるらしくてえーっとそのーアクセントはく父をえっとーお力マッチングを行なう際にえーまーそのー提案しようと思います後はあのーえスコア付けがあるらしいんですけどもそこはえーっとよく分からなかったので説明をお願いしたいと思いの
# rank = 2
# slide = 13-04_fix.match_word.jout.txt
# value = -3.32377970287624
#############################
んーそれではえーっと部分というペットと思っ
えーっとベクトルを特徴とする距離尺度を用いた音声検索を検出手法の検討見てて
え静岡大学大学院山本の木は
発表さしていただきます
本研究概要ですがえー我々はえー
そこはえー音声部分途中で発話されている箇所を特定する
えー音声検索を検出えー閾値
えーこれについてけんえー研究をしていますこの中に対して最も単純なアプローチとしてえー第五一音声認識システムによってえー
音声部分と思うと一か所
それに対してテキストレベルでのマッチングを行なうというものがあります
そしてこれにはえー高認識は未知語といったような問題がある為
せっかくの検出が困難という問題がある
うー七時の関連研究としましてはインデキシングをではえー検索アルゴリズムの改良といったことを行ないえー検索処理の高速に重点を置いたプロセスってまたはえー距離尺度の九二八九自動評価法の工夫などによる
検索性能の向上にえ自分でもう一日中
もう聞く訳でこの二つのプロ違うられています
なおこちらもえーサブベースのアプローチが主流となっています
えっと我々はえーこちらのえー検索性能の向上にえー主に一．五と当日を今回は発表者の
このサブのレベルのマッチングに基づく典型的なアプローチを紹介しますと
まずえー音声認識結果が検索をサーバーと列に変換しそしてえー
連続ＤＰマッチングによりえスポッティングを行ないます
これはサーバーとか六時五．四
後は特別の一つ目自動評価を一つの一部の問題にとして定式化するって思う
本研究ではそのー二音列に対する不連続ＧＰマッチング手法ですから
するとします
んー
我々の研究目的ですがえー音響的自動を考慮した
えー距離尺度の導入といったことを目的とします
えー先行研究ではその場と体の音響的類似度に基づく
二尺度やえー音素別特徴にも作る距離尺度のが提案されています
えー本研究ではサブワードとはえー二音の状態三図一でも作ってる尺度で
えー
以上滞在の分布間距離を特徴量とした新たな距離尺度えーこれを提案します
まずベースラインとしてい事実の概要をですね
んー
まず最初に音声とそれとおーす音声認識デコーダーはそうする
その後どうですの認識結果と
えー
単語ベースの認識結果を
優れ検索用データー別に蓄積します
なおこの際単語ベースの認識結果をＳＡＴと系列に変換して
えーデーターベースに
都会とします
えー
そして検索語は二十六された中検索語側音系列に変換し
その検索語が
志望であった場合は単語えーベースの認識結果
いうサポート系列
とーえー
持っキングを行ないそして未知語であった場合は
えー認識から三郎ベースの認識結果
とーえースポッティングを行ない
そしてえー
という結果を出力します
えこの際のサポートをレベルのもの新聞に基づく検索語のホテルですが
まずえー砂漠化の特徴量を提示し
主として連続ＤＰマッチングによるホテルを行ないます
えー
この海の側をどう体の特殊距離ですが
えー
まずＡさん程体の音響モデル
のえー一年の状態間の分布距離を
えー分布間距離えーこのような状態他のえー状態化の分布頭を一つ一一え実験マッチングを行なったと
って行ないえー砂漠化の特徴それを提示します
えーそして
でえー提示したいとくるこれをえー続いてるとしてもっとしえー連続ＤＰマッチング御承知の
えー
この際の文頭一つはえー一
ＨＭＭのえー出力分布間の分布間距離をえー三十するのですが
えー一般的にえー出力分布はえーこの別にえー幾つかのこの五成分からなるえー混合ガウス分布
になっていることがえー一般的です
えー混合ガウス分布間の分布間距離のえー
算出方法を色々提案されていますが
えーここでは
んーの混合数変化の二つですよ
をえーそれぞれ計算しその中の際一最小値を
で分布間てるとしてえー利用します
えー
えー
提案するアプローチとしましてえー
その後レベルの場合
って凄くではえー音響的なえー一つ一の関心を持ち
がえー音響モデル
んーとー
モデルを推定精度で三つある程度問題に対して
で我々はえー連続ＤＰマッチングにうえー抽出したえー方法区間をそこを取ると
えー状態単位の
えー系列に変換する
て状態レベルの詳細のスコア付けを行なう
えー更にえー分布間距離を元にして拡張した分布間距離ベクトルというものをえーもう一つ一でそれもこう作るっていう尺度を導入します
従来法と提案手法を比較してみますと
従来法をえサーバーとレベルのマッチングですのでえー計算量はですねですだから一個程度のその
それに対してえー提案手法は
えーサブ音レベル音を大切にえー起こしますので
えー詳細な服を付けをが二つの言葉で言いますがえー計算量が多いという問題があります
そこでえー計算量を抑えつつ精度も高いスコアを付け行ないたい
ということで
一発目でえーまずえ従来手法による方法絞り込み
そして日本常で
えー状態全てのえーマッチング行ないえー
こうリスコアリングを行なうという
一つの手法を適用します
二度提案するえー日本すえー七二システムのこういうお気に入ります
んまず一発目はえーですがシステムと同様になっておりえー
検索語の差分を取るとえそして検索対象のデーターベースの中のそのボール別の
連続ＤＰマッチングを行ないそして高校を出力します
一個の際には
えー砂漠化が付いてると一つ前に
えー
計算しておきえー検索時の
えー
計算量削減するということを行なっています
一つ目ですがこれはえーボールのおー提案法による詳細な付く訳です
一モデルえー検索語の
とーえー
えーそしてえー一一と二名で得られたこう区間
えーそれぞれの
のえサーバーを取ってるえー対応するＨＭＭ状態てると
えー
状態系列の指示のマッチングを行ない
そして
後はえー
えー
一月の
そしてえーもう一つ分布関する数によるえースコア計算を行ない
もう一つの不幸を
えー三つ下
そして二つの不幸って結合し最終的な面とそれのスコアとしえ
えっとその結果を元にえーけん結果をするかと
えー計算量の削減を行ない
えーこの提案手法のえー詳細な付く訳ですが
持つえー
一つ
二つのえーすことを行ない
一つ目は分布間距離をすると一え状態ですのでいいマッチング
でこれこれによってえー評価タイムって気持ちもえー一一一二個を算出することで
元はえーこちらでえー
状態系列の長さをえーん
この二の誤差に正規化する必要がないのですがえーその際えー
このＧ気持ちによってアラインメントを行なうことができます
んえー同時にえー
状態系列の
って政治家もこの言葉では
そしてもう一つ目のえーそこである分布間来る時に基づくです強くて
では
こちらのアラインメント結果
このえー文化をすると
えー
母音列をそれぞれえ算出しその二つの
えー系列から一類似のスコアえー
を単位とします
その際のえーこちらのえー
ものがえー
一具体的には後程説明しますがこれは分布間プリテストとなっておりこのように状態系列に沿ってえー並べたもの
止まっています
ではその分布間距離ベクトルとはないかと言いますと
言ってます先程を提示し多分被るっていうのはＨＭＭのある状態に対して一と一の定義を直接評価をしていました
それに対して分布間距離ベクトルは
である状態とでその間えー具体的には前音節ってん状態の
その距離
これをえー
この
間の距離を
四要素としたえーとベクトルの通りえこれにより特徴を想定しています
んー二
これこの目的はえー構造的な特徴の一音によってエージェントと精度を走行中の変動の要因に対す対する
えー観点性
あのー
で目的としています
んー
このえーっと一とかを取り
ベクトル
んー用いてえースコア付けをこの間にはえー我々はえー三つの式を
でそこを算出式を提示しました
まず一つ目は
えースコアって言いＭという項目数っていうものです
これはえー分頭内のえー言語それぞれえー三四つ四
そして二系列でその中の最大値を取る
それをスコアとするものです
んー
このおーう
式のえー目的としますとえー一つ重要性を強調する
ということが挙げられます
すると他の二つのえースコアのえー知識ベースだっ
もう一つ目
後はえー
えー
ん各ベクトル間で
えー普通の論を取るそしてえー時系列をてるしてするって音楽
つまりえー一九移動距離をするそしてそれをえー分析していく
というものです
えー
えーそしてもう一つはえー
同様にえー分布間で取るかっていうものの本に
そして二系列でおで分析していくって思う
っていう
以上のえー三つのうちいずれかで
えーんー使ってて
でフレームと過ごすことを行ない
えー一つ目の
とても際に利用します
えーっと先程えー一応大体のＧＰマッチングによるえースコアをもう三されそしてえー分割数に基づく
後はもう生産されると言いましたが
えーこの二つのこうえーっと爪の
で最終的な行動としてえー二つの不幸を結合して最終的なあースコアとして用います
概念としましては
えー
えー状態系列
の間はもうえー一回頭を考慮したえＧＰの後によるえースコア
そしてえー
ある状態とその他のえーっと具体えー多くの状態系列
えー多くの状態
んえーっと情報を持った
えー分布頭
ベクトルによるえー
後
えー
んー
一がこちらとなりえーそれぞれの不幸立ち直ってえー日本爪の最終的な今年の
えー
んー
のえー実験条件に入ります
検索対象ですがえー日本語話し言葉コーパス
えーし一つ前のこう講演データーを用います
音声認識結果はえー調べるネットワークんの反映された単語ですと文節列の二種類のリファレンスに結果を
一ベストを用います
この認識結果のえー性能はえーこのようになってます
なおえー我々はえー
んー既知語の
うーん既知語も検査語に対してはえー単語列のえー
認識結果を用いえー未知語の
っていう検査語の場合には音節ですの
認識結果を用います
続いてえー検索語ですがえー伝えるな多くの複合タスクの方もあるんで用いられたっぷり五十語を用います
んそして分布間距離のえー三つの際に利用し
するえー音響モデルは
八十コーパスのえーこの公園の得点講演データー
こう適応しそしてリファレンス認識結果を求める際のモデル学習と
この二条件で学習し作成しました
二つ上に一からえーその認識ではえートライホンのＨＭＭを
え用いていましたがえー我々はえー音節
平成六
を用います
えー
詳しい資料はこちらの方になっており
えー三十二混合のえー
三十
発電
一のえーＨＭＭで音節ＨＭＭを用います
評価指標ですがえーリコールプリシジョン
えうちえ
結構生成してえーリコールが
えー
ってこうプリシジョン曲線
そしてのえーこれらの
評価指標を用います
主にこのＦ値を
もう目にしてえー評価行ってきます
ではまず一ぐらいのおー
もう一か月
えー従来法えここでいうえ従来方法はえー
提案手法の本こそ年の三つまで連続的にマッチ
文のえー結果となって
これは音節レベルのちょっと表象しても
それに対して提案手法はえー分割手法を用いており
状態での食料理をし
そして分布間ベクトルを用いた貢献行なって
んー
えこちらを見ていただけると分かりますがえー
提案手法はえー
従来法に比べてえー
ポケット改善していることが分かります
そしてえー×手法を用いた音の有効性としてえー
検索時間
をえー比較してみますと
えー
一発目の三と別にどうすれ
まで含めた
減って四手法でこれを比較してみますとえー五分かあの検索時間
でえー
ですがえー検索精度がえーこれだけ大きく向上しておりますので
えー我々のえーとす手法加え一有効にえー行なわれたということが分かりました
えー
二
ここではえー分布間距離ベクトル
でうを用いたすとても歳はえー
終わっている自由になってる項目数を使用してました
えー
え先程えー
この
この検査音は三つの式をえー提示しました
そこでえーこの三つの式の
えー
とーそれぞれで
比較をしては
えー提示した式があー
定義したスコアをえーこの三つです
まず一つ目はえー四分以上性を強調した後
そして二つ目はえーゆっくりと定義を用いた
えー
用いて分析したこう
そして
もう一つうー三つ目が得る言語
文節一個
えーこの三つです
一つ前においてもえベースライン
えー上位性能を示してる言葉を彼は
そしてそれぞれで見てみるとえー
後はＤ次元のえー部分も口においてえー最も用例Ｆ値を示しました
このこところへ分布変わってると思っ一タスクをずっとこのおー実はえー一つ重要性を強調したものを
自宅木したもの方が
えー最も良い性能を示すということが分かりました
続いてえースコア結合文の一生を調べます
一つ目の二項ではえーと
状態単位のじ今自分より求めたスコアと
分布間距離ベクトルをえー用いて
算出した後
この二つをえー結合重み
掛けて
そして足し合わせたもの最終的に五つ目の
こうそしてもう一点は
えー
そこでこの
重みを
いう変化ファースト歳の
えーＦ値の影響をえー見て
まずえー
四五えー提案手法の
自分中央のえー含めたえーこっちも他をが
歳の
評価結果とえー一つなのみたいな
って思ううーどちらか文書
法を用いた場合えーつまり
一重みが〇もしくは一えーこちらのポイントにおいてもえー
従来法の一発目の別のものでえー提案法の方が一一点お示してる言葉を
っていうんここらも
えー
従来法えーつまりえー
んー
サブワード体のマッチングを行なう方法よりも
えー
提案手法であるえー
状態単位のマッチングをこの他えー視点はいいということが分かります
えー
あーそしてえ既知語をえーっとー未知語をそれぞれえー重みの影響を見てみますと
自分の身はあまりえー重みに影響がある影響はえーないということが分かりました
そして三自分を見てみますと重みを変化させることで
んー
検索の性能を上げることができました
このことからえー
状態単位後一気持ちのスコアと母に含むグループを用いたでスコアこの二つを利用することが有効である
といったことが分かりました
続いてえー分布間距離を算出する際のＨＭＭの出力分布の混合数次元数を変えた時の影響をみたいな
まず三十六時えーっとー三十八二を見てみますと
えー実験を書いたことによってもではあまり表は
声をよ
でえー今日はないっていうことが起こりました
って本当はえー混合数
交通ルールで見てみますとで本来はえー音声認識
えー結果のえー認識精度
とーえーこういった対応
隠して
えー考察して見るのが
あのかもしれませんが今回はそのデーターが
えー
むしろことはできなかったのでです
えーあくまでえー推測でしかないですがえー
えー一．一混合のあのー一Ｍを用いたえー認識はえー
その他の
っていう混合するえー
一認識性能をえー劣ると思われますが
閉店してえ今回のえー検索に用いた場合テスト
することさを少なく
打ち込ん五においても
えー有効であるということが言えます
ではえーまとめに入ります
って我々はえー実はどう単位のマッチングに基づくえーステージの為の
恋人をサポートですから
うー自動評価のえー改善手法を提案しましたここでは音響モデルのえー状態レベルの一っていうの全部
行ないえそして分布間距離ベクトルを特徴量とした
えー状態間距離尺度の導入を行ないました
そして音節でえーと状態レベルのえっとする手法に乗って
えー計算量の動向の特性を行ないました
今後の課題ですがえー今回は思い計算量の削減といったことあまり考えずにやっていましたので
えー今後はえー高速なんで新手法を工夫をすることによる
えー計算量の削減を取りたいと思います
えー
元建設この閾値の自動推定も挙げられます
後ここには記していないですがえー複数の認識結果を
えー利用したえー
計画っつうのも今後の課題として
行なっていたいと思います
以上で
発表終わります
#############################


#############################
# query = えっとーそう簡単六セクションへＣＤの研究なんですけどもんえーさて幾つアレーを用いた研究でえー操作で以下あ例を用いてえ検索対象を木構造に変換してえそうから探索を行なう時に京都ですけどもえーまクエリーが長くなると探索時間がえーと指数的に長くなるので決定木が長い場合は何クエリーを分割してえー検索を行なうというえー手法だったんですがでえー食を分割するとえーと分割する前えー二出て検出できて一旦認識誤りというのは分割後にはえー原子できなくなってしまうそうなので人とその部分が分かりづらかったのでその部分に関して説明をお願いしたいと思います
# rank = 1
# slide = 09-05_fix.match_word.jout.txt
# value = -4.73193071221126
#############################
叩きます
よろしくお願いします
平均年齢文章の父はえーあえー音声などの
えコンテンツの利用機会が増加しています
えまたそのコンテンツ体の数のえー急激に増加しています
えこれらを効率的に利用するにはえー音声に対するキーワード検索技術が
で必要となってきます
えしかし
え従来の研究は検索性能の向上に主眼を置いたものも多く
え高速検索えー高速性をの
んー向上を目指したものが少なくなっています
え近年では高速な音声検索の研究も幾つか行なわれて
きますがえこれらは大規模な索引データーベース
高校一九する必要があり
えーえ高速にアクセスする為にはえー高速なん二十記憶装置が必要となっています
えそこで本研究ではえー高速化するデーター領域な小さな音声検索手法の実現を目指しています
でそのプロットしましては
えコンパクトな検索用データー構造である三十二類を用いましてえ音素単位のマッチングを行なうことで
え音声検索を行ないます
え本発表の後について説明します
えまず初めにえ従来手法である三十二類を用いたテキスト曖昧検索について説明を行ないます
でその後おこの手法をえー音声検索に提供する為のえー提案手法について説明します
で最後に提案手法の評価実験についてえ説明を行ないます
えーそれでは従来手法である三十三類を用いたテキスト曖昧検索の説明に入ります
えー三つある一つはえー文字列検索用のデーター構造のことで
えーテキスト中の全てのサービスを相当したものです
え右の増加翻訳されの例なんですが
えこの例では
えー八分の方ブラというテキストに対して三つの例を構築しています
えこの下はあのー
部分が採録され
なっていましてえー
この部分があそっとされたさ三つで
でこの右のインデックスというのはその一つはテキスト中のどの位置から
で始まる顔しえ表わしています
でこう三百される特徴としましては
えー任意の文字列を効率的に検索できるというものがあります
え例えばこの三つある一から三四型という文字列を検索をしたいと
持った時にえ二文探索を行ないまして
えこの一二三八例が
で制限することが分かります
でインデックスを見ますと八と一つあってんでえーテキスト中では
え八五の一つをえピッチの一二三やれば失恋するというのが
え検索できます
でまたもう一つの特徴としましては必要な領域が小さいというのがあります
えこの三つあるいは実際には
先方のインデックスの並び書き起こししていれば良いのでえー
生のデーター領域が小さくて済みます
二十六二十三二類を用いたテキストを曖昧検索について説明します
曖昧検索とはえー誤りの類似性を考慮した検索のことで
えーこの手法はえー電話したのが提案しているものです
えー三十九つあるいは木構造となってましていきマッチングを行ないながらこの木構造を探索します
えその際にえー係を行なうことでえー効率的に木を探索します
でこれが軽いというのはえー探索の音まで
のえー系列と
えー検索キーワードとの力距離を計算しまして
えーその距離がある閾値を超えたら探索落ちるという処理です
で実際に油か多分分からやるえ
ポケットを探索する場合を例としまして
えアルゴリズムの説明を
えー行ないますえここで残りの式
訳生き方をします
えまずえールートノードから
探索を入れまして
えーノード一つ
二度食べに行って距離を
計算していきます
えそしてその距離がえー閾値をこれから
そこでやっぱり行ないましてそれ以上深くはえー探索を行ないません
で同様にして距離を計算しえ高い行ないながら
え探索しまして
やっぱりが行なわれずに
えー
二下の弟の
道を
え検索結果として出力します
えこの手法ですが
えー音声検索に提供するにあたっては幾つか問題点があります
まず一つ目はえーテキスト量の検索アルゴリズムであるということです
えーそうまでは音声データーの検索にも知ることができます
えもう一つはえ係の閾値の増加に対して
で処理時間が指数的に増加するという問題があります
えこれは
採録されの探索範囲の質的にしろこの為です
猫に示しています時構造を模索され
と考えますと
返し一日
で検索した時にこの二日三まで
え探索が必要だとしますと閾値を増加させる
するとえー閾値二ではこの
はえー一九五三ではこのはいという風に
え探索範囲が質的に広がります
えその為に
え閾値が
えーっとそれから閾値はえー検索キーワードの
えー長さに
奇麗させる必要がありますので
でそうしますとを検索キーワードの長さに対して処理時間が
え質的に掛かっするという問題が
おります
えこれらの問題を解決為の提案手法えーこれから説明します
えまず音声検索への適応ですが
でこれは音素単位のマッチングを行なうことで解決します
え音素を用いることでえーと音声をテキストとして扱うことが
できます
えー検索対象の音声データーを予め音声認識処理においえ音素列えーっと変換しておきます
えそして
え音声認識の結果得られた音素音素列に対してその一つあるいは構築し
え検索を行ないます
えーただこの音声認識の処理はえー音素によって誤りやその
え異なります
ですので
えーと朝からサリンの事件マッチング
で用いる局所距離にはえー音素間の音響的距離を適切に
で表わすものも知る必要があります
えそこで本研究では
音素弁別特徴の距離を
利用することとしました
え音素弁別特徴というのは二等がえー提案しているもので
え調音様式や
え一音一を表わす
二十五次元の素性で音素を弁別しています
日本素性というの例えば舌の位置が高いか低いか
やえーとー
あのー有声
文であるかそうでないかなというのあります
でえーこの素性
のハミング距離をえー音素間の距離として定義します
え例えば
ＰとＰという音素の距離は
えー
スピードのこの素性の系列と
実はこの素性の系列の
えーハミング距離を取りましてで二という風に定義されます
え同様にＰとＧＡでは
え一方事例のタレント移りまして八という風に
えー定義されます
え次に
えー検索キーワード長に対して処理時間の中するものについて
の解決方法え説明します
えこの問題に対してはえ企業の町えキーワードを分割して検索を行なうことで解決分かります
え検索公開しますとえーキーワードをえー固定長の分割し
にえー分割しましてえーこの分割されたキーワードをそれぞれに対して
アサリ鎖を検索します
見たら
え音素
時期は途中の音素認識の誤りは一応
ではないのでえー文化
木の一部はえー検索結果の
検出されないという
えー可能性があります
でそこでえー
え検索結果として
ん得られた一をえ候補としまして
えその前後に検索キーワードの力マッチングを行なうことで
えーその
ここの位置に本当に検索キーワードがあるかどうかっていうのを検証します
えただ全ての方向に対して検証を行なうとこういつもございなってしまいする時間が
えー大きくなってしまいますので
えー
できまし六を御覧前にこの方法数を削減すること
えー考えます
えその方法としましては
普通の文化が好きで検知されている方法はえー見つけまして
えそれ以外の方法ふりを起こします
でただこれを行なうには
え正解か所です少なくでその後の二つの文からスキーを検出できる必要があります
え現在の閾値設定では正解一で最低一つの
えー
あの敵が検出できます
え例えばキーワード全体で閾値が三であっ
二十するというえー
これを三分からすると文化月の
で閾値をそれぞれ一になります
えこれ検索しましてえー結果
え二つは
えー閾値をわずかに声え検索結果から落ちて
てしまっても全体でえー閾値
この日は全体で
えー閾値が一であれば
残りの一つはえー検出することができます
でもしも三つ共
えー実験と結果からえー起きてしまった場合はそれは
平均を全体でも閾値を超えてえーそのその一二は
えー検索キーワードは出現しないということになります
えーっと
えー現在の閾値を設定は先程のようになってるんですが
でこれ
をえー分割一の閾値を増やすことで最低二つ
あー分割しようえー検出できるようにします
でこれにはえー
ここにあります
式を用いて音素当たりの閾値を変化させます
あこの式中の日はえー分割の数でえＴは元の閾値です
えー先程の例
人達をこの式をえー適用しますと分割日
の閾値は一．五になります
えそしてそれ検索を行ないますとえ一つは閾値をわずかに超えて
え検索語の中でもえー全体で敷地内であれば残りの二つの県
分割日は
えー検索できます
はい検出できます
もしえー二つ
のえー検査
閾値を超えて
感じる場合にはそれはえーっと全体でもま閾値を越えて
えその中にはキーワードを指定しないということになります
えただ分割の二の場合
この式を適用しますと
え音素値の閾値を元の人場合になってしまいます
えそうしますと
え分割木の閾値五本の木は全体と同じになってしまい自分達ない場合よりも処理時間が増加
でしてしまいます
でそこで
三分割以上の場合にのみ分割を行なうことに
まず
え例えばえ六音素で分割する場合ですと録音数一二音素の際立っ分割せずに
二十八音素以上の場合にのみ分割を行ないます
二十二に
検索における閾値の設定について
えー説明します
え音素値の閾値にたい対する特性としては
えー閾値を起こしますと
記載されの検索
の範囲が狭くなりますので
で処理時間が短くて済みます
でまーその
よりえーと
検索キーワードに近い
結果しかはえー検検索されませんのでえー検索精度が高くなります
え京都に閾値を高くしますと
えこの処理時間と検索精度はえー二つになりますが
よりえー誤りを置く距離をした結果を
言えることができます
えそこへ実際の検索においてはえー低い閾値で
え初めは検索を行なって正確な結果を高速にユーザーに提示します
えそしてユーザーが結果を確認している間に
二回閾値で
で検索を行なってえより多くの結果を
提示するえー反復を検索の方法
後
取ります
えー
でここで提案手法のまとめを行ないます
え提案手法では音声認識処理結果の音素列に対して三つあるよ
えー適用しました
え音素間の距離の数弁別特徴の距離を適用します
えー検索キーワードの分割え検索方を導入しました
ですから低い音素値の閾値から反復をして検索を行なう
こととしました
えー四つ目に
この提案手法の評価の実験について説明します
んえ実験の
え環境はこの通りです
えおんす
えー検索対象のデーターにはえーＣＳＪの何せはさっ三百九十時間分の音声データーを
え用いました
でこれを
使って認識する
あのにはえーＪｕｌｉｕｓを用いました
でその音声認識の結果得られたえー音素列に対して三つあるよ
えー構築したところ約五十二メガバイトとなりました
でこのサイズであればま十分日本メモリーで処理ができると
あります
え次に
キーワードの分割されてですがえー予備実験の結果六音素で分割する場合が最も高い性能を示しましたので
えこの実験では六音素で分割を行なっています
えそれを検索性能の評価の
え実験
の説明を行ないます
え本実験では検索結果のリコールとプリシジョンおよび一人の時間を計測しました
え音素当たりの閾値を〇から一．四まで
え変化させて
んえー検索キーワードにはえー録音室を一に音声一二三十四つの名詞を
用いて検索を行ないました
えここで音素値の閾値の目安について説明します
えーこの図は独り暮らしという
え音素律の誤りをの例を
示しています
えー
この部分が誤りの
あー〇でえーその左側の数字は
えーこの誤りを許容できるえー音素当たりの閾値を表わしています
ですから
音素値の閾値を〇として検索した場合ですとこの結果が得られます
〇．六ですとこの範囲の結果が
一．〇だとこの範囲結果が
え検索結果として得られた
えーでは実験の結果です
えこの
えー図は
左上から六音素のキーワード一二音素の九十八の三時四をそ
もう一ワードをえ検索をした場合の結果で
えー過去グラフの横軸はえー閾値になっています
えーグラフ中の曲線は
えー三角印がありホールでえ近く
父はえ市場
で八千はえー
はい処理時間
を表わしています
日本傾向を見ますと
で低い閾値これは
で処理時間が非常に短く
ですんで検査ん
二箱泣いています
で閾値れ〇の場合では二ミリ秒閾値〇．二
たとえ二十ミリ秒以下で全ての場合
検索できています
今他の
一二音素以上のキーワードでは
えー高い正解精度を
保っています
えこのことから
でこれ式一の結果から提示するという手法が有効であると言えます
あなた〇．二までに限らずもう少し
えー閾値を分けた場合れた八グラム述べた場合でも
えー十分に高速にえー検索が来ないでいます
えただそれ以上
え閾値を挙げますと
九十八音素二十四音素の場合では
〇コーパス中に音素に比べまして急激に
で処理時間の増加しています
えこの違いは何かと言いますと分割を行なっているか行ってないか的違いがあるんですが
えーこれだけを見ますとえ分割を行なわない方が
えーいいのではないかという風に
見えます
えそこで実際に分割をせずに
で検索した後についても計測を行ないました
えその結果がえーこのグラフ
ですが
えー
見ていただく
って分かる通り実際には分割行った方は処理時間は短くて
えー住んでいます
健康のことからやはり分割検索を有効であると
ことを確認できました
え次に
あー更にえー
検索対象の時間を増やしまして一万二万文の音素列を作成して
で検索を行ないました
えこの一文字単語の音素列ですが
でこの七割
えー音声の収録時間を持つコーパスというのは存在しまして
存在していませんので
先程の実験で用いましたＣＳＪの
え音素列のサイズを下に新聞記事のデーターを変換してえー作成しました
でこの一文字間の文の音素を列から
えー
二千時間戦時下の曲一二十二日一文字単語の音素列を
えー切り出しましてえそれぞれを対象としてえ検索の実験行ないました
えその結果が
でこの下に示してるグラフです
左のグラフから
えー閾値は〇って二の場合〇．六の場合に一年〇の場合の結果です
んでグラフの横軸はえー検索対象のデーター長さで
えーグラフ中の曲線は
えー検索キーワードを
ごとのえー処理時間を表わしています
えこれを見ますと
〇にの閾値でえー一万時間を検索した場合
配置最も時間が終わって二十四音素の場合でも百二十ミリ秒程度で
えー検索が行ないいいます
えまた
この
えー結果全体を見ますと
検索対象のデーター町に比例して処理時間が増加しているということが分かります
えこの理由ですが
え検索
処理時間の内訳を調べたところ
え採録されの検索よりも検証のピッチマッチング
何をするえー時間が支配的となっていましたえまたこの現象のピッチマッチングの
えー対象の候補の数は
あえー検索対象のデーターの三日で静岡
できました
えこのことから
え全体の処理時間が検索対象のデーターの差に比例していると考えられます
で最後にまとめとしましてえ本研究では三十二類を用いた
高速な音声検索手法を提案しました
えー検索キーワード長に対する処理時間の増大の問題を
えキーワードの分割検索法の導入により解決しました
えまた実験により構成となっ検索結果を短時間ていうだけ二日の
んーであることを確認しました
えーマッサージ
こちらの実験により
えー処理時間が検索対象に比例してそこは
するということが分かりました
え今後の課題としましては一四国際分割できない場合の分割方法
やえー分割検索の
え検証のＧＰマッチングの高速化が挙げられます
発表内容は以上です
後楽し
#############################


#############################
# query = えっとーそう簡単六セクションへＣＤの研究なんですけどもんえーさて幾つアレーを用いた研究でえー操作で以下あ例を用いてえ検索対象を木構造に変換してえそうから探索を行なう時に京都ですけどもえーまクエリーが長くなると探索時間がえーと指数的に長くなるので決定木が長い場合は何クエリーを分割してえー検索を行なうというえー手法だったんですがでえー食を分割するとえーと分割する前えー二出て検出できて一旦認識誤りというのは分割後にはえー原子できなくなってしまうそうなので人とその部分が分かりづらかったのでその部分に関して説明をお願いしたいと思います
# rank = 2
# slide = 13-01_fix.match_word.jout.txt
# value = -4.8469742976691
#############################
えー
えタイトルはそれ種例を用いたこと構成検索における検索式二の二の方の改良と題しましてえーっとらしいです各大学の三八ページが発表いたします一
えーデーター構造を用いたあーこと構成検索を検出のおー提案をしてきましたえー
一例といった例はえー主にもう一つ検索に
えー使用されるデーター構造
えーってテキスト中の全ての計算いくと自分にえっとーとして入れてする改善したものあります
別に表示されっていうのは
何らか年ぐらい
という文字列を
一文字列の三２例を示しています
えー
え右のインデックスは
左のサインＸはテキスト中のどの位置から始まるかっていうのを示しています
でその二人の特徴としては
任意の文字列を効率的に検索をすることができるという点があります
って例えばプラスいる
文字列を検索する場合
そういった例を見る探索することで
インデックスの八と家の中に
え実現する言葉もあります
えまた実際には
え辞書順並べられたインデックスのなら何だけ御自身はいる為
使用が出てる駅が小さい継続長もあり
一えしかしえーオリジナルの三月あるいは完全一致検索をえー
想定しています
んえー音声を認識誤りに対応をして検索を行なった日には
変な形の
でわいわい計画を導入する必要があります
えそこで我々は
で家もしたがっ
えー提案したとＸアレーを用いたテキスト内の検索語を導入しています
えーこの手法では
とＸｉを木構造になって
ページにマッチングを行ないながら探索を行なうことで
文字の誤りや類似性を考慮した検索を行なうことが可能となっています
んー
でまた探索ノードまでの聞いていマッチング気が閾値を超えた場合
それ以降の探索方式いうことで
えー効率的に気を探索することが可能となっています
うん
えー声
んえーさっされまた特に使用する二マッチングを
二十九の定義についてえー説明をします
えー定義式は御覧のようになります
すえー音声認識は本当によって
誤りをしたことの為
入りませんえ局所性には
解決と距離をえーこれに対応させる必要がある
でそこで我々の結果凄いは
本当弁別特徴を利用しています
え音素分類特徴とは
え調音特徴という
え調音様式と調音位置から音素分裂したもの
物事を入れます
で書こうとかでこの
えー素性のハミング距離を求めることでえー
二マッチングの極小夜の
えーとさてえー音声の
えしかしえその二例
に対して聞いていませんの
えー行って検索を行なう手法は
えー閾値に対して政治家
する関数的に増加してしまうという問題があります
で閾値は検索キーワードの長さに比例して評価させる必要がある為
えー検査が暇そうに比例して処理時間が
指数関数的に増加してしまう訳もない場合まー
でそこで我々は
で検索キーワードを分割して検索を行なうことでえこの処理時間の中相って言います
でこの手法ではキーワードを分割して検索した場合に
平均はどう分割せずに検索した場合の
検索した場合と同様の結果結果が得られるように
四つのステップでえー検索を行なっています
えっとまず
でキーワードを分割しますえー
えー
次に
えー分割した各文が月は後で
そいで二重の観測を行ないます
一次に検索で得られた
んでえー
ここの出現位置が
こうそれ以上でえー
で近い
文を見つけます
えー
最後に見つかったえー一軒一
において
え元の警察には父の聞いていマッチング行って
えーその音声距離はえー閾値以下ならばえー最終的な計算結果と接するとしています
えまた二番目の検索の際に
正確分割キーワードの四次は元の検索キーはあの
非常にこう分割した
値に設定しています
えつまり各分割キーワードに
またえー認識率は等しいということにあります
でまた
え我々の検索手法では
生地を
え低く設定して検索をした場合
え短い短時間で
背の高い検索結果が
であります
一え一方でえー式場をした
五つ設定して検索を行なった場合
えー多くの検索結果が得られますが
長い処理時間
一が掛かってしまうという特徴があります
えー
えそこでえー初めは低い閾値で検索を行なってえー
背の高い
え検索結果を即座にユーザーに提示して
いうただその結果を確認している間に
生地は決定され検索を行なうことで
えっとーテニス部れた
え検索を行なう
行なうことを実現しています
えこのショート気軽分割の
減少をえー
によってえーことが音声検索結果を実現しています
えしかしえ一は文化政策の検証のステップにおいて
え一つ問題点があります
え今はスライドにえ示してるグラフは
え一音と話は一応その
えー検索キーワード
えー三十五
を使って検索した時の
えー各節の処理時間の割合と音の合計
ここに示している
えークラスターを取るように
えー一音素辺りの閾値側に連れて
え現象も実時間の割合がえー増加していることもあります
で検証の処理時間は
で二番目の検索のステップで現われる
候補数に依存しています
えーここただけ検証を行なう必要がある為
この検索の際に
えー改良の方法が現われた場合
えー傾斜をする時間が
え飛躍的に増大してしまうという問題点があります
で現在の検索の手法では
で各文だスキーはに与える閾値はえー
で一つ与えられています
えしかしえーこの場合
えー現われるコースにばらつきが生まれる場合があることが分かりました
でこの為
一部のキーワード一文の分割キーはどうで大量の方法が得られてしまい
えー検証のステップで
えー処理時間が増大し
で結果として全体の処理時間が
え大きくなってしまう
という問題がありました
えそこで今回は
え検索時にえー交通各文が次の文に現われる交通のばらつき抑えることで
えー合計が
えー交通の総数を焚いて
減少に係る数時間を削減することで
えより高速な音声検索
検索を検証を
減らすことを研究目的としています
ってやつに
えコースを削減する手法についてえー
頭の上を使って説明をします
でこの図は
えー一文全体の閾値要求として
分割数を
三とした場合の検索
んで
で上の図はえー従来の
えー閾値を一つ叩いて
検索した場合
理想は
え新しい手法で
生地を統制した場合
本当示します
え上の二では
えーそれをという
えー文化的はどんな交通があまり
現われていません
で一方で
四という
分割キーワードでは大量の
えーコースが現われています
でそこで
えーと四の閾値を
これを見与えて
生の閾値を
え少なめに与えることで
えー交通のばらつきを抑えることを考えます
で結果として合計のコースは
え百四十回百百人
平均所要時間が
えー減らせることが分かります
えこのように
えー
今まで
えー
分割キーワードにあったり閾値を
えー一つは的なもの
せっかく分割キーワードに個別にえー閾値を与えることで
えー交通のばらつき抑えることを考えます
ってしかし
えー
えそこで
えー
でこうすー
あ閾値を設定する場合にどのように
え閾値を設定すればいいのかという問題は
でそこで我々の検索手法では
甘く進化的探索アルゴリズムを用いていることから
えまず
で低い閾値でえー選択した場合の
えー交通の
で変数
ですから
で次の
検索でえー現われる
えコースを推測します
このセット二重に基づいて閾値を
えー設定することで
え現在の検索での
えー交通のばらつき抑え抑えることを考えます
父は
えーコースを
え同様に説得するか
ということを考えます
で三つあれの探索で得られるコースは
えーと幾つあれの探索範囲に
で比例すると考えます
えー一人一人の探索範囲が
一つに対してえー節的に
平成二年
次のような式〇パーセントを考えます
次に各分割き
フォワードに現われ交通
のばらつきを抑える為には
えこの式
えー
えこの式が同一になるように
えー閾値を設定する場合の為
で次のような式がある
で最後にえー火は二分割の
木や分割検索の結果が
え分割せずに検索した時の結果と
え同様となる為の条件付き
を使ってえーこれらの式を使って
で各文が好きなのに与える閾値を特定することを
考えます
えー
えしかし
えこの手法ではすえー交通の
水色の精度が不十分であることありました
えー
え理由としては
百歳の探索際に使用する地域にマッチングの距離を定義が
えー二種類
タイトルは
えー原因と考えられます
まず一つ目は
一日前の
それの定義です
えこれは弁別特徴のハミング距離に基づく平気で
基づいて決定します
え次にえー二モーラ一と二もうき
のえー挿入脱落形Ｔの値
えこれらは
えー最も検索性能が良くならない
形になるようにえー実験的にえー決定して
でこうした二種類の
えー定義がある為
え先程の式では一つの式で
えコースを説得しようとした為に正確な継続は
でできなかったってことは考えます
ってそこでこの二種類の距離定義を考慮した交通の水族
こうすることを考えます
てまず
え最初の括弧一の
え式をこのように変更します
ってまず第一項は
えー挿入句脱落形の
で交通の接触の式になり
そしてえー第二の方の式は
え使わない洋服も含んだえー交通の取得であります
これは二種類の
変更する訳で推測することで
で垂直性のあることを考え
結構括弧一の式に
の変更にそのまーそのーまえー伴ってえー各認識の
八六のように変更ない
で各その時期に関してはえー変更ありません
えこれらを式はえー原稿に
え詳しく形態というのでそちらを御覧ください
えこのような手法を用いて
え評価実験を行ないました
実験環境はえー御覧の通りとなっています
え検索対象の音声データーは
．四え自然の男性話者六．九時間を使用しました
またえー音声の
えー音声認識にはＪｕｌｉｕｓを用いています
で検索に使用したえーキーワードセットは
ん一最大の
こう監督ってところションの
えー次にえーホール助けを検索語セットの中
癖が分割が必要となるえー一本以上の検索を三十五使用しました
えまた音声でえー次元数による音声認識では
えー言語モデルにプールから学習したえーこういっするものモデル
音響モデルに特殊で
特定話者ＰＴＭのえートライホンモデルを使用しました
てまた来ていマッチングの際の挿入脱落ペナルティーは
でそれぞれ三と設定して
えー
え実験方法としましては
でまずえー閾値を
えー均等に調整して検索を行なった場合
えそして
結構スペースちょっとした方数に基づいて
生地を調整して検索を行なった場合
で最後に放送二種類に分けて
生地を調整して検索を行なった場合
で検索をそれぞれ行ないました
えーそしてその結果から
検索時間
交通
と先行数の推測制度について評価を行ないました
えまず行数についてですが
え今は生成表がえー二つの少年を
え合計の方数の比較
の表になります
え評価をこれように
え従来の
生地を検討に
えー調整して
検索を行なっ手法に比べて
えーコースを推測して閾値を調整する手法は
えーコースを大きく削減できていることあります
えまた
えー
する方法二の
えー手法では推定方法一の
手法に比べても
えーコースを
えー削減できていることは
ってついに
えー検索時間を
え評価
えーこれも
んとー四年
えー均等に
えー閾値を測定する手法に比べて
父のしえー就職を
えーコースに基づいてでそこを行なう
えー
二三構成に基づいて閾値を調整する
えショウガ
え良い結果が得られていることが分かります
で特に
で次に実験二から
えー一応高い認識実験から一．八
の結果はえー均等手法に比べて
えーする方法による評価
えー約三十パーセントを検索時間を
短縮できていることが分かりました
えこのような結果から
本コースを説得して
え閾値を調整する手法はえーここで出会っ
と言えば
えしかし
えここの検索結果を見てみると
健康数が増加して
計算速度が低下してしまった場合もありました
えー
えーこの理由としては
えー交通のセット二はえーあくまで統計的なデーターからえー求めたものである為
でその統計から大きくなってるような気が後は
適切に選択できていない
健康とは考えます
でこの為
よりえー性の高い
聖書を行なう為には
えキーワードを含むオントロジーに基づいた交通の接合する必要があると考える
えー
で次にえー交通の数得点の
についての評価
え表から分かるように
えー推測方法一に比べてえーするとこう人をえー
えー結果はえー
えー
で生徒精度が高いことが分かります
え特にえー閾値
えーっと
えーと推測し文の実測値の値するというのは
え実際に
実際あ現われた方です
の対数と
あえーと千
で実際新たこう
こうするとえー推測し
もう一つの回数
となって
え分散音の分散となって
でしたがってえー値があー両方共〇に近い程えー
すえー検索の精度は
高いってことが分かります
えーそしてえー生活自分の特徴対するに関しては
んえー閾値二．四から一発でえー節方法二の
今
えー高い結果を示しています
でまた分散に関しては
えっとの方でしいつでも
えー接合んにはままま
えー
言って持たせる方法二の手法をえー詳しく見てみると
えっとーに脱落波のこう数の設定は
声道方がえー置換誤りを含む
交通の数特性
えー高い精度を示していることありました
でこれはえー挿入脱落形ＩＴ
．八五人脱落のみ
のえー行数というのは
え式一の場合その時の三
えー変化するという特徴がある為
で安定してえー高い
一セットを行なうことができたと目を考えます
で最後にまとめはこのようになって
以上で発表を得ます
御清聴ありがとうございました
#############################


#############################
# query = はいえーっとはいあのーえーとビデオとか公園とかの録音機とか録画とかですねそれをえーとー子音ごとに分割するといううであのー研究があのーあると思うんですけれどもえーその子音分割する時にあのーま音声認識用提案ででその人し結果を使っえーあの分割するとまそういう研究があのーあるかなと思うんですけれどもえーあの音声認識するとあーの認識誤りとか怒りますよねでえーとあのー認識誤りがあるとあのー四分割の制度もやっぱり下がると思うんですけれどもあの意外と触らないということをあのーあのー言われてると思うんですあのー要はえーっとまー町があるところは同じように間違えるのでえーその認識誤りしてるけどもおんなじように間違えたものが手掛かりであるとえーというところがうまく使えであの新聞千分析楽しいん分割のえー戦の時代はそんな変わらないという話がまーあると思うんですけれどもただあのー置換誤りだけじゃなくて音声認識にはあのー挿入とか脱落とかの誤りもあると思うですねでま特にですね脱落誤り脱落するマットところやっぱりあのー影響があるような気がするんですけれどもえーその脱落誤りによっであのーどのぐらいその新聞活動性のね影響は出てくるのかえーこれをおー調べたあのー四えーとでは発表後ですかねそこを知りたいですけれどもえーっとまーあのーだからえー子音分割中で特にんえー脱落うーによってどのぐらいの影響があるのかというところをあーのーまー実験によってあのー調べたとそういうあのー発表があればあのーそれを探したいと思ってまーはいそれが島
# rank = 1
# slide = 09-08_fix.match_word.jout.txt
# value = -5.63753466052612
#############################
えっとー資格をするのカメラと申します
えーとですねいたします
えーっと本日は
えーっと講義音声を利用した後
一九．三等分割と検索について御報告させていただきます
えーっと
えーま皆さん部分というようにえーネットワーク上に最近特に色んなビデオ教材があのー
たくさん増えてきました
えしかしながらなかなか学生さんがあのー使いたいという目的なもんなんなかなか少ない
いうことで
でえーまー実際に作らないとなかなかうまく教育とかに使い
でいざ作るとなるとね
え時間とか手間が掛かって大変
いう訳で
えー私共は
えー
登録が遊び行数は幾らまー普通の大学等の方で四録画したものを
えーとかをえー話題元に自動的に分割数いたしまして
えー
ビデオ教材作成のテーマを
減らしたい
それから更にえー分割した
んえー子音の音に
えーっと
実際にえー見る時にそれをまー検索したいってのはえー目的で二
あここで子音と申し上げてるのは
えー
トピックをモデル化を全く知らサブトピックの区間をえここでは四と呼ばしていただいて
で実際にはこういう風に
えー自動的に
えー
子音境界が求まったとしますと
でこの中から練習とか不要な部分を削除しますと
えー
最低限のビデオ教材化できる
いうことですがこの
新聞月一を決めるのは非常に
えー大変何回も
でえー同じところを見直してあここだっていう風に決める際の画面ということな
でえー以前にあのー御報告さしていただきましたえーこういう支援するシステムの内容なんですが
でまず最初ビデオ素材から音声の情報を取り出しまして
え音声認識をしてて
と情報を言って
でこれを元にして
えー子音の分割位置推定を行なって
えその中から
えふような身を削除すれば四状態ができ
まこのシステムにつきましては
えーここのＵＲＬの方で
で公開させていただいており
でこのシステムは
え続いていやい対応の
音声認識ソフトであればえーそれでも使えるようになっておりまして
えー
語彙音声認識を使った
やり方とえ単純にポーズだけを使った素早く
買うことができればちゃんとお二種類用意をしており
で実際の画面はこのような
えー関係して
えーっと
ビデオを指定してえ分割っていう風にしますと
えーこういうシーンが出てきます
当該の信用をクリックしますとおー再生されますので不要であれば削除ボタンをですだけで
最低限のものができ
いうのはえー理想でござい
でえー本報告では
あーのーこれまで進めてましたあの素材として使ってました石川高専のえー二料理を言いますか本にビデオ
に加えまして
えーと
はい提案しテニスがあって大学三のえーデーターベースをえー利用させていただきまして
えこの二つを素材として
でえートピックのえサブトピックの分割と検索について調査した結果を報告させていただき
えまずサブトピックを分割につきましては
で二つのサブトピック分割手法を比較した結果
それから音声認識性能と方に携帯の
影響について御報告いたし
それからえーサブトピックの検索に関しましては
えーキーは父を実際にえー学生さんとかが
日は父して
えー指定する
ものと
え実際の発話内容との関係
それから音声認識性能の影響について御報告さ
まず最初にソースｉに関してですが
え石川高専の傾向にビデオにつきましては五名の教員による九十分のおー
えービデオでござい
でこれをえー接話型のヘッドセットを使用してますのでえー雑音との駅は殆どは
え音声認識には二つの音響モデルを使ってまして一つは
新聞記事
による
えー二千状態一録音を捉え方を持って
それからもう一つは
えー
ＣＳＪ
の
でえーっとー
音響モデルを
使わしていただい
それから
え言語モデルにつきましてもＣＳＪの言語モデルを使わしていた
でえーこのビデオはえーっとそれぞれ平均しまして各五百文ぐらい
で
えー
変わり
なってきた練習どうも含まれてまして
えー少しゆっくりしたケースです
それからえー
共通性が良い評価五って書いてますがえこれは最終的に子音としてえー
好奇
切った正解の数が二十
それから平均して
でパープレキシティーは四百ってことでちょっと音声認識としても難しい
え未知語率は平均で三．四ません
で実際音声認識をしてみますとえ新聞記事
で学習した音響モデルですという非常に低くてえー単語正解率で四十三パーセントぐらい
それからえーＣＳＪでえー学習された音響モデルでも
で五十三パーセント
ということで
えーっとー
なかなか厳しい
えー認識結果
で一方
えー
クラス二が第三のえー日本語をこう利用性やコンテンツコーパスとしているし
後英語話者六講義を使わしていたら
で学校にはあの前半後半に分かれてらっしゃるようで
えーそれぞれ七十五分
な旅行に文を使う
言わしていただき
で
でえー大学院の体の大き
でえーこのようなもので次子音の
えー分割位置を推定する訳ですが
えー
と二つの方法試しました一つは
えーここですと類似法と呼ばしていただいてますが
えー隣接してる新刊が
えー似ていれば
もう一つ付きの非
似ていなければ新聞月一月
存在するっていうようなえー単純な方法
でえー身を比較する為にそれぞれの子音ごとに
獣をインデックスが必要になりますがま通常使われるなら一ＦＹ
先程ちょっと話がありましたけど
えーっと
これはあー五四へあのー独立成分分析を用いた指標をおー使いまして市場のサイズを役さんとしており
性能的にはまーほぼ同等以上
ぐらいの間
で簡単に申し上げますと
えーっと冒頭文の
英語の頻度行列を
えー
話題と文
またえっとー後
二分割するようなえー方法に最終的になった
これによりましこの話題数字に設定できますので
でえー好きな自分
でやることができ
先程一番こうだと一万次元になってますがえここで百円ぐらいすると百二年でお様
いうことで計算時間がない
それでえーと
その進化を比較する度には八名を使い
んー身が似てるという個体表現が大きくなるんですがえー二なければえー小さくなるということなので
えーこの
四年の総和が最小になるように影響って計画法でこの切れ目を決めてやるというのは二十です
次にあの統計的手法について
えーっとこれは打ち合わせの方から御提案アーティスト分野で使われている
提案されてる方法ですがこれをえーのんびり音声に適用した結果です
でえーまず
えー単語の並びの与えられ
でこの単語の並びからシーンの切れ目を決めるという問題で単語の並びが与えられた時にえーっとそのシーンの切れ目
が最大になるような確率
そう最大なるように身を決めてやっ
いうことで
でこの中のえー分子の部分が最大なるような
セグメント一を決めてあっ
んで
テーマ細々したところは省略させていただきますけれども幾つかの形で
例えば
えーっとー
確信
のえー
単語まー他の
Ｃには依存しないとかっていう独立性の
えー
買ってきます本来は成り立たないと思うんですが簡略化の為に幾つかの
えー過程をえー仮定しますと
最終的にはこのような式で
えーこの
確率が計算でき
でこれはえ一般になっプラスぼうっと
えー
形で知られている
で方法で
えーっとーが五人の
えー単語数暮らすこと大語彙数分の
えその
子音内での
同じ単語数プラス一
これで
えー
この確率を
えーっと
金水一は
で今の
ちょっと細々とした日はえこちらの方ですけどもう一つの
えーっとＰＲえすの方は
単純に聴覚
で
与えて
でこれも同様に
えー対数化してから動的計画法で
えーっと
この確率が最大になるような
えーえ数を決めてやればいい
でこのような二つのえー方法についてえー四分割実験を行ないましたま水しか合成のビデオについてですけれども
えー音響モデル一
で横軸がえ分割五で分割数を文の数で
正規化したもの
例えば
凸のえー講師が百文感嘆文百文だとしますと
でそのうちえー二分割したら
分割に連れて一っていうような形で
でえー当然文化率あ分割分割三つ挙げますとえーこれがあのー
再現率なんですが際に繋がって
でえこちら適合率です
でえーこのおー
我々のこの研究ではえーっと適合率
よりも
でえーこの再現率の方重視いたします
これは実際ビデオ編集する時にシーンの切れ目がないと非常に
その切れ目を入れなくちゃいけない計算量は非常につらいので
でえっと再現率はなるべく高い方ができれば百パーセントになるとい
これが五十パーセントしかないと
半分は自分でシーンの切れ目を決めないといけないということになり
一方適合率が
えある程度までなら低くても無視すれば良いのであんまり多過ぎるとなかなかにづらくなってしまいますが
ある程度までであればもしすればいいのでそれ程気になりませんが適合率は
再現率の方はなるべく若い方がいいということで
ですがちょっと
あの再現率の方を中心に見てまいりたいと
でこの赤色のグラフが
えーと統計的手法による菜園
それから青色が
えー類似法による
え再現率です
でえー比較していただくと分かるように統計的手法の方が
えー少し良い結果
で音響モデルについてもえーこれは
えーっとＣＳＪで学会講演で学習したもですが同じ傾向が出て
更にえー書き起こしテキストについても同様に統計的手法の方が
えー良い結果が得ない
ま以上
のことより
えーっと統計的手法の方がＢ地方よりも
えー良さそうだということが分かり
次に
え音声認識性能の影響について
えー
調べました
え同じ結果なんですけれども見方を
グラフを買いまして
横軸が
えーっと先程の分割率ですが
えーっとー赤色が音響モデル一
えーそれから
えーっと
次熱が青色のものな音響モデルに
それから
で紫
のものな
えー書き起こしテキストで
えーっとかなり音声認識性能かなり違うにもかかわらず書き起こしテキストとほぼ同じようなカーブを描いており
でこの原因といたしましてはえー今回適用した方法というのはあのー母音の情報を使っていない
んで
同じようにややもあれば
でまー問題ない
いうようなことが気にしているの方法もある
んでえー
それを確認する意味で幾つかのシミュレーションの実験を行ない
これは書き起こしテキストをおーまざっと
が誤りを持たせたものです
でえー当然置換誤りな
であっても
えー原理的には
えー性能が一緒ということを
え実際に試してみて確認
しました横軸が
えー置換誤り
縦軸が
で先程の分割一〇．五から〇．四までの平均の
え再現率
それからこちらの方は横軸が
えーっと挿入誤り
これは書き起こしテキストにわざと挿入誤りを
えー入れたもので
って挿入誤りについても類似の方ではほぼ同じ
えー統計的手法でも二十パーセントぐらいまではほぼ同じ
でまー
それ程大きく影響しない
それから
でえー脱落誤り
についても
えー二十パーセント程度まで暮らしていましたが
それ程変わらない
で更に
えー
とー
脱落誤りが二パーセントでえ挿入誤りが五パーセント五十パーセント
それから
えー置換誤りを付加した場合ですに混合した場合
ちょっと音声認識を
え真似たような感じですが
えーについてもまーどの
条件についても大体
それ程
で大きな変動はない
まこういうなことから
えー二つの音響モデル書き起こしテキストシミュレーションをいずれの実験を通しても音声認識性能の影響は
宮内っていうことが分かっ
次にあのこう二境界の影響をなんですけれども
えーっと
まず
これはえー四じえー子音による新聞かつ結果です
でえーこの赤色の部分な書き起こしテキスト
それから青色が
えー
と音響モデル一致による結果です
んんでえーどちらも
ほぼ同じ分かって泣いてまして先程の音声認識性能に相手をしないというのと
で同じ結果がえー提案し率が大学のデーターベースでも同じ傾向が得られてい
それから
えーこの図は
えーっと高い評価四十四．四日間で大学のえーこう来それから青色の方が石川高専のおー工程なんですが
音韻形態がかなり違うんですけども
えほぼ同じようなか方以外体を
ま以上のことよりいーこうにこう携帯の影響もえ少なく取ったいうことがあり水
んで
え次に
図はえー検索について
えー
まーこれまでの結果あるのでえー簡単に
いただき
えまず利用する情報としては
え音声情報以内にスライド情報などさまざまな情報を用い方法がまあのー提案されていますが本報告では音声情報のみを
えー使います
これはスライドを用いない方にもまー対話したいってこともありまして
え音声情報のみを利用します
それから未知語対策につきましても
でこれまでの御発表が色々あったように音素えー音素インデックスファイルを
えー生成ＣＤを抑える方法であるとか
えサブワードを用いられる方法であるとか
ま先程もございましたが
傾向に音声から上って一
体を検索して
検索キーワードから六ページを比較して両方を比較するような方法ですとか
っていうさまざまな未知語対策がえ提案されて
それからあのー最初の御発表にありましたようにえ検索テストコレクションが
えーっとそろそろこう愛されそうってことで非常に楽しみにした
まこれができれば
でこう色んな
えー
方法を比較検討し易くなるってことで期待させていただい
でえ今回は
行ないました子音検索の予備実験Ａでは
えー各子音についてえそれぞれえー指標を求めて
えーそれがキーワードについても指標を求めて両者を比較するという単純なもの
指標には一般的な二杯で二を用いて
材料こちらと申し上げました場合冷えてもちょっとやったんですが
あまりまたうまく行ってないって言って
ここでは出てき
それから
えーっとこれは子音検索実験の結果ですでえーと縦軸はユーモアがあるということで
平均逆数順位んをえー
がありました
でこれはえー一ですとえ全て第一二三
〇．五ですと
でえーっとー
逆す七で二ということで二平均的には二ぐらいに
その検索したものが出てくるというな指標でござい
でキーワードとしては
で一つだけ指定した場合とか二月から一つまで
え横軸が言わですが変化
でえーこの最初のピンク色のものな
えーっとえ足ですか大学の四てるＣの書き起こしテキストによるもので
んで
でえーこのえーブルーの
ハウスい水色のものは
え石川高専の書き起こしテキストまほぼ同じカーブを描いておりまして
っていうまーあるＲがほぼ一致にしたいってことで
えほぼ一致入れてというなことで
えー非常に
高い結果で
えーところがえーこれについ
誰の音声認識
えテキストを使いますと極端に
触りまして
えーどちらも
でえーこのぐらい顔をしてしまー
まーちょっと
見た目がかなり川するんですけどもＭＲＩをなのでえ健康で主にいー何やってるようぐらいの八十
それからえーっと次にですねあのー実際にはあの学生さんがキーワードをしていするんですけど学生さんは色んないわゆる
否定のし方をするので
で実際に被験者そして学生さんに対し過去数年の五年生ぐらいの
学生さんに
キーワードを
でえーそれぞれの子音ごとに出してもえー
でえー出してもらってそのキーワードを使って実際検索してみたのが
えーとまずこのグラフですこれは書き起こしテキストなんて光っとしてはこの一番上のものとおー
このぐらいで
このぐらい触っ
いうことですね
で音声認識についてはこのタームから
この確認をしてしまう
でえーどうして落ちるのかなっていうことで
えーちょっと
調査したのがこの表です
でえー最初は当然未知語があるとそう分は確実に落ちてしまういうことでこれが
わりあいとしては平均的二十三．八パーセント五歳
一ワードの総数は
ここに書いてあると
これ百パーセントとしまして
えー一三．八パーセント程度の未知語で音です
それからえーと二視覚音声の場合にちょっと特徴的だったのは抽象化
でここであったさしていただいてるんですが
これは何かと申しますと
えー直接発話していないんだけれども
で発話内容を総括したり
ほイベントを表現したい
するような言葉例えば練習とか実習とか説明とか
例えばそれからこれこれを説明しますっていう場合もあれば言わずに説明する
んとま
それ説明っていう言葉は
でえー頭の中に出てこないんだけどまーちょっとした何とかの説明になっ
何とか飲酒
練習これからします理由が珍しくて
えーこれやってみましょうとかっていう場合が多いそういうことですそれをちょっとここでは
抽象化という表現で表わさしていただい
でえー交通の場合はそいつが多いもんですからって求まって
えー一一パーセントぐらい抽象化あるいはえー
まー内容をある程度理解
えーできると
えーより
あのー
感覚的には
体の概念的な表現をするのかなというのも
えーちょっと
そういう気もいたし
それが表現の揺らぎってのは
で表わしますという表現ていう言い方
あのーそういう表現の違い
んで
でこちらがあってただしえーい一日で大学の方の
えー
実際にどういう割合であったか
でえー未知語をは一一パーセントぐらいで
って抽象化は非常に少なくて
って言って八パーセントです
でこれはどうしてかって言うとま練習とかするのは少ないということと
えーそれから
えー多分
あのー
学生が五年生なんで大学院の推量いきなりＴでも
マイナスというよく分からなかったこういう
要するにそのまま
えー出てきたことをそのままいーワードとして書いた割合が多かったのかなというしない
後でしょうからですから
種抽象化っていう表現が出てくるのはこう三によってかなりこうばらつきがあるのかな
できない
そのデーターとしては
まだ少ないので何とも言えませんけれどもそういう傾向が
で以上まとめますと
えー
とー
えー
統計データー丸四の分割に関しましては統計的手法の方が類似法より良い結果でした
でえー音声認識性能を八五に携帯の影響は少ないということがあー確認できます
それからえー検索に関しましては
で三四五ばかりではなくて抽象化表現への対処っていうのも場合によっが必要になるかもしてます
それからえーこれは前から言われてることですが音声認識性能の影響はやはり大きい
えー
っていうことが確認されも
はい以上でござい
#############################


#############################
# query = はいえーっとはいあのーえーとビデオとか公園とかの録音機とか録画とかですねそれをえーとー子音ごとに分割するといううであのー研究があのーあると思うんですけれどもえーその子音分割する時にあのーま音声認識用提案ででその人し結果を使っえーあの分割するとまそういう研究があのーあるかなと思うんですけれどもえーあの音声認識するとあーの認識誤りとか怒りますよねでえーとあのー認識誤りがあるとあのー四分割の制度もやっぱり下がると思うんですけれどもあの意外と触らないということをあのーあのー言われてると思うんですあのー要はえーっとまー町があるところは同じように間違えるのでえーその認識誤りしてるけどもおんなじように間違えたものが手掛かりであるとえーというところがうまく使えであの新聞千分析楽しいん分割のえー戦の時代はそんな変わらないという話がまーあると思うんですけれどもただあのー置換誤りだけじゃなくて音声認識にはあのー挿入とか脱落とかの誤りもあると思うですねでま特にですね脱落誤り脱落するマットところやっぱりあのー影響があるような気がするんですけれどもえーその脱落誤りによっであのーどのぐらいその新聞活動性のね影響は出てくるのかえーこれをおー調べたあのー四えーとでは発表後ですかねそこを知りたいですけれどもえーっとまーあのーだからえー子音分割中で特にんえー脱落うーによってどのぐらいの影響があるのかというところをあーのーまー実験によってあのー調べたとそういうあのー発表があればあのーそれを探したいと思ってまーはいそれが島
# rank = 2
# slide = 12-10_fix.match_word.jout.txt
# value = -5.76382148138476
#############################
えーそれはえー複数音声にシステムを併用した
えーお父の作品にある
検索性能の改善と題しまして
えー定式近く大学の駅が未決定が発表さしていただきます
えー
えまず全体流れはえこのようになっています
えまーまずえー研究目的と背景ですが
えー
音声を含んだえーマルチメディアコンテンツの増加に伴い
でこれら功利的に検索する手段っていうのがえー望まれています
えしかしながら
えー
えーこういった音声を一つで書き起こすということにまーが非常にこう差があります
そこでえー音声認識システムを用いてえー自動的に書き起こす必要があります
しかしながらえー自動で書き起こした結果にはえー認識誤りが含まれていまして
で更に大語彙連続音声認識えーでえー認識した後には
えー辞書に登録されていない単語一語
がえー書き起こされないという問題があります
そしてえー更にその従来手法であるえー連続ｄＢえーではえー長時間の世界に対して処理時間に問題があると
いうのがえー金銭の問題としてあります
えーこれらを踏まえてえー目的として認識誤りや未知語を含んだえ長時間の音声ファイルに対してえー高速な検索手法のえー提案と評価
というのをえー挙げています
えー
そして
えー今回の発表ではえー特にえー挿入脱落この距離のえー緊密化とえー複数認識システム併用
でこれを用いたえー性能の改善にえー弱えー着目しています一
まずえー概要ですが
って英語音声データーから英単語を検索したいと言った時には
え一般的にはえーとこの音声データーをえー自動音声認識
でえーテキストに書き起こすと
でそれを
含めます
その際にえーっとだいぶ連続音声認識でえー認識しまうと
ふえーま
んー
ん辞書に含まれていない単語が認識たり強くされないという問題があります
えーそこでえーさまざまな研究でえー行ないできるのはえー単語単位の中でえーそれ小さいさまざま単位でえー認識をして一つに書き起こすといった方法が取られています
ふん本研究ではえー音節認識を用いてえーテキストに書き起こします
えこのようにえー
音節認識することでえー後子供に必要ができます
しかしながらえー認識誤りの問題がありましてえー置換誤りや
え脱落誤り
そういう誤りといったものがあっあいあります
一としてえー検索の従来法としましてはえーまず一般的なのがえー連続ＤＰにあるワードスポッティングが挙げられます
とこの他にもえー作品を用いたこの先されてはえー単語集合を用いたえー単語数といったものが挙げられています
本研究ではえー朝までの距離月のという
方法を提案しています
えーとステートにもえ人優しさをえーす
え話者照合について説明します
へ我々のえーシステム内容がえーこちらの図になっていまして
えまずえーユーザーからえー検索語がえー適当で与えられます
そしてえーこの検索語がえー未知語が既知語がえーのえー判定四大語彙連続音声認識の辞書を使って判定します
ってもしこれがえーっと未知語やった場合に
えー音節認識からえ予め作成したえーと五月の作品
こちらからえ音節単位で検索を行ないますえー
そしてえーもしえー既知語であった場合はえーそれに加えてだいぶ連続音声認識結果
えーを用いたえーと単語単位の検索
こちらを併用します
そしてえーＮの索引の構築の方向をえーここで説明しますえ本研究ではえこの犬なのＮをえー
三としましてえーとー音節のトライグラム
こうえー作品としてえー採用しています
船の索引がえー一つですとそのートライグラム
の映画でえー構成されていまして
各ポジションで
えーっと例も作っていきます
そしてえー作ったこれらを
えそれに相当しておくことでえー高速に検索が可能となります
そしてえーこの作品からのえー検索方法ですが
えーこのえー検索語がえー例えば
二二という検索別れ際に
えーこれをまずえー複数のおトライグラムに分割します
えー
そして
えーまーこの場合ですとえー二三というそれがま特に家という二本トライグラムに分割してこれをそれぞれえー作品から検索をします
そしてえーそのそれぞれ検索結果
からえー出現数連接を確認しましてえー言説が確認できたものをえー最終的にという風にしています
えーそしてえーと認識誤りに関しましてえー探索を行なっていまして
えー
我々はえーどっちかうんそういう活躍する前出して探索を行なっています
えまずえー使われただけではえー認識以下のえ複数の候補上位Ｎベストを用いて
トライグラムを作成してえ索引を構築することでえー対処しています
また
えーそう山高く
ではえー音節を一つ側さ三つ組み
はいそれでも作成して索引登録すると
いう方法で対処してます
そしてえ脱落誤りに関しましてはえー検索の際にえー
検索語が書かせてえー検索することで
えー探索を行なっています
えーそしてえーまー
これらのえー認識はま探索行なうことでえーぼけ画像化してしまうという問題があるんですが
これに関してはえーその認識誤り探索をどの程度行ったかという情報を
えー距離としてえ索引記録することで対処しています
え実際にえー例で説明しますとまず使いあまり高くはえーこの例ですと認識
こう頭にし結果のえー次ですあまり
をえー使ってえさまざまなパターンのトライグラムを構築していきます
てこのようにすることで
えー新しい音節があこのツリーですに含まれていた場合にえー力の人達できるといった方法になっています
でこの時の距離というのは
えーこの場合ですとからのえー距離で
えー×できるよう使ってえー定義しています
えー
そしてえっとー次にえー住んだ二百の作品という別の力価格のえー元さ手法としまして
先に説明したつかの大学ではえーと複数個に含まれている場合は安心できる
形態素が含まれてる場合を対処できるんですが
えーその検知できないというのが多く存在していまして
これを解決する為にえーと二音節でもマッチするようなえー包摂アスタリスクを何としてえー索引登録しておくという方法でやっています
えー
えーっと実際どういうものかと言うとえーこういったえーあってリスク
をえートライグラムにつき一つ何でして
えー
作品を作っていて水にを付けて登録し力という方法になっています
でえーこれはえー何の距離というのはまーえー先程の形で距離にえー比較えーっと比べましてえ比較的高いこと一九のえー採用しています
一個の音することでえ複数個に含まれない近いあまり御対処するができます
でえー次に凄いあまりことに関しましてはえー
そんな全くではえーっと
日英二次の作る際にえー一応テストバスはえー二つ文をえー作っておくと
いうことでえー
このバイクを飛ばした二つには言葉一つ二つに
これらをえー
タグに登録しておきます
んー
でこの時のえー距離は従来手法今までえー気がした手法ですとえーと〇か一えーそういうの結構人間社会で背中の日で表わしていましたが今回はこの距離を気に使わするということでえー後程詳しく説明いたします
んー
そしてえー脱落誤り
えーの対策に関しましてはえー検索語からえー
検索語の文節を
えー脱落させて
えー検索すると
いうことを行なっていまして
まえー検査語からオブザだけで二回検索するということいたとしています
で
てこの処理もえー今回えー従来手法では
二つあった二音節の方
をえー距離として
採用していましたが今回は厳密これをお見せしました
またえー挿入とえ脱落こちらの探索を組み合わせ方でえー四から六月にもなります
え例えばえーこの例ですとえー文えー
二二というえー単語が復元とえー各二つ書かれてしまった場合に
えーまずそう山高くて
えー一つはその一二をフーリエという一二を作ってお
そうします
でえー検索の際に脱落誤りが削減えー検査語から後活躍させた検索語フリーで検索することで
えー認知結果に
えーが含まれて置換誤りがあった場合でもえー一つが可能となっています
えー
そしてえっと本手法のえーＧＰとの類似点としましては
えーまず
その挿入と脱落のことというのを何設定することはできるという点が挙げられます
て逆に相違点としましてはえー聞いていることがあってその日日は検査語と認識以下のえー
音節別の二十九位を正確に警察ができるんですけど本手法はえこれをすぐはできないと
いうえー
違いがあります
んまた
経理ＢはＡの展開しているこの挿入誤りとお肉のＮ個
も脱落誤りでしていますが
本手法ではその二たり
ん〇一音節に
という風にここ来ています
え本手法の方が制限が厳しい為にこれは減少してしまうんですが私は向上すると
いう風に考えられます
でえっと今回提案する調査しましてえ距離に使うということで
従来手法では先程説明ストーリーにえ挿入脱落うーこれは距離はえー
えー
挿入の有無をえー脱落の音節の数
防衛として定義していましたで今回えー喧嘩するにあたって
え誤りとかって通常舌の前後のコンテキストのまたそれ距離を採用しました
典型例に挙げますとえークラスをにあまり高くの場合で
えー
この服もえー挿入誤りと
えー仮定して好きですがまトライグラム作る際の距離というのは
えーこの
そうやめたか警察俳優の音節で
えーこの場合と二と三のえー距離を計算しまして小さい方を対応すると
いう方法を取っています
それでえーと距離はえー先程〇か一日の日だったのものをえーこのようにえー変更しました
えー
ってまたはえー
今回はあその左えーつ挿入と仮定した音節のえ左コンテキスト母音群も考慮して
えーえ距離
を定義しました
後マイナスとＡとＢという
えー音節第一第コンテストがあるんすけど存在の
え母音部分にある
これもえー距離に考慮して
距離として考慮しました
そしてえーと複数人システムのえー四ということで
えー
本研究では店の検索性能が改善の為にえー二つのシステムを使って
えー各予稿つきましてそれぞれの検査結果を統合するといった方法を取っています
まずえーベースの認識実験中ばえー本研究で方がデコーダーに二つ二つ二つを
買って
え音響モデル音節モデルを使っています
そしてえー今回新たに併用するえー認知システムの方はえーデコーダーは二十五月を採用しまして音響モデルはトライホンモデルとなっています
あっそしてえーっとま
と二を複数認識実験用のえー流れなんですがえーまずえー
えー二つのえー
一認識かとえー近くにして書か
えーそれぞれえーＮグラム作品と単語の認知インデックスエ作為の
それ作っておきます
で
て
えー
んー予めえー二つえーとお酒を作っておきに
え検索を与えられ際に
えーこの索引がそれぞれ検索を行ないます
そしてえーこの二つのえー認識掛から作って検索結果とえー一つの検索結果
こちらのどちらかにえー
組まれていればんすすると
いうような方法でえー併用行ないました
でえー
え評価実験に入ります
で今回えー検索対処しましたのはえー日本語話し言葉言葉コーパスＣＳＪの行データー約四十時間を使っていて
えー検索語をにはえー音声雑音処理はグループの
これが継続長えーこちらドライバーを使いました
えー未知語既知語はそれぞれ五十種類となっています
えそして
えー
認識に用いたえーっとおー
条件としまして二つプロセスの方では音響モデルは左コンテキスト依存の音節モデル学習には九二に千五百二十個声を使って今
で言語モデルはえー音節のグラフの言語モデルでえー学習はえー本当モデルとどういう風になっています
八十四つの方法はえーこれは沿線でないんのえーワークショップで配布されましたえ認識がこちらを使っております
えー
まずＡプラスプラスプラスのえー認識システムのえーポーズにし結果はえーこのようになっていまして
えーと五月まで考慮するとあの九十五パーセントえー非常に高いグループになっています
てえーＪｕｌｉｕｓの方はえーこのような結果になっていましてえーＪｕｌｉｕｓの方はえーとー宣言全てのえーＮベスト使っている為え確率が低いのではえーこれとはえー八十三パーセントとなっています
そしてプレゼントもして用いてえー連続ＤＰはえー大雑把に
んでのえー連続ＤＰで
えー中には
音節ＨＭＭに基づく形で距離
ん使っています
低認識科目数候補を用いるということでえ今回はえー二つ結果の語ですと
一二つの個別と使いましたえー
父の定義はえーこのような式になっていてえー明日はえー
示している通りになっています
え実験内容はこのようになっています
えー
えまずえーっとー従来手法とえーベースラインのえー
んえーグラフをえここに示していますえー横軸にこれで勝手自覚したんだとなっていますでところが後まー従来手法でもえー
ベースラインよりもえー性能が良いというような結果がえーあります
えー
でえーとこの一の従来手法に対してえー距離の現実があって後で
んで挿入誤りの距離を現実化した際のえーグラフがこちらになっていますえーピーク値のえー最大値がえー従来法が〇．五六番なのに対してえー
二十八手法でえー村や形の距離を変化することによってえー約二パーセントのえー改善が得られます
でえーそして夏はかなり一方脱落誤りの方はえー
ってこちらが多い気になるんですが
え従来法よりもえー性能下がってしまうというような結果になっていますえーこちらの方ちょっとまで原因がよくあります
あれ
そしてえーっとーまそういうの距離の平均一日二際にえー母音の考慮えーした場合としない場合のえー三つの歳で一語こちらに示していまして
えー母音のこれはえー竹刀よりは母音を考慮した方が良いというような結果になっています
えー
でえーっと挿入句脱落えーこちらの図に
二のえー両方とも
喧嘩した場合のえーグラフが紫の線になっていてえー口で見るとえー
最も良いえーこのえーく比較して中では最も良いっていうな結果になっています
あってえー次に二二システム変容ということでえー
えーベースライン
えーまい従来法がえーこちらになっていますでこれに対して
えー
Ｊｕｌｉｕｓの個別の音節認識のえ個別の結果を併用したのが青い点が出ています
ところ挙げますとおえー従来法よりもえー二値型三パーセントの改善が二三パーセント程の改善が抱いていて二日ぐらいにでも
あえーをここに書いできるということが分かると思います
ましかしながらえー
で全然別やコンピューターネットワークこれらを使いますと
えーこう数が増えてしまう為かえー湧き出し誤りが映像化してえー精度が下がってしまうというような結果になっています
んん
そしてえーっと既知語の方
えーこちらの方はえー従来法にもえーベースラインと従来法がこちらのようになっていてこれそれぞれえー二つの醍醐認識が
えー
えーからえー作成さセンチインデックスを採用して
展示インデックスを使っな方法になっています
ってでこれに対してえー提案手法
えーにえー
通常質問一つの鉄の個別の規格化したのがお以前
それに加えてえーすＪｕｌｉｕｓの場合誤認識の結果こちらを足したものがあるのでやっていますで何えーっとー認識しても併用することでえー個別と
を併用するとでえーえ口で約二パーセントの改善が言われてますん仕方がないと第五日のえー結果を併用することを
でえー
まえ従来法よりは良くなっているんですけどまーん
この人最大値は〇一の餌が詰まってますがえーまほぼ同じ程度というような結果になっています
んー
でえー最後に検索時間のえー比較なんですが
えーまず
えー今までのえーＧＰマッチングとえー従来法の検索時間の比較がこちらになりまして
え従来法ですとえー
ピッチマッチングのえー
で約六百枚
えー事例えー従来法はえー一見てくれ
一九五〇．一見てくれんけど〇だ可能となっていますで
誰でも
ＢＢが気の毒なことというような結果になっています
んー
でえー今回えー提案したえ複数認識システム
んえー後はえー谷のえー含めた場合の
えー検査結果がこちらになっていましてんー
えー弾力がありことでえー検索時間はえーと
分か
行ってしまうんですけど
えーまたその二つにしてもうまく利用した場合でもえー日目でく程遅くなってしまうというな結果なっていますがえーこれのえーＧＰに比べて約五十代
のえー高速に検索することが可能となっていますえー
んで
言ってえーまとめにえーなります
え未知語検索ではえー世論
んー距離のえ均一化によるえー性能の改善が
であると
えー挿入母音脱落の距離をえーただ一句よりが
えー
でえー一度でえー下の方が得られました
んーまがあえー普通に自然の変位をえーこちらはえーま未知語既知語共にえー性能
オープンし結果のえこれその
利用することで性能が改善することを示しましたまー
えー
て検索時間に関しましてはえー紙を用いてえー数えシステムの併用行っても平均一えー一九八人一さんとお花非常にこうすぐに検査ができるということをしてしました以上で発表終わります
で構成されございました
#############################


#############################
# query = と音声で他の解析をしているんですがそのーその解析のやり方一つにそのーベクトル解析っていうのがでそのそのスペクトル解析ってなったっていう二十帯域ごとにそのパワーを求めですでいややつらしいんですけどえーとまー自分で色々調べていたんですけどまそのスペクトル解析の方法の一つに先れたバイク方でっていうのがあるらしくてでまー後と三で見たんですけどあんまり分からなかっ側でまそれを説明してるようなえーでんっていうのをちょっと探している欲しいとえー混合音のでえーお願いします
# rank = 1
# slide = 08-18_fix.match_word.jout.txt
# value = -4.03563824591968
#############################
ん入っては初めは
えスペクトル情報を用いた場合苦労えーとー後実験一というテーマで
法政大学情報科学分野×が発表いたします
えーまず最初にライトの部分について御説明を反対させていただきます
で第二六といいますのは
その体系や生活の記録でえー
えーと位置情報という喋り方で記録されます
えー利用例といたしましては
いう五六八二十方法などが挙げられます
えまず三五六と言います笑いの音というのはす生活を上で記録しているので
同じようなことを記録されたそうな利用のし方できます
側に一致といいますのは例えばえー画像で
落語を記録した場合に一一応画像で振り返るということができます
でその為には一日の出来事を要約して
普段とは違った構造を決定する必要性があります
えー
二年後半といいますのはえーっとこのライフを取ることで普段の構造をモデル化し
普段の行動とは異なった報道をさせて日本語生成するようなシステムは考えられます
でこのことを考えた場合にえー
声道が出来事の再現性が最も良いと思われますが
でデーター量がその膨大な為に
で同様インデキシングが必要に私は
でその為に
二つの意味を持つえー画像区切りであるし四ケースする必要性があります
えここでえー先程言いましたインデキシングの例を挙げさしていただきます
でこれはえー
財大学に来また自宅に変えるというような場合の例です
えまず家でまー一番最初はまー自宅から始まります
でその中でえー大学に行く丸の間に
え自宅から駅まであるん
ところのえー
歩くようインデキシングやえー下町
そう車内などが挙げられますま大学では授業や
で研究さで研究てる
時が食堂で
給食などを取っているような場合だ
んで一にされます
まこのように一音一にはなってます
えー
にえらい国の新聞類に関する従来研究について説明いたします
えまずスペクトルを用いた研究
にはえースカート三．五分類したものがあります
でこれは希望だけの八以下の四名来る音を
平均スペクトルと学習データーの二乗誤差の
平均と標準偏差を使って
検出し人の声を
そのー声の倍音構造を使って検出しています
えーこの人の声の出現頻度でえスコアと三人ぼけとしています
えまた一つを用いた方には
えー
で手法を用いて建物がえ建物外でえー誤分類した者や
えーいわゆる情報を用いて
えー
気を元にえーっと分類したものがあります
でこれはえー一月数やえー引き数をヒストグラムを利用して行なわれています
えーここで画像で記録する
えーライフを記録する場合の問題点を
そしてえー
数を変化を利用する場合には
え講演音声による重要な位置にオーケーです
意味を第一のケースが起きることはあります
えー例としましてえー友達をさしていただきます
えー
位相変化というのはまーこういうバスと電車の発声数ができます
えー
この上の写真がそのー
例なんですがえー
まずホームで六会話の方法はん海の方も見て待っている状態
そこに電車が入ってきて
その餌に乗り込んというよう分かったのですが
これ一つ一つが色素が分かっているので
子音として分類されてしまいます
後でえー電車の二十九月から
ちょっとという子音を構成する本しか使われるべきですので
えー
最初の二枚の
ところはえー仕事として扱われ
これこのようなものが集まってえー下町という子音が構成され話者内は別の四になる
というようなもう切れ方が適当だと思われます
で本研究ではあった
このように
で電車が入ってくる時にはえー
んで下の音がしますので
で後情報に加え
音響情報を用いてえ子音の系列を行ないました
でここで本研究の本研究では子音と外の定義をいたします
え子音はえーホールでえ昭和三十五分から常触れて
ちょっとアメリカ夏になります
でこのえー家族との番号と
あの別の
番号は対応しています
これ実はでしたの進行方向です
でまず一つ目が
電車で文法のホームでは二十一部分進行方向に対して
えー前方で
訂正が発話する時
えー二番が
提唱方法の方をモデル化するということで電車の進行方向に対して
方法ですがその時
え三番が
えー同じようにえー
電車で見方でホームの計算から電車が閉鎖してくると
えー
四番がえーと高校のホームでお弟子達
で五番と僕は五六七はえー言語に関係なく警察官
えまたえー五九番が二十八ページを使わない時の方では廃棄時
私は妹として扱っています
この括弧の中の
え発声八あるなどはえー以下の
説明時のえ役所になります
で具体的にどのような音がするかということですが
二つにあー
えー
んー
えー
んー車内の
んー
えー社内の音の方ではアナウンス八えー二音と音が含まれています
こんなことを
えー識別していきます
えー
最適にその死でした後の子音をどのように同定していくかということですが
えまず
ある外の
ことが入力された場合にそれを感じがセットにします
えーそんな感じがスペクトルという第一は三時間という風にいたします
それをのおー短時間でのスペクトル一つ一つに対し
フィルターの分析を行ない
えー
メル周波数上で
んー性格が一つのコーパスすることで
あースペクトル包絡を求めます
でこのパワースペクトル包絡を用いて
えー今回は二つの方法です音の識別を行ないました
一つはパターン間距離を用いた方法でもう一つ確率モデルを用いた方えー
でこの
ん識別によりえーちょっと話者内にあると
いう風に
統計誰からこの子音と見なします
ちょっと頭が意外と識別された場合にはちょっと取り出します
えー
そのー
んえー
ちょっとの識別はえー入力音とかちょっとのプロトタイプの比較によってはされますがえーその為のプロトタイプの抽出方法について説明いたします
できる科学分析はえーメル周波数上で探索を用いて帯域を算出している
えー
海することでえー帯域ごとに特徴は集約的特徴をより明確にやり方後に行って
発話間距離を用いた方法では差が出易いと思われます
えプロトタイプはこの下の図のように
てえー求めます
でまず学習データーを感じかスペクトルにして
けれどワーク分析をした者
平均してえ平均パワースペクトル包絡を求めます
これがプロトタイプになります
今回は比較の為に
えーパワースペクトルを平均したものでも
えー後えー識別実験を行なっています
これプロトタイプです
左側がえーパワースペクトル包絡を用いた場合で
右側が
三十二パーセント平均した者ということになります
えー
次にえーパターン環境にちょっと
二三四ちょっと識別の方法について説明をしていきます
えー入力音とプロトタイプのパターン距離を
って思うような式でえ求めます
この式を思うと
あーこの式を実行することでえーま上の図にあるようにプロトタイプと
短時間スペクトルとその入力との
えー個体間距離が求まります
んこの距離が最小になる
ちょっと
でちょっと候補という風に見なすが
えーここら感じがスペクトル一つの
あそっと方法といいますのは三時間ステップ一つのものですので
えー入力されたデーターに対して
んー二系列で
えー
とー
ちょっと方法出していきます
えこの場合ですと
並列化が最も多いので
補償とは通貨ということになります
次にもう一つの方法であるえー確率モデル
を用いた方法について説明していきます
えーフィルターバンク出力の帯域ごとのおー
まーあのー対数を取ることでえーまず
ほい短時間スペクトルえこれをえたばこ分析を行なったものですが
その奇麗とは分析を行なった堅い木の分布を見ていると
このような
対数正規分布になります
これは対数を取ることでえーま正規分布として扱いこれの平均気温差を求めることで
えー確率モデルを推定します
この平均取りますのはえ学習データー一つ一つから出したものを平均で
競技車は
学習データーデーター全体から求めた共産で
これを元にちょっとの確率モデルを推定いたしました
で今回はえーフィルター実は三十八次元でしたので三十八一年対数的で
ということになります
でこれを用いましてえー入力に対する
いうを求めちょっと推定を行ないます
えーニュー
はえ獲得の入力に対する尤度は
えーこのような式で求められます
この入力音といいますのはえー
ん入力されてきた音を
のえーパワースペクトルパターン時間スペクトルにしてえーと分析を行なった文を
適したもの入力としています
でこの式を
求めまして
えー尤度は
最大のものをその時の町として推定いたします
でこれはえープロトタイプの抽出やえー後の行なうテストをあー
ひょっとし九十八の為のデーター収録の方法について
体をですね
録音条件は
えこちらの
図のように
えー
紅葉たんでね海の方の方を用いサンプリング周波数四十八キロヘルツ二酸化ビット数二十四取れば色々こうをいたしました
え一日それ中国の方をし調査をして交渉して
その後また中国語の構成乗車するというような構造を繰り返し
データーを録音しました
えー収録
あの時間帯はえー二六が一時から一六時の間でえー一二が一歳児が中心となっています
んーそうすそう収録時間は重視時間でした
えー
収録場所はＪＲ中央線のみたいと非常時期で
で電車の種類は中央線の数は二種類と時は最終
で二十二の頻度は昼頃は一時間二十本程度でした
一人称と識別実験を行なったんですがえー
その方法について説明をしていきます
んであのー
表がえー学習データーテストデーター数と
てその平均時間になっています
で下の表がえー
ただスペクトル変化は分析する時の条件です
感じかと
適当にする時の条件はデーター長が
発生四十八．〇一月一日千二十四．
アイデンティティーとは二千四十八点です
でたばこ分析を行なう時の条件は三角の町はメル周波数上で二百
生活シフトはメル周波数以上で百
配列数が三十八次元なっています
ことが条件彼実験を行なった結果がこの表のようになります
この識別率といいますのは
正解数をテストデーター数で割ったものをパーセントで表示したものです
でここで
んー八着という人ちょっと増えているのですが
これはこの上の八
頭のデーターをもう一回かするちょっと
とすとしてまとめたものです
衣ということでもえー
四五の合計数が増え
えーということができます
えー下一番下の平均はその話し方の部分はそのちょっとの平均識別率になっています
でこれがえー詳しい結果です
えーこのおー図えこの図はえーこの冗談が
反対側はえーっと
いうあのデーター数になっています
えー例えばこの八．二
こう入力した時の結果でえー発声と
結果を得たのが〇パーセント
でえー経済取ってたのが
一五．四パーセントえデーター数が二
価値ある取れたのは二十三パーセントえデーター数が三というんー三読みます
えー
八音をえー
これはえパターン間距離の
後パワースペクトル包絡を用いたパターン化距離での
結果なんですが
その傾向とあーこう識別の傾向としましては
えーまず発声加えて調べ見ます言われ易い
本柱Ｆがあって最近は
頭ある状態って言います言われ易い
八Ｒが入っています言われ易いということがたであります
温かい距離を用いた方法についてのです
考察を行なっていきます
え今回の実験では全体の的に低い識別率でした
えこれはえー今回は平均だけを利用し識別している形に
で電車の速度や夏により終わり違いが出てくると思われるので
風呂状態二三日にしているという方式ですされたものと思われます
えまたえー走ればピークに特徴がありあまりプロトタイプは似てるものはないと思われたのですが
えー識別率でした
えこのテストデーターをえーもう一つ一つをま調べてみたところ
日がなかったり日が連れているものがありました
この下の図に示すようにえーこちらの図はえー
そうですね
まプロトタイプになっています
赤い点が
父が多い点がテストデーターです
紅葉にピークがずれたり
ピークがないものがありました
えー
そうよりかは文では識別が困難だと思われます
で次に確率モデルを用いた場合の
結果ですがえーこのようになりました
表の見方は先程と同じでえー
後識別の傾向としましては二十政府が
傾斜にまつわる易く
えーＡタイプは
頭には違うんーえー八
猿が
私え国間違い易いというような傾向がありました
えー特に識別率の低かったえー
提示音と反射ｒについて
考察をしていきます
えー検索は柱としても識別が多かったり
えー
この二つの音を聴取してみるとなることが分かります
えー
えー
面はえーですねあのーこんー
え次に私はあのーんーんー
えー
えー
んー
んー
んー
そこであり
どうも違うというは分かるのですが
ホテル対応が平均しているので
それで類似してしまったのではないかと思われます
でこのようなものへの対象としてはえースペクトルを
時間変化の利用などが挙げられる挙げられます
でまた
私はＲは発声として後識別されました
プラセンタはと出力を調べてみたところこれは
三十二脳血管一二音のフィルターはと出力分布なのですが
頭の発声法はこのように平均が近く
分布を被っています
えー全く英語識別がされなかった
ですが
また概念を識別が長く続かえー帯域に関しましてはこのように分布も
あまり被って楽平均を離れている
でこのようにえー
あー
んペア平均が近いものにやはり間違い易いという傾向があるです
えー
次に
変化行った三つの手法について
の比較を行なっていきます
えー平均識別率はやはりそこ動いた場合の
あースペクトル平均が三十
二十一平均を用いた者が三十七パーセント
んー包絡を用いた音は二十七パーセント
クイズモデルがあー一一パーセントとなりました
八募集をした
場合ではえー
二十二一致した場合の識別平均識別率は
二十一平均が八十七パーセントバスケットボールは七十三パーセント
ある一モデルは九十六パーセントえ識別率でした
方法事柄確率モデルが最もよくちょっと識別ができたのではないかと思います
でこれはえー平均だけでなく分散も考慮した駄目だと思われます
で後は二にえーこれは平成二はニューヨークで
正解した例なんですが
んこちらが終わるんですがパワーだけをんーと
でこの
赤い点がもしある
平均パワースペクトル包絡で青い線が
平成九の平均パワースペクトル包絡なんですがどちらかと言うと
柱に近いような
んー人気は
えーしかしえー
風に分散が大きく異なっている為
高校生の働きえ
不正解であるという試合という風に識別されたのではないかと思われます
ほぼ最も識別率が良かった確率モデルを用いましてえーちょっとおー検出実験を行ないました
補償と検出実験といいますのは二つ以上のちょっとから
でちょっとを検出するというものです
で具体的にはえー
今回はこのような回帰に挟まれたあるそう統計一つ
するということを行ないました
えー
んーまーテストデーターの一例としてこのようなものが得られ
私は帯域の状態で始まっ
んーんーんえー後でえ周波数を出して
えーまたえー
最近はちょっとになりますえー
えこのようなテストデーター
えー
えー時系列でえー前から一定感覚
ある程度時間幅で
ちょっとを検出ういたしました
え地方は四秒六秒二十四の方は楽なしっていう
二十三種類
これはえーこの時間波形からえー
えー四秒四四つまたは六秒二十秒です
黒い矢印の範囲で
ちょっと識別を行なっていきました
後もう一つはえー四秒六十八秒であったのですが
で終わらこう時間窓半分とした文
でこれはこの黒いやってる人赤い矢印の範囲で
ちょっと識別を行なってきました
えーこちらがその結果になります
えー
このえーずっとこのグラフはえー
そこ軸が時間で縦軸がその時に軽視されたショットということになります
えー
えー上に書いてありちょっとはえー
正解ちょっと変換正解一ということになります
この場合ですとえーっと千部分が正解で赤線部分のケースなので
でこの二ここの部分は正解しているのですが次に
方は正解まそこで正解をして最後は正解っていうことになります
って全体のおーな傾向といたしましてはえーちょっと変化ちょっとが変化する時に
不要なちょっと訂正が見られました
でこれは確率モデルはちょっと全体でモデル化しているのですが
えー二系列手前から検出していくというのは
えー
ちょっと全体が入力されることがないのでまそれが原因だと思われます
でまた時間ほ本を終わら繰り返しですが
えー時間幅は
を狭くすることを合計数が増えました
また終わらから行なうことでまー一つが増えました
まいずれにしてもケースが避けられないので
えー何らかの条件情報が
情報が変化する時を建設
するということを利用することが考えられます
え例えばえー画像や音響情報が
変化する点を検出することで
それを用いてその検出を行なうかを推定使っ行っ範囲を推定するという方法です
えー最後にまとめと今後の課題について
ですからえー
ほん今回はちょっと識別実験を行ないました
え仮説の方の方を用いたパターン×が二十八パーセント
二十．二兵器を用いたパターン半球で
表の識別が三十八パーセント一一モデルは七十五パーセントというえーついて識別率でした
またえー確率モデルによるそっと穴実験では
ちょっとが変化する時に不要なショートのケースが見られました
え今後の課題といたしましては時間スペクトルの時間変化の利用をやって
ちょっと検知実験は
評価手法
えー二十九使った時の対処法や
不快の方で下の二十九え今回はそれを考慮していないので
先行していかなければならないと思われます
えまたえーどうもすいません
今回の手法をえーどうしてえ最も良い適用していくか
ということが挙げられます
以上で発表終わります
#############################


#############################
# query = と音声で他の解析をしているんですがそのーその解析のやり方一つにそのーベクトル解析っていうのがでそのそのスペクトル解析ってなったっていう二十帯域ごとにそのパワーを求めですでいややつらしいんですけどえーとまー自分で色々調べていたんですけどまそのスペクトル解析の方法の一つに先れたバイク方でっていうのがあるらしくてでまー後と三で見たんですけどあんまり分からなかっ側でまそれを説明してるようなえーでんっていうのをちょっと探している欲しいとえー混合音のでえーお願いします
# rank = 2
# slide = 10-21_fix.match_word.jout.txt
# value = -4.08732726935931
#############################
まーあの七．短大の川の水もします
で本日は対象密着型マイクを用いた態度文と発話の収録のこの三そういう
タイトルで
発表さしていただきますとま第二六という文脈で
ＲＡかいない音とか発話を収録するということを試みて
いきたいと思います
まほ
分かってた原稿を書いたと日本の色々死を積分形の見方でしてす五分で若干資料の方に起こるをえーできるだけはしております
えっとまーあのーま勝手の分類ですけどまだ一六基本的にまーそこの
外的なロボットま内的な六つの川もどうもあるようですで解析やるというのも本人があ
で体験した
ものの
記録ま外の風景濃いところに
二絵を見たよとかこういう音を聞いてるとかこういうところに
いったよとかまそういったの方にま色んな方法にへの入力の
記録という意味でのま第二六と
後まー
本人が
えどういう状態であったとか表二に移動したかとか戻ることを喋ったかとかまそういった意味での
ま本人から出力する
で父意味でのまー
それを記録すると意味でのまーん第二六とま両方共あるようで
でえーっとと家の中で生活するとのえー生活の軌跡とか
を記録する
ものとか
まー
えーマニュアルが
ん内的六
で
二えーまー応用としては
えー家族の
記録とかまお年寄り
四
の方の二次のことを見守る
ような
え使われ方子供するようで
で
まー
えー
ま凄く簡単なす頭型とどうしても思い付いたことそのすぐ録音できるような環境を整備するとか
そういったものも含まれるんではないかと思います
で解析老後は
まー
えーそこに
先生があるのなくて動くとこう人が
えーグラフなかったかなとかま幾つかを
えー装着して
で
移動する先々で
えー
その後に
えー夫や
って言うとおーまその位置情報など含めて
補強するというのが
あのースタンダードな
いう方針なのです
んでまそん中に
ま応答というのが
ま色々
組まれていて
パソコンの音とか
もう外で記録としての入力としてのことも外部の音を
店内で記録としてはその日は何の差別とか
えーそれと
えー体の動き
ま空の状態の中でも
体の中のことと言え両方とも含まれているので
えこういった
ことに注目して
えー
第二六の
広く
父ができないかと
えー検討
しております
テーマ
まその中で問題と的な音を
え今回母音とえー
態度をん
えー体内の弟
ここで喋ってる音
も収録
にえー着目することになるんですがそうすると
でも動機としては
えーっと発話の収録とか
外部のとこはもう既に
結構やられているようですので
体内の情報情報体内の状態を
えー約六十
積極的に活用できないことに
あえー考えてきた
んで
その体内ノードだけではなくて
境界の環境を
自発的行動を
トマトともペア自分が喋ってる夫とを関連されさせて
ま両方それらもバスで記録したいと
ことによって
えー外の刺激とかが
本人の中の
体内の
下にどう影響したかとか
あるいは高二の体内をどういう
えー
二状態だったから
えーこういう行動に出たかとかそういったことがまーあの関連付けて
でえー記録し分析できるんじゃないかとえー考えました
でえーまーその繰り返しないまそう音に注目することで
えーカイ二回環境音や
違ってき発売は
態度
という形で一二三一元的にまー使うことができるんじゃないかと
えー考えた島
でまその実現するって機械として
後音的にはまーあのー九八六のもので
ま家とか
えーセンサーが
用意された三守り可能な場所以外でも
ま収録できるような
早朝ます
準備したい
んでえー
ま早朝ちか町期間の
えー創作にも負担がない
では一度
とーまずえー準備する必要がある訳ですけど
まそれ
そして
えーまその県もう七千万台で
えー二千四年ぐらいに
お金開発が
のマイク
というものが使えるんではないかと
って考えており
これについてはえ何ちょうどもう一度
御紹介します
て
えーっと収録さ
あえーライフ六のま一つの意味で名詞として
体に
えー
三万文の場合はまーあのーい量的波形とか
ま色々あの応用が考えられますので
これ局所本人が要するでイメージとしては
ま例えばえーっと
洗車歩いてる時に階段が多くてキーでしたんだけどあの場所は
もう以下のようにショートんだけど個だけとかまー思った時に
その人は
のライフログに
いう選手のデーターなから高級数や
えー
え呼吸の
パワーが有意に高かった場所検索して
とその時間情報とか
えそこでえー収録は
とー
まー同時に
んえーピッチ情報があればその一表一ますとまこういった使われ方が四つあったりえー
えーっとえ
まそのプレゼンテーションをリラックスしていたとしてだろうかとそこに初めて説明する部分では緊張してなかっただろうかとかそういったものをえ後でチェックするというのを
ま発音収録されているので
ピークスをキーワードに音声検索してそのガイド本女子にもとても心拍数とかＦ０を提示して
えー
緊張具合とこう知ることが
後で確認することができるとまー一例としたこういったえー五四ができるんではないかと思います
えねでえそのーマイク
えーっと五のあのこの
えー二つ程後のスライドで改めてこう紹介しますがのマイク
というのは
あーのー対象に密着してえー
適当に小さなさ第四声を
収録するデバイスなんですねそれを
使ってえー既に
一え二回目の色んな信号を面白く証拠というま試みはやっぱりどうも
後五分でちょっと今年三落としてしまっていたんですがえー
体のマイクロホンを用いたのかとか食情報の
テープかと収集
もやっぱり
死んでずんんその電極とかまー魅力は戦争とか色々ある訳ですけどそういうのを使って
後ろから非常にあの負担が大きいので
この名前こう同様に
えー新日本の
えー収録と
でもえま同時に勿論その何も発話の収録
ここでえーっと使えないかというま調査はされて今
やはりまーあのー死んでんずに特化しても見比べ×らも
の性能をする訳ですけども
んのか使えるかもしれないとまそういったあのーぐらいの
他のところは得られている
て
そのー
まこのマイクを使うことによって
ま利点としては
以以上道端であるので体温態度が終了感
って予備的にま色々えー取ってみたんですがましょうが機能ぐるぐるお腹なろうとか
言って大きな
というのとか
方針音と後やはりえーっと
んー
えーっとはい
えー
そこもあのー重きを問わ収録できること水も確認してありますので
えーっと
で
つまり点もう一つとしては
ま音声帯域も
勿論収録はできるただ
えー
高域成分が
あのー名前この構成であの構造上どうしても
用いるという欠点終わるんですけども音声帯域の習得できる
で
まこれは本来あの望ましくないことだったんですがま外部ももう
赴任して
来るものだから外部面白くできる
いう訳です
で
一番最初はまどこに
何を取ることを気にし始めのことをしたんですがまやっぱり一番あのー主要な
分かり易い音であるということで心臓の音は
常に取れるポジションで始めようということで
んえー胸の上の
一番下が捕れる場所に変なマイク
後接することから始めまし
で
ま最初あのー研究しない使っ実環境とかで
あのーじ実際にえーデーターを収録して
取れる音の周波数特性とか
って体内のえー
どういう音が取れるかというの間違ってるというところをしてまして
で
その後に
えーま色んな生の情報も遊びをする予定であります
ま発話六については実環境発話
もう発話区間検出とか
えーま音声認識性能とか
はいどうについてはま心拍数
えーこう係数なども
あーあえー自動抽出とか
あるいは
歯に伝統を
ま赤色響きとかそういったもの
貢献する
まそれぞれ
もあの主規制を使ったり
また音響特徴でのＧＭＭ
作ってとかでも何となく
町方針があるのでこれを進めていきたいと
んで今
でそんなになるものであのーこの辺りは今日おーえーと発表できると人ですがまだあのー
データーを取ったでこういうことになりましたとかまそういうえー段階ですのでまー
そういった音を
実際にそれをと取れたかというのをまー皆さん聞いていただくというのも今日の
えー発表の
名詞ま抽出をしさせていただきたいと思います
えー
で
えとまこの資料一の話と
えー
えー幾つかの収録していて
うえー
研究する実験しないで
父が
音の比較と
あの試験的に
もう外に出て
本を収録した結果について
ま幾つか来てもらって
えー
まとめたいと思い
えー
でえーっとまずま本当毎年音構造とえーその他のマイクの
えー御紹介
えー
えー
ものマイクですま二千四年にえーと開発されたんですが
ま基本的な構造は
でこれは下半分が
その体
心上野のマイクですね
あのー
ま資本のえーま特にここのものでもないもので十分な
コンデンサーマイク
を
えーってえー振動目のところを
まシリコンで
方形で
えそのシリコンを
えー媒体として肌に
一密着させると
でそのシリコンというのは
あーのー音響インピーダンスが側と近い
ということで
えー
方から苦しん道を
ま比較的あのー
ロスなしに
振動伝えることができるそういった構造ですね
んで
ま最小はまこういうマイクまで付いたかと水と
あまりに聞こえないぐらいの小さな島帯域声を
え振動
そしてえー
気温自体が
いう
のがえー目的でしたので
学ぶを取る食べる前ということでまこういった構造の前ともこれはランダムマイクと
あのー総称しておりまー
てまその後そのシリコンでなくてウレタンの方が
ツリーとか
鳥を元の構造とこのようにあのー改良を加え歳とか
えー計量化されたりとか色々をしてる訳ですがま基本的な
の考え方はこの構造です
で
えーとまこれはつまー実際のデーターではあるんですが枚名詞のようなものとしてみて
いただければいいんですが
まー
なも発生
もう
えーこれで収録するとですね
結果的に
まー一時間にも仙台でこう二キロヘルツ
より下の部分しか
あのー
成分がない
ことしか取れないんですね
てこれまでのまー我々もずっとあの理由どこが
分からなくて多分放射特性がないからだろうとか
と声帯振動のその一言
こう位置が低い影響が強いんだろうとか
何何とかないけど
んーやっぱり
体内の伝達で
をそこなれるんだとか色々考えていたんですが
って思って勝手にその
えー
ま記念日だから先生が
よく
測定したところのマイク自体がオクターブ当たり一の何デシベル下がるという特性がもう道もあってこれはまー
このマイクでもあるみたいだという
あのことを報告されてありますので
多分どういう
ものであっても
結果的にこういった上級これまでしか取れない
そういう
まー
構造の丸四です
一出てえー二．四六に使った
えーバイクの転換ですが
まず×別のマイクこれも後にあのー名前怖いですか
して
あのー
集大成とかそう調整をこう
え向上させたものです
一でしたが
そうしんので
えー上が
重心の
で送信のあのえ真ん中国これが
学ぶマイクで中央にコンデンサーマイクがもう待ってると
で
まー
すあのー
作り易いような
あのしゅしゅの収集を
付けて
基本的なもの耳の全ての面白二のことを想定して作られたもの
でま一回
あのー
こっから
デジタルう
録音機のこと気に書いままアナログにしてしまうって言うとこういうスタンスを持たないところもあるのでそれをまーあの
えー新しく
父システムでは
まデジタル
でえーその他の古いような
えー期待も作ってます
今回の収録ではまー六十に生かしたものもう一度録音機でデジタルにします
で体内思い付くのが
ま同じえー
えー口頭で作るんですが
えー
目的そして大人を待ってみましょうというちょっとあの研究がありまして
それでえー
まー二つの中
に上がっていてえー使うことを想定して
ま比較的別に言う必要もないので
安定して
あのー寝ている人の中に乗せるような
んで
あのー収音反意語を広げるという子供とそしてこう体も
で広げたまに来るのを作りました
で
おこれもえっとー
で先程のマイク旅行知能がまー本来のこれあの今回の目的に近いのでまこれを
えっとそのーある気が気にしていたんですがまこれを
えーやっぱり
方法として
んんえー収録しました
ってこちらも一つ前のこちらもそうですが
あのー
え飼ってる人の目につ付ける形になるので
が残って方法が難しくてですねもうあのま規則を使ったりとか
色々試してみたんですがもう
なかなかまだ決定的な音が見つからなかったのでま声の収録では
あのー凄くですがあのー雑多な訳ですが
えー幾ら太って車が持ってるみたいなね固定するという形でえー止めてま
でこれも比較用の
え店長新規何ですか
えー
わりと文の
まこういううーものがあってあのー
やっぱりその体内身をおー
えー
あー聞くのも目的ですので
ま幾つかま二つ子供があってその中で
もえーと
痛いなと思うという
このということが
強調して聞こえる
本をあーもうどうで
でえーま比較用に漱石だとこの二はそれぞれのえー測定
収録してみました
えーとやっぱり本当しんき
足の形で聞くものなので
んあのー
と本き一九六月に
えーまだ三ちょっと
あのまここでのマイクを入ってしまうんですが実平行に
年に一を掴むということでえーまー何度か宿泊しました
んー
えー
で収録した音とのえー
訳ですがまこれも室内で習得した音を
ですねえーっと
ＰＣの三の雑音勝手三十七ＤＤＩのもあしますから親で
えー収録した男
子供は比較の為に
できるとか実際の雑音をスピーカーで六十ＢＢえぐらいの人になるように再生した音
中で
えー
発声した
ま無音の部分と発声したこと
のえーデーター
え発声内容あのー
んー
情報システムへのユーザー発話ですが特にま今回意味はえーございません
であ×です名前
で使った作った
父も
えー彼は資料二音の
えー
一発話近くに銀行あるいは二というものが
上はえー
〇
ヘルツから二十二．一キロヘルツ
までのスペクトログラムでえー
真下は
ま千ヘルツまでを拡大したもの
まー
やはり
あのー四十キロヘルツ以上はもうないので
の
下の部分だけ注目して
えー表示しており
ってことですと
えー
えーっとそうですね
まーし日本がやっぱり聞こえて
であのー所々こういう二スペクトル
の中でスペクトログラムでもとんとこう言って出て
でえ空間
絶対ない思い
あのー丸くて大きいやつです
まーちょっと三十二日の音量の問題でもあるんですがま同じように
あのー唇音が
最初の方で
独特と聞こえてえ
えスペクトルでもその父
んで言うまでもないですが外部マイク
あこれも走ってあのー当時これと同時にするとえー現在マイクで収録した
ことをですねこれが共
そのこれ
多い
まこれまでそま身と当然取れる
ものではない
で店長新規のおー
ですね
で八ページ目とやっぱり
あのー適切なフィルター九月にかけてあるのでま唇音が凄く波形レベルでも大きく出たえー
もう
んで
その結果あのー
も
減少し下の文特性というのはよく分からない人もこれも結果的にあのー四十ヘルツぐらいでもうそして
ある
不要ですね
雑音耐性とかで
体内思い付く
を使った時の
えー後ろ二音と
でえー外部のマイクで取ったこと
ですね
一つのタイプの前で父とおもあのーもうよく
本
んー
うー持ってえー
えー
うー二えーはあー
もう普通のことな訳ですけどでかいない思い出でどのくらい音が入ること言うと
こういう
あのーんー
んー
んー
んで
えー
もう本当にあのー
えー単純に上の方が計画という
んんの鴨はスペクトル二四六的な層ですけどもあのー絶えない神は
勿論当然の方
すえーっていうようなことが
えーとこれます
判定ですねこれをその密着するか月特性が届かないじゃないかということで多くの考えまして
えー
法律のまここでの機能のあの講演音声をまーちょっと置いて若干
あーの普通の外うまいそしてその前こう
二番
て収録した方法で
もう
えーっとですね
まあのー
えー形に付けて様が外になる前二つ顔が結局まー
同じような回帰情報としかも取れないまそういうマイクなんですね
で
これをまそこの環境でえーと
ま実際付けて
ん見たという
本を紹介したいと思います
ソフトの千葉で調べたのでま型紙と全く分からない
訳です
んでえー
えついてここにあのー参照用の
最近マイクも付けてですがまそれも
まこれたまたまあのー隠れて見えない
船が側から見るともう殆ど分からない
んで手法ができる
でま色々屋外で取ったり
えー敵の中で
でしかない訳通さない
えー屋内
ま食堂とか
父も
それをまーあのー利用者な訳ですけど
睡眠中の候補とかいう試みを下のそのまー×です名前です取って
一応こう書いていた
えー
精度車の中の音
怒ら外部マイクですんー
問題マイクの音も普通文と文ですが
んで
えー
えーっと足りない思い
の
他難いですねま車の振動計を提供凄く広くて
振幅は大きく
つまりま
で
歩いてるところを
そういうマイクだとえー
えー
後のまー母音結論です
まー仕事がま聞こえる時代なんですが
体内をマイクだとま決めずま実用的な建築ある時ま九月のずれ出してしょうがとても大変です
というのはします
あって
えーっと
あまりにも
えーっとそうですね
ま就寝中もあのー振幅の進歩の音がちょっと
ほいで
やっぱり
えっとー
とても
あのー
二人目が当然それナイフがいない音の
えーんというものどんだ
うちの父から
えっと今こう
もっと汚いですけどこういうことでは聞こえないんですけど
あのー昔風のあのーまー
それも
でまーとところもあのーま
ん奇麗じゃないんで弟妹も出さない予定ですがま聴覚の
ぐるぐるなろうとかもこういった
あーのー
スペクトル頃の手にいるようにあの結構遺伝子型
えー
ですね
最初にえーっと
二五度文と発話環境当日でるってキロをドライブログを提案しても今なら
この四系列の仕事れないんですがあのー日本のことです
で
ま課題としてま先程述べたような
あのードキュメント処理もやりたい
というのもありますのでこのまー進めていきたいと思います
で
最も保守的にうち一つのマイクで取る必要ないんじゃないかというねちょっとも
で最後のトイレを持っていきまして
勿論マイクと腕のマイクでえー良好で
え進めていてそれはかと
え考えれます以上です
#############################


#############################
# query = 統計的機械翻訳っていうそのそうですねあの対訳文と言うかあのー日本語とで五の二つの対訳でん高い値をたくさん用意しておきはまー計算機でまー外に翻訳できるって枠組みがあるんですがえーまーそれのその理論と言うか原理とかそういうのを説明しているえーまー心と言うかスライドを後えーお願いします
# rank = 1
# slide = 09-20_fix.match_word.jout.txt
# value = -4.53200671672818
#############################
えーと日本大学の何度です表記のタイトルで発表します
んー
えーっと研究の背景なんですがまー気にえーっとーまーこの
一回の音節なんですがま恩恵音声ドキュメント検索ってのはまー盛んにやられてる
でま公園とか行為などを持っ検索対象として
まそれを検索するということをんがやられて
でま音声だけネットワークグループというのに私も所属してましてえーとそこで
えま色々タスクも作ってるというな状況
で一機能の
間の先生のおー話にありましたけども
不満のＮＴＣＩＲとかそんなところではまー言語の音声ドキュメント
検索というのが行なわれてる
えーＴＤとかでは
ま世界
ミヤブラウザーというのを使ってまして
えーと多言語の静的面倒検索ということをまー何かやろうとしてくるというような状況にあり
いい時のあの話でもありました通りまた言語を対象とする場合は
まあのークエリーを翻訳するとか
検索対象の精度を検討応援するというような丸四五つのあるというな話なんですが
まやっぱり検索語
検索した後にまそれを見た時に分かり易いというような観点から考えますと
ま検索対象
ま翻訳しておくことが望ましいということがあると思い
でえーっとまー検索対象の程度決めるとま翻訳しようとする訳なんですがま大体においてまそういう音声ドキュメントは
後方性の高い部分です
でそういう先生の高い文に対して
現在の機械翻訳ってのは
ま結構難しいというような
感じです
え四で一方自然性は低い文書に対しては
ま比較的容易な
翻訳んができるというような状況がありますこれはどういうことかと言いますと
ま二重性の高い文というのはまー
実音声ドキュメントの書き起こしみたいなものでして
で二重性の低い文ていうのはここでは
ま直訳調の文章ということを想定している
で実際の例なんですが
まーあのー毎朝犬の散歩に来ますというような
文章用翻訳しますと
第四五相談を
お婆時計貧乏人とかいう
ちょっと変ないようになり
で一方町で性の低い日本語私には朝私の犬の散歩が一つもあります
んーこんな風な
えーっと文章にしてやると
まー英語にしてあるとはえ用例坂が多くお前とかビザモーニングということで
ま結構うまく翻訳ができるいうことがあります
そういう訳でえーっとーこの
ほい焼く前に
変換細い編集と言うんですがそしてあることが重要度
いうことでここでは
私え性の高い文を
ま二重性の低い音契約書の文章に変換してあるということを考えます
つでえーとその機械翻訳の前二つの問題なんですがま色々まいやられてますが基本的には
前編集をどう行なうかってことを
まモデル化しないといけないんー
でえーっとまー今までの研究ではまそれは
後でやってる訳なんですが
で基本的に値を水が自然な文とま直訳調の文
×という方が準備する必要があって
まそれ人手で集めるのは結構すぐ
それから
直訳調の文が集まったとしてももう
最終的な翻訳にとって必ずしも
観光地の文の方が
自然な文よりもうまく翻訳できるという訳ではないですので
まそういうものは
学習データーから覗いてやるということが必要
でその上でまこういうペアのコーパスが集まったとしてもうそこから
まー毎日え規則をですね獲得するってのは
えーやはり大きな問題
という訳で本研究では
えっとー
この
直訳調の文と自然な文の対応っていうのを
まー自動で獲得して
そう思うから毎日え規則もま自動で
獲得しようということが本研究の目的です
えー
でえーとまー実際にやっと型で聞いた翻訳の枠組みを用いてえ前えー使用することを考えます
でまー統計的しか親がま音声認識で同じ枠組みでしてえーま原言語
えー単語列例数与えられた時に
まそれを最もよく説明する単語列Ｔ易い
おー求める問題としてまこんな式を変形してって言ってるこの式を求める
んで
えーっとこの
確率を与えるモデルは変換モデル
でして
こちら確率与えるものモデルは言語モデルになっ
いうことです
で毎日一を考えた場合には
このＳの方に自然な文の文字列を
でこちらの二の方にま直訳調の文の文字列ということにしてやって
まこっからこう声が聞かれてやればいいというような問題になります
道をちょっとあえーやはり毎日があって困りますのでここでは一応このｐｔを与えて言語モデルを直訳調の言語モデル
とー
呼びます
でこれ食べアクションテキストで学習します
でこちらのえーっとＰのＳＴという
ま返還確率与えるモデルを前にして変化モデルと呼ぶことにします
でえっと学習データーをまー自動で獲得する
獲得のし方についてお話
で今回は
毎日翻訳を対象として実験をすること
にしました
という訳で日本語文の前研修を行ないます
えー学習データーの獲得なんですが今日本語文と
日本語ちゃう訳文がいるんですがまそれは日英対訳コーパスを利用して
日本語文と
ま対訳例文をＭＤ翻訳した日本語直訳
とーす今
後分かりにくいので図で説明しますと
ま日英対訳コーパスがあってまそん中には
えーとたくさんの対訳ペアがある
いうことです
でそっからえーっとウェブの方
毎日機械翻訳に掛けてやって
まこれ色んな本焼きがあると思うので色々
栗
で一方まこちらそんまー持ってきて
でこちらはまー自然な日本語
こちらは直訳調の日本語文と仮定しまして
まこれこのペアを自然な文と直訳調の文の提案
てやるということをします
んでえーっとまーこのこん中で全部は使える訳ではないので概要ですと選択するんですが
活動しますどうするかと言いますと
えーと毎回ま最終的にはあの英語にしてい言い方を選びたい部分で毎日えー機械翻訳機にもう一度掛けます
そうしましてえーまこちらも全部掛けて
んで
これとこれを比較して前編成しない場合のえー母音より
まこっちの方が潰れていった場合には
二十四
歳
んでまーそのえーっとん何が優れているかというのは
もっともっとこれは
この
対訳コーパスのえー文から付けましたので
これを持ってきて
でこいつとの距離を
ま何らかの尺度でえー
計ってやって
こう一により近いやつを残してやるいうことをし
でま残った五文がありますからこれを生み出した
えっと元の
直訳調の日本語文のみを残してやると
いうことをします
でそうすると
過去の日本語文を前編集でこちらえー書いてやって翻訳するとまこれよりは良くなるということが創作
ということになっ
つまりこれをこう書き替えてこういう翻訳してあると
直接翻訳するより良くなっいうことですので
このペアを
学習データーとして
もう何か
学習データーの使用に追加するということででこれを
まーコーパス中の日本語程度の対
えーっと色んな対訳
文提案に対してやり
今こうやってやるとま色んな部屋が集まるんですが
でえーもう一度二おさらいしますと
九枚平成変化モデルは
この対訳提案しようから学習します
でこちらな言語モデルの方は
こちらの
直訳調の文から学習し
でえーっと実験なんですがまず学習データーの自動獲得をしました
で実験データーの板のえー二つ対訳コーパス三万一千五百八十文釣りを使います
でここはえーっとー色んな
二日後約一は使えるんですが今回は一個にしました
結婚など
最後にえっともっと前文との
距離四
掛かるんですがその類似尺度は二つと通します
で結局
また約八音を決定文の方は
二日翻訳四．一え翻訳して
でこの
日本語音の方はえー文に翻訳して
でこれ共に一スコアを計算して
文字こっちが違っていれば
これとこれのペアを学習データーに使うということをします
でえーっとこのペアってのが三万一千五百八十文についやって
実験これとこれの部屋が使えたというのが
五万九千五百九十六
いうことで
ま九十四パーセントが
ま高齢をこう書き替えてやると
いーえ文になるということが分かります
つまり前平成
でまーま殆どの
ま日英対訳コーパスのデーターが
毎日絵に使えるということがまーこのデーターに対してはえー
行ないます
で実際にえーと学習
データーが集まりましたのでま前編集システムでのあちょっと少ないんですけども統計モデルを学習し
でデコーダーはもうぜー
数を使いましてまえー因子モデルは銀座で学習しました
でえーとフレーズトランスでしたモデルを使います
んで直訳調言語モデルはえーあれＳＤへ電話する
後で学習した
えーと五グラムを使いますとま大体専門家ででは魚とかあなたが救われることが多いみたいです
で変化概要は今回はえーっと単語と文節をえー使用します
で今回日本語日本語の変数変換ですので
ま付属語のみの変換というのはまー
何かこうもう動詞に対する各格はまー
へん化してしまう可能性があってまそういう変化は考えにくいですので
ま文節単位であるということも考えます
まー実際にはフレーズトランス依存モデル使ってますのでえーま単語単位に変化してると言っても
ま一部はフレーズなってるというような感じです
でえーっと実際に結果なんですがこちらが文節単位にやった結果でこちらが単語たえーやったきっかけ
んでまず
えーとクローズデーターの評価なんですが
あまり新鮮な水の場合ですと
まんま決して悪い
タスククローズデーター全部に対しやった結果
えーっとまー明らかに
文節単位でも単語単位でも
まよくなってるということが分かり
でま枠組みとしてはま正しく機能するということが分かりました
二階でした文の割合はこちらのまある六十七パーセントぐらい
いうことで
ま文節の方がクローズドデーターに対してはいいという感じで
で一方まーオープン正当なんですがま平均で見ると結局改善は見られますです
んでまーよく見てみると返した文の割合ってのは大体同じぐらい
あるというような結果になります
でまー平均の精度で見ると
んまーオープンあの分節単位でやった方がいいんですが
破壊です多分という単位で見ると
って言い単語単位にやった方がいいと良い結果でま今回は文節と単語どっちがいいかということは
ちょっとあのー判断は
付いてます
ただ
まーあのー
クローズドデーターの
開店のし方とかを見ると
まー文節単位ってのはかなり
えーっとー学習データーに依存してるのではないかと
いうような
缶詰め
んでま全体的に学習ぶ
データー不足してまして
ま特に文節単位は
なかなか学習してるんじゃないかなということがま考え一
でまー実際にえーっと単語と音節の他あのー
統計量なんですがまな
単語の場合は
ん延べ単語数はま大体一名が単語で異なり語数は
ちょっと二十二型ぐらいなんですけど
文節の場合は
斜め文節数は
苦なくっていうことなり分節が多い明らかに送っている
殆ど出てこない一回ぐらいしか出てこない文節ばかり
ですので
まーマリちゃんついでに弾けないなというのはまーそれでも意外とオープンデーターには多いというな状態
でそれからえっとー
機械翻訳のデコーダーというのはまーパラメーター値人数ができまして
まそれも木の付いてましたんで使いました
で実際に何やったかって言うとま直訳調の日本語文を参照役として
毎日ような日本語文のブルースコアを最大化
ま書いてますけども
結局まい編集した後の日本語文があっ直訳調の日本語文
に近くなるように中デコーディングのパラメーターを
二十合成します
いうことで
で開発えっと二百文に対して
まやったところ
ま少し良くなります
んでえーオープンデーターに対してもま同じような結果で
ほんの少し良くなったんですが結局やっぱり
前編成しなかった場合に比べて
の改善は
六月と言うか
得られますんです
で町に都があるんですが実際にはまー
えーっとまえー
日本語母音お前編集して直訳調にするように知覚してませんので
最終目的や日英翻訳ですので
毎日翻訳が良くなるようにまーこれも睡眠ですてればいいかなと
いうようなことは考ええー
でえーっと実際にどんなあのー学校が見られたかという例なんですがえーっと
例えば道は偏りスタートを苦心し
大半の人率がこの一の高い子付近でしてたというような
ま携帯のやつなんですけどまい編集してやると
まどうはより高く開きました
登り続けていて殆どの契約は一日後また彼の近くで結ばれました
ま大体三家に切るんですが
で後例文にしてみますと
まー明らかにこっちの方が
点もありいー英語になってるんですがまこれで意味が通じるかどうか差別問題なんですが
こっちやよりはかなりいー
良い文になってる
思われる
特にを終わりの方が
結構
分かり易くなってるような気がします
えーっともう一つは何かこんな一つで
四人の国えー
んどうこうしたこのでる娘さんの生命によると
何とか二という数がやっぱりこれも
何かこんな風に変換できまして
何かこの辺に
によると側ではあーになってまして
上位に下がまサインしましたぐらいになってるんですけど
もうこれぐらいにもう
だいぶ違いまして
まこちら講演雑誌理由は場面となん
こうパブリックここれ子音とか
ちょっとよく分からないで出しなんですが
こちらのまで出すから結構分かり易くなっていて
ま特に終わりの方の文数を
間違えではなくてま多分
日本でもある状態になって
んで一方うまくよいかなかった例なんですけど
ま何かこんな文章ですが
となっなぜかこうプロジェクトは終了二千年全反応を計画してますというような
ちょっと変な
日本語になってしまいまして
まこんな風に
現代日本語は勿論現代英語に
なってしまうというような感じです
まこれは何か
多分学習データーに一体引きずられたんだと思い
え以上で数がえーとまとめますと日え翻訳における統計的前編集をします
で学習データーを自動獲得して
毎日対訳コーパスからほぼ同サイズの学習データーを自動獲得可能であるということが
分かります
て翻訳対話
んま文節単語についてはっつってこう
分からなかったんですが
まーあのー
レベルコメントセットでえーっとこれに
クローズドな実験見る限りはあーデーターが多ければ行なうのかなというようなえーそうで
二年四十パーセント程度の分類
えーっと
英語の品質が向上したんですが
ま平均的には一項では見られませんでした
でまードキュメント検索の為の翻訳としては
まーい編集があった場合とない場合の翻訳文から
ま利用法から
えー索引語など作ってやればいいということも考えられますのでま半分ぐらい
よくなってるということでえーま要素によっては利用可能な精度ではないかと
いう風なことは
見えますがままやってみねとかいうこと
て今後の課題は
んーまとっ毎日の学習データーをま複数のＭＤシステムなど使ってですね
増やしてやるま実際もっと
日英コーパス持ってくれは
人ですがまそこで
そいから
えーっとまえー編集でデコーダーを
ま最終的内容が良くなるようにパラメーターついに
でやればいいかなっていうことを考えています
発表は以上です
#############################


#############################
# query = 統計的機械翻訳っていうそのそうですねあの対訳文と言うかあのー日本語とで五の二つの対訳でん高い値をたくさん用意しておきはまー計算機でまー外に翻訳できるって枠組みがあるんですがえーまーそれのその理論と言うか原理とかそういうのを説明しているえーまー心と言うかスライドを後えーお願いします
# rank = 2
# slide = 07-22_fix.match_word.jout.txt
# value = -4.63350934437911
#############################
はいに神戸大学の男女です表記のタイトルで発表します
えー初めにですがえー研究背景ですがまー皆さん学校に来られて皆さんもずっとこう刺されてると思うんですがまマルチメディアのコンテンツま音声だけという眠いですが
まそういうものの方は開封して
まそれを検索しようと
いうようなえー
いう気がま非常に高まってい
でそこでですね話し言葉の
音声認識というものは
ま必要かつ重要な二つであるということで我々の研究をしては決して
で実際にはですね話し言葉
ま公園とか痒いとかですね
まそういうものの音声の認識の認識精度っていうのは大体
ま六割ぐらいから
の八十八パーセントまＣＳＪとかではこれぐらいになっている訳ですがまこのような認識精度になっている時
えー
そいでですねまーどういう音を使う
んかということを考えてみますと
毎日新聞とかですね我々なったんですが重要文にあのインデキシングとか
ま情報検索まこういうことやる場合にはですね
ま必ずしも全てを書き起こす必要がまーありません
でキーワード
本
とかですねま重要な単語っていうのがあ認識実際すれば
ま現状の認識精度でまある程度こういう問題利用可能というような状態になってると思い
一方ですねま放送ニュースの字幕付与と月二回力の作成まこういったものを考えますと
ま特に放送ニュースの字幕付与は
ま昨日の話にもありますように日本ではまー
でまかなりの精度が求められるという話もありますし
ま会話文の作成
となるとですね
今言ったんですね
まー
後程後で人が生成する訳ですから
ま必ずいたん全てをテキスト化しておいて
んーまそういう必要が要求ある訳です
でま音声認識の構成とかっていうのが必要になってくる
いいような
えー父が
に
でですね放送ニュースとかですね体力ま今国際化の時代でして
でえーまそういうところ考えますとま丸二チャンネルの音声が利用可能なケースがま多いと
いうことで
って帰りに見ますとま二つの場合ですとまた国語で放送する
ま放送があったりですね
後はま国際会議とかですと同時通訳物なんかがありましてそこへ同時通訳の音声が
まー流れてくるというような状況があって一
ま結構あるというような状態です
でして
まそういう場合はですね
まーあのーチャンネルが複数ありまして
その複数のチャンネルに
ま異なる言語で同じ内容が入ってくる
そういう状況が
ま仮定できる訳ですね
で従来このような真ん丸チャンネルの入力を仮定したような研究っていうのはま今日の発表にもございましたけども
ま基本的には同一の設計の仮定してましてま何をやるのが目的かと言うとま雑音除去とか
ま方位推定とかするのがまー目的
全体をする訳なんですがま本研究ではそうではなくて
えー全てのチャンネルに入ってくるのは複数の異なる言語
ですが同じ内容の発話
いうような状況家庭
でこの認識をやったいよということで
考えて
明確チャンネルの音声の認識をま情報にないながら同時に
実行するということをえー一体
ことを考えます
説明えーっとーえ具体的には機械翻訳ま本当翻訳モデルなんですがま父的なモデルを使ってえ音声認識をやってやろうということになる
でま色に一一二年のまー二千五年のところでもん何では発表があった訳なんですが
まこれはえー
旅行が音声であったりする場合にはなくてかっ解答がテキストデーターというな状態
を仮定するようなものも
組まれてますま旅行が音声の場合もありますが
また両方をえーヨーロッパ系の人語でして五十も視覚的に行けますしまー近い
ですがま日本語英語っていうようなこういう機械翻訳がまー困難であるようなタスク
後ですねえ対象として研究ってのがまだやられてないということでえーまやってみました
いう風な
でえーちょっと皆さんあのー例えば一日
変なんですがずっと付き合ってる
初めに統計的に
音声認識を話しいー申しますと
ま音声認識ってのはえ音声が与えられた時にそれを最もよく説明する
単語列を求めるま式にはとこういう
プロセスな法ですが
まー展開していって結局はこのこういうような
で一方最大化するような
単語列を求めるということになる訳なんですがでここで
何品のダブルスを担った得るものが言語モデル
んでＰのＸは多分声ですねこれ与えるものが
音響モデルと呼ばれます
その辺が当たり前なんで
軽く延ばしまして
でえ統計に機械翻訳の方の話なんですが
これも同じような考えていきまして
まある人の原言語なんですがその単語列
が与えられた時に
それを最もよく説明する
別の言語の
目的言語なんですがその単語列を
あっ
それを最もよく説明する別の言語の単語列を求めるプロセスと
てえー定式化され
で次に掛けますとこうなりましてでこのモデルを翻訳モデルと
えー四人
であっこのモデルこの確率は楕円モデルを翻訳モデルと呼んでましてこれを翻訳スコアとか
またえーえ
単語の太陽とですね文の太陽とかあってで今
んでえーこれを使った音声認識についてずっと定式化をしてる人
でここではまー複数言語と言いましたが二か国語をえー考えてみます
で日英の同時認識してえーま日本語の場合の認識
の式を書いています
でこの場合はですね日本語の音声Ｘと
ま英語の音声Ｙが与えられた時に
それを最もよく説明する日本語の文字列を求める問題として定式化できまして
んでま色々
変形していくんですが
まこの辺は
ちょっと
走りまして
えーっとー
まここで英語の可能な単語列というのを
ちょっと
どうにえーしまして
三ちょっと整理してみますと
まこんな感じの式になり
んこれよく見ますとここが
日本語の音声認識のスコアなってまして
ここ外部の音響モデルのスコアですね
でこれが翻訳スコアなんですがちょっと見通し悪いのでもう少し変
金
もう少し変形します
全ての
はいなんですが対数取っていまして
ま重み入れてみますとまこんな好きで
なります
でここ
ベイズの
って言って展開してみますと
まこんな感じになりまして
でここにみんなでえっとここにみんなでありますので
まこの重みを
え一二三四αと言って
Ｂを元はと言って整理しますと
ま緊急こんな感じの式になる訳
でこれ見ますと
この部分が日本語音声認識のスコアなってまして
ま対数取ってるんですが
でこの部分が英語の音声認識のスコアになってまして
でこの部分が翻訳モデルのスコアになってると
そういう状態になり
違って音声認識日本語の音声認識を行なう時に日本語の音声認識のスコアと
ま英語の
中間
構造みたいなものと
翻訳モデルのスコアがあれば
音声認識が行なえる
いうことになり
でえーただ頭でかって書いてみますと
ま日本語の前求める場合は
日本語の音声認識の
システムどういうあの音声認識のシステム用意しまして
電話中間表現ですねＮベストリストだっ
あまり
ま単語グラフなんかを出して日系
それからもう一つ翻訳モデルっていうのを用意しまして
でここで
まリスコアリングをしてあるこの式に基づいてリスコアリングしてやるというようなことに
形
でこれが一応定式化した
ものですでこの枠組みが正しいかどうかっていうのちょっと予備実験をして
評価をしてみました
具体的には
えーえモノホンの音声認識を行なわずにつまり英語の方はまテキスト与えて
音声認識が百パーセントできた状態を仮定して
ま日本語の音声認識を行なうということをしてしました
んで
まずえー見ますとこれ先程と同じ図なんですが
ここのところが
英語のテスト三になりまして
んでえー式はこの式になり
ってのが好き
もう一回見てみますと
ま日本語の音声
後
上のテキストが与えられた時にそれが最もよく説明する
日本語文字列体を
求めるプロセスで
典型性と行ない
でこれを
えー後の音声与えた場合なスピードを比較してみますと
まここ見ますとここで
このいいなＭっていうのが英語の
あの可能な文字列全てなんですが
まこれが一通りの場合とですね
評価になるということが分かり
という訳でまー枠組みとした同一ですので
こちらを使って
えー
評価を
まーあのこの枠組みが正しいかどうかっていうのを
えー検証してみた
そういうことになり
即ち日本語の音声認識のスコアと
翻訳モデルのスコアでリスコアリングした
そういうことになります
で次にあのこの馴染みがあんまりいないと思われるこの
翻訳モデルの方について説明します
で翻訳モデルですがこれは異なる言語の文字列
ここでは二五三と書いてますがその対応そこは
ま翻訳スコアと呼んでもいいですがそれを
与えるもんで
んで
でここで問題になるのは
多分
に例がありますように
ま語順がそもそも異なることがあると
殆ど異なるでしょうそれから
言語間でのたい単語の対応はですね必ずしも一大事ではないという問題があると
いうことになる
それから
正しい対応付けまこれ今人間が書いてる訳で
正しい対応付けなってる訳なんですが
まそれがコンピューター的には何が
正しいか自明ではないと
いうことで
その確率モデルとして全て
の可能性を考えてですねそれを
全部足してやるというようなことをして
でこの一つの対応関係をアラインメントという見まして
それをまＡとして表わしますとこのような
確率を全ての可能な
アラインメントで
えー
三年住ん取ってやれば
いいということになり
でえー具体的にはＩＰＡのモデルスリーというものを利用しまして
採用しましてこの確率を計算し
×について少し説明し
大人のせりふのＳＤでは
えー
内容スコアを
四つのモデルでモデル化します
で
二つ目は
ここにありますここここの対応スコアを与える
パパに良いモデルなんですが
これはある
原言語の
単語がですね目的言語の
前の単語に対応する確率を
またえーとモデル
その場合は丸二
二単語に
えー繁殖してますこの
この値を
与えるような
隔離
すーモデルです
そいからも二つ目のモデルは
ここなんですが
低年齢自然閉鎖音モデルにまして
これはですね目的言語の
単語例えばは国家を使いたい要する英語ってのが英語の単語はありませんので
その場合はぬるというものに対応してると見なします
即ち音の前にえーそのするモデルが必要でして
まその
モデルって
で三つ目は
まこれは直感的に分かり易いんですが二十四個モデルで
ある
言語の単語がもう一つの言語の単語に翻訳され
そういう確率を与えるモデル
で最後に
語順の入れ替えを
いいですようなモデルでして
プラス一つのモデルで生まれまして
それは元の
言語の丸一の単語が
目的言語のある一つの単語とま採用するという確率は却って
でＩＰＡのモデルツリーでは
その
一応絶対値で与えてるとそういうような状態になっ
でえー評価実験を行ないました
で先程もまーおんなじ説明あるんですが
まこの式に基づいてえー
つまり
対訳英語テキスト与えて日本語音声認識を行ないました
んで音声認識でＮベストリストを生成して
の方訳モデル
のスコアを
用いてリスコアリングするということを
やりました
で評価実験のデーターなんですが
評価データーは
で今回は日英対訳ニュース記事
を持ってきましてそれの日本語の
部分を読み上げました
日本語を読み上げたのは日本語母語話者三名
が五十分ずつ百五十六二三挙げました
で基本的に言うと読み上げてますので
ま御読み上げ音声認識システムを使いました
暮らしＳＲ子音の最終マンに入ってるものをそのまま
買いましていいやつは三．辺に
で音響モデルは
えー何て言いある多数話者モデル
んで
それから言語モデルは新聞記事から学習した
単語トライグラム
モデルこれを使います
で翻訳モデルの方は
先程説明したはい三のモデルツリーを
にはプラスプラスというもので学習しました
で学習データーはどういった記事一対訳コーパス
でしてえーこれは五万六千人
日本語が
約
六十七万単語で英語が百三十二万単語ぐらいです
んでこれで
先程の
ＩＢＭモデルスリーの四つのモデルを
学習しました
で実験なんですが
えーっと音響モデルの方についてえーまモノホンとトライホン使ってみたんですが
ま結果三名ずつなんで
えー
六割
で縦軸がえーと認識率でしてえ赤色が
普通に音声認識を行なった場合です
で青いのが翻訳モデル使った場合
で見てみますと
翻訳モデルを用いた場合に
まあのー認識率が
でこの辺の食結構女性ということが分かり
で特にまーこの辺ですね元々認識率が低いようなところで
精度の向上が
ま見られるというようなことがありました
え実際の話し言葉の音声認識っていうのはもっと元々認識率低いところに
あるんじゃないかと思われますので
漫画がこういうことをやってやると良くなる可能性があるんじゃないかという関数多いと
でえその次に
今この
言語島民の頑張って掛かってるんですがこれを
ま事後的に良くなるように決定していったんですがこれを打ってみたらどうなるか
いうのを
えー
でこれモノホンの結果なんですが
ま〇．五から〇．〇から一まで
〇．〇五刻みでやってまして
ま三ミリありまして
疑いようがベースラインで
の色が
えー提案手法です
んでま見てみますと元々認識率が低いようなこの二つ
の結果はだいぶうー何やっても良くなるんですが
元の二太陽熱はちょっと
えー
重みが高くなっ
まー
と翻訳モデルのみを強くすると
逆効果になってるというような効果があっ結果が見られました
これ何か大会という訳では多分ないと思うんですが物と実験が必要と思い
それから
トライホンの方なんですがこれはちょっと思ったえー作って
何かあんまりどこがいいのかってのよく分からない
で調査した範囲にもま対立というのがよく分からない
いうような
先程するような対立ってのはないん何なかったんで
もうちょっと頑張って調べなっていて
んで
ま以上調べてみたんですがまー元々
認識率がトライホン使った場合高いので第一候補が
一番いいんじゃないかといういうのもあったのです調べてみたんですが
まＮベストリストで二十
ベストぐらい出してですね
えーっとーそん中から一番いいものを選ぶということやりますと
こっから五パーセントぐらい全部上がるということが
分かりましたので
ま何かうまいことを選択が
できればまだまだこれは改善するよう違う
なるなというところは分かって
ただちょっと
本なぜこうなってるのかってのは今検討して
えっとまとめますとま国際会議とかニュース
二日で丸二チャンネルですね異なる言語で同じ内容の発話があるような
場合の音声認識をについて検討しました
でえ予備実験としまして
日本語音声認識時にま英語の方は認識しなくてテキストとま機械翻訳を用いて
実験してみて
そういう枠組みがきちんとうまくうーことを確認しました
で今後の課題は
ま実際の話し言葉での実験および評価することと
ま日本語と英語両方ですね
今ここ敬語の方が誤りがなかったので
よくなってる可能性も
まずではありますので
で音声認識してみる
でそれから
ま今は
自分の
太陽っていうのは先に付いてるような状態ですし
まー同時通訳
とかとは少し性質が違いますので一体よこしたものですので
ま同時通訳とかを音声認識してみるというなことも
ま必要だろうなということは
って考えて
でそれが最適なと思うんですね先程の
ま振ってみたんですが
まあんまり分からない熱でこれこれをちょっとどうやってき見るか
いうところを
検討していただい
思って
発表は以上
#############################


